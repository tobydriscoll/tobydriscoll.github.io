[{"authors":["driscoll"],"categories":null,"content":"Toby Driscoll is a professor in the Department of Mathematical Sciences at the University of Delaware. His research interests are in scientific computation, mathematical software, and applications of mathematics in the life sciences. He is the head of the Center for Applications of Mathematics in Medicine at UD.\nDownload my CV\n","date":1560124800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1560124800,"objectID":"bcd8b92ffec473009473572f345ee8f9","permalink":"https://tobydriscoll.net/authors/driscoll/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/driscoll/","section":"authors","summary":"Toby Driscoll is a professor in the Department of Mathematical Sciences at the University of Delaware. His research interests are in scientific computation, mathematical software, and applications of mathematics in the life sciences. He is the head of the Center for Applications of Mathematics in Medicine at UD.\nDownload my CV","tags":null,"title":"Toby Driscoll","type":"authors"},{"authors":["admin"],"categories":null,"content":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet. Duis dapibus diam vel metus tempus vulputate.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://tobydriscoll.net/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"Nelson Bighetti is a professor of artificial intelligence at the Stanford AI Lab. His research interests include distributed robotics, mobile computing and programmable matter. He leads the Robotic Neurobiology group, which develops self-reconfiguring robots, systems of self-organizing robots, and mobile sensor networks.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Sed neque elit, tristique placerat feugiat ac, facilisis vitae arcu. Proin eget egestas augue. Praesent ut sem nec arcu pellentesque aliquet.","tags":null,"title":"Nelson Bighetti","type":"authors"},{"authors":["Toby Driscoll"],"categories":null,"content":"  Buy at the SIAM bookstore. Members of SIAM, including student members, get a 30% discount.\n    This textbook is designed to introduce undergraduates in math, computer science, engineering, and related fields to the principles and practice of numerical computation. Our approach emphasizes linear algebra and approximation. The text presents mathematical underpinnings and analysis, complemented with 45 functions and over 160 examples coded in MATLAB, all available for download. Previous experience in MATLAB is not required. The functions and examples have also been implemented in Julia and Python.\nThe text is organized to be useful for either a one-semester introduction or two-semester sequence, with the most advanced techniques and concepts held back for the second half of the book.\nPlease note the known errata.\nResources The book\u0026rsquo;s functions and example scripts can be downloaded as a MATLAB toolbox and installed by double-clicking the file. Alternatively, you can visit the Github page that has the needed files, as well as suggested in-class labs and projects, slides for instructors, and links to some (slightly outdated) videos linked to the text.\nThere are also Julia versions and Python versions of the function and example files.\nContents  Numbers, problems, and algorithms  Floating point numbers Problems and conditioning Stability of algorithms  Square linear systems  Polynomial interpolation Computing with matrices Linear systems LU factorization Efficiency of matrix computations Row pivoting Vector and matrix norms Conditioning of linear systems Exploiting matrix structure  Overdetermined linear systems  Fitting functions to data The normal equations The QR factorization Computing QR factorizations  Roots of nonlinear equations  The rootfinding problem Fixed point iteration Newton\u0026rsquo;s method in one variable Interpolation-based methods Newton for nonlinear systems Quasi-Newton methods Nonlinear least squares  Piecewise interpolation and calculus  The interpolation problem Piecewise linear interpolation Cubic splines Finite differences Convergence of finite differences Numerical integration Adaptive integration  Initial-value problems for ODEs  Basics of IVPs Euler\u0026rsquo;s method Systems of differential equations Runge-Kutta methods Adaptive Runge-Kutta Multistep methods Implementation of multistep methods Zero-stability of multistep methods  Matrix analysis  From matrix to insight Eigenvalue decomposition Singular value decomposition Symmetry and definiteness Dimension reduction  Krylov methods in linear algebra  Sparsity and structure Power iteration Inverse iteration Krylov subspaces GMRES MINRES and conjugate gradients Matrix-free iterations Preconditioning  Global function approximation  Polynomial interpolation The barycentric formula Stability of polynomial interpolation Orthogonal polynomials Trigonometric interpolation Spectrally accurate integration Improper integrals  Boundary-value problems  Shooting Differentiation matrices Collocation for linear problems Nonlinearity and boundary conditions The Galerkin method  Diffusion equations  Black-Scholes equation The method of lines Absolute stability Stiffness Method of lines for parabolic PDEs  Advection equations  Traffic flow Upwinding and stability Absolute stability for advection The wave equation  Two-dimensional problems  Tensor-product discretizations Two-dimensional diffusion and advection Laplace and Poisson equations Nonlinear elliptic PDEs   Gallery               ","date":1559779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559779200,"objectID":"0455b53ad1327a6a3818103e97a2793f","permalink":"https://tobydriscoll.net/project/fnc/","publishdate":"2019-06-06T00:00:00Z","relpermalink":"/project/fnc/","section":"project","summary":"Undergraduate textbook in computational mathematics.","tags":["book","matlab","scientific computing","teaching"],"title":"Fundamentals of Numerical Computation","type":"project"},{"authors":["Toby Driscoll"],"categories":null,"content":"  Buy from the SIAM bookstore. Members of SIAM, including student members, get a 30% discount. Download PDF for free.    Written by Nick Trefethen, Asgeir Birkisson, and myself, Exploring ODEs takes a look at ordinary differential equations unlike any other text. Rather than focusing on the mechanics of finding solutions in a limited number of special problems, we use Chebfun to illustrate the wide range of behavior of those solutions for a variety of linear, nonlinear, and multidimensional problems, including initial-value, boundary-value, and eigenvalue problems. Each short chapter includes a detailed application and a favorite reference. The text is accessible as an accompaniment or follow-up to a standard first undergraduate text on ODEs. All of the MATLAB codes generating the examples and figures are available for download, as is the full text in PDF, from the book\u0026rsquo;s website.\nContents  Introduction First-order scalar linear ODEs First-order scalar nonlinear ODEs Second-order equations and damped oscillations Boundary-value problems Eigenvalues of linear BVPs Variable coefficients and adjoints Resonance Second-order equations in the phase plane Systems of equations The fundamental existence theorem Random functions and random ODEs Chaos Linear systems and linearization Stable and unstable fixed points Multiple solutions of nonlinear BVPs Bifurcation Continuation and path-following Periodic ODEs Boundary and interior layers Into the complex plane Time-dependent PDEs Appendix A: Chebfun and its ODE algorithms Appendix B: 100 more examples  ","date":1559779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559779200,"objectID":"e3360cc5c894999f21677288ce9840e4","permalink":"https://tobydriscoll.net/project/explode/","publishdate":"2019-06-06T00:00:00Z","relpermalink":"/project/explode/","section":"project","summary":"A different kind of introduction to ODEs.","tags":["book","matlab","teaching"],"title":"Exploring ODEs","type":"project"},{"authors":["Toby Driscoll"],"categories":null,"content":" Buy at the SIAM bookstore. Members of SIAM, including student members, get a 30% discount.\n Buy at Amazon in the U.S.    Learning MATLAB is a concise, essentials-only introduction to MATLAB for those who have programming experience in other procedural languages. At about 100 pages, it\u0026rsquo;s meant as a supplemental guide in a numerical analysis or scientific computing course or as a standalone tutorial for those who need to get started quickly in MATLAB. Learning MATLAB does not cover every feature or calling syntax, but focuses on those parts of MATLAB that have proven themselves indispensible to me in my 20 years as a MATLAB programmer. (Fun fact: I was a runaway winner of \u0026ldquo;MATLAB Jeopardy\u0026rdquo; at the 1995 MATLAB Conference.) The book grew out of a summer workshop that I taught to grad students for 8 years at Delaware.\nThe chapters in Learning MATLAB are: Introduction, Arrays and matrices, Scripts and functions, More on functions, Graphics, Advanced techniques, and Scientific computing. Each feature is demonstrated by examples, and every chapter includes exercises ranging from routine to very challenging.\n","date":1559779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559779200,"objectID":"6768b49cf9b35ac73e6983cffcce4a18","permalink":"https://tobydriscoll.net/project/learning-matlab/","publishdate":"2019-06-06T00:00:00Z","relpermalink":"/project/learning-matlab/","section":"project","summary":"Streamlined approach to MATLAB for veteran programmers.","tags":["book","matlab","programming","teaching"],"title":"Learning MATLAB","type":"project"},{"authors":["Toby Driscoll"],"categories":null,"content":" See the table of contents of this book Buy the book directly from CUP Buy the book at Amazon (U.S.)    Schwarz-Christoffel Mapping is a monograph by myself and Nick Trefethen on the constructive and computational aspects of Schwarz–Christoffel conformal maps. These maps transform the interior or exterior of a region bounded by a polygon to the interior of a disk, half-plane, strip, rectangle, or more exotic canonical region. Unlike many other numerical conformal mapping methods, they are substantially faster to compute than the full solution of an elliptic partial differential equation on the same domain. Because the maps are conformal, they offer a powerful way to solve certain classical problems for the Laplacian operator.\nThe book includes 76 quantitatively precise figures illustrating theoretical and applied aspects of Schwarz–Christoffel maps. The appendix includes code snippets that produce some of these figures using my free Schwarz-Christoffel Toolbox for MATLAB.\n","date":1559692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559692800,"objectID":"33bea5a4bc85be368f7bb43bc03c715a","permalink":"https://tobydriscoll.net/project/schwarz-christoffel-mapping/","publishdate":"2019-06-05T00:00:00Z","relpermalink":"/project/schwarz-christoffel-mapping/","section":"project","summary":"Monograph on a major conformal mapping method.","tags":["book"],"title":"Schwarz–Christoffel Mapping","type":"project"},{"authors":["Toby Driscoll"],"categories":null,"content":"   Chebfun is a free MATLAB package and open source software project. Its aim is to provide numerical computation with functions. My interest in and contribution to the system is most visibly in the solution of ordinary and (1+1 dimensional) partial differential equations. Using familiar MATLAB syntax such as \\ and eigs, solutions to boundary-value or eigenvalue problems can be obtained with full numerical precision automatically.\nGallery          ","date":1559779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559779200,"objectID":"fca3168b0ceab3a0cf7b9ab41dc768c2","permalink":"https://tobydriscoll.net/project/chebfun/","publishdate":"2019-06-06T00:00:00Z","relpermalink":"/project/chebfun/","section":"project","summary":"Computing with functions instead of numbers.","tags":["software","matlab","scientific computing"],"title":"Chebfun","type":"project"},{"authors":["Toby Driscoll"],"categories":null,"content":"The SC Toolbox is a problem-solving environment for computation and interaction with conformal maps to regions bounded by polygons, including unbounded regions, logical quadrilaterals, and channels. It includes a module for the solution of the Laplace equation on such regions with piecewise constant boundary conditions, to ten digits or more in seconds. Nearly all of the Toolbox functions are accessible through a graphical interface.\nThe software is distributed primarily on Github. You can directly download a zip archive of the latest release.\nThere is an old user guide that remains fairly relevant. There are also many usage examples in my book, which has a lot of mathematical and computational information about S–C maps.\nIf you need a copy for an older version of MATLAB (major versions 4,5,6), please contact me.\n          ","date":1559692800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559692800,"objectID":"85d10f086846d8fa2279e9e5fe812590","permalink":"https://tobydriscoll.net/project/sc-toolbox/","publishdate":"2019-06-05T00:00:00Z","relpermalink":"/project/sc-toolbox/","section":"project","summary":"Conformal mapping to regions bounded by polygons.","tags":["software","matlab"],"title":"Schwarz–Christoffel Toolbox for MATLAB","type":"project"},{"authors":["Toby Driscoll"],"categories":null,"content":"In over 25 years of MATLAB programming, I\u0026rsquo;ve contributed a few utilities and MATLAB gadgets that I\u0026rsquo;ve found helpful. For example:\n unplot Delete the most recently plotted object(s). Used it so, so many times. latex Convert a matrix into a LaTeX matrix or table. Maybe the table data type in MATLAB has obsoleted this, but it\u0026rsquo;s still handy for writing papers from time to time. gslope Click twice on a plot and get the slope between the points. Useful for determining convergence rates. sparse Toeplitz matrix construction Some practical sparse matrices are Toeplitz. This takes the pain out of constructing them. piecewise-defined function builder Creates a single callable function from a collection of piecewise definitions.  ","date":1559779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559779200,"objectID":"79f725f9d60a3fe08fd42d82d7e4c1ca","permalink":"https://tobydriscoll.net/project/matlabcentral/","publishdate":"2019-06-06T00:00:00Z","relpermalink":"/project/matlabcentral/","section":"project","summary":"Contributions to the MATLAB ecosystem.","tags":["software","matlab","programming"],"title":"MATLAB software","type":"project"},{"authors":["Toby Driscoll"],"categories":null,"content":" In 1991, mathematicians Gordon, Webb, and Wolpert (Invent. Math. 110, pp 1\u0026ndash;22) solved a famous problem posed by M. Kac: \u0026ldquo;Can one hear the shape of a drum?\u0026rdquo; That is, do the Dirichlet eigenvalues of a membrane determine the shape of the membrane? Their answer was \u0026ldquo;No!\u0026rdquo;, and they used a powerful mathematical technique to produce a counterexample, which in its simplest form is a pair of eight-sided nonconvex polygons. Gordon, Webb, and Wolpert also noted that a more elementary technique known as transplantation can be used to show that the spectrum of the Laplacian with Dirichlet conditions is the same for both regions. However, actually finding what the eigenvalues are is far more difficult; it\u0026rsquo;s essentially impossible to do analytically.\nWu, Sprung, and Martorell (Physical Review E , Jan 1995) were among the first to present the results of computations of modes for these shapes, but the accuracy of their results was not clear. Physicists Sridhar and Kudrolli at Northeastern University built microwave cavities in the shapes of the two polygons and determined 54 eigenvalues experimentally (Physical Review Letters, April 4, 1994,Science News, September 17, 1994). Their results were accurate only to about 0.1%.\nA little-known method due to Descloux and Tolley performed more accurately than all of these. The underlying principle is to exploit the well-known expansions of an eigenfunction near the corners. The criterion that selects eigenvalues is the matching of values and normal derivatives of the local expansions at interfaces within the polygons. Using this method in MATLAB, and incorporating a crucial improvement, in 1997 I published eigenvalues and modes 1–25 for both regions that were accurate to twelve digits.\nOne of the most basic uses of eigenmodes is to represent vibrations governed by the wave equation. Below are a few animations of such vibrations, based on combinations of the first sixteen modes. Each movie runs for three periods of the first mode.\n  Mode $n$ contributes $(1/n)^2$ to the solution.     Mode $n$ contributes $1/n$ to the solution.     Odd mode $n$ contributes $1/n$ to the solution with an alternating sign.     Approximation to the drums being `plucked\u0026rsquo; at their centers.   The story of these and other isospectral shapes continued to develop from there, mathematically and computationally, but I was not much involved with most of it.\nGallery     ","date":1560124800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560124800,"objectID":"6fc1561932b51ad3c5020676f4fafefd","permalink":"https://tobydriscoll.net/project/drums/","publishdate":"2019-06-10T00:00:00Z","relpermalink":"/project/drums/","section":"project","summary":"Eigenmodes of isospectral drums.","tags":["scientific computing"],"title":"Isospectral drums","type":"project"},{"authors":["Kevin W Aiton","Tobin A Driscoll"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"1dc72be906fa7fd07d01f3d3986db44a","permalink":"https://tobydriscoll.net/publication/aiton-preconditioned-nonlinear-iterations-2019/","publishdate":"2019-06-06T14:48:50.025743Z","relpermalink":"/publication/aiton-preconditioned-nonlinear-iterations-2019/","section":"publication","summary":"","tags":null,"title":"Preconditioned Nonlinear Iterations for Overlapping Chebyshev Discretizations with Independent Grids","type":"publication"},{"authors":["Richard J Braun","Lan Zhong","Tobin A Driscoll","Carolyn G Begley","Deborah Antwi","P Ewen King-Smith"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"7ee49906e514ce00943d125a3b86b511","permalink":"https://tobydriscoll.net/publication/braun-models-tear-break-2018/","publishdate":"2019-06-06T14:48:50.023883Z","relpermalink":"/publication/braun-models-tear-break-2018/","section":"publication","summary":"","tags":null,"title":"Models for Tear Break Up Dynamics and Imaging","type":"publication"},{"authors":null,"categories":["academia","computing","teaching"],"content":"For a few years, I\u0026rsquo;ve been a fan of clickers (aka personal response systems) for large lecture sections. Clickers are a simple\u0026ndash;and scalable\u0026ndash;way to incorporate a little widespread active learning in the classroom. They can\u0026rsquo;t work miracles, but they do allow me to reward attendance, rouse the students once in a while, and give good feedback to all of us about how well the latest concepts are sinking in. I like the accountability: If you got the question wrong when 80% of the class got it right, that\u0026rsquo;s on you, but if 20% of the class got it right, that\u0026rsquo;s on me.\nUD is an iclicker shop. When I want to poll the class, I click a \u0026ldquo;go\u0026rdquo; button on a small toolbar that overlays any other application. When I\u0026rsquo;m done, I click \u0026ldquo;stop.\u0026rdquo; I can show the results and designate the correct answer on the spot, or I can go back later and pick the right answer while looking at a screenshot from when the question started.\nIn the past I\u0026rsquo;ve used clickers with handwritten questions projected using a document camera. I don\u0026rsquo;t get the screenshot this way, but it works fine. However, in the best case I\u0026rsquo;m left to manage 50-100 sheets of paper for a course. That\u0026rsquo;s something I\u0026rsquo;m increasingly cranky about doing in my life overall, and I\u0026rsquo;m likely to fail at it during the heat of a lecture, especially when (as I like to do) I start replaying questions from past weeks or months. Plus, if I later decide to tweak a question or the answer choices, I\u0026rsquo;ve got to scrap a page and rewrite it.\nEnter Jekyll. This is a brilliant software t0ol that converts lightly marked data files into a website. It\u0026rsquo;s blog-centric, but it can be used for other kinds of data as well, and I\u0026rsquo;ve customized it for collecting clicker questions. You can get it for yourself from this Github repo. It requires being comfortable with a command line, but it\u0026rsquo;s not otherwise technically challenging.\nFor instance, in one file I have\n--- layout: question chapter: Introduction title: Derivative --- {::comment} The \\dd macro is defined in /_includes/texmacros.md. {:/comment} What is $\\dd{}{x}\\left(e^x\\right)$? 1. *$e^x$*{: #correct} 1. $x$ 1. $1$ 1. $\\ln(x)$ 1. $\\tan(x)$ The page that results can be viewed here. It\u0026rsquo;s pretty easy to see how the output arises from the input. All I do is make one file per question, putting them into subdirectories if I want. They\u0026rsquo;re collected and indexed by the \u0026ldquo;chapter\u0026rdquo; property at the top of the file.\nHaving maintained more than one website of HTML files by hand, I found Jekyll to be a revelation. Headers and footers can be included automatically on all pages set to a certain style. (I use this to define MathJax macros in one file that get copied into all the output question pages.) Content, such as an index or table of contents, can be generated programmatically based on properties of the data. There\u0026rsquo;s a nice step-by-step series for getting started with Jekyll on the ProfHacker blog.\nJekyll versus raw HTML is like using a power drill/driver versus the Craftsman screwdriver with the hard plastic handle that digs divots into your palm when there\u0026rsquo;s a job of any decent size. I\u0026rsquo;ll probably move my personal site this blog over to Jekyll at some point.\n","date":1517604896,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517604896,"objectID":"3f43236dff301f102ddd48b88391be7d","permalink":"https://tobydriscoll.net/blog/jekyll-for-clicker-questions/","publishdate":"2018-02-02T20:54:56Z","relpermalink":"/blog/jekyll-for-clicker-questions/","section":"post","summary":"For a few years, I\u0026rsquo;ve been a fan of clickers (aka personal response systems) for large lecture sections. Clickers are a simple\u0026ndash;and scalable\u0026ndash;way to incorporate a little widespread active learning in the classroom. They can\u0026rsquo;t work miracles, but they do allow me to reward attendance, rouse the students once in a while, and give good feedback to all of us about how well the latest concepts are sinking in. I like the accountability: If you got the question wrong when 80% of the class got it right, that\u0026rsquo;s on you, but if 20% of the class got it right, that\u0026rsquo;s on me.","tags":null,"title":"Jekyll for clicker questions","type":"post"},{"authors":["Kevin W Aiton","Tobin A Driscoll"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"2d71dfaf234778fd47d60afc0a334e7e","permalink":"https://tobydriscoll.net/publication/aiton-adaptive-partition-unity-2018-a/","publishdate":"2019-06-06T14:48:50.023057Z","relpermalink":"/publication/aiton-adaptive-partition-unity-2018-a/","section":"publication","summary":"","tags":null,"title":"An Adaptive Partition of Unity Method for Multivariate Chebyshev Polynomial Approximations","type":"publication"},{"authors":["Kevin W Aiton","Tobin A Driscoll"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"100969f5219258e6cb2ad36312f5b7c1","permalink":"https://tobydriscoll.net/publication/aiton-adaptive-partition-unity-2018/","publishdate":"2019-06-06T14:48:50.019562Z","relpermalink":"/publication/aiton-adaptive-partition-unity-2018/","section":"publication","summary":"","tags":null,"title":"An adaptive partition of unity method for Chebyshev polynomial interpolation","type":"publication"},{"authors":["Tobin A Driscoll","Richard J Braun","Joseph K Brosch"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"0500fee248e606d1e75b8fb083bd6fe6","permalink":"https://tobydriscoll.net/publication/driscoll-simulation-parabolic-flow-2018/","publishdate":"2019-06-06T14:48:50.011787Z","relpermalink":"/publication/driscoll-simulation-parabolic-flow-2018/","section":"publication","summary":"","tags":null,"title":"Simulation of parabolic flow on an eye-shaped domain with moving boundary","type":"publication"},{"authors":null,"categories":["math"],"content":"I\u0026rsquo;m going to wrap up the long-paused MATLAB versus Julia comparison on Trefethen \u0026amp; Bau by chugging through all the lectures on iterative methods in one post.\nI\u0026rsquo;m back to using gists\u0026ndash;not thrilled with any of the mechanisms for sharing this stuff.\n Lecture 32 (sparse matrices and simple iterations) Lecture 33 (Arnoldi iteration) Lecture 34 (Arnoldi eigenvalues)  These are remarkable mainly in that they have such striking similarity in both languages. Aside from square brackets and working around the 1x1/scalar distinction in Julia, little differs besides the syntax of the eigs command.\nOne frustration, though. I decided to try an interesting alternative to PyPlot in Julia, the Plots package. Actually Plots tries to be a generalization of and alternative route to using PyPlot/matplotlib. I decided to try the PlotlyJS backend instead, however. It makes lovely graphics with very responsive interaction. Since the rendering is in Javascript, I thought it would be perfectly portable, but you can\u0026rsquo;t see the output in the gist above, even though it should be embedded in the notebook.\nI liked using Plots OK; for the most part it\u0026rsquo;s just different, not better or worse that I could see. I found it awkward to work with subplots. I ended up creating 4 plots individually and then displaying them in a table using another call to plot. I find MATLAB\u0026rsquo;s setup more convenient. I also could not figure out how to coax a contour plot with a contour at a specified value, which seems like a big lack.\n Lecture 35 (GMRES) Lecture 36 (Lanczos and MINRES) Lecture 37 (Conjugate gradients) Lecture 40 (Preconditioning)  Again the differences are minor. In sparse and iterative methods I found Julia to place a greater emphasis on keyword arguments. For example,\n(xCG,~,~,~,resnorm) = cg(A,b,tol=1e-14,maxIter=100);  There are default values for tol and maxIter, but if you want to override them you must type the keyword. On the other hand, MATLAB\u0026rsquo;s arguments are purely positional:\n[xCG,~,~,~,resnorm] = pcg(A,b,1e-14,100);  If I wanted to specify the maximum number of iterations without changing the default tolerance, then I would need to use an empty matrix in the third position. When one uses a command that does take named parameters as inputs, it\u0026rsquo;s typically done using 'propname',propval pairs. Except when it isn\u0026rsquo;t, such as for ODEs and optimization. Confusing! As a user I don\u0026rsquo;t love typing out the keywords, but Julia at least lets me skip the quote marks. I also know from experience that Julia\u0026rsquo;s version is a lot easier and clearer to implement on the other side.\nSo that\u0026rsquo;s that. I feel that I am at least ready to get off the bunny slopes with Julia. I haven\u0026rsquo;t found a compelling reason to switch to it, aside from supporting open source software for science (no small thing). Of course I\u0026rsquo;ve barely scratched the surface. On the flip side, MATLAB has a lot of well-designed and -maintained packages, and its environment still makes a smoother experience for newcomers. If you can afford it, it\u0026rsquo;s still a great option for interactive numerical computing.\nI wonder about the future of Julia. Had Python not gotten a head start, I could see an outpouring of effort to make high-quality Julia packages and Julia being a complete MATLAB reboot. But numpy and scipy do exist, and despite their flaws, they have a huge first-mover advantage. It\u0026rsquo;s a snap to use Python packages in Julia, so there\u0026rsquo;s not a dichotomy here. But if the package you want to use a lot exists only in Python, the case for Julia weakens. Overall though, it\u0026rsquo;s a nice thing that we have several strong, expressive high-level environments for numerical computing. Happy coding!\n","date":1486152970,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1486152970,"objectID":"e0e9266890cd1f829814f5f8d006f9ae","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-iterative-methods/","publishdate":"2017-02-03T20:16:10Z","relpermalink":"/blog/trefethen-bau-matlab-julia-iterative-methods/","section":"post","summary":"I\u0026rsquo;m going to wrap up the long-paused MATLAB versus Julia comparison on Trefethen \u0026amp; Bau by chugging through all the lectures on iterative methods in one post.\nI\u0026rsquo;m back to using gists\u0026ndash;not thrilled with any of the mechanisms for sharing this stuff.\n Lecture 32 (sparse matrices and simple iterations) Lecture 33 (Arnoldi iteration) Lecture 34 (Arnoldi eigenvalues)  These are remarkable mainly in that they have such striking similarity in both languages.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia: Iterative methods","type":"post"},{"authors":["Joseph K Brosch","Ziwei Wu","Carolyn G Begley","Tobin A Driscoll","Richard J Braun"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"f2c3809d2de9714519d4e395300ee539","permalink":"https://tobydriscoll.net/publication/brosch-blink-characterization-using-2017/","publishdate":"2019-06-06T14:48:50.013564Z","relpermalink":"/publication/brosch-blink-characterization-using-2017/","section":"publication","summary":"","tags":null,"title":"Blink Characterization Using Curve Fitting and Clustering Algorithms","type":"publication"},{"authors":["Lloyd N Trefethen","Ásgeir Birkisson","Tobin A Driscoll"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"39ffd78e074c7609e874f83a7262bc0d","permalink":"https://tobydriscoll.net/publication/trefethen-exploring-od-es-2017/","publishdate":"2019-06-06T14:48:50.020572Z","relpermalink":"/publication/trefethen-exploring-od-es-2017/","section":"publication","summary":"","tags":null,"title":"Exploring ODEs","type":"publication"},{"authors":["Tobin A Driscoll","Richard J Braun"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"580b064e23d1496989e5f107a4d37bce","permalink":"https://tobydriscoll.net/publication/driscoll-fundamentals-numerical-computation-2017/","publishdate":"2019-06-06T14:48:50.025026Z","relpermalink":"/publication/driscoll-fundamentals-numerical-computation-2017/","section":"publication","summary":"","tags":null,"title":"Fundamentals of Numerical Computation","type":"publication"},{"authors":["Richard J Braun","Tobin A Driscoll","Carolyn G Begley","P Ewen King-Smith","Javed I Siddique"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"6b482f1812eeb994812ed032be5a1478","permalink":"https://tobydriscoll.net/publication/braun-tear-film-breakup-2017/","publishdate":"2019-06-06T14:48:50.010841Z","relpermalink":"/publication/braun-tear-film-breakup-2017/","section":"publication","summary":"","tags":null,"title":"On Tear Film Breakup (TBU): Dynamics and Imaging","type":"publication"},{"authors":null,"categories":["society and culture"],"content":"I\u0026rsquo;ve just finished one of the most remarkable fiction reading experiences I\u0026rsquo;ve had in quite some time: It Can\u0026rsquo;t Happen Here, by Sinclair Lewis.\nICHH is a satirical novel written and set in 1935 America. It describes the rise of a populist dictatorship modeled closely along the rise of the Nazis in Germany.(Lewis\u0026rsquo; wife, Dorothy Thompson, was the first American journalist expelled from Nazi Germany and was clearly responsible for much of the shape of the book.)\nThis was near the height of the Depression, and FDR\u0026rsquo;s New Deal was controversial and, at that point unsuccessful (or not yet successful, if you want to look at it that way). There were multiple signs of unrest and populism, not least of which was Huey Long, then governor of Louisiana and apparently plotting to hijack the Democratic party to get elected President in 1936 or 1940. (Long was assassinated in 1935, as the book was being finished.)\nICHH is not great as a novel. The characters are essentially allegorical, and the plot barely needs them. The core of the book is as a dystopian speculation about the near future of the USA. Lewis himself called it \u0026ldquo;propaganda for American democracy.\u0026rdquo; As such, its relevance to 2016 is astonishing. I could pick out dozens of quotes. Here are just three extended ones.\n \u0026hellip;what burns me up [isn\u0026rsquo;t] that old soap-boxer\u0026rsquo;s old chestnut about how one tenth of one percent of the population at the top have an aggregate income equal to 42 percent at the bottom\u0026hellip;.[It\u0026rsquo;s] the fact that even before this Depression, in what you folks called prosperous times, 7 per cent of all the families in the country earned $500 a year or less\u0026mdash;remember, those weren\u0026rsquo;t the unemployed, on relief; those were the guys that still had the honor of doing honest labor.\nThe most confusing thing about the campaign of 1936 was the relationship of the two leading parties. Old-Guard Republicans were complaining that their proud party was begging for office, hat in hand; veteran Democrats that their traditional Covered Wagons were jammed with college professors, city slickers, and yachtsmen.\nMost Americans had learned in school that God had supplanted the Jews as chosen people by the Americans, and this time done the job much better, so that we were the richest, kindest, and cleverest nation living; that depressions were but passing headaches and that labor unions\u0026hellip;must not set up an ugly class struggle by combining politically; that, though foreigners tried to make a bogus mystery of them, politics were really so simple that any village attorney or any clerk in the office of a metropolitan sheriff was quite adequately trained for them; and that if John D. Rockefeller or Henry Ford had set his mind to it, he could have become the most distinguished statesman, composer, physicist, or poet in the land.\n So much is in the book: the rural/urban dynamic, the American disdain for and distrust of intellectualism, the cluelessness of intellectuals, racism, anti-Semitism, antifeminism, the lust for a \u0026ldquo;ringmaster-revolutionist\u0026rdquo;, the contrast between a boring, calculating candidate and a hot populist who draws big rallies, the failure of newspapers (i.e. the media in 1935), the use of radio for disintermediation (i.e., Twitter), the belief by the banking establishment that things would soon moderate and work in their favor, etc. Lewis also spells out the horrors of a concentration camp\u0026mdash;familiar ground to us today, but sensational to much of the public in 1935.\nIn 1935 the bogeyman was communism, not Islam, and the threat seems to be the extreme left, not the right. But that hardly matters. What ICHH made so clear to me is how America, through its history, culture, and politics, is a host susceptible to a certain pattern of symptoms. And maybe it\u0026rsquo;s not just America, and not just liberal democracy, but literally part of our DNA.\nI\u0026rsquo;m quickly going over in my head in political science here. My reaction to the book is complicated. I recommend that you pick up a copy and at least get through the fictional election, though it\u0026rsquo;s neither easy nor fun to read.\nThe book was apparently adapted to a smash hit play in 1937. I would be surprised if it doesn\u0026rsquo;t undergo a revival in the near future.\n","date":1482074914,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1482074914,"objectID":"9f3a726122f442f2b2e142ead5ecaee4","permalink":"https://tobydriscoll.net/blog/it-already-has-happened-here/","publishdate":"2016-12-18T15:28:34Z","relpermalink":"/blog/it-already-has-happened-here/","section":"post","summary":"I\u0026rsquo;ve just finished one of the most remarkable fiction reading experiences I\u0026rsquo;ve had in quite some time: It Can\u0026rsquo;t Happen Here, by Sinclair Lewis.\nICHH is a satirical novel written and set in 1935 America. It describes the rise of a populist dictatorship modeled closely along the rise of the Nazis in Germany.(Lewis\u0026rsquo; wife, Dorothy Thompson, was the first American journalist expelled from Nazi Germany and was clearly responsible for much of the shape of the book.","tags":null,"title":"It already has happened here","type":"post"},{"authors":null,"categories":["computing","math","teaching"],"content":"Part V of T\u0026amp;B is on dense methods for eigenvalue and singular value problems. For my course, this is the part of the text that I condense most severely. In part that\u0026rsquo;s due to the need to cover unconstrained nonlinear solving and optimization stuff later on. But I also find that this is the least compelling part of the text for my purposes.\nIt\u0026rsquo;s heavily weighted toward the hermitian case. That\u0026rsquo;s the cleanest situation, so I see the rationale. But it\u0026rsquo;s pretty surprising that the lead author of Spectra and Pseudospectra mentions eigenvalue conditioning and sensitivity only in a single exercise! (The exercises not in the lecture named \u0026ldquo;Eigenvalue problems,\u0026rdquo; nor the one named \u0026ldquo;Overview of eigenvalue algorithms.\u0026rdquo; It\u0026rsquo;s under \u0026ldquo;Reduction to Hessenberg or tridiagonal form.\u0026rdquo;) In contrast with the tone of earlier parts of the book, one could study the methods of these sections thoroughly and yet not appreciate when the answers are inaccurate, or possibly irrelevant. Because I took this course from Trefethen at a crucial time in the development of his thinking on the subject, my perception of the issues behind computing eigenvalues is quite different from what the text itself conveys.\n(EDIT: If I had but read a few sections more before writing the above, I would have recalled that there is discussion about this in Lecture 34, under \u0026ldquo;A Note of Caution: Nonnormality.\u0026rdquo; It\u0026rsquo;s all laid out in clear language, so mea culpa. The ordering still feels a little awkward. I\u0026rsquo;ll probably have a half or full class period just on nonnormality.)\nSo. In my class I touched on 24-29, and you can find my related MATLAB notebooks and Julia notebooks on them. (I\u0026rsquo;ve given up on using Gists for these. The web interface can\u0026rsquo;t seem to handle having a lot of notebooks in one Gist, the rendering is slow, and I see no advantage for me beyond static HTML.) They\u0026rsquo;re a little rough in places, as it\u0026rsquo;s been challenging to keep up the pace.\nThere aren\u0026rsquo;t big MATLAB/Julia issues to report. If anything, I think Julia has cleaned up and rationalized some of the quirkiness of the MATLAB versions. In MATLAB, one uses eig for everything. The results depend on the number of output arguments.\n\u0026gt;\u0026gt; A = hilb(3); \u0026gt;\u0026gt; lambda = eig(A) lambda = 0.0027 0.1223 1.4083 \u0026gt;\u0026gt; [X,D] = eig(A) X = -0.1277 0.5474 0.8270 0.7137 -0.5283 0.4599 -0.6887 -0.6490 0.3233 D = 0.0027 0 0 0 0.1223 0 0 0 1.4083  It\u0026rsquo;s a bit awkward that the position of the eigenvalue output changes, and that it\u0026rsquo;s a vector in one case and a matrix in the other. And the difference goes beyond cosmetics: the calculation can be significantly faster if eigenvectors are not required. Julia gives you three variants, so you can retrieve exactly what you want.\njulia\u0026gt; A = [1/(i+j) for i=1:3, j=1:3]; julia\u0026gt; (λ,X) = eig(A) ([0.000646659,0.0409049,0.875115], [0.19925 -0.638787 -0.743136; ... -0.411255]) julia\u0026gt; λ = eigvals(A) 3-element Array{Float64,1}: 0.000646659 0.0409049 0.875115 julia\u0026gt; D = eigvecs(A) 3×3 Array{Float64,2}: 0.19925 -0.638787 -0.743136 -0.761278 0.376612 -0.527843 0.617053 0.670906 -0.411255  You even have eigmax and eigmin when the spectrum is real. One thing neither language gives you is an easy way to specify a sort order for the results. In MATLAB, for instance, one ends up doing things like:\n\u0026gt;\u0026gt; [X,D] = eig(A); \u0026gt;\u0026gt; lambda = diag(D); \u0026gt;\u0026gt; [~,idx] = sort(real(lambda)); \u0026gt;\u0026gt; X = X(:,idx); lambda = lambda(idx) lambda = -2.1898 + 1.4354i -2.1898 - 1.4354i 0.0301 + 0.6095i 0.0301 - 0.6095i 1.2276 + 2.2020i 1.2276 - 2.2020i 1.8278 + 0.0000i  Meh. It\u0026rsquo;s not a lot better in Julia, as far as I can tell.\njulia\u0026gt; A = randn(7,7); julia\u0026gt; (λ,X) = eig(A); julia\u0026gt; idx = sortperm(real(λ)); julia\u0026gt; X = X[:,idx]; λ = λ[idx] 7-element Array{Complex{Float64},1}: -3.38359+0.0im -2.33084+0.233909im -2.33084-0.233909im 0.415007+0.0im 1.03098+0.0im 1.11426+2.34596im 1.11426-2.34596im  Altogether, Julia is feeling less like a foreign country and more like a province. Sometimes I even remember to use square brackets on the first try.\n","date":1477577799,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477577799,"objectID":"014a50e6e887295be8a48e20a869be1e","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lectures-24-29-eigenvalue-stuff/","publishdate":"2016-10-27T14:16:39Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lectures-24-29-eigenvalue-stuff/","section":"post","summary":"Part V of T\u0026amp;B is on dense methods for eigenvalue and singular value problems. For my course, this is the part of the text that I condense most severely. In part that\u0026rsquo;s due to the need to cover unconstrained nonlinear solving and optimization stuff later on. But I also find that this is the least compelling part of the text for my purposes.\nIt\u0026rsquo;s heavily weighted toward the hermitian case. That\u0026rsquo;s the cleanest situation, so I see the rationale.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia, Lectures 24-29: Eigenvalue stuff","type":"post"},{"authors":null,"categories":["computing","teaching"],"content":"Three in one this time: Lecture 20, which is on Gaussian elimination / LU factorization, Lecture 21, on row pivoting, and Lecture 23, on Cholesky factorization. I mainly skipped over Lecture 22, about the curious case of the stability of pivoted LU, but the main example is dropped into the end of my coverage of pivoting.\nThe Julia surprises are, not surprisingly, coming less frequently. In Lecture 20 I had some fun with rational representations. I like using MATLAB\u0026rsquo;s format rat when presenting Gaussian elimination, as it allows me to recall the way the process looks when learned by hand. It\u0026rsquo;s a fun trick, but of course the underlying values are still all double precision, and the rational approximations to them are found ex post facto. By contrast, Julia offers true rational numbers, constructed and shown using the // operation.\nCompare the MATLAB\nformat rat I = eye(4); L21 = I + (-5/17)*I(:,2)*I(:,1)'; L31 = I + (-9/17)*I(:,3)*I(:,1)'; L41 = I + (-4/17)*I(:,4)*I(:,1)';  to the Julia\nI = eye(Rational,4); L21 = copy(I); L21[2,1] = -5//17; L31 = copy(I); L31[3,1] = -9//17; L41 = copy(I); L41[4,1] = -4//17;  The MATLAB code requires only the format call, because it\u0026rsquo;s only the display of results that is affected. The Julia code is doing something deeper and needs more changes as a result.\nJulia could use something like a format command. I almost always find MATLAB\u0026rsquo;s terminal output more readable, or at least easier to manipulate into a good form. Here\u0026rsquo;s one example using the rational output. First, MATLAB:\n17 2 3 13 93 0 194/17 155/17 71/17 963/17 0 101/17 92/17 87/17 574/17 0 230/17 243/17 -18/17 1158/17  And the Julia:\n4x5 Array{Rational{T\u0026amp;lt;:Integer},2}: 17//1 2//1 3//1 13//1 93//2 0//1 194//17 155//17 71//17 963//34 0//1 101//17 92//17 87//17 287//17 0//1 230//17 243//17 -18//17 579//17  I almost never need that header line that Julia gives. The numbers are already showing themselves to be Rational, and the shape of the array is self-evident. (Though I now see that MATLAB 2016b is adding such headers to non-float output.) The zero structure also jumps out more clearly in the MATLAB case, though it\u0026rsquo;s profligate with whitespace.\nAnother comparison, of MATLAB (using the default format):\n1 0 0 0 0 1 0 1 0 0 0 2 0 0 1 0 0 4 0 0 0 1 0 8 0 0 0 0 1 16 0 0 0 0 0 32  versus Julia:\n6×6 Array{Float64,2}: 1.0 0.0 0.0 0.0 0.0 1.0 0.0 1.0 0.0 0.0 0.0 2.0 0.0 0.0 1.0 0.0 0.0 4.0 0.0 0.0 0.0 1.0 0.0 8.0 0.0 0.0 0.0 0.0 1.0 16.0 0.0 0.0 0.0 0.0 0.0 32.0  There\u0026rsquo;s nothing wrong per se about Julia\u0026rsquo;s. But which version would you write down, or expect to see in print? One last case, of a matrix that is supposed to be triangular but for a little roundoff. First, Julia:\n4×4 Array{Float64,2}: 17.0 2.0 3.0 13.0 0.0 13.5294 14.2941 -1.05882 0.0 0.0 -2.93913 5.06957 5.55112e-16 0.0 -4.44089e-16 4.09024  And MATLAB, using the default format:\n17.0000 2.0000 3.0000 13.0000 0 13.5294 14.2941 -1.0588 0 0 -2.9391 5.0696 0.0000 0 -0.0000 4.0902  Julia has chosen to align on the decimal point. It\u0026rsquo;s also suppressing trailing zeros, except for the first, giving an odd and false impression of values that have a precise number of significant digits. MATLAB\u0026rsquo;s choice of right alignment is visually superior, and only exact zero gets a special display. True, you might want that exponential notation for the tiny values; you can get it by changing the format.\n\u0026gt;\u0026gt; format short e \u0026gt;\u0026gt; U U = 1.7000e+01 2.0000e+00 3.0000e+00 1.3000e+01 0 1.3529e+01 1.4294e+01 -1.0588e+00 0 0 -2.9391e+00 5.0696e+00 5.5511e-16 0 -4.4409e-16 4.0902e+00 \u0026gt;\u0026gt; format short g \u0026gt;\u0026gt; U U = 17 2 3 13 0 13.529 14.294 -1.0588 0 0 -2.9391 5.0696 5.5511e-16 0 -4.4409e-16 4.0902  It\u0026rsquo;s nice to have options.\n","date":1477153215,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1477153215,"objectID":"c32f3a8fd2634ad2f758eff11a182cd0","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lectures-20-21-23-solving-square-systems/","publishdate":"2016-10-22T16:20:15Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lectures-20-21-23-solving-square-systems/","section":"post","summary":"Three in one this time: Lecture 20, which is on Gaussian elimination / LU factorization, Lecture 21, on row pivoting, and Lecture 23, on Cholesky factorization. I mainly skipped over Lecture 22, about the curious case of the stability of pivoted LU, but the main example is dropped into the end of my coverage of pivoting.\nThe Julia surprises are, not surprisingly, coming less frequently. In Lecture 20 I had some fun with rational representations.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia: Lectures 20, 21, 23: Solving square systems","type":"post"},{"authors":null,"categories":["computing","math","teaching"],"content":"Here are the notebooks in MATLAB and Julia.\nThe new wrinkle in these codes is extended precision. In MATLAB you need to have the Symbolic Math toolbox to do this in the form of vpa. In Julia, you have to use version 0.5 or (presumably) later, which had a surprising side effect I\u0026rsquo;ll get to below.\nThe reason for extended precision is that this lecture presents experiments on the accuracy of different algorithms for linear least squares problems. In order to demonstrate this on a fairly ill conditioned problem, the answer is supposed to be computed in extended precision, yielding a normalization constant that sets the desired quantity to be 1 for at least 16 significant digits.\nThe least squares problem comes from fitting exp(sin(4t)) to a polynomial of degree 14. I see two ways to define how extended precision is to be used. Option (1) is to form the matrix $A$ and the vector $b$ in double precision, then solve the least squares problem with them, but in extended precision. Option (2) is to build in extended precision from the beginning of the problem, creating $A$ and $b$ that differ in the extended digits. I was first attracted to option (1), but option (2) has the clear advantage that the result should be independent of machine and language, whereas in the other case the data could be rounded or computed differently to double precision.\nHere\u0026rsquo;s how this looks in MATLAB.\nt = vpa(0:m-1,64)'/vpa(m-1,64); % 64 sig. digits! A = t.^0; for j = 1:14, A=[A,t.*A(:,j)]; end b = exp(sin(4*t)); [Q,R] = qr(A,0); % Householder QR x1 = R\\ (Q'*b); [Q,R] = mgs([A b]); % Gram-Schmidt QR x2 = R(1:15,1:15) \\ R(1:15,16);  Here are the outputs for the last element of x in the four methods:\n2006.7874531048518338761038143559 2006.7874531048518338761038143553 2006.7874531048518338766907539159 2006.7874531048518338761038143555  It\u0026rsquo;s not a problem that the third result disagrees in the last 10 or so digits, since that\u0026rsquo;s an unstable method.\nHere\u0026rsquo;s how it went in Julia.\nsetprecision(BigFloat,128); # use 128-bit floats t = convert(Array{BigFloat},collect(0:m-1))/convert(BigFloat,m-1); A = [t[i].^j for i=1:m, j=0:n-1]; b = exp(sin(4*t)); (Q,R) = qr(A); x1 = R\\ (Q'*b); (Q,R) = mgs([A b]); x2 = R[1:15,1:15] \\ R[1:15,16]; x3 = (A'*A)$$A'*b); x4 = A\\b;  That first line isn\u0026rsquo;t pretty, but after that it\u0026rsquo;s quite natural. I found Juila\u0026rsquo;s extended precision to be fast compared to MATLAB\u0026rsquo;s. The results:\n2.006787453104851833876103814338068195207e+03 2.006787453104851833876103814355358077263e+03 2.006787453104851834342923924263804001505e+03 2.006787453104851833876103814376793404332e+03  These are the same up to the last couple of digits of MATLAB\u0026rsquo;s answer. Unfortunately, my values don\u0026rsquo;t agree with what\u0026rsquo;s in T\u0026amp;B, which is 2006.787453080206. The text doesn\u0026rsquo;t say much about how this was done, so it\u0026rsquo;s impossible for me to say why.\nI probably don\u0026rsquo;t pay enough attention to extended precision. I know some people in the radial basis function community who use it to overcome the very poor conditioning of those bases. They seem quite happy with it. It\u0026rsquo;s always felt like cheating to me, but that\u0026rsquo;s hardly a rational argument.\nAbove I said that there was an unexpected side effect related to my using extended precision in Julia. I discovered that (a) it became available in base Julia in version 0.5 and (b) the homebrew Julia I had installed was version 0.4.3, even though 0.5 had apparently been out for a while. Upon upgrading, I found that my MGS routine throwing an error! The offending line was\nA[:,j+1:n] -= Q[:,j]*R[j,j+1:n];  The issue is that now both of the references on the right-hand side are vectors, which have only one dimension. Therefore the implied outer product is considered undefined. I had to switch to\nA[:,j+1:n] -= Q[:,j:j]*R[j:j,j+1:n];  Because j:j is a range, not a scalar, the submatrix references are two-dimensional matrices with appropriate singleton dimensions, so the outer product proceeds.\nI\u0026rsquo;m not sure how to feel about this. It\u0026rsquo;s disturbing to extract a row of a matrix and get an object without a row shape. In fact you can even say it\u0026rsquo;s got a column shape, because you are allowed to transpose it into a 1-by-n matrix! On the other hand, there are consistent rules governing the indexing, and 0D, 1D, and 2D extractions are all possible. I\u0026rsquo;m starting to think that the true problem is that I learned and conceptualize linear algebra in a way that works up to dimension 2 but contains some implied hacks that break multilinear algebra. I wish I knew this stuff better.\n","date":1476220595,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476220595,"objectID":"ba4134ee61c9e378a7d58eea96666e26","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lecture-19-stability-of-least-squares/","publishdate":"2016-10-11T21:16:35Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lecture-19-stability-of-least-squares/","section":"post","summary":"Here are the notebooks in MATLAB and Julia.\nThe new wrinkle in these codes is extended precision. In MATLAB you need to have the Symbolic Math toolbox to do this in the form of vpa. In Julia, you have to use version 0.5 or (presumably) later, which had a surprising side effect I\u0026rsquo;ll get to below.\nThe reason for extended precision is that this lecture presents experiments on the accuracy of different algorithms for linear least squares problems.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia: Lecture 19, Stability of least squares","type":"post"},{"authors":null,"categories":["computing","teaching"],"content":"I\u0026rsquo;ve run into trouble managing gists with lots of files in them, so I\u0026rsquo;m back to doing one per lecture. Here are Lecture 12 and Lecture 13.\nWe\u0026rsquo;ve entered Part 3 of the book, which is on conditioning and stability matters. The lectures in this part are heavily theoretical and often abstract, so I find a little occasional computer time helps to clear the cobwebs.\nRight off the top, in reproducing Figure 12.1, I ran right into the trap I worried about in my last post regarding polynomials in Julia. In MATLAB, the polynomial coefficients are just a plain vector. That makes perturbing them trivial:\np = poly([1,1,1,0.4,2.2]); % polynomial with these roots q = p + 1e-9*randn(size(p)); % perturb its coefficients  In Julia, you can use the Polynomials package and get polynomial objects. Behold:\nusing Polynomials p = poly([1,1,1,0.4,2.2]); # polynomial with these roots q = p + Poly(1e-9*randn(6)); # perturb coefficients  Note that poly constructs a polynomial from a vector of roots, while Poly constructs one from a vector of coefficients. Sure enough, I used poly in both lines the first time around. It\u0026rsquo;s a pernicious mistake, because it produces no error\u0026mdash;the polynomials can be added no matter what. The mistake was mine, but I think this is an unfortunate design.\nThe only other notable usage in Lecture 12 is my first use of a comprehension:\nhilb(n) = [ 1.0/(i+j) for i=1:n, j=1:n ];  This is a pretty handy way to create a matrix.\nIn Lecture 13 I had some fun dissecting floating point numbers in both systems. There was only one area in which Julia didn\u0026rsquo;t go as smoothly as I would hope. MATLAB offers realmin and realmax , which give the smallest and largest normalized floating point numbers. While Julia has similar-sounding commands, they are interpreted differently:\njulia\u0026gt; typemin(Float64), typemax(Float64) (-Inf,Inf)  Eh, not so much. There is even one more layer of subtlety. Consider\njulia\u0026gt; (prevfloat(Inf),nextfloat(0.0)) (1.7976931348623157e308,5.0e-324)  The first of these values is exactly the same as realmax, but the second is not realmin. IEEE 754 double precision has \u0026ldquo;denormalized\u0026rdquo; numbers that let you trade away bits of precision to get closer to zero in magnitude. Julia is reporting the smallest denormalized number, not the smallest full-precision number. Julia\u0026rsquo;s not wrong, but access to the extreme finite double precision values isn\u0026rsquo;t as straightforward as it could be.\nOne last observation. Trefethen \u0026amp; Bau refer to the value $2^{-53}$ as \u0026ldquo;machine epsilon.\u0026rdquo; This isn\u0026rsquo;t what MATLAB and Julia use, which is $2^{-52}$. Nick Higham\u0026rsquo;s Accuracy and Stability of Numerical Algorithms also has \u0026ldquo;machine epsilon\u0026rdquo; at $2^{-52}$ and calls $2^{-53}$ \u0026ldquo;unit roundoff.\u0026rdquo; Stoer and Bulirsch (2nd ed.) call $2^{-53}$ \u0026ldquo;machine precision.\u0026rdquo; Corless and Fillion seem to agree with Higham. Golub and Van Loan (3rd ed.) don\u0026rsquo;t use \u0026ldquo;machine epsilon\u0026rdquo; at all, and in the index one finds\n Machine precision. See unit roundoff.\n Sigh. The mathematical uses are, unsurprisingly, consistent. Frankly, I feel better about my personal inconsistencies at using those terms: at least I stood on the shoulders of giants.\n","date":1475603877,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475603877,"objectID":"aff98fbdd5328e39302c200658bc5b98","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lectures-12-13-conditioning-and-floating-point/","publishdate":"2016-10-04T17:57:57Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lectures-12-13-conditioning-and-floating-point/","section":"post","summary":"I\u0026rsquo;ve run into trouble managing gists with lots of files in them, so I\u0026rsquo;m back to doing one per lecture. Here are Lecture 12 and Lecture 13.\nWe\u0026rsquo;ve entered Part 3 of the book, which is on conditioning and stability matters. The lectures in this part are heavily theoretical and often abstract, so I find a little occasional computer time helps to clear the cobwebs.\nRight off the top, in reproducing Figure 12.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia, Lectures 12-13: Conditioning and floating point","type":"post"},{"authors":null,"categories":["computing","teaching"],"content":"This week\u0026rsquo;s notebooks (MATLAB and Julia\u0026ndash;now all lectures are together for each language) are about least squares polynomial fitting.\nThe computational parts are almost identical, except for how polynomials are represented. In MATLAB, a vector of coefficients is interpreted as a polynomial in the context of particular functions, such as polyval. The major pain is that the convention is for the coefficients to be ordered from high degree to low, which is almost always the opposite of what you really want. Hence I\u0026rsquo;ve gotten used to writing code like\np = @(x) polyval( c(end: -1:1), x-1955 );  It\u0026rsquo;s not a big deal, but it trips up some students every semester.\nJulia has a full-fledged polynomial type, if you care to add and load the package. And, it expects ordering from the constant term to the highest degree. So I came up with\np = Poly(c); q = t -\u0026gt; p(t-1955);  Simple enough, but I find two disappointments. First, it\u0026rsquo;s a bare-bones class. For instance, the second object q above is also a polynomial, but we\u0026rsquo;ll never know it formally, or be able to get its coefficients. A shiftvar method or something similar would be nice. Second, in the effort to clone the MATLAB interface, a potential for serious confusion was introduced. The command p=poly(c) also works, but (like MATLAB\u0026rsquo;s counterpart) constructs a polynomial whose roots, not coefficients, are given. This is way too easy a mistake to make.\nAnother element this time was that I tried using the nascent Plots package for Julia. It\u0026rsquo;s an interesting attempt to graft a graceful interface onto the various graphics backends that already exist. I was motivated to try it because AFAIK, the PyPlots package lacks a counterpart to fplot from MATLAB. Perhaps in part because of my time with the Chebfun project, I have been putting more emphasis in my teaching on representing functions as such, rather than implicitly as vectors of numbers. It bothers me now, for example, that functions such as interp1 and ode45 return numbers or structures rather than callable functions, which is what their algorithms should be doing in the deep sense.\nAnyhow, I end up using fplot a lot because of my emphasis on functions, and couldn\u0026rsquo;t find a counterpart in PyPlot. In Plots, however, the plot command handles both numerical and functional arguments alike. Here\u0026rsquo;s a snippet from the notebook:\np = Poly(c); plot( t-\u0026gt;p(t-1955), 1955,2000 ) plot!( year,anomaly, m=:o,l=nothing ); title!(\u0026quot;World temperature anomaly\u0026quot;); xlabel!(\u0026quot;year\u0026quot;); ylabel!(\u0026quot;anomaly (deg C)\u0026quot;)  Not bad! You can see a couple of quirks though. One is the use of keyword arguments in line 3; the arguments m=:o and l=nothing respectively set the point markers to circles and the lines connecting points to be suppressed. This takes getting used to, but it\u0026rsquo;s memorable and compact enough.\nThe other quirk that you see above is the use of the banged commands like plot! and title!. The bang in Julia is a convention meaning \u0026ldquo;operate in place\u0026rdquo; or \u0026ldquo;overwrite existing.\u0026rdquo; By default, the MATLAB-like commands replace the existing plot, so they have to be banged in order to build on top of it instead. This is a bit dubious in the case of titles and labels––why would I create a new plot by issuing a title?––but it is at least consistent, and, unlike the global state used in MATLAB by the hold command, works the same regardless of context and history.\nOne quirk––to me, a bug––that you don\u0026rsquo;t see is that the default in Plots is that every plot creates or adds to a legend. I\u0026rsquo;m not a big fan of plot legends in most contexts, but you\u0026rsquo;re welcome to them if you like them. However, I don\u0026rsquo;t find it reasonable to have one forced on me for a graph with a single curve that I didn\u0026rsquo;t give a label to! I turned off this travesty by starting off with\nusing Plots; pyplot(legend=false);  which at least is straightforward, though entangled with my choice of backend.\n","date":1475068756,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475068756,"objectID":"3243adb13e5fe5e3f9b3356b31b3a162","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lecture-11-least-squares/","publishdate":"2016-09-28T13:19:16Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lecture-11-least-squares/","section":"post","summary":"This week\u0026rsquo;s notebooks (MATLAB and Julia\u0026ndash;now all lectures are together for each language) are about least squares polynomial fitting.\nThe computational parts are almost identical, except for how polynomials are represented. In MATLAB, a vector of coefficients is interpreted as a polynomial in the context of particular functions, such as polyval. The major pain is that the convention is for the coefficients to be ordered from high degree to low, which is almost always the opposite of what you really want.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia, Lecture 11: Least squares","type":"post"},{"authors":null,"categories":["Uncategorized"],"content":"For today\u0026rsquo;s notebooks I got caught on a problem I anticipated in theory but failed to spot in practice for longer than I would like to admit.\nFirst let me mention how interesting this Lecture is to me personally. The title of the lecture is \u0026ldquo;MATLAB\u0026rdquo;, and it details three numerical experiments. The first of these uses QR factorization of a discretization of monomials in order to approximate the Legendre polynomials. I skipped this one here because I opted in class to show how Gram-Schmidt looks using Chebfun. (It\u0026rsquo;s awesome.)\nThe other two numerical experiments show different aspects of numerical instability of the Gram-Schmidt algorithm, classical and modified. The MATLAB version looks just like I would have written it 20 years ago:\n[U,S,V] = svd(randn(80)); s = 2.^(-1:-1:-80); A = U*diag(s)*V'; semilogy(s,'.') [Qc,Rc] = gs(A); \u0026amp;nbsp;% classical hold on, semilogy(diag(Rc),'o') [Qm,Rm] = mgs(A); % modified semilogy(diag(Rm),'s')  The idea is that the diagonal elements of R descend exponentially just like the singular values do. If you run this code (or peek at the link at the top), you see that MGS stops tracking them right around machine precision, whereas the less stable classical version wanders off at about half of the available digits.\nI did introduce my own wrinkle here. I can\u0026rsquo;t believe I haven\u0026rsquo;t thought of using this for teaching before, but by the conversion A=single(A) I can simulate a different value of machine epsilon without changing anything else! It backs up the observations from the first graph.\nIn Julia this gambit ran into a big snag. Here was my first code for MGS:\nfunction mgs(A) m,n = size(A); Q = zeros(m,n); R = zeros(n,n); for j = 1:n R[j,j] = norm(A[:,j]); Q[:,j] = A[:,j]/R[j,j]; R[j,j+1:n] = Q[:,j]'*A[:,j+1:n]; A[:,j+1:n] -= Q[:,j]*R[j,j+1:n]; end return Q,R end  Everything was fine in double precision. After a couple of missteps, I figured out how to make A` single precision:\nA = convert(Array{Float32},A)  Not beautiful, but it works. However, while it had the desired effect on MGS, it did nothing to classical GS! It finally came down to a surprise:\njulia\u0026gt; typeof( 1.0f0 + 1.0f0 ) Float32 julia\u0026gt; typeof( 1.0f0 + 1.0 ) Float64  A single plus a double is double. The rule in Julia is that the operands are converted to a type that can represent them both. MATLAB gives a different outcome, converting both numbers to single:\n\u0026gt;\u0026gt; class( single(1) + 1 ) ans = single  I suppose the philosophy here is that there\u0026rsquo;s no point padding the numbers with meaningless digits\u0026mdash;the moment you introduce a single precision value, you\u0026rsquo;ve chosen that level of precision. I think that\u0026rsquo;s the more sensible choice for floating point; Julia is concerned with the consistency of its much more intricate and far-reaching type system. For Julia I changed the initialization of Q and R to\nQ = zeros(A); R = zeros(Q[1:n,1:n]);  That way they are initialized with the correct type in either case.\nNow for the bonehead move of the day. I seemed to get inconsistent and nonreproducible results in the single precision cases. I went away, did other things, came back into a fresh session, and\u0026hellip;no difference between double and single precision. I may have said a few things I now come to regret. Finally I remembered the key: Julia passes by reference, not value. MGS alters the input matrix, which has no effect outside the function in MATLAB but changes the \u0026lsquo;master copy\u0026rsquo; in Julia. A little switch to\nfunction mgs(B) A = copy(B);  and all was well. This is an example of how much MATLAB has shaped my thinking about programming. IIRC, MATLAB doesn\u0026rsquo;t always pass by value; if an input argument is not altered, it is not copied. But it\u0026rsquo;s handled by the compiler, not the programmer.\nIf nothing else I\u0026rsquo;m getting ever more clarity on the ways MATLAB keeps things simple. Variables are bound to their values, period. Single precision is an irrevocable choice. Scalars and 1x1 matrices are the same thing. Don\u0026rsquo;t it always seem to go that you don\u0026rsquo;t know what you\u0026rsquo;ve got \u0026lsquo;til it\u0026rsquo;s gone?\n","date":1474401154,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1474401154,"objectID":"7e7e43974e2db96962d7cb980c063257","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lecture-9-matlab/","publishdate":"2016-09-20T19:52:34Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lecture-9-matlab/","section":"post","summary":"For today\u0026rsquo;s notebooks I got caught on a problem I anticipated in theory but failed to spot in practice for longer than I would like to admit.\nFirst let me mention how interesting this Lecture is to me personally. The title of the lecture is \u0026ldquo;MATLAB\u0026rdquo;, and it details three numerical experiments. The first of these uses QR factorization of a discretization of monomials in order to approximate the Legendre polynomials.","tags":null,"title":"Trefethen \u0026  Bau \u0026   MATLAB \u0026   Julia, Lecture 9: MATLAB","type":"post"},{"authors":null,"categories":["computing","math","teaching"],"content":"This lecture is about the modified Gram-Schmidt method and flop counting. The notebooks are here.\nI\u0026rsquo;m lost.\nAlmost as an afterthought I decided to add a demonstration of the timing of Gram-Schmidt compared to the asymptotic flop count. Both MATLAB and Julia got very close to the trend as got into the hundreds, using vectorized code:\nn_ = collect(50:50:500); time_ = zeros(size(n_)); for k = 1:length(n_) n = n_[k]; A = rand(1200,n); Q = zeros(1200,n); R = zeros(600,600); tic(); R[1,1] = norm(A[:,1]); Q[:,1] = A[:,1]/R[1,1]; for j = 2:n R[1:j-1,j] = Q[:,1:j-1]'*A[:,j]; v = A[:,j] - Q[:,1:j-1]*R[1:j-1,j]; R[j,j] = norm(v); Q[:,j] = v/R[j,j]; end time_[k] = toc(); end using PyPlot loglog(n_,time_,\u0026quot;-o\u0026quot;,n_,(n_/500).^2,\u0026quot;--\u0026quot;) xlabel(\u0026quot;n\u0026quot;), ylabel(\u0026quot;elapsed time\u0026quot;)  I noticed that while the timings were similar, Julia lagged MATLAB just a bit. I decided this would be a great chance for me to see Julia\u0026rsquo;s prowess with speedy loops firsthand.\nCompare the vectorized and unvectorized Julia versions here:\n Look at the last line\u0026ndash;it\u0026rsquo;s allocating 1.4GB of memory to make the nested loop version happen! I thought perhaps I should use copy to create v in each pass, but that change didn\u0026rsquo;t help. I even tried writing my own loop for computing the dot product, to no avail.\nIt did help a little to replace the line in which v is updated with\nv = broadcast!(-,v,Q[:,i]*R[i,j])  The bang on the name of the function makes it operate in-place, overwriting the current storage. Apparently Julia will create some syntactic sugar for this maneuver in version 0.5. Here it reduced the memory usage to 1.1 GB.\nJulia\u0026rsquo;s reputation is that it\u0026rsquo;s great with loops, especially compared to MATLAB and Python. As a Julia newbie I recognize that there may still be only a small change I need to make in order to see this for myself. But I feel as though having to use that broadcast!, or even the more natural .= that may be coming, is already too much to ask. I\u0026rsquo;m frustrated, confused, and disappointed.\n","date":1474314282,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1474314282,"objectID":"6f1940a24bd7229cf5c1419751d9b335","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lecture-8-gram-schmidt/","publishdate":"2016-09-19T19:44:42Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lecture-8-gram-schmidt/","section":"post","summary":"This lecture is about the modified Gram-Schmidt method and flop counting. The notebooks are here.\nI\u0026rsquo;m lost.\nAlmost as an afterthought I decided to add a demonstration of the timing of Gram-Schmidt compared to the asymptotic flop count. Both MATLAB and Julia got very close to the trend as got into the hundreds, using vectorized code:\nn_ = collect(50:50:500); time_ = zeros(size(n_)); for k = 1:length(n_) n = n_[k]; A = rand(1200,n); Q = zeros(1200,n); R = zeros(600,600); tic(); R[1,1] = norm(A[:,1]); Q[:,1] = A[:,1]/R[1,1]; for j = 2:n R[1:j-1,j] = Q[:,1:j-1]'*A[:,j]; v = A[:,j] - Q[:,1:j-1]*R[1:j-1,j]; R[j,j] = norm(v); Q[:,j] = v/R[j,j]; end time_[k] = toc(); end using PyPlot loglog(n_,time_,\u0026quot;-o\u0026quot;,n_,(n_/500).","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia, Lecture 8: Gram-Schmidt","type":"post"},{"authors":null,"categories":["teaching","computing"],"content":"Here are the Jupyter notebooks for Lecture 6 and Lecture 7. (I finally noticed that a Gist can hold more than one notebook\u0026hellip;duh.)\nNot much happened in Lecture 6, but I got gobsmacked in Lecture 7. It happened when I tried to convert this boring MATLAB code for backward substitution.\nA = magic(9); b = (1:9)'; [Q,R] = qr(A); z = Q'*b; x(9,1) = z(9)/R(9,9); for i = 8:-1:1 x(i) = (z(i) - R(i,i+1:9)*x(i+1:9)) / R(i,i); end  Here is what I first tried in Julia.\nA = round(10*rand(9,9)); b = (1:9); m = 9; (Q,R) = qr(A); z = Q'*b; x = zeros(m); x[m] = z[m]/R[m,m]; for i = m-1:-1:1 x[i] = (z[i] - R[i,i+1:m]*x[i+1:m]) / R[i,i]; end  Seems straightforward, but line 4 gives an error. I\u0026rsquo;m not going to copy the error message here, in case you\u0026rsquo;re using mobile data right now. What I mean is that it is verbose, not to mention obscure. You don\u0026rsquo;t appreciate simple, clear error messages until you get something else!\nAnyhow, I then remembered that in Julia, the colon construction (1:9) produces a Range, not a Vector. As I understand it, Julia embraces a lazy design philosophy: it avoids evaluation of an expression until the last possible moment. Suppose the only use of that Range is to describe a loop iteration\u0026mdash;in that case, why have a vector?\nI\u0026rsquo;m all for lazy philosophy. (Haw haw!) It\u0026rsquo;s not clear to me why the context Q'*b does not automatically convert the Range into a Vector. It\u0026rsquo;s even less clear why they have deprecated the idiom [1:9] to create a Vector; it works for now but gives a warning. Instead one should use collect:\nA = round(10*rand(9,9)); b = collect(1:9); m = 9; (Q,R) = qr(A); z = Q'*b; x = zeros(m); x[m] = z[m]/R[m,m]; for i = m-1:-1:1 x[i] = (z[i] - R[i,i+1:m]*x[i+1:m]) / R[i,i]; end  Feels very odd to me still, but okay.\nWe are not out of the woods yet. This version still fails in the loop body, again vomiting opaque error messages. Remember how, back in Lecture 2, I mentioned that scalars and 1x1 matrices are different things? Inside the loop above, z[i] is a scalar and the product is a length-1 vector. But the subtraction works anyway, as z[i] is silently promoted to a 1-vector also. No, the problem comes with the assignment: you can\u0026rsquo;t assign a 1-vector to an element of an array of numbers.\nThere\u0026rsquo;s a very long (space and time) discussion about this and related issues in Julia. Suffice it to say that what mathematicians do with scalars, vectors, matrices, and tensors isn\u0026rsquo;t rigorously consistent\u0026mdash;or at least, there seem to be multiple, incompatible rigorous ways to use them.\nIn this particular case I have found two unsatisfying workarounds. The idiom x[i:i] produces a Vector, not a scalar, so the assignment goes through. Or we can work on the other side of the assignment and pull out the scalar from the vector:\n(z[i] - R[i,i+1:m]*x[i+1:m])[1] / R[i,i]  Now, it\u0026rsquo;s pleasing that this syntax does work, as there is no good MATLAB equivalent for indexing into a temporary expression. I just wish it was in the service of something less dismal.\nAgain: Julia\u0026rsquo;s designers have solid reasons for doing things this way. I wouldn\u0026rsquo;t consider it a dealbreaker for research codes, but this episode is not something I would want to explain to undergrads who are just wrapping their heads around LU factorization. It pulls you right out of thinking about math and into thinking about strict-typing, pinhead-dancing angels. How unfortunate.\n","date":1474057678,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1474057678,"objectID":"450e6f7aa5d76673923950a7b6309a36","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lectures-6-7/","publishdate":"2016-09-16T20:27:58Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lectures-6-7/","section":"post","summary":"Here are the Jupyter notebooks for Lecture 6 and Lecture 7. (I finally noticed that a Gist can hold more than one notebook\u0026hellip;duh.)\nNot much happened in Lecture 6, but I got gobsmacked in Lecture 7. It happened when I tried to convert this boring MATLAB code for backward substitution.\nA = magic(9); b = (1:9)'; [Q,R] = qr(A); z = Q'*b; x(9,1) = z(9)/R(9,9); for i = 8:-1:1 x(i) = (z(i) - R(i,i+1:9)*x(i+1:9)) / R(i,i); end  Here is what I first tried in Julia.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia, Lectures 6-7","type":"post"},{"authors":null,"categories":["computing","teaching"],"content":"Notebooks are viewable for matlab and julia.\nThis is one of my favorite demos. It illustrates low-rank approximation by the SVD to show patterns in voting behavior for the U.S. Congress. With no a priori models, project onto two singular vectors and pow\u0026ndash;meaning and insight jump out.\nI took one shortcut. I have a MATLAB script that reads the raw voting data from voteview.com and converts it to a matrix. No doubt I would learn a lot about I/O in Julia if I translated it, but I got short on time and instead saved it locally from MATLAB. Then load it using the MAT package for Julia and Bob\u0026rsquo;s your uncle.\nI did stumble into a nasty gotcha, though. I decided to make histograms for the distributions of the \u0026ldquo;partisan\u0026rdquo; and \u0026ldquo;bipartisan\u0026rdquo; coordinate values. Unfortunately, there\u0026rsquo;s a name clash: MATLAB\u0026rsquo;s best known histogram plotter is called hist, but Julia has a built-in function by that name that just bins the data. I knew there was also a hist() in PyPlot, but to my bafflement the access for it was not PyPlot.hist(), which does exist:\nhelp?\u0026gt; PyPlot.hist hist(v, e) -\u0026amp;gt; e, counts Compute the histogram of v using a vector/range e as the edges... hist(v[, n]) -\u0026amp;gt; e, counts Compute the histogram of v, optionally using approximately...  This is Julia\u0026rsquo;s built-in function. The next thing I tried was typing in Pyplot. and hitting tab for a list of completions. Most of the familiar MATLAB-style plotting functions are there, but no hist, just hist2D, which is not equivalent. I don\u0026rsquo;t remember now where I found it, but the way to call the function I want is the bizarre plt[:hist]. Neither ?plt nor tab completion gives any whiff of this syntax or possibility. Obviously there\u0026rsquo;s some logic at work here, and no doubt my Julia and Python ignorance are showing, but this was the most frustrating Julia experience I\u0026rsquo;ve had yet.\n(Ironically, MATLAB has a newer plotting function called histogram, which does not seem to conflict with any Julia names!)\n","date":1473709628,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473709628,"objectID":"be53c1b00217209e7b8f5f587b016d1b","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lecture-5-more-on-the-svd/","publishdate":"2016-09-12T19:47:08Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lecture-5-more-on-the-svd/","section":"post","summary":"Notebooks are viewable for matlab and julia.\nThis is one of my favorite demos. It illustrates low-rank approximation by the SVD to show patterns in voting behavior for the U.S. Congress. With no a priori models, project onto two singular vectors and pow\u0026ndash;meaning and insight jump out.\nI took one shortcut. I have a MATLAB script that reads the raw voting data from voteview.com and converts it to a matrix. No doubt I would learn a lot about I/O in Julia if I translated it, but I got short on time and instead saved it locally from MATLAB.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia Lecture 5: More on the SVD","type":"post"},{"authors":null,"categories":["computing","math","teaching"],"content":"The notebooks: matlab and julia.\nToday is about some little conveniences/quirks in Julia. Starting here:\nt = linspace(0,2*pi,300); x1,x2 = (cos(t),sin(t));  The second line assigns to two variables simultaneously. It\u0026rsquo;s totally unnecessary here, but it helps to emphasize how the quantities are related.\nNext we have\nU,σ,V = svd(A)  I\u0026rsquo;m unreasonably happy about having Greek letters as variable names. Just type in \u0026lsquo;\\sigma\u0026rsquo; and hit tab, and voila! It\u0026rsquo;s a reminder of how, in the U.S. at least, we\u0026rsquo;re so used to living within the limitations of ancient 128-character ASCII\u0026mdash;telegraphs, really\u0026mdash;that we can be surprised by expanded possibilities.\nLater on we have diagm(σ). In MATLAB, the diag function has two roles: convert a vector to a diagonal matrix, and extract the diagonal elements of a matrix. This creates a curious edge case for MATLAB: for example, diag([1 2 3])  returns a 3-by-3 matrix, not the single element 1. This is almost always what you want, but I\u0026rsquo;ve run into gotchas wherein a program works perfectly until an input of the \u0026lsquo;wrong\u0026rsquo; size silently changes the behavior of a function. In Julia the two functionalities are separated into diag and diagm, which avoids the edge case ambiguity. I think it\u0026rsquo;s worth the clarity here to have the extra command.\nThe one thing I missed having in the Julia version was MATLAB\u0026rsquo;s format command, which lets you set the default display of numbers in all following output. In this notebook I just had numbers as placeholders and really wanted just to show shapes and sizes. Julia\u0026rsquo;s full-length output obfuscates the sizes quite a bit, and I\u0026rsquo;d like to tell it to calm down with all those digits for a little while (rather than saying so with each new output). If that capability is there, I overlooked it.\n","date":1473684667,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473684667,"objectID":"82717c1f85bcc8231d16767dfc0a43b9","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lecture-4-svd/","publishdate":"2016-09-12T12:51:07Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lecture-4-svd/","section":"post","summary":"The notebooks: matlab and julia.\nToday is about some little conveniences/quirks in Julia. Starting here:\nt = linspace(0,2*pi,300); x1,x2 = (cos(t),sin(t));  The second line assigns to two variables simultaneously. It\u0026rsquo;s totally unnecessary here, but it helps to emphasize how the quantities are related.\nNext we have\nU,σ,V = svd(A)  I\u0026rsquo;m unreasonably happy about having Greek letters as variable names. Just type in \u0026lsquo;\\sigma\u0026rsquo; and hit tab, and voila! It\u0026rsquo;s a reminder of how, in the U.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia, Lecture 4: SVD","type":"post"},{"authors":null,"categories":["computing","math","teaching"],"content":"Here are the MATLAB and julia notebooks.\nThe big issue this time around was graphics. This topic dramatically illustrates the advantages on both sides of the commercial/open source fence. On the MATLAB side, it\u0026rsquo;s perfectly clear what you should do. There are many options that have been well constructed, and it\u0026rsquo;s all under a relatively consistent umbrella. There are things to learn and options to choose, but it\u0026rsquo;s clear what functions you will be using to make, say, a scatter plot, and a lot of similarity across commands.\nJulia graphics are another story. At this writing, there are two options recommended on Julia\u0026rsquo;s official page about plotting packages: PyPlot and Gadfly. It doesn\u0026rsquo;t take much exploration to decide that the former is favored by MATLAB veterans and the latter, by R devotees. Confusingly, the general download page for Julia mentions a third package called Plots that is supposed to integrate all of the backends. It\u0026rsquo;s still early days for Julia, and I\u0026rsquo;m sure much remains in flux.\nMoreover, because you can (quite easily) import and run Python code in Julia, in principle you have access to all Python plotting packages. One of the big players is matplotlib, which is more or less what Julia\u0026rsquo;s PyPlot is supposed to provide. But there are also Bokeh, plotly, and pyqtgraph\u0026mdash;for all I know, many more besides. All of these can make gorgeous graphics, often highly interactive and even hosted in the cloud. The relative merits are not at all clear.\nHere we run into the paradox of choice: having many options, even good ones, can provoke anxiety rather than satisfaction. Which package do I invest time in learning? MATLAB limits choice but provides a sort of editorial, almost paternal, reassurance.\nMy personal goal is to learn Julia from the standpoint of a MATLAB user, so PyPlot it is. All in all, the transition isn\u0026rsquo;t bad, though there are some twists.\nIn the last few years I\u0026rsquo;ve been more often turning to automatic function plotting in MATLAB, using fplot, ezsurf, and ezcontour. If PyPlot supports those, I have yet to find out about them. So it\u0026rsquo;s back to the world of evaluating functions on tensor product grids. A MATLAB veteran turns to meshgrid, but Julia supports broadcasting across singleton dimensions. For example:\nusing PyPlot x = linspace(-1,1,90); y = x'; contour(x[:],y[:],sqrt(x.^2 .+ y.^2))\u0026lt;/pre\u0026gt;  Because x has a column shape while y has a row shape, the .+ operator broadcasts each along the \u0026ldquo;missing\u0026rdquo; dimension. It\u0026rsquo;s a clever shortcut once you know it. It works just as well for contours of the vector 1-norm, but for the max norm I had to broadcast manually:\ncontour(x[:],y[:],broadcast(max,abs(x),abs(y)))  It\u0026rsquo;s not clear to me why that broadcast should not happen automatically, given that max is a dedicated elementwise operator.\nThere\u0026rsquo;s more Julia subtlety hiding in this notebook, but those issues will wait for another time.\n","date":1473276766,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1473276766,"objectID":"02695ff484236802faaa143d0150e042","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lecture-3-norms/","publishdate":"2016-09-07T19:32:46Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lecture-3-norms/","section":"post","summary":"Here are the MATLAB and julia notebooks.\nThe big issue this time around was graphics. This topic dramatically illustrates the advantages on both sides of the commercial/open source fence. On the MATLAB side, it\u0026rsquo;s perfectly clear what you should do. There are many options that have been well constructed, and it\u0026rsquo;s all under a relatively consistent umbrella. There are things to learn and options to choose, but it\u0026rsquo;s clear what functions you will be using to make, say, a scatter plot, and a lot of similarity across commands.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia, Lecture 3: Norms","type":"post"},{"authors":null,"categories":["computing","math","teaching"],"content":"Here are the matlab and julia notebooks.\nTwo things stood out this time. First, consider the following snippet.\nu = [ 4; -1; 2+2im ] v = [ -1; 1im; 1 ] println(\u0026quot;dot(u,v) gives \u0026quot;, dot(u,v)) println(\u0026quot;u'*v gives \u0026quot;,u'*v)  The result is\ndot(u,v) gives -2 - 3im u'*v gives Complex{Int64}[-2 - 3im]  Unlike in MATLAB, a scalar is not the same thing as a 1-by-1 matrix. This has consequences. The code (u'*v)*eye(3) throws a dimension mismatch error, while the equivalent with dot is fine. In the strict sense this is correct, and I suppose Julia made a decision to be strict in contrast to MATLAB\u0026rsquo;s typical laxity. The price is that little bump introduced into a transition that is normally seamless in the minds of users and programmers 99% of the time.\nThe other difference is in style more than anything else. Compare MATLAB\u0026rsquo;s\n[Q,~] = qr(A);  to Julia\u0026rsquo;s\nQ = qr(A)[1]  Julia\u0026rsquo;s version would be easier if you wanted to extract the $n$th output, where $n$ is a variable, though you could manage it in MATLAB with cells. I\u0026rsquo;m not sure how common that situation is. Also, it could be a surprise in MATLAB that\nQ=qr(A)  does not do the same thing, because the content and meaning of the outputs depend on the number of outputs.\nA distinction for QR factorization in particular in the two languages is that MATLAB returns the full version by default, while Julia defaults to the skinny form. The latter is nice because an unsuspecting student (or professor) who calls qr(A) in MATLAB for a really tall matrix might as well kill the process and restart MATLAB Julia makes you do something extra to get the memory-dangerous version.\n","date":1472843574,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472843574,"objectID":"09e0520fd29610dd13eb6c1b00cea225","permalink":"https://tobydriscoll.net/blog/trefethen-bau-matlab-julia-lecture-2/","publishdate":"2016-09-02T19:12:54Z","relpermalink":"/blog/trefethen-bau-matlab-julia-lecture-2/","section":"post","summary":"Here are the matlab and julia notebooks.\nTwo things stood out this time. First, consider the following snippet.\nu = [ 4; -1; 2+2im ] v = [ -1; 1im; 1 ] println(\u0026quot;dot(u,v) gives \u0026quot;, dot(u,v)) println(\u0026quot;u'*v gives \u0026quot;,u'*v)  The result is\ndot(u,v) gives -2 - 3im u'*v gives Complex{Int64}[-2 - 3im]  Unlike in MATLAB, a scalar is not the same thing as a 1-by-1 matrix. This has consequences.","tags":null,"title":"Trefethen \u0026 Bau \u0026 MATLAB \u0026 Julia, Lecture 2","type":"post"},{"authors":null,"categories":["computing","teaching"],"content":"Have a look at the MATLAB and Julia versions of the notebooks for this lecture.\nThe first disappointment in Julia comes right at the start: no magic command in Julia! Why not? I love demonstrating with magic square matrices:\n They are instantly familiar or at least understandable to any level of mathematician. They have integer entries and thus display compactly. You can demonstrate sum, transpose, and diag naturally. And getting the \u0026ldquo;antidiagonal\u0026rdquo; sum is a nice exercise. The even-sized ones are singular. They have the memorable eigenvector $[1,\\;1,\\; \\cdots\\; 1]$.  What a shame. I substitute random matrices, which sacrifices some reproducibility. At least the same code would work in MATLAB.\nAnother gotcha comes in line 2: if you create a vector with all integer entries, they are stored as integers. Famously, in MATLAB every number is a complex float unless you specifically declare it otherwise. Julia\u0026rsquo;s approach is standard in computer science, and there are excellent practical reasons for using it. Nor is it difficult to force Julia to use floats. Nevertheless the issue illustrates one of the subtle ways that MATLAB caters to those who are immersed in scientific computing, where pure integer results are rare.\nNext up is a simple but significant change in the syntax: square brackets [ ]for indexing of matrices and vectors. In MATLAB parentheses () serve both this purpose and to make function calls. Julia makes sense to me here. It makes this expression unambiguous:\nF( [1 2 3] )  In MATLAB this could be an access to the first three elements of an array F, or (the Julia meaning) a call to a function F with a vector passed as the first argument. I can\u0026rsquo;t think of a reason to have those different actions be expressed identically. I imagine the clash would complicate parsing code, but that\u0026rsquo;s an area I know nothing about.\nFrom here things settle down. Julia wants me to say 1im rather than 1i or 1j for the imaginary unit; fine. And I must remember to use spaces to separate columns in a matrix construction or concatenation. I often use commas for this in MATLAB. I\u0026rsquo;m a little confused because commas are used to create tuples in Julia, so I would have expected\nx = [ 1, 2, 3 ]  to create (if anything) an array whose single element is the tuple 1,2,3. Instead I get a column vector with entries 1, 2, and 3, which, while a lot more useful, was a small surprise to this newbie.\nEnumerating the differences like this makes the experience sound far more frustrating than I found it to be. It\u0026rsquo;s more like driving a car with a different-feeling clutch than going from an automatic to a manual transmission.\nAnd I really appreciate the Jupyter notebooks! More on them versus the MATLAB Publisher and new Live Editor another time.\n","date":1472759768,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472759768,"objectID":"bd83800dd5173fa193e46630b5eb7680","permalink":"https://tobydriscoll.net/blog/trefethen-bau-lecture-1/","publishdate":"2016-09-01T19:56:08Z","relpermalink":"/blog/trefethen-bau-lecture-1/","section":"post","summary":"Have a look at the MATLAB and Julia versions of the notebooks for this lecture.\nThe first disappointment in Julia comes right at the start: no magic command in Julia! Why not? I love demonstrating with magic square matrices:\n They are instantly familiar or at least understandable to any level of mathematician. They have integer entries and thus display compactly. You can demonstrate sum, transpose, and diag naturally. And getting the \u0026ldquo;antidiagonal\u0026rdquo; sum is a nice exercise.","tags":null,"title":"Trefethen \u0026 Bau, Lecture 1","type":"post"},{"authors":null,"categories":["math","computing","teaching"],"content":"This semester I\u0026rsquo;m teaching MATH 612, which is numerical linear and nonlinear algebra for grad students. Linear algebra dominates the course, and for that I\u0026rsquo;m following the now classic textbook by Trefethen \u0026amp; Bau. This book has real meaning to me because I learned the subject from Nick Trefethen at Cornell, just a year or two before the book was written. It\u0026rsquo;s when numerical analysis became an appealing subject to me.\nThat course is also when I started to learn MATLAB. I\u0026rsquo;ve been using MATLAB for over 20 years and I\u0026rsquo;m damn good at it. I\u0026rsquo;ve written a book that teaches it, and another book largely based on asoftware package I wrote for conformal mapping, and I was an early and key contributor to the Chebfun project. I even dominated a game of MATLAB Jeopardy as a grad student at the 1995 MATLAB Conference (when version 4.2 of MATLAB ruled the Earth).\n(It isn\u0026rsquo;t quite contemporary, but the 1996 home page for the Cornell Center for Applied Mathematics has a banner graphic created in MATLAB\u0026mdash;by yours truly.)\nThe tl;dr is that MATLAB has dominated my professional life since that course. It\u0026rsquo;s still a great tool to use for that course, too\u0026mdash;in my mind, learning the theory and learning the numerics are inextricable. In the context of computing, it\u0026rsquo;s incredible to have a 25-year winning streak!\nBut while the pedagogical value remains as high as ever, MATLAB is a smaller part of the \u0026ldquo;desktop scientific computing\u0026rdquo; landscape than it was. It\u0026rsquo;s still a behemoth, but there are more good options than ever. For some time I have felt neglectful toward options that are similar but different, namely SciPy and Julia. I\u0026rsquo;ve picked up bits and pieces of them, but not enough to do any serious work.\nThus I\u0026rsquo;ve decided to learn Julia the same way I did MATLAB: by using it as we cover elementary numerical linear algebra. The students will still get MATLAB, but I\u0026rsquo;ll be doing Julia in parallel. For each lecture (chapter) of Trefethen \u0026amp; Bau, I\u0026rsquo;ll make two Jupyter notebooks with identical text and two versions of the codes. I\u0026rsquo;m not rewriting T\u0026amp;B, just trying to illustrate some of the concrete ideas and conclusions in each lecture. I\u0026rsquo;m sure my early Julia efforts will be cringeworthy to the cognoscenti, but just as with learning a human language, you have to risk sounding stupid for a while in order to start sounding less stupid. If I can keep up the pace, I\u0026rsquo;ll blog about what I learn about porting to Julia with each new notebook.\n","date":1472756225,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1472756225,"objectID":"8b638f58e568e10dce38b95731e74430","permalink":"https://tobydriscoll.net/blog/trefethen-bau-via-matlab-and-julia/","publishdate":"2016-09-01T18:57:05Z","relpermalink":"/blog/trefethen-bau-via-matlab-and-julia/","section":"post","summary":"This semester I\u0026rsquo;m teaching MATH 612, which is numerical linear and nonlinear algebra for grad students. Linear algebra dominates the course, and for that I\u0026rsquo;m following the now classic textbook by Trefethen \u0026amp; Bau. This book has real meaning to me because I learned the subject from Nick Trefethen at Cornell, just a year or two before the book was written. It\u0026rsquo;s when numerical analysis became an appealing subject to me.","tags":null,"title":"Trefethen \u0026 Bau, via MATLAB and Julia","type":"post"},{"authors":["Lan Zhong","Christiaan F Ketelaar","Richard J Braun","Tobin A Driscoll","Peter Ewen King-Smith","Carolyn G Begley"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"9544ce66031d87047e63455358120978","permalink":"https://tobydriscoll.net/publication/zhong-mathematical-modeling-glob-driven-2016/","publishdate":"2019-06-06T14:48:50.026535Z","relpermalink":"/publication/zhong-mathematical-modeling-glob-driven-2016/","section":"publication","summary":"","tags":null,"title":"Mathematical Modeling of Glob-Driven Tear Film Breakup","type":"publication"},{"authors":["Tobin A Driscoll","Endre Süli","Alex Townsend"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"128f283c1a3d037330eeb95d3a347165","permalink":"https://tobydriscoll.net/publication/driscoll-new-directions-numerical-2016/","publishdate":"2019-06-06T14:48:50.022122Z","relpermalink":"/publication/driscoll-new-directions-numerical-2016/","section":"publication","summary":"","tags":null,"title":"New Directions in Numerical Computation","type":"publication"},{"authors":["Joseph Brosch","Tobin Driscoll","Richard Braun"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"1542a46ff3d8a89888f3aec86b73e8ee","permalink":"https://tobydriscoll.net/publication/brosch-simulation-thin-film-2016/","publishdate":"2019-06-06T14:48:50.009212Z","relpermalink":"/publication/brosch-simulation-thin-film-2016/","section":"publication","summary":"","tags":null,"title":"Simulation of Thin Film Equations on an Eye-Shaped Domain with Moving Boundary","type":"publication"},{"authors":null,"categories":["math","society and culture"],"content":"Something fun for Friday?\nMy older son binge-watched Futurama on Netflix a few months ago. This was one of the funniest shows of at least recent TV history. Especially if you like nerdy, cultural-reference, rapid-fire style humor like a real Gen-Xer.\nIt\u0026rsquo;s also probably the first and only time in television history that a new mathematical theorem was proved for and first presented in a series episode. The whole run of the series had numerous mathematical references. This may have something to do with the fact that co-creator and writer Ken Keeler has a PhD in applied math from Harvard.\n","date":1438359100,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438359100,"objectID":"1b866407dba148c1cade327c0917e130","permalink":"https://tobydriscoll.net/blog/why-not-zoidberg/","publishdate":"2015-07-31T16:11:40Z","relpermalink":"/blog/why-not-zoidberg/","section":"post","summary":"Something fun for Friday?\nMy older son binge-watched Futurama on Netflix a few months ago. This was one of the funniest shows of at least recent TV history. Especially if you like nerdy, cultural-reference, rapid-fire style humor like a real Gen-Xer.\nIt\u0026rsquo;s also probably the first and only time in television history that a new mathematical theorem was proved for and first presented in a series episode. The whole run of the series had numerous mathematical references.","tags":null,"title":"Why not Zoidberg?","type":"post"},{"authors":null,"categories":["computing","matlab"],"content":"I just scratched a MATLAB itch. So many times I\u0026rsquo;ve seen\u0026mdash;and experienced myself\u0026mdash;people popping open figure windows in MATLAB, then trying to juggle them and move them around the screen so that you can see all of them at once. If you know what you\u0026rsquo;re doing, you can dock them into the desktop and lay them out there, but it\u0026rsquo;s still a lot of clicks.\nSo, I present showall.m, a little function that will automatically bring forward all the figures (or the ones you specify) and lay them out in a grid. Now you can master your figures!\n","date":1438290891,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438290891,"objectID":"6c296071db7e11e14de3b3cb480f031a","permalink":"https://tobydriscoll.net/blog/showall/","publishdate":"2015-07-30T21:14:51Z","relpermalink":"/blog/showall/","section":"post","summary":"I just scratched a MATLAB itch. So many times I\u0026rsquo;ve seen\u0026mdash;and experienced myself\u0026mdash;people popping open figure windows in MATLAB, then trying to juggle them and move them around the screen so that you can see all of them at once. If you know what you\u0026rsquo;re doing, you can dock them into the desktop and lay them out there, but it\u0026rsquo;s still a lot of clicks.\nSo, I present showall.m, a little function that will automatically bring forward all the figures (or the ones you specify) and lay them out in a grid.","tags":null,"title":"showall","type":"post"},{"authors":null,"categories":["academia","math","teaching"],"content":"I just received a copy of SIAM News on a dead tree. It features a piece by Chris Johnson and Hans de Sterck about \u0026ldquo;Data Science: What Is It and How Is It Taught?\u0026rdquo; As usual in these articles, I find the specifics more interesting than the generalities of a panel discussion. I really liked this bit about the new program in Computational Modeling and Data Analytics at Virginia Tech:\n In a sense, creating such a program offers the opportunity to rethink curricula on classical topics like calculus that have at many institutions not seen substantial change throughout most of the past century.\n This! Well outside the context of data science, too.\nI\u0026rsquo;m so sick of teaching calculus as though it were still 1960. Not that calculus has changed, of course, but what we need from it has been utterly transformed. In the age of computing, knowledge of calculus is more useful for posing the right questions\u0026mdash;as opposed to getting answers to mindless exercises that can be done in seconds on Wolfram Alpha. Don\u0026rsquo;t even get me started on teaching series convergence tests to engineering freshmen.\nAs far as how to teach data science\u0026hellip;let me figure out how to learn it, first. I\u0026rsquo;m intrigued by this repository as a start.\n  Thanks to @kzawadz for the infographic. Covered by Creative Commons A/NC/SA license.   ","date":1438263393,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438263393,"objectID":"ea44ed67c280f5ffe6d1074654d39e87","permalink":"https://tobydriscoll.net/blog/data-science-data-science/","publishdate":"2015-07-30T13:36:33Z","relpermalink":"/blog/data-science-data-science/","section":"post","summary":"I just received a copy of SIAM News on a dead tree. It features a piece by Chris Johnson and Hans de Sterck about \u0026ldquo;Data Science: What Is It and How Is It Taught?\u0026rdquo; As usual in these articles, I find the specifics more interesting than the generalities of a panel discussion. I really liked this bit about the new program in Computational Modeling and Data Analytics at Virginia Tech:","tags":null,"title":"Data science? Data science!","type":"post"},{"authors":null,"categories":["academia","math"],"content":"Nick Trefethen has posted a wonderful graph showing how the average length of papers published in several SIAM journals has doubled over the last 40 years.\n","date":1438181047,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438181047,"objectID":"f73cb2c30a71bd31cbe5fe9e59cce295","permalink":"https://tobydriscoll.net/blog/length-of-papers/","publishdate":"2015-07-29T14:44:07Z","relpermalink":"/blog/length-of-papers/","section":"post","summary":"Nick Trefethen has posted a wonderful graph showing how the average length of papers published in several SIAM journals has doubled over the last 40 years.","tags":null,"title":"Length of papers","type":"post"},{"authors":null,"categories":["science"],"content":"I\u0026rsquo;m a little late getting this news, but I\u0026rsquo;m fascinated by an experiment at Australian National University showing (once again) in a vivid way how strange the quantum mechanical world is.\nThe experiment was a variation on the celebrated double slit experiment that shows how photons are both particles and waves, at least in some interpretations of the universe. That\u0026rsquo;s freakish in a not-news kind of way, as is the fact that the same is true of good old atoms, which might seem more as though they should stay particular all the time.\nOne amusing view of the ANU experiment is that an atom can \u0026ldquo;decide\u0026rdquo; to be either particle-like or wave-like *based on information from the future.* Just like the restaurant at the end of the universe, that is, of course, impossible.\nIf I were a better physicist I could explain this to you, but in all honesty it was just the lack of intuitiveness about high energy physics (and maybe the contemporaneous demise of the Superconducting Super Collider) that turned me off to the subject as an undergraduate. Still, what a universe to live in, eh Horatio?\n","date":1437700005,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437700005,"objectID":"61384fb6af99ae3ec20d77a1ffa9ad96","permalink":"https://tobydriscoll.net/blog/quantum-weirdness/","publishdate":"2015-07-24T01:06:45Z","relpermalink":"/blog/quantum-weirdness/","section":"post","summary":"I\u0026rsquo;m a little late getting this news, but I\u0026rsquo;m fascinated by an experiment at Australian National University showing (once again) in a vivid way how strange the quantum mechanical world is.\nThe experiment was a variation on the celebrated double slit experiment that shows how photons are both particles and waves, at least in some interpretations of the universe. That\u0026rsquo;s freakish in a not-news kind of way, as is the fact that the same is true of good old atoms, which might seem more as though they should stay particular all the time.","tags":null,"title":"Quantum weirdness","type":"post"},{"authors":null,"categories":["math","teaching"],"content":"I recommend the post What I Wish I Had Learned More About in College Mathematics, written by Sabrina Schmidt, a former math undergrad at Vassar who now works as a data manager. My favorite quote:\n I wish that I had been introduced earlier and more often to applications, as they would have provided me with a better idea of potential areas of specialization after graduation.\n She goes on to mention PageRank (which I usually cover in my numerical computation courses) as an application of linear algebra, and e-commerce as an application of number theory. She also has other STEM courses, statistics, and computer science on her wish list for her former self.\nGood read.\n","date":1437575324,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437575324,"objectID":"1a9737be7d22cc17c0cc62b7bd2d4c79","permalink":"https://tobydriscoll.net/blog/a-retrospective-look-at-college-math/","publishdate":"2015-07-22T14:28:44Z","relpermalink":"/blog/a-retrospective-look-at-college-math/","section":"post","summary":"I recommend the post What I Wish I Had Learned More About in College Mathematics, written by Sabrina Schmidt, a former math undergrad at Vassar who now works as a data manager. My favorite quote:\n I wish that I had been introduced earlier and more often to applications, as they would have provided me with a better idea of potential areas of specialization after graduation.\n She goes on to mention PageRank (which I usually cover in my numerical computation courses) as an application of linear algebra, and e-commerce as an application of number theory.","tags":null,"title":"A retrospective look at college math","type":"post"},{"authors":null,"categories":["teaching"],"content":"In June I attended a MathWorks faculty research summit in Boston. The idea was to bring together academics and industry reps. As one of the very few non-engineers, it didn\u0026rsquo;t give me much fodder for research. But there was a parallel session for educators with a couple of crossover sessions. I spoke in one of those about what I have learned from flipping the classroom in my numerical computation course.\nThe executive summary: Connecting with students in person is the main thing separating me from a MOOC. Major challenges in this particular course are the wide variety of backgrounds of the students, and material that spans advanced mathematics as well as some skill with computer coding. My goal is to teach how to bridge the two, to become fluent enough in both types of thinking to at least know when to go the experts and what to ask. Flipping lets students have time to fill in soft spots in their knowledge while absorbing new material, and to get help from me and their peers while they wrestle with putting new ideas into practice. I have no data on whether they do better in this style of class. (They believe they do a bit better, though like it a bit less.) But I know that I am more engaged, and so I\u0026rsquo;m giving them the best that I have to offer.\n","date":1437400001,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437400001,"objectID":"9323d79a024ad98a18575910dc1b243b","permalink":"https://tobydriscoll.net/blog/flipping-experiences/","publishdate":"2015-07-20T13:46:41Z","relpermalink":"/blog/flipping-experiences/","section":"post","summary":"In June I attended a MathWorks faculty research summit in Boston. The idea was to bring together academics and industry reps. As one of the very few non-engineers, it didn\u0026rsquo;t give me much fodder for research. But there was a parallel session for educators with a couple of crossover sessions. I spoke in one of those about what I have learned from flipping the classroom in my numerical computation course.","tags":null,"title":"Flipping experiences","type":"post"},{"authors":null,"categories":["teaching"],"content":"In keeping with my post on how grades in a course affect student motivation, I\u0026rsquo;ve been pondering alternatives to the classic mean-them-and-mean-it model.\nAll of my family members have spent time studying karate. (I\u0026rsquo;m a brown belt, FYI, which is like an A.B.D.) One thing I\u0026rsquo;ve always liked about the dojos I\u0026rsquo;ve known is how the belt promotion system works. It\u0026rsquo;s what I would now call a mastery based learning concept. Students are tested to advance to the next belt when they are ready, regardless of time spent in the system (of course there are practical limitations on the speed of progression). The tests themselves are rigorous but the results are typically foregone conclusions, by design.\nTruly self-paced mastery learning is difficult to fit into the college grading model. With a technology assist it\u0026rsquo;s possible in topics like pre-calculus and at least some calculus, and probably a few other introductory courses I\u0026rsquo;m not familiar with. I don\u0026rsquo;t see how I could do it in my advanced course this fall.\nI could also think of a more corporate model, which is where most of the students will end up. So the first few weeks would be like an interview to determine the initial job rank (i.e., final grade). Based on performance I would give personal feedback and update their ranks accordingly throughout the term. This goes hand in hand with continuous assessment, which I plan to do anyway.\nBecause the later material in part builds on earlier concepts, I could argue that progress later on could make up for early struggles. In any case students would be free to fight for grade promotions to the very end of the course. Unlike the karate model, demotions are possible, so they couldn\u0026rsquo;t reach an acceptable level and just lay back.\nA radical realization of this concept would include doing away with the numerical grades on each assignment! I admit, that excites me\u0026mdash;I can\u0026rsquo;t stand the arbitrariness of deciding how many \u0026ldquo;points\u0026rdquo; each mistake is worth. I see no reason why a grading rubric can\u0026rsquo;t be precise without being applied quantitively.\nThis would be a huge culture shift for me and for the students. It\u0026rsquo;s risky. I\u0026rsquo;d love to hear opinions and experiences trying to do this sort of thing in math.\n","date":1437140343,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1437140343,"objectID":"80833a48018bc745b7ea1dcb66a1326d","permalink":"https://tobydriscoll.net/blog/promotion-system/","publishdate":"2015-07-17T13:39:03Z","relpermalink":"/blog/promotion-system/","section":"post","summary":"In keeping with my post on how grades in a course affect student motivation, I\u0026rsquo;ve been pondering alternatives to the classic mean-them-and-mean-it model.\nAll of my family members have spent time studying karate. (I\u0026rsquo;m a brown belt, FYI, which is like an A.B.D.) One thing I\u0026rsquo;ve always liked about the dojos I\u0026rsquo;ve known is how the belt promotion system works. It\u0026rsquo;s what I would now call a mastery based learning concept.","tags":null,"title":"Promotion system","type":"post"},{"authors":null,"categories":["teaching"],"content":"Grading is weird in so many ways. In the U.S. system, we report a \u0026ldquo;letter\u0026rdquo; grade that is basically an integer from 0 to 10 or so. This value appears on the student\u0026rsquo;s transcript without comment or context, which is an inherently meaningless way to present any data.\nBut the raw value itself isn\u0026rsquo;t well defined anyway. When I give a student a C+ in calculus, does it mean that she mastered about 75% of the major topics in the course? Or does it mean that she understands about 3\u0026frasl;4 of what is going on in any particular topic? Which of these is preferable? Would a C+ in bicycle riding be enough of a prerequisite to learn how to ride a motorcycle?\nThe closest analog to grades in the real world that I can think of is the annual or quarterly performance review. There are doubts being expressed about these too. In a piece on Bloomberg Business, long-time management consultant Aubrey Daniels says, \u0026ldquo;It’s a sadistic process for what purpose I don’t know\u0026hellip;.Think of a sports team: A coach doesn’t wait until the end of a season to give his players feedback.\u0026rdquo; So, we\u0026rsquo;re coming back around to continuous assessment.\nYet the form of the assessment needs to change too.\nWhat motivates people in the workplace? For one thing, being recognized for their successes. In math we tend to view perfection as the standard, and everything that falls short on homework or exams earns deductions. This is a notably dismal and discouraging viewpoint for learners. It emphasizes the negativity of errors both large and small. When you compare the (hopefully!) flawless and polished solutions on the answer key with your own stumbling attempts, how could you feel anything but foolish? Where is the upside?\nAnother thing that motivates us in the real world is a chance to fix our failures. If you\u0026rsquo;ve scored badly on two midterms in a calculus course, you\u0026rsquo;re probably wise to invest your effort elsewhere. The chances of pulling yourself out of the muck are small, in part because averages are heartless and have perfect memory. I always have disdained grading methods that forgive early bad scores or give \u0026ldquo;extra\u0026rdquo; credit chances, but I have to admit that a system that makes recovery from a bad start seem impossible is no way to maintain motivation.\nI don\u0026rsquo;t have answers yet, but I\u0026rsquo;m thinking about some things. More later.\n","date":1436883785,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436883785,"objectID":"3b347fa18572f8174c8ec4840da3276b","permalink":"https://tobydriscoll.net/blog/grades-and-motivation/","publishdate":"2015-07-14T14:23:05Z","relpermalink":"/blog/grades-and-motivation/","section":"post","summary":"Grading is weird in so many ways. In the U.S. system, we report a \u0026ldquo;letter\u0026rdquo; grade that is basically an integer from 0 to 10 or so. This value appears on the student\u0026rsquo;s transcript without comment or context, which is an inherently meaningless way to present any data.\nBut the raw value itself isn\u0026rsquo;t well defined anyway. When I give a student a C+ in calculus, does it mean that she mastered about 75% of the major topics in the course?","tags":null,"title":"Grades and motivation","type":"post"},{"authors":null,"categories":["math"],"content":"So here I am at the Delaware Bio Breakfast. Nobody is more surprised than I! Making a career out of math seems like an odd path to trying to improve human health, but here I sit.\n","date":1436875203,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436875203,"objectID":"610affa58652eec41468422be4530716","permalink":"https://tobydriscoll.net/blog/bio-breakfast/","publishdate":"2015-07-14T12:00:03Z","relpermalink":"/blog/bio-breakfast/","section":"post","summary":"So here I am at the Delaware Bio Breakfast. Nobody is more surprised than I! Making a career out of math seems like an odd path to trying to improve human health, but here I sit.","tags":null,"title":"Bio breakfast","type":"post"},{"authors":null,"categories":["math","teaching"],"content":"I\u0026rsquo;ve come to think that in math at least, continuous learning and assessment may be more important even than http://www.crlt.umich.edu/tstrategies/tsal. The traditional model of chunking assessments into weekly or monthly batches encourages the cram-and-dump style of \u0026ldquo;learning.\u0026rdquo; Since students are allowed to delay work on assignments that are crucial to their understanding of incoming material, it\u0026rsquo;s impossible for them to build that understanding in real time. Instead they copy and hope to parse later, when assessment is demanded.\nIt\u0026rsquo;s tempting to say that students should suck it up and organize their time better. This attitude ignores human nature, especially the nature of people in late adolescence and early adulthood. Even a large part of my own work is deadline-driven rather than proactive. And I love math!\nAny big change in expectations encounters resistance. Fortunately, breaking through that resistance sometimes spills over into breaking resistance to the tough job of learning itself. The trick is doing so in a way that feels fair to the students and manageable to the instructor. It\u0026rsquo;s hard to overthrow everything at once.\nHere\u0026rsquo;s what I\u0026rsquo;m thinking for my fall course on numerical computing. Each class meeting (3 times a week) has a cycle associated with it:\nBefore class: 1. (them) Read/watch and reflect. 2. (them) Take an online quiz on the new material.\nIn class: 3. (mostly me) Review problem spots. Fill in some of the details. 4. (us) Work to produce one graph or one table relevant to the new material. 5. (them) Turn in a description of what is still not clear.\nAfter class: 6. (me) While everything is fresh, I take one last try at explaining material that is still confusing. 7. (them) Do a couple of homework problems. Before the next meeting, for full credit; before the following meeting, for partial credit.\nAs you can tell, this is a lot of work for everyone, and\u0026ndash;by design\u0026ndash;it\u0026rsquo;s not flexible. To compensate, I won\u0026rsquo;t give exams. There will be some group projects for summative assessments instead.\n","date":1436801146,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436801146,"objectID":"bd9301d6f6cf33f99f96d01bcc4467c4","permalink":"https://tobydriscoll.net/blog/making-continuous-assessment-work/","publishdate":"2015-07-13T15:25:46Z","relpermalink":"/blog/making-continuous-assessment-work/","section":"post","summary":"I\u0026rsquo;ve come to think that in math at least, continuous learning and assessment may be more important even than http://www.crlt.umich.edu/tstrategies/tsal. The traditional model of chunking assessments into weekly or monthly batches encourages the cram-and-dump style of \u0026ldquo;learning.\u0026rdquo; Since students are allowed to delay work on assignments that are crucial to their understanding of incoming material, it\u0026rsquo;s impossible for them to build that understanding in real time. Instead they copy and hope to parse later, when assessment is demanded.","tags":null,"title":"Making continuous assessment work","type":"post"},{"authors":null,"categories":["math"],"content":"Last week my 14-year-old son asked rhetorically, \u0026ldquo;How is it that more people aren\u0026rsquo;t addicted to math?\u0026rdquo;\nI know son, I know.\n","date":1436480240,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1436480240,"objectID":"6bf972831503416348cb4b2d92698960","permalink":"https://tobydriscoll.net/blog/addiction/","publishdate":"2015-07-09T22:17:20Z","relpermalink":"/blog/addiction/","section":"post","summary":"Last week my 14-year-old son asked rhetorically, \u0026ldquo;How is it that more people aren\u0026rsquo;t addicted to math?\u0026rdquo;\nI know son, I know.","tags":null,"title":"Addiction","type":"post"},{"authors":["Lan Zhong","CF Ketelaar","RJ Braun","TA Driscoll","PE King-Smith","Carolyn G Begley"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"5df1446654c0b292102fa50f26c0a1dd","permalink":"https://tobydriscoll.net/publication/zhong-model-problem-blob-driven-2015/","publishdate":"2019-06-06T14:48:50.004779Z","relpermalink":"/publication/zhong-model-problem-blob-driven-2015/","section":"publication","summary":"","tags":null,"title":"A Model Problem for Blob-Driven Tear Film Breakup (TBU)","type":"publication"},{"authors":["Tobin Driscoll"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"e8794c2f1583e74558dea4765a659e8f","permalink":"https://tobydriscoll.net/publication/driscoll-open-source-software-2015/","publishdate":"2019-06-06T14:48:50.002741Z","relpermalink":"/publication/driscoll-open-source-software-2015/","section":"publication","summary":"","tags":null,"title":"An Open Source Software Project for Numerical Conformal Mapping","type":"publication"},{"authors":["Longfei Li","Richard J Braun","Tobin A Driscoll","William D Henshaw","Jeffrey W Banks","P Ewen King-Smith"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"0fc9e0e0b87efac4c402dd0d1a82efef","permalink":"https://tobydriscoll.net/publication/li-computed-tear-film-2015/","publishdate":"2019-06-06T14:48:50.001626Z","relpermalink":"/publication/li-computed-tear-film-2015/","section":"publication","summary":"","tags":null,"title":"Computed Tear Film and Osmolarity Dynamics on an Eye-Shaped Domain","type":"publication"},{"authors":["Michael Stapf","Richard Braun","Carolyn Begley","Tobin Driscoll","Peter Ewen King-Smith"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"e8a058382f83ed501a317afa0559c3f8","permalink":"https://tobydriscoll.net/publication/stapf-modeling-tear-film-2015/","publishdate":"2019-06-06T14:48:50.003818Z","relpermalink":"/publication/stapf-modeling-tear-film-2015/","section":"publication","summary":"","tags":null,"title":"Modeling Tear Film Evaporation and Breakup with Duplex Films","type":"publication"},{"authors":["Tobin A Driscoll","Nicholas Hale"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"e6f65ea73a573c0acce9f327ad2c6e61","permalink":"https://tobydriscoll.net/publication/driscoll-rectangular-spectral-collocation-2015/","publishdate":"2019-06-06T14:48:49.982561Z","relpermalink":"/publication/driscoll-rectangular-spectral-collocation-2015/","section":"publication","summary":"","tags":null,"title":"Rectangular spectral collocation","type":"publication"},{"authors":["RJ Braun","Longfei Li","William Henshaw","Tobin Driscoll","PE King-Smith"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"05f6bfcc962102f756fbb73aa7007071","permalink":"https://tobydriscoll.net/publication/braun-solute-dynamics-imaging-2015/","publishdate":"2019-06-06T14:48:50.007305Z","relpermalink":"/publication/braun-solute-dynamics-imaging-2015/","section":"publication","summary":"","tags":null,"title":"Solute Dynamics and Imaging in the Tear Film on an Eye-Shaped Domain","type":"publication"},{"authors":["Christiaan Ketelaar","Lan Zhong","RJ Braun","TA Driscoll","PE King-Smith","CG Begley"],"categories":null,"content":"","date":1420070400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420070400,"objectID":"2aa9e11848871b0c9825e65d8742b53a","permalink":"https://tobydriscoll.net/publication/ketelaar-tear-film-dynamics-2015/","publishdate":"2019-06-06T14:48:50.005795Z","relpermalink":"/publication/ketelaar-tear-film-dynamics-2015/","section":"publication","summary":"","tags":null,"title":"Tear Film Dynamics Around a Rigid Model Blob","type":"publication"},{"authors":["Tobin A Driscoll","Nicholas Hale","Lloyd N Trefethen"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"6f4957a09aad35a0c209fa50e10510f6","permalink":"https://tobydriscoll.net/publication/driscoll-chebfun-guide-2014/","publishdate":"2019-06-06T14:48:49.995801Z","relpermalink":"/publication/driscoll-chebfun-guide-2014/","section":"publication","summary":"","tags":null,"title":"Chebfun Guide","type":"publication"},{"authors":["Michael McCulloch","Lei Chen","Gilberto Schleiniger","Tobin Driscoll"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"8cfcfc5eb6463c633d931126b05730cd","permalink":"https://tobydriscoll.net/publication/mcculloch-datadrivenmathematical-2014/","publishdate":"2019-06-06T14:48:49.999077Z","relpermalink":"/publication/mcculloch-datadrivenmathematical-2014/","section":"publication","summary":"","tags":null,"title":"DATA DRIVEN MATHEMATICAL MODELING OF THE SINGLE VENTRICLE ANATOMY AND PHYSIOLOGY","type":"publication"},{"authors":["Quan Deng","RJ Braun","Tobin A Driscoll"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"15310bb5661cb4937b141f7f17cfca4e","permalink":"https://tobydriscoll.net/publication/deng-heat-transfer-tear-2014/","publishdate":"2019-06-06T14:48:49.992283Z","relpermalink":"/publication/deng-heat-transfer-tear-2014/","section":"publication","summary":"","tags":null,"title":"Heat Transfer and Tear Film Dynamics over Multiple Blink Cycles","type":"publication"},{"authors":["Tobin A Driscoll","JAC Weideman"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"b04ff28d4f9cc2f6ec200e7338ecec36","permalink":"https://tobydriscoll.net/publication/driscoll-optimal-domain-splitting-2014/","publishdate":"2019-06-06T14:48:49.994266Z","relpermalink":"/publication/driscoll-optimal-domain-splitting-2014/","section":"publication","summary":"","tags":null,"title":"Optimal domain splitting for interpolation by Chebyshev polynomials","type":"publication"},{"authors":["Quan Deng","Richard J Braun","TA Driscoll","P Ewen King-Smith"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"e6e6d8e951bf3e669f4ab83bc06c6c32","permalink":"https://tobydriscoll.net/publication/deng-model-tear-film-2013/","publishdate":"2019-06-06T14:48:49.981763Z","relpermalink":"/publication/deng-model-tear-film-2013/","section":"publication","summary":"","tags":null,"title":"A Model for the Tear Film and Ocular Surface Temperature for Partial Blinks","type":"publication"},{"authors":["Asgeir Birkisson","Tobin A Driscoll"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"17fc0cf9be34b1feba74260b719a7bf9","permalink":"https://tobydriscoll.net/publication/birkisson-automatic-linearity-detection-2013/","publishdate":"2019-06-06T14:48:49.977647Z","relpermalink":"/publication/birkisson-automatic-linearity-detection-2013/","section":"publication","summary":"","tags":null,"title":"Automatic Linearity Detection","type":"publication"},{"authors":["Longfei Li","RJ Braun","TA Driscoll","WD Henshaw","JW Banks","PE King-Smith"],"categories":null,"content":"","date":1356998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1356998400,"objectID":"063b4875af0d8801ede422103ee6cecb","permalink":"https://tobydriscoll.net/publication/li-coupling-osmolarity-dynamics-2013/","publishdate":"2019-06-06T14:48:49.981038Z","relpermalink":"/publication/li-coupling-osmolarity-dynamics-2013/","section":"publication","summary":"","tags":null,"title":"Coupling Osmolarity Dynamics within Human Tear Film on an Eye-Shaped Domain","type":"publication"},{"authors":["Quan Deng","Tobin A Driscoll"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"831c0557037261a4628868ec325e2112","permalink":"https://tobydriscoll.net/publication/deng-fast-treecode-multiquadric-2012-a/","publishdate":"2019-06-06T14:48:49.964322Z","relpermalink":"/publication/deng-fast-treecode-multiquadric-2012-a/","section":"publication","summary":"","tags":null,"title":"A Fast Treecode for Multiquadric Interpolation with Varying Shape Parameters","type":"publication"},{"authors":["Quan Deng","Tobin Driscoll","Richard Braun"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"64e65e2b4e84fe921c26497c325e57a6","permalink":"https://tobydriscoll.net/publication/deng-model-problem-tear-2012/","publishdate":"2019-06-06T14:48:49.973842Z","relpermalink":"/publication/deng-model-problem-tear-2012/","section":"publication","summary":"","tags":null,"title":"A Model Problem for Tear Film Distribution on a Moving Rectangular Domain","type":"publication"},{"authors":["Asgeir Birkisson","Tobin A Driscoll"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"413b6bf7e90112fb3d29557a5f8153d4","permalink":"https://tobydriscoll.net/publication/birkisson-automatic-frechet-differentiation-2012-a/","publishdate":"2019-06-06T14:48:49.939592Z","relpermalink":"/publication/birkisson-automatic-frechet-differentiation-2012-a/","section":"publication","summary":"","tags":null,"title":"Automatic Fréchet Differentiation for the Numerical Solution of Boundary-Value Problems","type":"publication"},{"authors":["Tobin Driscoll"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"c4f6c3a27afadb76491074c34f006a30","permalink":"https://tobydriscoll.net/publication/driscoll-chebfun-pd-es-2012/","publishdate":"2019-06-06T14:48:49.998301Z","relpermalink":"/publication/driscoll-chebfun-pd-es-2012/","section":"publication","summary":"","tags":null,"title":"Chebfun for PDEs","type":"publication"},{"authors":["William M Reid","Tobin A Driscoll","Matthew F Doty"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"0a7fc1507025ce23efad5974f9d980cd","permalink":"https://tobydriscoll.net/publication/reid-forming-delocalized-intermediate-2012-a/","publishdate":"2019-06-06T14:48:49.960415Z","relpermalink":"/publication/reid-forming-delocalized-intermediate-2012-a/","section":"publication","summary":"Experiments and theoretical models suggest that the performance of intermediate band solar cells based on quantum dots (QDs) will be enhanced by the formation of delocalized intermediate bands. However, reasonable device performance has only been achieved when the QD separation is large and energy states are localized to individual QDs. In this paper we analyze the formation of delocalized bands in a realistic QD material that has inhomogeneously distributed energy levels. We calculate the QD uniformity or barrier thickness necessary to create delocalized states in realistic materials and propose a design to create delocalized states while including strain balancing layers.","tags":null,"title":"Forming Delocalized Intermediate States with Realistic Quantum Dots","type":"publication"},{"authors":["RJ Braun","R Usha","GB McFadden","TA Driscoll","LP Cook","Peter Ewen King-Smith"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"936e75a9f06a997c6d651b166b483b97","permalink":"https://tobydriscoll.net/publication/braun-thin-film-dynamics-2012/","publishdate":"2019-06-06T14:48:49.930485Z","relpermalink":"/publication/braun-thin-film-dynamics-2012/","section":"publication","summary":"","tags":null,"title":"Thin Film Dynamics on a Prolate Spheroid with Application to the Cornea","type":"publication"},{"authors":["AMA Neves","TA Driscoll","ARH Heryudono","AJM Ferreira","CMM Soares","RMN Jorge"],"categories":null,"content":"","date":1293840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1293840000,"objectID":"eadb0b90aa66b4c5d0736193b125bf16","permalink":"https://tobydriscoll.net/publication/neves-adaptive-methods-analysis-2011-a/","publishdate":"2019-06-06T14:48:49.94468Z","relpermalink":"/publication/neves-adaptive-methods-analysis-2011-a/","section":"publication","summary":"","tags":null,"title":"Adaptive Methods for Analysis of Composite Plates with Radial Basis Functions","type":"publication"},{"authors":["David C Usher","Tobin A Driscoll","Prasad Dhurjati","John A Pelesko","Louis F Rossi","Gilberto Schleiniger","Kathleen Pusecker","Harold B White"],"categories":null,"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262304000,"objectID":"e851602e9fce6529b3bbe85c81a30488","permalink":"https://tobydriscoll.net/publication/usher-transformative-model-undergraduate-2010-a/","publishdate":"2019-06-06T14:48:49.942396Z","relpermalink":"/publication/usher-transformative-model-undergraduate-2010-a/","section":"publication","summary":"","tags":null,"title":"A Transformative Model for Undergraduate Quantitative Biology Education","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262304000,"objectID":"31e3100197f180fc658219b6f57521c7","permalink":"https://tobydriscoll.net/publication/driscoll-automatic-spectral-collocation-2010-a/","publishdate":"2019-06-06T14:48:49.929659Z","relpermalink":"/publication/driscoll-automatic-spectral-collocation-2010-a/","section":"publication","summary":"","tags":null,"title":"Automatic Spectral Collocation for Integral, Integro-Differential, and Integrally Reformulated Differential Equations","type":"publication"},{"authors":["Alfa RH Heryudono","Tobin A Driscoll"],"categories":null,"content":"","date":1262304000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1262304000,"objectID":"c500b8d901a9678a59146bf3e96cec57","permalink":"https://tobydriscoll.net/publication/heryudono-radial-basis-function-2010-a/","publishdate":"2019-06-06T14:48:49.933244Z","relpermalink":"/publication/heryudono-radial-basis-function-2010-a/","section":"publication","summary":"","tags":null,"title":"Radial Basis Function Interpolation on Irregular Domain through Conformal Transplantation","type":"publication"},{"authors":["LN Trefethen","N Hale","RB Platte","TA Driscoll","R Pachón"],"categories":null,"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230768000,"objectID":"0ceb411772dca80195502998b49f910c","permalink":"https://tobydriscoll.net/publication/trefethen-chebfun-version-2009/","publishdate":"2019-06-06T14:48:49.976775Z","relpermalink":"/publication/trefethen-chebfun-version-2009/","section":"publication","summary":"","tags":null,"title":"Chebfun Version 2","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":1230768000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1230768000,"objectID":"c8c17010311bd52ce1972290781cbf6f","permalink":"https://tobydriscoll.net/publication/driscoll-learning-matlab-2009/","publishdate":"2019-06-06T14:48:49.931294Z","relpermalink":"/publication/driscoll-learning-matlab-2009/","section":"publication","summary":"","tags":null,"title":"Learning MAtlAB","type":"publication"},{"authors":["KL Maki","RJ Braun","TA Driscoll","PE King-Smith"],"categories":null,"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199145600,"objectID":"f2b3eab2ff66d599770e51b2cd931bde","permalink":"https://tobydriscoll.net/publication/maki-overset-grid-method-2008-a/","publishdate":"2019-06-06T14:48:49.925953Z","relpermalink":"/publication/maki-overset-grid-method-2008-a/","section":"publication","summary":"","tags":null,"title":"An Overset Grid Method for the Study of Reflex Tearing","type":"publication"},{"authors":["Thomas K DeLillo","TA Driscoll","Alan R Elcrat","JA Pfaltzgraff"],"categories":null,"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199145600,"objectID":"a1833314ae88da9526a5a4984609d8f3","permalink":"https://tobydriscoll.net/publication/delillo-radial-circular-slit-2008-a/","publishdate":"2019-06-06T14:48:49.928812Z","relpermalink":"/publication/delillo-radial-circular-slit-2008-a/","section":"publication","summary":"","tags":null,"title":"Radial and Circular Slit Maps of Unbounded Multiply Connected Circle Domains","type":"publication"},{"authors":["Richard Braun","Jeff McFadden","Usha Ranganathan","Tobin Driscoll","Ewen King-Smith"],"categories":null,"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199145600,"objectID":"7f2934dd8fa2f8ede30dda016971677e","permalink":"https://tobydriscoll.net/publication/braun-recent-progress-modeling-2008/","publishdate":"2019-06-06T14:48:49.971716Z","relpermalink":"/publication/braun-recent-progress-modeling-2008/","section":"publication","summary":"","tags":null,"title":"Recent Progress on Modeling the Human Tear Film","type":"publication"},{"authors":["Tobin A Driscoll","Folkmar Bornemann","Lloyd N Trefethen"],"categories":null,"content":"","date":1199145600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1199145600,"objectID":"ff1583e40ba4dfea5077d117af5bc9e2","permalink":"https://tobydriscoll.net/publication/driscoll-chebop-system-automatic-2008-a/","publishdate":"2019-06-06T14:48:49.911679Z","relpermalink":"/publication/driscoll-chebop-system-automatic-2008-a/","section":"publication","summary":"","tags":null,"title":"The Chebop System for Automatic Solution of Differential Equations","type":"publication"},{"authors":["Kara L Maki","RJ Braun","TA Driscoll","A Heryudono","PE King-Smith","P Fast"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"b463d8116c7072d64bc8f1c1a7ae65c1","permalink":"https://tobydriscoll.net/publication/maki-overset-grid-method-2007/","publishdate":"2019-06-06T14:48:49.970057Z","relpermalink":"/publication/maki-overset-grid-method-2007/","section":"publication","summary":"","tags":null,"title":"A Overset Grid Method for Fourth Order Evolution Equations of Human Tear Film","type":"publication"},{"authors":["Tobin A Driscoll","Alfa RH Heryudono"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"b383d8590c02a17ca3f8ba0daad2dc1a","permalink":"https://tobydriscoll.net/publication/driscoll-adaptive-residual-subsampling-2007-a/","publishdate":"2019-06-06T14:48:49.898659Z","relpermalink":"/publication/driscoll-adaptive-residual-subsampling-2007-a/","section":"publication","summary":"","tags":null,"title":"Adaptive Residual Subsampling Methods for Radial Basis Function Interpolation and Collocation Problems","type":"publication"},{"authors":["Tobin A Driscoll","Bengt Fornberg"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"83dd80c2f4740a9e05e27a9de3410a8d","permalink":"https://tobydriscoll.net/publication/driscoll-padebased-interpretation-correction-2007/","publishdate":"2019-06-06T14:48:49.943927Z","relpermalink":"/publication/driscoll-padebased-interpretation-correction-2007/","section":"publication","summary":"","tags":null,"title":"Pade-Based Interpretation and Correction of the Gibbs Phenomenon","type":"publication"},{"authors":["Tobin A Driscoll","Kara L Maki"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"9d79bb98a65f298d3c8ecfee5c14dd25","permalink":"https://tobydriscoll.net/publication/driscoll-searching-rare-growth-2007-a/","publishdate":"2019-06-06T14:48:49.927811Z","relpermalink":"/publication/driscoll-searching-rare-growth-2007-a/","section":"publication","summary":"","tags":null,"title":"Searching for Rare Growth Factors Using Multicanonical Monte Carlo Methods","type":"publication"},{"authors":["A Heryudono","RJ Braun","TA Driscoll","KL Maki","LP Cook","PE King-Smith"],"categories":null,"content":"","date":1167609600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167609600,"objectID":"1e26f389447b9b5a546dde9b70c9a91a","permalink":"https://tobydriscoll.net/publication/heryudono-singleequation-models-tear-2007/","publishdate":"2019-06-06T14:48:49.922225Z","relpermalink":"/publication/heryudono-singleequation-models-tear-2007/","section":"publication","summary":"","tags":null,"title":"Single-Equation Models for the Tear Film in a Blink Cycle: Realistic Lid Motion","type":"publication"},{"authors":["Thomas K DeLillo","Tobin A Driscoll","Alan R Elcrat","John A Pfaltzgraff"],"categories":null,"content":"","date":1136073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136073600,"objectID":"0b0cbb962ab7e9143705dbda3230aa7a","permalink":"https://tobydriscoll.net/publication/delillo-computation-multiply-connected-2006-a/","publishdate":"2019-06-06T14:48:49.926865Z","relpermalink":"/publication/delillo-computation-multiply-connected-2006-a/","section":"publication","summary":"","tags":null,"title":"Computation of Multiply Connected Schwarz-Christoffel Maps for Exterior Domains","type":"publication"},{"authors":["Rodrigo B Platte","Tobin A Driscoll"],"categories":null,"content":"","date":1136073600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136073600,"objectID":"951a27f63e87d20d5f24f2907e9e1f43","permalink":"https://tobydriscoll.net/publication/platte-eigenvalue-stability-radial-2006-a/","publishdate":"2019-06-06T14:48:49.906742Z","relpermalink":"/publication/platte-eigenvalue-stability-radial-2006-a/","section":"publication","summary":"","tags":null,"title":"Eigenvalue Stability of Radial Basis Function Discretizations for Time-Dependent Problems","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":1104537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1104537600,"objectID":"40de731aef607e2912f09db7516674f1","permalink":"https://tobydriscoll.net/publication/driscoll-algorithm-843-improvements-2005/","publishdate":"2019-06-06T14:48:49.913121Z","relpermalink":"/publication/driscoll-algorithm-843-improvements-2005/","section":"publication","summary":"","tags":null,"title":"Algorithm 843: Improvements to the Schwarz-Christoffel Toolbox for MATLAB","type":"publication"},{"authors":["Rodrigo B Platte","Tobin A Driscoll"],"categories":null,"content":"","date":1104537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1104537600,"objectID":"c5ce5ce269b9f08f175d2f275370051c","permalink":"https://tobydriscoll.net/publication/platte-polynomials-potential-theory-2005-a/","publishdate":"2019-06-06T14:48:49.90581Z","relpermalink":"/publication/platte-polynomials-potential-theory-2005-a/","section":"publication","summary":"","tags":null,"title":"Polynomials and Potential Theory for Gaussian Radial Basis Function Interpolation","type":"publication"},{"authors":["John A Pelesko","Tobin A Driscoll"],"categories":null,"content":"","date":1104537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1104537600,"objectID":"ea55d166072f0f6a796e0eb5d135776a","permalink":"https://tobydriscoll.net/publication/pelesko-effect-smallaspectratio-approximation-2005/","publishdate":"2019-06-06T14:48:49.924135Z","relpermalink":"/publication/pelesko-effect-smallaspectratio-approximation-2005/","section":"publication","summary":"","tags":null,"title":"The Effect of the Small-Aspect-Ratio Approximation on Canonical Electrostatic MEMS Models","type":"publication"},{"authors":["Tobin Driscoll"],"categories":null,"content":"","date":1072915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1072915200,"objectID":"de948412393056a0d7948b2b56334a2d","permalink":"https://tobydriscoll.net/publication/driscoll-practical-guide-boundary-2004/","publishdate":"2019-06-06T14:48:49.965588Z","relpermalink":"/publication/driscoll-practical-guide-boundary-2004/","section":"publication","summary":"","tags":null,"title":"A Practical Guide to Boundary Element Methods With the Software Library BEMLIB. By C. P OZRIKIDIS. CRC Press, 2002. 440 Pp. ISBN 1584 883235. $99.95 (Hardback)","type":"publication"},{"authors":["Tobin A Driscoll","John A Pelesko"],"categories":null,"content":"","date":1072915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1072915200,"objectID":"260f445637351f28d61b87e399b4ab57","permalink":"https://tobydriscoll.net/publication/driscoll-approximations-canonical-electrostatic-2004/","publishdate":"2019-06-06T14:48:49.941391Z","relpermalink":"/publication/driscoll-approximations-canonical-electrostatic-2004/","section":"publication","summary":"","tags":null,"title":"Approximations in Canonical Electrostatic MEMS Models","type":"publication"},{"authors":["Rodrigo B Platte","Tobin A Driscoll"],"categories":null,"content":"","date":1072915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1072915200,"objectID":"8bad48e9c4277bd2682900ed2b6f455e","permalink":"https://tobydriscoll.net/publication/platte-computing-eigenmodes-elliptic-2004-a/","publishdate":"2019-06-06T14:48:49.902551Z","relpermalink":"/publication/platte-computing-eigenmodes-elliptic-2004-a/","section":"publication","summary":"","tags":null,"title":"Computing Eigenmodes of Elliptic Operators Using Radial Basis Functions","type":"publication"},{"authors":["Charles R Collins","Tobin A Driscoll","Kenneth Stephenson"],"categories":null,"content":"","date":1072915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1072915200,"objectID":"d11b417f131997cd9962275842bc42a1","permalink":"https://tobydriscoll.net/publication/collins-curvature-flow-conformal-2004/","publishdate":"2019-06-06T14:48:49.932351Z","relpermalink":"/publication/collins-curvature-flow-conformal-2004/","section":"publication","summary":"","tags":null,"title":"Curvature Flow in Conformal Mapping","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":1041379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1041379200,"objectID":"c856990c19e88cde0a4db5505e8987ec","permalink":"https://tobydriscoll.net/publication/driscoll-crash-course-matlab-2003/","publishdate":"2019-06-06T14:48:49.936489Z","relpermalink":"/publication/driscoll-crash-course-matlab-2003/","section":"publication","summary":"","tags":null,"title":"A Crash Course in Matlab","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":1041379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1041379200,"objectID":"cfa73b914479eb5e255e4e6202245119","permalink":"https://tobydriscoll.net/publication/driscoll-improved-schwarz-chrisoffel-toolbox-2003/","publishdate":"2019-06-06T14:48:49.946532Z","relpermalink":"/publication/driscoll-improved-schwarz-chrisoffel-toolbox-2003/","section":"publication","summary":"","tags":null,"title":"An Improved Schwarz-Chrisoffel Toolbox for MATLAB","type":"publication"},{"authors":["Tobin A Driscoll","HPW Gottlieb"],"categories":null,"content":"","date":1041379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1041379200,"objectID":"5417255900569f5817fe1e7752c8c308","permalink":"https://tobydriscoll.net/publication/driscoll-isospectral-shapes-neumann-2003-a/","publishdate":"2019-06-06T14:48:49.925032Z","relpermalink":"/publication/driscoll-isospectral-shapes-neumann-2003-a/","section":"publication","summary":"","tags":null,"title":"Isospectral Shapes with Neumann and Alternating Boundary Conditions","type":"publication"},{"authors":["Tobin Driscoll","Louis Rossi"],"categories":null,"content":"","date":1041379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1041379200,"objectID":"9c2016ad08fa599943f708e82e14e7f0","permalink":"https://tobydriscoll.net/publication/driscoll-numerical-examination-model-2003/","publishdate":"2019-06-06T14:48:49.968161Z","relpermalink":"/publication/driscoll-numerical-examination-model-2003/","section":"publication","summary":"","tags":null,"title":"Numerical Examination of a Model of Thermo-Acoustic Instabilites in Lean, Pre-Mixed Combustors.","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":1009843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1009843200,"objectID":"ce9d1d60ec1ce9c92515f64101602760","permalink":"https://tobydriscoll.net/publication/driscoll-composite-runge-kutta-2002-a/","publishdate":"2019-06-06T14:48:49.910363Z","relpermalink":"/publication/driscoll-composite-runge-kutta-2002-a/","section":"publication","summary":"","tags":null,"title":"A Composite Runge–Kutta Method for the Spectral Solution of Semilinear PDEs","type":"publication"},{"authors":["Tobin A Driscoll","Bengt Fornberg"],"categories":null,"content":"","date":1009843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1009843200,"objectID":"e1ae73c74ae1bdcf7b1ba4fe0e303898","permalink":"https://tobydriscoll.net/publication/driscoll-interpolation-limit-increasingly-2002-a/","publishdate":"2019-06-06T14:48:49.892998Z","relpermalink":"/publication/driscoll-interpolation-limit-increasingly-2002-a/","section":"publication","summary":"","tags":null,"title":"Interpolation in the Limit of Increasingly Flat Radial Basis Functions","type":"publication"},{"authors":["Bengt Fornberg","Tobin A Driscoll","Grady Wright","Richard Charles"],"categories":null,"content":"","date":1009843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1009843200,"objectID":"40357fd9899430341cad5e68adb1b9c9","permalink":"https://tobydriscoll.net/publication/fornberg-observations-behavior-radial-2002-a/","publishdate":"2019-06-06T14:48:49.895807Z","relpermalink":"/publication/fornberg-observations-behavior-radial-2002-a/","section":"publication","summary":"","tags":null,"title":"Observations on the Behavior of Radial Basis Function Approximations near Boundaries","type":"publication"},{"authors":["Tobin A Driscoll","Lloyd N Trefethen"],"categories":null,"content":"","date":1009843200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1009843200,"objectID":"a47aa0df5f96b3a6f2d2096552b28e4e","permalink":"https://tobydriscoll.net/publication/driscoll-schwarz-christoffel-mapping-2002/","publishdate":"2019-06-06T14:48:49.97531Z","relpermalink":"/publication/driscoll-schwarz-christoffel-mapping-2002/","section":"publication","summary":"","tags":null,"title":"Schwarz–Christoffel Mapping","type":"publication"},{"authors":["Michele Goano","Francesco Bertazzi","Paolo Caravelli","Giovanni Ghione","Tobin A Driscoll"],"categories":null,"content":"","date":978307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":978307200,"objectID":"a35e9aa8d7f3f9ad29804e1af5e28211","permalink":"https://tobydriscoll.net/publication/goano-general-conformalmapping-approach-2001-a/","publishdate":"2019-06-06T14:48:49.903536Z","relpermalink":"/publication/goano-general-conformalmapping-approach-2001-a/","section":"publication","summary":"","tags":null,"title":"A General Conformal-Mapping Approach to the Optimum Electrode Design of Coplanar Waveguides with Arbitrary Cross Section","type":"publication"},{"authors":["Tobin A Driscoll","Bengt Fornberg"],"categories":null,"content":"","date":978307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":978307200,"objectID":"c7d6d13858a07555bd7239cf8d2284e9","permalink":"https://tobydriscoll.net/publication/driscoll-padebased-algorithm-overcoming-2001-a/","publishdate":"2019-06-06T14:48:49.897625Z","relpermalink":"/publication/driscoll-padebased-algorithm-overcoming-2001-a/","section":"publication","summary":"","tags":null,"title":"A Padé-Based Algorithm for Overcoming the Gibbs Phenomenon","type":"publication"},{"authors":["Tobin A Driscoll","Bengt Fornberg"],"categories":null,"content":"","date":946684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":946684800,"objectID":"7e024051d07a5a41467f4deedeaf50e6","permalink":"https://tobydriscoll.net/publication/driscoll-note-nonsymmetric-finite-2000/","publishdate":"2019-06-06T14:48:49.940513Z","relpermalink":"/publication/driscoll-note-nonsymmetric-finite-2000/","section":"publication","summary":"","tags":null,"title":"Note on Nonsymmetric Finite Differences for Maxwell's Equations","type":"publication"},{"authors":["Michelle Ghrist","Bengt Fornberg","Tobin A Driscoll"],"categories":null,"content":"","date":946684800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":946684800,"objectID":"0372a1a998dfb62c6152f5cd02cf8b9b","permalink":"https://tobydriscoll.net/publication/ghrist-staggered-time-integrators-2000-a/","publishdate":"2019-06-06T14:48:49.901439Z","relpermalink":"/publication/ghrist-staggered-time-integrators-2000-a/","section":"publication","summary":"","tags":null,"title":"Staggered Time Integrators for Wave Equations","type":"publication"},{"authors":["Bengt Fornberg","Tobin A Driscoll"],"categories":null,"content":"","date":915148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":915148800,"objectID":"92fcf3879eebe9e40d7e58abec9879dd","permalink":"https://tobydriscoll.net/publication/fornberg-fast-spectral-algorithm-1999-a/","publishdate":"2019-06-06T14:48:49.894773Z","relpermalink":"/publication/fornberg-fast-spectral-algorithm-1999-a/","section":"publication","summary":"","tags":null,"title":"A Fast Spectral Algorithm for Nonlinear Wave Equations with Linear Dispersion","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":915148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":915148800,"objectID":"05b6cd21ec3a7542905378bcd244c88a","permalink":"https://tobydriscoll.net/publication/driscoll-nonoverlapping-domain-decomposition-1999-a/","publishdate":"2019-06-06T14:48:49.934514Z","relpermalink":"/publication/driscoll-nonoverlapping-domain-decomposition-1999-a/","section":"publication","summary":"","tags":null,"title":"A Nonoverlapping Domain Decomposition Method for Symm's Equation for Conformal Mapping","type":"publication"},{"authors":["Tobin A Driscoll","Bengt Fornberg"],"categories":null,"content":"","date":915148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":915148800,"objectID":"9c68e17a1584e8ad28853c6959d83865","permalink":"https://tobydriscoll.net/publication/driscoll-block-pseudospectral-methods-1999/","publishdate":"2019-06-06T14:48:49.915525Z","relpermalink":"/publication/driscoll-block-pseudospectral-methods-1999/","section":"publication","summary":"","tags":null,"title":"Block Pseudospectral Methods for Maxwell's Equations II: Two-Dimensional, Discontinuous-Coefficient Case","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":915148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":915148800,"objectID":"4b895344569c664ab62a1e6165a7b398","permalink":"https://tobydriscoll.net/publication/driscoll-computational-conformal-mapping-1999/","publishdate":"2019-06-06T14:48:50.021353Z","relpermalink":"/publication/driscoll-computational-conformal-mapping-1999/","section":"publication","summary":"","tags":null,"title":"Computational Conformal Mapping (Book Review)","type":"publication"},{"authors":["Tobin A Driscoll","Bengt Fornberg"],"categories":null,"content":"","date":883612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":883612800,"objectID":"6ae22d7b67ff9ab24301f381e148d237","permalink":"https://tobydriscoll.net/publication/driscoll-block-pseudospectral-method-1998-a/","publishdate":"2019-06-06T14:48:49.909188Z","relpermalink":"/publication/driscoll-block-pseudospectral-method-1998-a/","section":"publication","summary":"","tags":null,"title":"A Block Pseudospectral Method for Maxwell's Equations: I. One-Dimensional Case","type":"publication"},{"authors":["Tobin A Driscoll","Kim-Chuan Toh","Lloyd N Trefethen"],"categories":null,"content":"","date":883612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":883612800,"objectID":"7b42797755229454c69831dad299ba1e","permalink":"https://tobydriscoll.net/publication/driscoll-potential-theory-matrix-1998-a/","publishdate":"2019-06-06T14:48:49.896665Z","relpermalink":"/publication/driscoll-potential-theory-matrix-1998-a/","section":"publication","summary":"","tags":null,"title":"From Potential Theory to Matrix Iterations in Six Steps","type":"publication"},{"authors":["Tobin A Driscoll","Stephen A Vavasis"],"categories":null,"content":"","date":883612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":883612800,"objectID":"484b81df87ba09d9d4cfb42e2fb5a78d","permalink":"https://tobydriscoll.net/publication/driscoll-numerical-conformal-mapping-1998-a/","publishdate":"2019-06-06T14:48:49.900447Z","relpermalink":"/publication/driscoll-numerical-conformal-mapping-1998-a/","section":"publication","summary":"","tags":null,"title":"Numerical Conformal Mapping Using Cross-Ratios and Delaunay Triangulation","type":"publication"},{"authors":["Lloyd N Trefethen","Tobin A Driscoll"],"categories":null,"content":"","date":883612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":883612800,"objectID":"482e0b1238d28d97cb871876affb16e5","permalink":"https://tobydriscoll.net/publication/trefethen-schwarz-christoffel-mapping-computer-1998/","publishdate":"2019-06-06T14:48:49.918901Z","relpermalink":"/publication/trefethen-schwarz-christoffel-mapping-computer-1998/","section":"publication","summary":"","tags":null,"title":"Schwarz-Christoffel Mapping in the Computer Era","type":"publication"},{"authors":["Tobin A Driscoll","Bengt Fornberg"],"categories":null,"content":"","date":883612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":883612800,"objectID":"6ebc62ccba2e850c5f4750b307d8c61a","permalink":"https://tobydriscoll.net/publication/driscoll-uses-berenger-pml-1998/","publishdate":"2019-06-06T14:48:49.969169Z","relpermalink":"/publication/driscoll-uses-berenger-pml-1998/","section":"publication","summary":"","tags":null,"title":"Uses of the Berenger PML in Pseudospectral Methods for Maxwell's Equations","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":852076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":852076800,"objectID":"1df1b153ae0960c06f1c88d7b0b12b13","permalink":"https://tobydriscoll.net/publication/driscoll-eigenmodes-isospectral-drums-1997-a/","publishdate":"2019-06-06T14:48:49.899497Z","relpermalink":"/publication/driscoll-eigenmodes-isospectral-drums-1997-a/","section":"publication","summary":"","tags":null,"title":"Eigenmodes of Isospectral Drums","type":"publication"},{"authors":["G Wojcik","B Fomberg","R Waag","L Carcione","J Mould","L Nikodym","T Driscoll"],"categories":null,"content":"","date":852076800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":852076800,"objectID":"c55f7dfaeba11f049bb4e02dcc333c3a","permalink":"https://tobydriscoll.net/publication/wojcik-pseudospectral-methods-largescale-1997/","publishdate":"2019-06-06T14:48:49.904503Z","relpermalink":"/publication/wojcik-pseudospectral-methods-largescale-1997/","section":"publication","summary":"","tags":null,"title":"Pseudospectral Methods for Large-Scale Bioacoustic Models","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":820454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":820454400,"objectID":"ce9203ac347848c4194d4fadfb641365","permalink":"https://tobydriscoll.net/publication/driscoll-algorithm-756-matlab-1996/","publishdate":"2019-06-06T14:48:49.892338Z","relpermalink":"/publication/driscoll-algorithm-756-matlab-1996/","section":"publication","summary":"","tags":null,"title":"Algorithm 756: A MATLAB Toolbox for Schwarz-Christoffel Mapping","type":"publication"},{"authors":["Tobin Allen Driscoll"],"categories":null,"content":"","date":820454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":820454400,"objectID":"cc3ec668d476223bb4df1ef0244e52fb","permalink":"https://tobydriscoll.net/publication/driscoll-domain-decomposition-methods-1996/","publishdate":"2019-06-06T14:48:49.972458Z","relpermalink":"/publication/driscoll-domain-decomposition-methods-1996/","section":"publication","summary":"","tags":null,"title":"Domain Decomposition Methods for Conformal Mapping and Eigenvalue Problems","type":"publication"},{"authors":["Tobin A Driscoll","Kim-Chuan Toh","Lloyd N Trefethen"],"categories":null,"content":"","date":820454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":820454400,"objectID":"a9468eea9881b0e28ac641dcee28b800","permalink":"https://tobydriscoll.net/publication/driscoll-matrix-iterations-six-1996/","publishdate":"2019-06-06T14:48:49.935524Z","relpermalink":"/publication/driscoll-matrix-iterations-six-1996/","section":"publication","summary":"","tags":null,"title":"Matrix Iterations: The Six Gaps between Potential Theory and Convergence","type":"publication"},{"authors":["Stephen A Vavasis"],"categories":null,"content":"","date":820454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":820454400,"objectID":"b6c89698220a7971198bf137550aaa72","permalink":"https://tobydriscoll.net/publication/vavasis-numerical-conformal-mapping-1996/","publishdate":"2019-06-06T14:48:50.008411Z","relpermalink":"/publication/vavasis-numerical-conformal-mapping-1996/","section":"publication","summary":"","tags":null,"title":"Numerical Conformal Mapping Using Cross-Ratios and Delaunay Triangulation","type":"publication"},{"authors":["Tobin A Driscoll","Lloyd N Trefethen"],"categories":null,"content":"","date":820454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":820454400,"objectID":"ec9226944ba2e41c14bdda89a6cb2c63","permalink":"https://tobydriscoll.net/publication/driscoll-pseudospectra-wave-equation-1996-a/","publishdate":"2019-06-06T14:48:49.920956Z","relpermalink":"/publication/driscoll-pseudospectra-wave-equation-1996-a/","section":"publication","summary":"","tags":null,"title":"Pseudospectra for the Wave Equation with an Absorbing Boundary","type":"publication"},{"authors":["Jeffrey S Baggett","Tobin A Driscoll","Lloyd N Trefethen"],"categories":null,"content":"","date":788918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":788918400,"objectID":"18795df99d3ca3bc5279db2297ffe662","permalink":"https://tobydriscoll.net/publication/baggett-mostly-linear-model-1995/","publishdate":"2019-06-06T14:48:49.893758Z","relpermalink":"/publication/baggett-mostly-linear-model-1995/","section":"publication","summary":"","tags":null,"title":"A Mostly Linear Model of Transition to Turbulence","type":"publication"},{"authors":["TA Driscoll","LN Trefethen"],"categories":null,"content":"","date":757382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":757382400,"objectID":"1ba82e41cb2ba2f561ddb2f5ed0bc4df","permalink":"https://tobydriscoll.net/publication/driscoll-conformal-mapping-convergence-1994/","publishdate":"2019-06-06T14:48:49.997263Z","relpermalink":"/publication/driscoll-conformal-mapping-convergence-1994/","section":"publication","summary":"","tags":null,"title":"Conformal Mapping and Convergence of Krylov Iterations","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":757382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":757382400,"objectID":"b5d834cee0c0530d3779c6a41f58ec01","permalink":"https://tobydriscoll.net/publication/driscoll-schwarz-christoffel-toolbox-user-1994/","publishdate":"2019-06-06T14:48:49.937553Z","relpermalink":"/publication/driscoll-schwarz-christoffel-toolbox-user-1994/","section":"publication","summary":"","tags":null,"title":"Schwarz-Christoffel Toolbox User's Guide","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":757382400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":757382400,"objectID":"e41a1e0a229d6cdd474e6f6965102490","permalink":"https://tobydriscoll.net/publication/driscoll-schwarz-christoffel-toolbox-matlab-1994/","publishdate":"2019-06-06T14:48:49.907797Z","relpermalink":"/publication/driscoll-schwarz-christoffel-toolbox-matlab-1994/","section":"publication","summary":"","tags":null,"title":"Schwarz-Christoffel Toolbox for MATLAB","type":"publication"},{"authors":["JOHN E DZIELSKI","TOBIN A DRISCOLL"],"categories":null,"content":"","date":725846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":725846400,"objectID":"d04428c8f52307ef5f017964ad16d6d5","permalink":"https://tobydriscoll.net/publication/dzielski-error-bound-solution-1993-a/","publishdate":"2019-06-06T14:48:49.980224Z","relpermalink":"/publication/dzielski-error-bound-solution-1993-a/","section":"publication","summary":"","tags":null,"title":"Error Bound on the Solution of a Linear Differential Equation in Chebyshev Series","type":"publication"},{"authors":["Lloyd N Trefethen","Anne E Trefethen","Satish C Reddy","Tobin A Driscoll"],"categories":null,"content":"","date":725846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":725846400,"objectID":"bf61b7d802d9dad26dac0f6aa2391e0b","permalink":"https://tobydriscoll.net/publication/trefethen-hydrodynamic-stability-eigenvalues-1993-a/","publishdate":"2019-06-06T14:48:49.891195Z","relpermalink":"/publication/trefethen-hydrodynamic-stability-eigenvalues-1993-a/","section":"publication","summary":"","tags":null,"title":"Hydrodynamic Stability without Eigenvalues","type":"publication"},{"authors":["Tobin A Driscoll","Lloyd N Trefethen"],"categories":null,"content":"","date":725846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":725846400,"objectID":"795c8a695bd554239a0930e74f3f6013","permalink":"https://tobydriscoll.net/publication/driscoll-pseudospectra-wave-operator-1993/","publishdate":"2019-06-06T14:48:49.938832Z","relpermalink":"/publication/driscoll-pseudospectra-wave-operator-1993/","section":"publication","summary":"","tags":null,"title":"Pseudospectra of the Wave Operator with an Absorbing Boundary","type":"publication"},{"authors":["Lloyd N Trefethen","Anne E Trefethen","Satish C Reddy","Tobin A Driscoll"],"categories":null,"content":"","date":694224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":694224000,"objectID":"7f3ff69379e16484a92ceda7e2d10de9","permalink":"https://tobydriscoll.net/publication/trefethen-new-direction-hydrodynamic-1992/","publishdate":"2019-06-06T14:48:49.923197Z","relpermalink":"/publication/trefethen-new-direction-hydrodynamic-1992/","section":"publication","summary":"","tags":null,"title":"A New Direction in Hydrodynamic Stability: Beyond Eigenvalues","type":"publication"},{"authors":["TA Driscoll","JE Dzielski"],"categories":null,"content":"","date":694224000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":694224000,"objectID":"310257ffdd87c32a591b7c58ac5ef83a","permalink":"https://tobydriscoll.net/publication/driscoll-computational-efficiency-functional-1992/","publishdate":"2019-06-06T14:48:49.974578Z","relpermalink":"/publication/driscoll-computational-efficiency-functional-1992/","section":"publication","summary":"","tags":null,"title":"Computational Efficiency of a Functional Expansion Algorithm for Linear Quadratic Optimal Control","type":"publication"},{"authors":["Tobin A Driscoll"],"categories":null,"content":"","date":662688000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":662688000,"objectID":"3d1c414e719c63ffd730adba0108f242","permalink":"https://tobydriscoll.net/publication/driscoll-comparison-computational-efficiency-1991/","publishdate":"2019-06-06T14:48:50.015559Z","relpermalink":"/publication/driscoll-comparison-computational-efficiency-1991/","section":"publication","summary":"","tags":null,"title":"Comparison of Computational Efficiency and Sensitivity of Several Solution Algorithms for the Linear-Quadratic Optimal Control Problem","type":"publication"}]