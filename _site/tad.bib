@book{1994a,
  title = {Generatingfunctionology},
  author = {Wilf, H. S.},
  year = {1994},
  publisher = {{Elsevier}},
  doi = {10.1016/c2009-0-02369-1},
  file = {/Users/driscoll/Dropbox/library/Book/Wilf_1994_generatingfunctionology.pdf}
}

@article{1996a,
  title = {Table of Contents},
  author = {Middendorf, Joan and Kalish, Alan},
  year = {1996},
  month = feb,
  journal = {The National Teaching {{\&}} Learning Forum},
  volume = {5},
  number = {2},
  pages = {1--12},
  publisher = {{Wiley-Blackwell}},
  doi = {10.1002/ntlf.10026},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Middendorf_Kalish_1996_Table of contents.pdf}
}

@book{2000a,
  title = {How People Learn},
  year = {2000},
  month = aug,
  publisher = {{National Academies Press}},
  doi = {10.17226/9853},
  file = {/Users/driscoll/Dropbox/library/Book/2000_How people learn.pdf}
}

@article{Abelson_Breaking_2007,
  title = {Breaking down the Blink},
  author = {Abelson, Mark B and Walker, Pamela},
  year = {2007},
  keywords = {No DOI found}
}

@book{abramowitzHandbookMathematicalFunctions2013,
  title = {Handbook of Mathematical Functions: With Formulas, Graphs, and Mathematical Tables},
  shorttitle = {Handbook of Mathematical Functions},
  editor = {Abramowitz, Milton and Stegun, Irene A.},
  year = {2013},
  series = {Dover Books on Mathematics},
  edition = {9. Dover print.; [Nachdr. der Ausg. von 1972]},
  publisher = {{Dover Publ}},
  address = {{New York, NY}},
  isbn = {978-0-486-61272-0},
  langid = {english},
  annotation = {OCLC: 935935300}
}

@article{AdcockAdaptiveSampling2022,
  title = {An {{Adaptive}} Sampling and Domain Learning Strategy for Multivariate Function Approximation on Unknown Domains},
  author = {Adcock, Ben and Cardenas, Juan M. and Dexter, Nick},
  year = {2022},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2202.00144},
  urldate = {2024-02-26},
  abstract = {Many problems in computational science and engineering can be described in terms of approximating a smooth function of \$d\$ variables, defined over an unknown domain of interest \${\textohm}{\textbackslash}subset {\textbackslash}mathbb\{R\}\^{}d\$, from sample data. Here both the curse of dimensionality (\$d{\textbackslash}gg 1\$) and the lack of domain knowledge with \${\textohm}\$ potentially irregular and/or disconnected are confounding factors for sampling-based methods. Na\"{\i}ve approaches often lead to wasted samples and inefficient approximation schemes. For example, uniform sampling can result in upwards of 20{\textbackslash}\% wasted samples in some problems. In surrogate model construction in computational uncertainty quantification (UQ), the high cost of computing samples needs a more efficient sampling procedure. In the last years, methods for computing such approximations from sample data have been studied in the case of irregular domains. The advantages of computing sampling measures depending on an approximation space \$P\$ of \${\textbackslash}dim(P)=N\$ have been shown. In particular, such methods confer advantages such as stability and well-conditioning, with \${\textbackslash}mathcal\{O\}(N{\textbackslash}log(N))\$ as sample complexity. The recently-proposed adaptive sampling for general domains (ASGD) strategy is one method to construct these sampling measures. The main contribution of this paper is to improve ASGD by adaptively updating the sampling measures over unknown domains. We achieve this by first introducing a general domain adaptivity strategy (GDAS), which approximates the function and domain of interest from sample points. Second, we propose adaptive sampling for unknown domains (ASUD), which generates sampling measures over a domain that may not be known in advance. Our results show that the ASUD approach consistently achieves the same or smaller errors as uniform sampling, but using fewer, and often significantly fewer evaluations.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Mathematics,Numerical Analysis (math.NA)}
}

@article{AdcockAdaptiveSampling2023,
  title = {An {{Adaptive Sampling}} and {{Domain Learning Strategy}} for {{Multivariate Function Approximation}} on {{Unknown Domains}}},
  author = {Adcock, Ben and Cardenas, Juan M. and Dexter, Nick},
  year = {2023},
  month = feb,
  journal = {SIAM Journal on Scientific Computing},
  volume = {45},
  number = {1},
  pages = {A200-A225},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/22M1472693},
  urldate = {2023-04-26},
  abstract = {In this paper, we address the problem of approximating a multivariate function defined on a general domain in \$d\$ dimensions from sample points.  We consider weighted least-squares approximation in an arbitrary finite-dimensional space \$P\$ from independent random samples taken according to a suitable measure. In general, least-squares approximations can be inaccurate and ill-conditioned when the number of sample points \$M\$ is close to \$N = {\textbackslash}dim(P)\$. To counteract this, we introduce a novel method for sampling in general domains which leads to provably accurate and well-conditioned approximations.  The resulting sampling measure is discrete and therefore straightforward to sample from.  Our main result shows near-optimal sample complexity for this procedure; specifically, \$M = {\textbackslash}mathcal\{O\}(N {\textbackslash}log(N))\$ samples suffice for a well-conditioned and accurate approximation.  Numerical experiments on polynomial approximation in general domains confirm the benefits of this method over standard sampling.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Adcock et al_2023_An Adaptive Sampling and Domain Learning Strategy for Multivariate Function.pdf}
}

@misc{adcockCompressedSensingApproaches2017,
  title = {Compressed Sensing Approaches for Polynomial Approximation of High-Dimensional Functions},
  author = {Adcock, Ben and Brugiapaglia, Simone and Webster, Clayton G.},
  year = {2017},
  month = jun,
  number = {arXiv:1703.06987},
  eprint = {1703.06987},
  primaryclass = {math},
  publisher = {{arXiv}},
  urldate = {2022-07-11},
  abstract = {In recent years, the use of sparse recovery techniques in the approximation of high-dimensional functions has garnered increasing interest. In this work we present a survey of recent progress in this emerging topic. Our main focus is on the computation of polynomial approximations of high-dimensional functions on \$d\$-dimensional hypercubes. We show that smooth, multivariate functions possess expansions in orthogonal polynomial bases that are not only approximately sparse, but possess a particular type of structured sparsity defined by so-called lower sets. This structure can be exploited via the use of weighted \${\textbackslash}ell\^{}1\$ minimization techniques, and, as we demonstrate, doing so leads to sample complexity estimates that are at most logarithmically dependent on the dimension \$d\$. Hence the curse of dimensionality - the bane of high-dimensional approximation - is mitigated to a significant extent. We also discuss several practical issues, including unknown noise (due to truncation or numerical error), and highlight a number of open problems and challenges.},
  archiveprefix = {arxiv},
  keywords = {Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Adcock et al-2017-Compressed sensing approaches for polynomial approximation of high-dimensional.pdf;/Users/driscoll/Zotero/storage/N3N5V9YN/1703.html}
}

@article{adcockGapTheoryPractice2021,
  title = {The {{Gap}} between {{Theory}} and {{Practice}} in {{Function Approximation}} with {{Deep Neural Networks}}},
  author = {Adcock, Ben and Dexter, Nick},
  year = {2021},
  month = jan,
  journal = {SIAM Journal on Mathematics of Data Science},
  volume = {3},
  number = {2},
  pages = {624--655},
  issn = {2577-0187},
  doi = {10.1137/20m131309x},
  urldate = {2021-06-14},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Adcock_Dexter_2021_The Gap between Theory and Practice in Function Approximation with Deep Neural.pdf}
}

@misc{adcockMonteCarloBad2022,
  title = {Is {{Monte Carlo}} a Bad Sampling Strategy for Learning Smooth Functions in High Dimensions?},
  author = {Adcock, Ben and Brugiapaglia, Simone},
  year = {2022},
  month = aug,
  number = {arXiv:2208.09045},
  eprint = {2208.09045},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  urldate = {2022-08-31},
  abstract = {This paper concerns the approximation of smooth, high-dimensional functions from limited samples using polynomials. This task lies at the heart of many applications in computational science and engineering -- notably, those arising from parametric modelling and uncertainty quantification. It is common to use Monte Carlo (MC) sampling in such applications, so as not to succumb to the curse of dimensionality. However, it is well known this strategy is theoretically suboptimal. There are many polynomial spaces of dimension \$n\$ for which the sample complexity scales log-quadratically in \$n\$. This well-documented phenomenon has led to a concerted effort to design improved, in fact, near-optimal strategies, whose sample complexities scale log-linearly, or even linearly in \$n\$. Paradoxically, in this work we show that MC is actually a perfectly good strategy in high dimensions. We first document this phenomenon via several numerical examples. Next, we present a theoretical analysis that resolves this paradox for holomorphic functions of infinitely-many variables. We show that there is a least-squares scheme based on \$m\$ MC samples whose error decays algebraically fast in \$m/{\textbackslash}log(m)\$, with a rate that is the same as that of the best \$n\$-term polynomial approximation. This result is non-constructive, since it assumes knowledge of a suitable polynomial space in which to perform the approximation. We next present a compressed sensing-based scheme that achieves the same rate, except for a larger polylogarithmic factor. This scheme is practical, and numerically it performs as well as or better than well-known adaptive least-squares schemes. Overall, our findings demonstrate that MC sampling is eminently suitable for smooth function approximation when the dimension is sufficiently high. Hence the benefits of improved sampling strategies are generically limited to lower-dimensional settings.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Functional Analysis,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Adcock_Brugiapaglia_2022_Is Monte Carlo a bad sampling strategy for learning smooth functions in high.pdf;/Users/driscoll/Zotero/storage/AIBT7DJW/2208.html}
}

@article{adcockNearOptimalSamplingStrategies2020,
  title = {Near-{{Optimal Sampling Strategies}} for {{Multivariate Function Approximation}} on {{General Domains}}},
  author = {Adcock, Ben and Cardenas, Juan M.},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Mathematics of Data Science},
  volume = {2},
  number = {3},
  pages = {607--630},
  issn = {2577-0187},
  doi = {10.1137/19M1279459},
  urldate = {2022-07-11},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Adcock_Cardenas-2020-Near-Optimal Sampling Strategies for Multivariate Function Approximation on.pdf}
}

@book{adcockSparsePolynomialApproximation2021,
  title = {Sparse Polynomial Approximation of High-Dimensional Functions},
  author = {Adcock, Ben and Brugiapaglia, Simone and Webster, Clayton G.},
  year = {2021},
  series = {Computational Science and Engineering},
  number = {25},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  abstract = {"This is a book about polynomial approximation in high dimensions"--},
  isbn = {978-1-61197-687-8},
  lccn = {QA221 .A33 2021},
  keywords = {Approximation theory}
}

@article{AitonAdaptivePartition2018,
  title = {An Adaptive Partition of Unity Method for {{Chebyshev}} Polynomial Interpolation},
  author = {Aiton, Kevin W and Driscoll, Tobin A},
  year = {2018},
  journal = {SIAM Journal on Scientific Computing},
  volume = {40},
  number = {1},
  pages = {A251--A265},
  doi = {10.1137/17m112052x},
  copyright = {All rights reserved},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Aiton_Driscoll_2019_An Adaptive Partition of Unity Method for Multivariate Chebyshev Polynomial.pdf}
}

@article{AitonAdaptivePartition2019,
  title = {An {{Adaptive Partition}} of {{Unity Method}} for {{Multivariate Chebyshev Polynomial Approximations}}},
  author = {Aiton, Kevin W. and Driscoll, Tobin A.},
  year = {2019},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {41},
  number = {5},
  pages = {A3230-A3245},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/18m1184904},
  urldate = {2022-02-11},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Aiton_Driscoll_2019_An Adaptive Partition of Unity Method for Multivariate Chebyshev Polynomial2.pdf}
}

@article{AitonPreconditionedNonlinear2020,
  title = {Preconditioned {{Nonlinear Iterations}} for {{Overlapping Chebyshev Discretizations}} with {{Independent Grids}}},
  author = {Aiton, Kevin W. and Driscoll, Tobin A.},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {42},
  number = {4},
  pages = {A2360-A2370},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/19m1242483},
  urldate = {2021-09-09},
  abstract = {The additive Schwarz method is usually presented as a preconditioner for a PDE linearization based on overlapping subsets of nodes from a global discretization. It has previously been shown how to apply Schwarz preconditioning to a nonlinear problem. By first replacing the original global PDE with the Schwarz overlapping problem, the global discretization becomes a simple union of subdomain discretizations, and unknowns do not need to be shared. In this way, restrictive-type updates can be avoided, and subdomains need to communicate only via interface interpolations. The resulting preconditioner can be applied linearly or nonlinearly. In the latter case, nonlinear subdomain problems are solved independently in parallel, and the frequency and amount of interprocess communication can be greatly reduced compared to global preconditioning of the sequence of linearized problems.},
  copyright = {All rights reserved},
  keywords = {33F05,65N55,97N40,additive Schwarz,domain decomposition,No DOI found,partition of unity,polynomial interpolation},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Aiton_Driscoll-2020-Preconditioned Nonlinear Iterations for Overlapping Chebyshev Discretizations.pdf;/Users/driscoll/Dropbox/library/Journal Article/Aiton_Driscoll-2020-Preconditioned Nonlinear Iterations for Overlapping Chebyshev Discretizations2.pdf}
}

@inproceedings{alastrueyArterialPulseWave2012,
  title = {Arterial Pulse Wave Haemodynamics},
  booktitle = {11th {{International Conference}} on {{Pressure Surges}}},
  author = {Alastruey, Jordi and Parker, Kim H and Sherwin, Spencer J and others},
  year = {2012},
  pages = {401--442},
  publisher = {{Virtual PiE Led t/a BHR Group Lisbon, Portugal}},
  keywords = {No DOI found},
  file = {/Users/driscoll/Zotero/storage/JHA5QIAW/Alastruey et al. - 2012 - Arterial pulse wave haemodynamics.pdf}
}

@article{Albin2011,
  title = {A Spectral {{FC}} Solver for the Compressible {{Navier}}--{{Stokes}} Equations in General Domains {{I}}: {{Explicit}} Time-Stepping},
  author = {Albin, Nathan and Bruno, Oscar P.},
  year = {2011},
  month = jul,
  journal = {Journal of Computational Physics},
  volume = {230},
  number = {16},
  pages = {6248--6270},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.jcp.2011.04.023},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Albin_Bruno_2011_A spectral FC solver for the compressible Navier–Stokes equations in general.pdf}
}

@article{AlHassaniehLocalCompatibility2022,
  title = {Local {{Compatibility Boundary Conditions}} for {{High-Order Accurate Finite-Difference Approximations}} of {{PDEs}}},
  author = {Al Hassanieh, Nour G. and Banks, Jeffrey W. and Henshaw, William D. and Schwendeman, Donald W.},
  year = {2022},
  month = dec,
  journal = {SIAM Journal on Scientific Computing},
  volume = {44},
  number = {6},
  pages = {A3645-A3672},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/21M1458454},
  urldate = {2023-01-09},
  abstract = {We describe a new approach to derive numerical approximations of boundary conditions for high-order accurate finite-difference approximations. The approach, called the local compatibility boundary condition (LCBC) method, uses boundary conditions and compatibility boundary conditions derived from the governing equations, as well as interior and boundary grid values, to construct a local polynomial, whose degree matches the order of accuracy of the interior scheme, centered at each boundary point. The local polynomial is then used to derive a discrete formula for each ghost point in terms of the data. This approach leads to centered approximations that are generally more accurate and stable than one-sided approximations. Moreover, the stencil approximations are local since they do not couple to neighboring ghost-point values, which can occur with traditional compatibility conditions. The local polynomial is derived using continuous operators and derivatives, which enables the automatic construction of stencil approximations at different orders of accuracy. The LCBC method is developed here for problems governed by second-order partial differential equations, and it is verified in two space dimensions for schemes up to sixth-order accuracy.},
  keywords = {65M06,65M12,65M20,65M22,boundary conditions,compatibility conditions,heat equation,high-order finite-differences,wave equation},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Al Hassanieh et al_2022_Local Compatibility Boundary Conditions for High-Order Accurate.pdf}
}

@article{Ali_Industrial_2006,
  title = {Industrial Perspective in Ocular Drug Delivery},
  author = {Ali, Yusuf and Lehmussaari, Kari},
  year = {2006},
  volume = {58},
  number = {11},
  pages = {1258--1268},
  issn = {0169-409X},
  doi = {10.1016/j.addr.2006.07.022},
  abstract = {In the development of a commercial drug product, the formulator must consider various perspectives. The bioavailability of the active drug substance is often the major hurdle to overcome. In the past it has been common to add viscosity-enhancing agents or mucoadhesive polymers into formulations to improve ocular bioavailability. In addition to these conventional approaches, non-conventional technologies such as nanotechnology, microspheres and prodrugs could be considered to optimize the product.Along with bioavailability, the formulator must also consider the tolerability and stability of the final drug product. Quite often, the final formulation is the ideal compromise between the three.Authorities in different parts of the world have set strict requirements and guidelines for development and approval of drug products. In order to secure an expeditious development process and the shortest possible review and approval time, the formulator should be familiar with the current requirements and regulations.},
  pmid = {17079049}
}

@article{alqahtaniSolutionIllposedProblems2022,
  title = {Solution of Ill-Posed Problems with {{Chebfun}}},
  author = {Alqahtani, A. and Mach, T. and Reichel, L.},
  year = {2022},
  month = sep,
  journal = {Numerical Algorithms},
  issn = {1572-9265},
  doi = {10.1007/s11075-022-01390-z},
  urldate = {2022-09-21},
  abstract = {The analysis of linear ill-posed problems often is carried out in function spaces using tools from functional analysis. However, the numerical solution of these problems typically is computed by first discretizing the problem and then applying tools from finite-dimensional linear algebra. The present paper explores the feasibility of applying the Chebfun package to solve ill-posed problems with a regularize-first approach numerically. This allows a user to work with functions instead of vectors and with integral operators instead of matrices. The solution process therefore is much closer to the analysis of ill-posed problems than standard linear algebra-based solution methods. Furthermore, the difficult process of explicitly choosing a suitable discretization is not required.},
  langid = {english},
  keywords = {41A10,45B05,47A52,65F22,Chebfun,Ill-posed problem,Inverse problem,Tikhonov regularization,Truncated SVE},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Alqahtani et al_2022_Solution of ill-posed problems with Chebfun.pdf}
}

@article{amparoEvaluatingCorneal2017,
  title = {Evaluating {{Corneal Fluorescein Staining Using}} a {{Novel Automated Method}}},
  author = {Amparo, Francisco and Wang, Haobing and Yin, Jia and Marmalidou, Anna and Dana, Reza},
  year = {2017},
  month = may,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {58},
  number = {6},
  pages = {BIO168-BIO173},
  issn = {1552-5783},
  doi = {10.1167/iovs.17-21831},
  abstract = {Purpose: To evaluate interobserver concordance in measured corneal fluorescein staining (CFS) using the National Eye Institute/Industry (NEI) grading scale and the Corneal Fluorescein Staining Index (CFSi), a computer-assisted, objective, centesimal scoring system. Methods: We conducted a study to evaluate CFS in clinical photographs of patients with corneal epitheliopathy. One group of clinicians graded CFS in the images using the NEI while a second group applied the CFSi. We evaluated the level of interobserver agreement and differences among CFS scores with each method, level of correlation between the two methods, and distribution of cases based on the CFS severity assigned by each method. Results: The level of interobserver agreement was 0.65 (P {$<$} 0.001) with the NEI, and 0.99 (P {$<$} 0.001) with the CFSi. There were statistically significant differences among clinicians' measurements obtained with the NEI (P {$<$} 0.001), but not with the CFSi (P = 0.78). There was a statistically significant correlation between the CFS scores obtained with the two methods (R = 0.72; P {$<$} 0.001). The NEI scale allocated the majority of cases (65\%) within the higher quartile in the scale's severity (12-15/15). In contrast, the CFSi allocated the majority of cases (61\%) within the lower quartile in the scale's severity (0-25/100). Conclusions: The CFSi is easy to implement, provides higher interobserver consistency, and due to its continuous score can discriminate smaller differences in CFS. Reproducibility of the computer-based system is higher and, interestingly, the system allocates cases of epitheliopathy in different severity categories than clinicians do. The CFSi can be an alternative for objective CFS evaluation in the clinic and in clinical trials.},
  langid = {english},
  pmid = {28693042},
  keywords = {Analysis of Variance,Corneal Diseases,Diagnostic Techniques Ophthalmological,Dry Eye Syndromes,Epithelium Corneal,Fluorescein,Fluorescent Dyes,Humans,Image Processing Computer-Assisted,Observer Variation,Prospective Studies,Reproducibility of Results},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Amparo et al-2017-Evaluating Corneal Fluorescein Staining Using a Novel.pdf}
}

@article{Anderson2010,
  title = {A {{Rayleigh}}--{{Chebyshev}} Procedure for Finding the Smallest Eigenvalues and Associated Eigenvectors of Large Sparse {{Hermitian}} Matrices},
  author = {Anderson, Christopher R.},
  year = {2010},
  month = sep,
  journal = {Journal of Computational Physics},
  volume = {229},
  number = {19},
  pages = {7477--7487},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.jcp.2010.06.030},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Anderson_2010_A Rayleigh–Chebyshev procedure for finding the smallest eigenvalues and.pdf}
}

@article{ankerstOPTICSOrderingPoints1999,
  title = {{{OPTICS}}: Ordering Points to Identify the Clustering Structure},
  shorttitle = {{{OPTICS}}},
  author = {Ankerst, Mihael and Breunig, Markus M. and Kriegel, Hans-Peter and Sander, J{\"o}rg},
  year = {1999},
  month = jun,
  journal = {ACM SIGMOD Record},
  volume = {28},
  number = {2},
  pages = {49--60},
  issn = {0163-5808},
  doi = {10.1145/304181.304187},
  urldate = {2022-04-09},
  abstract = {Cluster analysis is a primary method for database mining. It is either used as a stand-alone tool to get insight into the distribution of a data set, e.g. to focus further analysis and data processing, or as a preprocessing step for other algorithms operating on the detected clusters. Almost all of the well-known clustering algorithms require input parameters which are hard to determine but have a significant influence on the clustering result. Furthermore, for many real-data sets there does not even exist a global parameter setting for which the result of the clustering algorithm describes the intrinsic clustering structure accurately. We introduce a new algorithm for the purpose of cluster analysis which does not produce a clustering of a data set explicitly; but instead creates an augmented ordering of the database representing its density-based clustering structure. This cluster-ordering contains information which is equivalent to the density-based clusterings corresponding to a broad range of parameter settings. It is a versatile basis for both automatic and interactive cluster analysis. We show how to automatically and efficiently extract not only 'traditional' clustering information (e.g. representative points, arbitrary shaped clusters), but also the intrinsic clustering structure. For medium sized data sets, the cluster-ordering can be represented graphically and for very large data sets, we introduce an appropriate visualization technique. Both are suitable for interactive exploration of the intrinsic clustering structure offering additional insights into the distribution and correlation of the data.},
  keywords = {cluster analysis,database mining,visualization},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Ankerst et al-1999-OPTICS.pdf}
}

@article{anthimopoulosLungPatternClassification2016,
  title = {Lung {{Pattern Classification}} for {{Interstitial Lung Diseases Using}} a {{Deep Convolutional Neural Network}}},
  author = {Anthimopoulos, Marios and Christodoulidis, Stergios and Ebner, Lukas and Christe, Andreas and Mougiakakou, Stavroula},
  year = {2016},
  month = may,
  journal = {IEEE Transactions on Medical Imaging},
  volume = {35},
  number = {5},
  pages = {1207--1216},
  issn = {1558-254X},
  doi = {10.1109/tmi.2016.2535865},
  abstract = {Automated tissue characterization is one of the most crucial components of a computer aided diagnosis (CAD) system for interstitial lung diseases (ILDs). Although much research has been conducted in this field, the problem remains challenging. Deep learning techniques have recently achieved impressive results in a variety of computer vision problems, raising expectations that they might be applied in other domains, such as medical image analysis. In this paper, we propose and evaluate a convolutional neural network (CNN), designed for the classification of ILD patterns. The proposed network consists of 5 convolutional layers with 2 {\texttimes} 2 kernels and LeakyReLU activations, followed by average pooling with size equal to the size of the final feature maps and three dense layers. The last dense layer has 7 outputs, equivalent to the classes considered: healthy, ground glass opacity (GGO), micronodules, consolidation, reticulation, honeycombing and a combination of GGO/reticulation. To train and evaluate the CNN, we used a dataset of 14696 image patches, derived by 120 CT scans from different scanners and hospitals. To the best of our knowledge, this is the first deep CNN designed for the specific problem. A comparative analysis proved the effectiveness of the proposed CNN against previous methods in a challenging dataset. The classification performance ( 85.5\%) demonstrated the potential of CNNs in analyzing lung patterns. Future work includes, extending the CNN to three-dimensional data provided by CT volume scans and integrating the proposed method into a CAD system that aims to provide differential diagnosis for ILDs as a supportive tool for radiologists.},
  keywords = {Algorithms,automated tissue characterization,biological tissues,Computed tomography,computer aided diagnosis system,computer vision problems,computerised tomography,consolidation,convolution,Convolution,Convolutional neural networks,CT volume scans,deep convolutional neural network,deep learning techniques,Design automation,diseases,Diseases,feature extraction,Feature extraction,feature maps,ground glass opacity,honeycombing,Humans,ILD pattern classification,image classification,Image Interpretation Computer-Assisted,interstitial lung diseases,learning (artificial intelligence),lung,Lung,Lung Diseases Interstitial,lung pattern classification,Lungs,medical image analysis,medical image processing,micronodules,neural nets,Neural networks,Neural Networks (Computer),reticulation,texture classification,Tomography X-Ray Computed},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Anthimopoulos et al_2016_Lung Pattern Classification for Interstitial Lung Diseases Using a Deep.pdf;/Users/driscoll/Zotero/storage/5J3MCY8X/7422082.html}
}

@book{AntoulasInterpolatoryMethods2020,
  title = {Interpolatory {{Methods}} for {{Model Reduction}}},
  author = {Antoulas, A. C. and Beattie, C. A. and G{\"u}{\u g}ercin, S.},
  year = {2020},
  month = jan,
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia, PA}},
  doi = {10.1137/1.9781611976083},
  urldate = {2023-04-12},
  isbn = {978-1-61197-607-6 978-1-61197-608-3},
  langid = {english}
}

@article{Ar_valo_2002,
  title = {A Collocation Formulation of Multistep Methods for Variable Step-Size Extensions},
  author = {Ar{\'e}valo, Carmen and F{\"u}hrer, Claus and Selva, M{\'undefined}nica},
  year = {2002},
  month = aug,
  journal = {Applied Numerical Mathematics},
  volume = {42},
  number = {1-3},
  pages = {5--16},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0168-9274(01)00138-6},
  keywords = {Collocation,Multistep methods,Ordinary differential equations (ODEs),Variable step-size formulas},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Arévalo et al_2002_A collocation formulation of multistep methods for variable step-size extensions.pdf}
}

@article{arridgeSolvingInverseProblems2019,
  title = {Solving Inverse Problems Using Data-Driven Models},
  author = {Arridge, Simon and Maass, Peter and {\"O}ktem, Ozan and Sch{\"o}nlieb, Carola-Bibiane},
  year = {2019},
  month = may,
  journal = {Acta Numerica},
  volume = {28},
  pages = {1--174},
  publisher = {{Cambridge University Press}},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492919000059},
  urldate = {2022-12-06},
  abstract = {Recent research in inverse problems seeks to develop a mathematically coherent foundation for combining data-driven models, and in particular those based on deep learning, with domain-specific knowledge contained in physical--analytical models. The focus is on solving ill-posed inverse problems that are at the core of many challenging applications in the natural sciences, medicine and life sciences, as well as in engineering and industrial applications. This survey paper aims to give an account of some of the main contributions in data-driven inverse problems.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Arridge et al_2019_Solving inverse problems using data-driven models.pdf;/Users/driscoll/Zotero/storage/A28TVPS3/CE5B3725869AEAF46E04874115B0AB15.html}
}

@book{ascherComputerMethodsOrdinary1998,
  title = {Computer Methods for Ordinary Differential Equations and Differential-Algebraic Equations},
  author = {Ascher, U. M. and Petzold, Linda Ruth},
  year = {1998},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  isbn = {978-0-89871-412-8},
  lccn = {QA372 .A78 1998},
  keywords = {Data processing,Differential equations,Differential-algebraic equations}
}

@book{ascherNumericalSolutionBoundary1995,
  title = {Numerical Solution of Boundary Value Problems for Ordinary Differential Equations},
  author = {Ascher, U. M. and Mattheij, Robert M. M. and Russell, R. D.},
  year = {1995},
  series = {Classics in Applied Mathematics},
  number = {13},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  isbn = {978-0-89871-354-1},
  lccn = {QA379 .A83 1995},
  keywords = {Boundary value problems,Numerical solutions}
}

@article{atkinsonComputingLeastTrimmed1999,
  title = {Computing Least Trimmed Squares Regression with the Forward Search},
  author = {Atkinson, A. C. and Cheng, T.-C.},
  year = {1999},
  month = nov,
  journal = {Statistics and Computing},
  volume = {9},
  number = {4},
  pages = {251--263},
  issn = {1573-1375},
  doi = {10.1023/a:1008942604045},
  urldate = {2020-11-06},
  abstract = {Least trimmed squares (LTS) provides a parametric family of high breakdown estimators in regression with better asymptotic properties than least median of squares (LMS) estimators. We adapt the forward search algorithm of Atkinson (1994) to LTS and provide methods for determining the amount of data to be trimmed. We examine the efficiency of different trimming proportions by simulation and demonstrate the increasing efficiency of parameter estimation as larger proportions of data are fitted using the LTS criterion. Some standard data examples are analysed. One shows that LTS provides more stable solutions than LMS.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Atkinson_Cheng_1999_Computing least trimmed squares regression with the forward search.pdf}
}

@book{atkinsonElementaryNumericalAnalysis2004,
  title = {Elementary Numerical Analysis},
  author = {Atkinson, Kendall E. and Han, Weimin},
  year = {2004},
  edition = {3rd ed},
  publisher = {{J. Wiley \& Sons}},
  address = {{Hoboken, NJ}},
  isbn = {978-0-471-43337-8},
  lccn = {QA297 .A83 2004},
  keywords = {Numerical analysis}
}

@book{atkinsonIntroductionNumericalAnalysis1989,
  title = {An Introduction to Numerical Analysis},
  author = {Atkinson, Kendall E.},
  year = {1989},
  edition = {2nd ed},
  publisher = {{Wiley}},
  address = {{New York}},
  isbn = {978-0-471-62489-9},
  lccn = {QA297 .A84 1989},
  keywords = {Numerical analysis}
}

@article{aujolOptimalConvergenceRates2019,
  title = {Optimal {{Convergence Rates}} for {{Nesterov Acceleration}}},
  author = {Aujol, Jean-Francois and Dossal, Charles and Rondepierre, Aude},
  year = {2019},
  month = jan,
  journal = {SIAM Journal on Optimization},
  volume = {29},
  number = {4},
  pages = {3131--3153},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1052-6234},
  doi = {10.1137/18M1186757},
  urldate = {2022-02-25},
  abstract = {In this paper, we study the behavior of solutions of the ODE associated to Nesterov acceleration. It is well-known since the pioneering work of Nesterov that the rate of convergence \$O(1/t\^{}2)\$ is optimal for the class of convex functions with Lipschitz gradient. In this work, we show that better convergence rates can be obtained with some additional geometrical conditions, such as {\L} ojasiewicz property. More precisely, we prove the optimal convergence rates that can be obtained depending on the geometry of the function \$F\$ to minimize. The convergence rates are new, and they shed new light on the behavior of Nesterov acceleration schemes. We prove in particular that the classical Nesterov scheme may provide convergence rates that are worse than the classical gradient descent scheme on sharp functions: for instance, the convergence rate for strongly convex functions is not geometric for the classical Nesterov scheme (while it is the case for the gradient descent algorithm). This shows that applying the classical Nesterov acceleration on convex functions without looking more at the geometrical properties of the objective functions may lead to suboptimal algorithms.},
  keywords = {34D05,65K05,65K10,90C25,90C30,Lojasiewicz property,Lyapunov functions,ODEs,optimization,rate of convergence},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Aujol et al_2019_Optimal Convergence Rates for Nesterov Acceleration.pdf}
}

@article{aurentzFastBackwardStable2015,
  title = {Fast and {{Backward Stable Computation}} of {{Roots}} of {{Polynomials}}},
  author = {Aurentz, Jared L. and Mach, Thomas and Vandebril, Raf and Watkins, David S.},
  year = {2015},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {36},
  number = {3},
  pages = {942--973},
  issn = {0895-4798, 1095-7162},
  doi = {10.1137/140983434},
  urldate = {2020-06-18},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Aurentz et al-2015-Fast and Backward Stable Computation of Roots of Polynomials.pdf}
}

@article{avanzoliniCADCSSimulationClosedloop1988,
  title = {{{CADCS}} Simulation of the Closed-Loop Cardiovascular System},
  author = {Avanzolini, Guido and Barbini, Paolo and Cappello, Angelo and Cevenini, Gabriele},
  year = {1988},
  month = jan,
  journal = {International Journal of Bio-Medical Computing},
  volume = {22},
  number = {1},
  pages = {39--49},
  issn = {00207101},
  doi = {10.1016/0020-7101(88)90006-2},
  urldate = {2019-12-06},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Avanzolini et al_1988_CADCS simulation of the closed-loop cardiovascular system.pdf}
}

@article{avanzoliniTimeVaryingMechanicalProperties1985,
  title = {Time-{{Varying Mechanical Properties}} of the {{Left Ventricle-A Computer Simulation}}},
  author = {Avanzolini, G. and Barbini, Paolo and Cappello, A. and Cevese, A.},
  year = {1985},
  month = oct,
  journal = {IEEE Transactions on Biomedical Engineering},
  volume = {BME-32},
  number = {10},
  pages = {756--763},
  issn = {0018-9294},
  doi = {10.1109/TBME.1985.325490},
  abstract = {A numerical model of left ventricular (LV) pump function, incorporating cardiac muscle mechanics and LV geometry, was used to derive a simple linear model of local LV contractile properties. This simplified model views the ventricle as a pressure generator (related to isovolumic contraction) coupled with two time-varying elements: 1) a viscous term (related to the dissipative properties of the myocardium), and 2) an elastic term (related to the tension-length curve of activated fiber and to LV geometry).},
  keywords = {HLHS},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Avanzolini et al_1985_Time-Varying Mechanical Properties of the Left Ventricle-A Computer Simulation.pdf}
}

@article{Awisi-GyauChangesCorneal2019,
  title = {Changes in {{Corneal Detection Thresholds After Repeated Tear Film Instability}}},
  author = {{Awisi-Gyau}, Deborah and Begley, Carolyn G. and Situ, Ping and Simpson, Trefford L.},
  year = {2019},
  month = oct,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {60},
  number = {13},
  pages = {4234--4240},
  issn = {1552-5783},
  doi = {10.1167/iovs.19-27802},
  urldate = {2022-08-05},
  abstract = {To use a human-based model to study the effects of repeated tear film instability on corneal detection thresholds to cold, mechanical, and chemical stimuli.    Twenty-five subjects participated in three study visits. A computer-controlled Belmonte esthesiometer was used to estimate corneal detection thresholds to cold, mechanical, and chemical stimuli before, after, and 30 minutes following 10 consecutive sustained tear exposure (STARE) trials. Subjects turned a pain knob (0--10) to indicate discomfort during STARE trials. The area of tear breakup and thinning in each trial was analyzed. Symptoms were evaluated by the Current Symptom Questionnaire (CSQ).    There was a significant time effect on CSQ symptoms during both visits (Friedman test, P \&lt; 0.001), with immediately after repeated STARE and 30 minutes later significantly differing from before STARE (Wilcoxon, P \&lt; 0.017). Tear breakup occurred in every trial, ranging from 25\% to 88\% of the exposed corneal area and all subjects indicated discomfort during trials. There was a significant time effect on mechanical thresholds between before STARE mechanical thresholds and 30 minutes later (repeated measures analysis of variance [ANOVA] P \&lt; 0.001), but not cold (P = 0.057) or chemical (P = 0. 565) thresholds.    In this study, tear breakup during STARE trials was associated with discomfort, which when repeated, resulted in increased symptoms of ocular discomfort and alterations of mechanical sensory thresholds after 30 minutes. These results suggest that tear film instability, which is thought to occur repeatedly during normal blinking among dry eye patients over the day, can produce neurosensory alterations.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Awisi-Gyau et al-2019-Changes in Corneal Detection Thresholds After Repeated Tear Film Instability.pdf;/Users/driscoll/Zotero/storage/F38QZJMS/article.html}
}

@article{aydemirEffectPolar2011,
  title = {The {{Effect}} of {{Polar Lipids}} on {{Tear Film Dynamics}}},
  author = {Aydemir, E. and Breward, C. J. W. and Witelski, T. P.},
  year = {2011},
  month = jun,
  journal = {Bulletin of Mathematical Biology},
  volume = {73},
  number = {6},
  pages = {1171--1201},
  issn = {0092-8240, 1522-9602},
  doi = {10.1007/s11538-010-9555-y},
  urldate = {2020-07-11},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Aydemir_Breward_Witelski-2011-The Effect of Polar Lipids on Tear Film Dynamics2.pdf}
}

@article{Babuska2010,
  title = {A Stochastic Collocation Method for Elliptic Partial Differential Equations with Random Input Data},
  author = {Babu{\v s}ka, Ivo and Nobile, Fabio and Tempone, Ra{\'u}l},
  year = {2010},
  month = jan,
  journal = {SIAM Review},
  volume = {52},
  number = {2},
  pages = {317--355},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/100786356},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Babuška et al_2010_A stochastic collocation method for elliptic partial differential equations.pdf}
}

@article{baerSingularHopfBifurcation1986,
  title = {Singular {{Hopf Bifurcation}} to {{Relaxation Oscillations}}},
  author = {Baer, S. M. and Erneux, T.},
  year = {1986},
  month = oct,
  journal = {SIAM Journal on Applied Mathematics},
  volume = {46},
  number = {5},
  pages = {721--739},
  issn = {0036-1399, 1095-712X},
  doi = {10.1137/0146047},
  urldate = {2020-06-18},
  langid = {english}
}

@article{bagbabaAutomatedGrading2018,
  title = {An {{Automated Grading}} and {{Diagnosis System}} for {{Evaluation}} of {{Dry Eye Syndrome}}},
  author = {Ba{\u g}baba, Ay{\c s}e and {\c S}en, Baha and Delen, Dursun and Uysal, Bet{\"u}l Seher},
  year = {2018},
  month = oct,
  journal = {Journal of Medical Systems},
  volume = {42},
  number = {11},
  pages = {227},
  issn = {1573-689X},
  doi = {10.1007/s10916-018-1086-3},
  abstract = {This article describes methods used to determine the severity of Dry Eye Syndrome (DES) based on Oxford Grading Schema (OGS) automatically by developing and applying a decider model. The number of dry punctate dots occurred on corneal surface after corneal fluorescein staining can be used as a diagnostic indicator of DES severity according to OGS; however, grading of DES severity exactly by carefully assessing these dots is a rather difficult task for humans. Taking into account that current methods are also subjectively dependent on the perception of the ophtalmologists coupled with the time and resource intensive requirements, enhanced diagnosis techniques would greatly contribute to clinical assessment of DES. Automated grading system proposed in this study utilizes image processing methods in order to provide more objective and reliable diagnostic results for DES. A total of 70 fluorescein-stained cornea images from 20 patients with mild, moderate, or severe DES (labeled by an ophthalmologist in the Keratoconus Center of Yildirim Beyazit University Ataturk Training and Research Hospital) used as the participants for the study. Correlations between the number of dry punctate dots and DES severity levels were determined. When automatically created scores and clinical scores were compared, the following measures were observed: Pearson's correlation value between the two was 0.981; Lin's Concordance Correlation Coefficients (CCC) was 0.980; and 95\% confidence interval limites were 0.963 and 0.989. The automated DES grade was estimated from the regression fit and accordingly the unknown grade is calculated with the following formula: Gpred~=\,1.3244 log(Ndots) - 0.0612. The study has shown the viability and the utility of a highly successful automated DES diagnostic system based on OGS, which can be developed by working on the fluorescein-stained cornea images. Proper implemention of a computationally savvy and highly accurate classification system, can assist investigators to perform more objective and faster DES diagnoses in real-world scenerios.},
  langid = {english},
  pmid = {30298212},
  keywords = {Cornea,Corneal images,Dry eye,Dry Eye Syndromes,Female,Fluorescein,Fluorescein staining,Fluorophotometry,Health Status Indicators,Humans,Image processing,Male,Oxford grading scale}
}

@article{BaggettMostlyLinear1995,
  title = {A Mostly Linear Model of Transition to Turbulence},
  author = {Baggett, Jeffrey S and Driscoll, Tobin A and Trefethen, Lloyd N},
  year = {1995},
  journal = {Physics of Fluids},
  volume = {7},
  number = {4},
  pages = {833--838},
  doi = {10.1063/1.868606},
  copyright = {All rights reserved}
}

@unpublished{Bailey2006u,
  title = {Tanh-Sinh High-Precision Quadrature},
  author = {Bailey, David H.},
  annotation = {19 Jan 2006},
  file = {/Users/driscoll/Dropbox/library/Manuscript/Bailey_Tanh-sinh high-precision quadrature.pdf}
}

@article{BaileyComparisonThree2005,
  title = {A Comparison of Three High-Precision Quadrature Schemes},
  author = {Bailey, David H. and Jeyabalan, Karthik and Li, Xiaoye S.},
  year = {2005},
  month = jan,
  journal = {Experimental Mathematics},
  volume = {14},
  number = {3},
  pages = {317--329},
  publisher = {{Informa UK Limited}},
  doi = {10.1080/10586458.2005.10128931},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bailey et al_2005_A comparison of three high-precision quadrature schemes.pdf;/Users/driscoll/Dropbox/library/Journal Article/Bailey_Jeyabalan_Li-2005-A Comparison of Three High-Precision Quadrature Schemes.pdf}
}

@article{BakerLowrankIncremental2012,
  title = {Low-Rank Incremental Methods for Computing Dominant Singular Subspaces},
  author = {Baker, C. G. and Gallivan, K. A. and Van Dooren, P.},
  year = {2012},
  month = apr,
  journal = {Linear Algebra and its Applications},
  series = {Special {{Issue}} Dedicated to {{Danny Sorensen}}'s 65th Birthday},
  volume = {436},
  number = {8},
  pages = {2866--2888},
  issn = {0024-3795},
  doi = {10.1016/j.laa.2011.07.018},
  urldate = {2022-06-03},
  abstract = {Computing the singular values and vectors of a matrix is a crucial kernel in numerous scientific and industrial applications. As such, numerous methods have been proposed to handle this problem in a computationally efficient way. This paper considers a family of methods for incrementally computing the dominant SVD of a large matrix A. Specifically, we describe a unification of a number of previously independent methods for approximating the dominant SVD after a single pass through A. We connect the behavior of these methods to that of a class of optimization-based iterative eigensolvers on ATA. An iterative procedure is proposed which allows the computation of an accurate dominant SVD using multiple passes through A. We present an analysis of the convergence of this iteration and provide empirical demonstration of the proposed method on both synthetic and benchmark data.},
  langid = {english},
  keywords = {Convergence analysis,Incremental SVD,Iterative methods,Pass-efficient linear algebra,Singular value decomposition},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Baker et al-2012-Low-rank incremental methods for computing dominant singular subspaces.pdf;/Users/driscoll/Zotero/storage/W4JUGWE8/Baker et al. - 2012 - Low-rank incremental methods for computing dominan.pdf;/Users/driscoll/Zotero/storage/2X8I4NMP/S0024379511005301.html}
}

@article{BaltenspergerExponentialConvergence1999,
  title = {Exponential Convergence of a Linear Rational Interpolant between Transformed {{Chebyshev}} Points},
  author = {Baltensperger, Richard and Berrut, Jean-Paul and No{\"e}l, Benjamin},
  year = {1999},
  month = feb,
  journal = {Mathematics of Computation},
  volume = {68},
  number = {227},
  pages = {1109--1120},
  issn = {0025-5718, 1088-6842},
  doi = {10.1090/S0025-5718-99-01070-4},
  urldate = {2023-04-18},
  abstract = {In 1988 the second author presented experimentally well-conditioned linear rational functions for global interpolation. We give here arrays of nodes for which one of these interpolants converges exponentially for analytic functions},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Baltensperger et al_1999_Exponential convergence of a linear rational interpolant between transformed.pdf}
}

@article{Bandlitz_Time_2014,
  title = {Time Course of Changes in Tear Meniscus Radius and Blink Rate after Instillation of Artificial Tears},
  author = {Bandlitz, Stefan and Purslow, Christine and Murphy, Paul J and Pult, Heiko},
  year = {2014},
  volume = {55},
  number = {9},
  pages = {5842},
  issn = {1552-5783},
  doi = {10.1167/iovs.14-14844}
}

@article{Bartels1972,
  title = {Solution of the Matrix Equation {{AX}}+{{XB}}={{C}}},
  author = {Bartels, R. H. and Stewart, G. W.},
  year = {1972},
  month = sep,
  journal = {Communications of the ACM},
  volume = {15},
  number = {9},
  pages = {820--826},
  publisher = {{Association for Computing Machinery (ACM)}},
  doi = {10.1145/361573.361582},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bartels_Stewart_1972_Solution of the matrix equation AX+XB=C.pdf}
}

@article{Barton1971,
  title = {The Automatic Solution of Systems of Ordinary Differential Equations by the Method of {{Taylor}} Series},
  author = {Barton, D.},
  year = {1971},
  month = mar,
  journal = {The Computer Journal},
  volume = {14},
  number = {3},
  pages = {243--248},
  publisher = {{Oxford University Press (OUP)}},
  doi = {10.1093/comjnl/14.3.243},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Barton_1971_The automatic solution of systems of ordinary differential equations by the.pdf}
}

@article{Baszenski1997,
  title = {Fast Polynomial Multiplication and Convolutions Related to the Discrete Cosine Transform},
  author = {Baszenski, G{\"u}nter and Tasche, Manfred},
  year = {1997},
  month = feb,
  journal = {Linear Algebra and its Applications},
  volume = {252},
  number = {1-3},
  pages = {1--25},
  publisher = {{Elsevier BV}},
  doi = {10.1016/0024-3795(95)00696-6},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Baszenski_Tasche_1997_Fast polynomial multiplication and convolutions related to the discrete cosine.pdf}
}

@article{Bauer2000,
  title = {Numerical Methods for Optimum Experimental Design in {{DAE}} Systems},
  author = {Bauer, Irene and Bock, Hans Georg and K{\"o}rkel, Stefan and Schl{\"o}der, Johannes P.},
  year = {2000},
  month = aug,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {120},
  number = {1-2},
  pages = {1--25},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0377-0427(00)00300-9},
  keywords = {Chemical reaction kinetics,Direct approach,Internal numerical di erentiation,Nonlinear DAE models,Optimum experimental design,Parameter estimation},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bauer et al_2000_Numerical methods for optimum experimental design in DAE systems.pdf}
}

@article{bayonaRolePolynomialsRBFFD2017,
  title = {On the Role of Polynomials in {{RBF-FD}} Approximations: {{II}}. {{Numerical}} Solution of Elliptic {{PDEs}}},
  shorttitle = {On the Role of Polynomials in {{RBF-FD}} Approximations},
  author = {Bayona, Victor and Flyer, Natasha and Fornberg, Bengt and Barnett, Gregory A.},
  year = {2017},
  month = mar,
  journal = {Journal of Computational Physics},
  volume = {332},
  pages = {257--273},
  issn = {00219991},
  doi = {10.1016/j.jcp.2016.12.008},
  urldate = {2022-08-01},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bayona et al-2017-On the role of polynomials in RBF-FD approximations.pdf}
}

@article{bayonaRolePolynomialsRBFFD2019,
  title = {On the Role of Polynomials in {{RBF-FD}} Approximations: {{III}}. {{Behavior}} near Domain Boundaries},
  shorttitle = {On the Role of Polynomials in {{RBF-FD}} Approximations},
  author = {Bayona, V{\'i}ctor and Flyer, Natasha and Fornberg, Bengt},
  year = {2019},
  month = mar,
  journal = {Journal of Computational Physics},
  volume = {380},
  pages = {378--399},
  issn = {00219991},
  doi = {10.1016/j.jcp.2018.12.013},
  urldate = {2022-08-01},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bayona et al-2019-On the role of polynomials in RBF-FD approximations.pdf}
}

@article{Beatson1998,
  title = {Fast Evaluation of Radial Basis Functions: Moment-Based Methods},
  author = {Beatson, R. K. and Newsam, G. N.},
  year = {1998},
  month = sep,
  journal = {SIAM Journal on Scientific Computing},
  volume = {19},
  number = {5},
  pages = {1428--1449},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/s1064827595293569},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Beatson_Newsam_1998_Fast evaluation of radial basis functions.pdf}
}

@article{Beatson2001,
  title = {Fast Solution of the Radial Basis Function Interpolation Equations: Domain Decomposition Methods},
  author = {Beatson, R. K. and Light, W. A. and Billings, S.},
  year = {2001},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {22},
  number = {5},
  pages = {1717--1740},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/s1064827599361771},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Beatson et al_2001_Fast solution of the radial basis function interpolation equations.pdf}
}

@article{Beatson2010,
  title = {Error Bounds for Anisotropic {{RBF}} Interpolation},
  author = {Beatson, Rick and Davydov, Oleg and Levesley, Jeremy},
  year = {2010},
  journal = {Journal of Approximation Theory},
  volume = {162},
  number = {3},
  pages = {512--527},
  issn = {0021-9045},
  doi = {10.1016/j.jat.2009.08.004},
  mrnumber = {2600981},
  keywords = {41A05 (65D05)}
}

@article{beattieSamplingfreeModelReduction2020,
  title = {Sampling-Free Model Reduction of Systems with Low-Rank Parameterization},
  author = {Beattie, Christopher and Gugercin, Serkan and Tomljanovi{\'c}, Zoran},
  year = {2020},
  month = nov,
  journal = {Advances in Computational Mathematics},
  volume = {46},
  number = {6},
  pages = {83},
  issn = {1572-9044},
  doi = {10.1007/s10444-020-09825-8},
  urldate = {2021-03-22},
  abstract = {We consider the reduction of parametric families of linear dynamical systems having an affine parameter dependence that allow for low-rank variation in the state matrix. Usual approaches for parametric model reduction typically involve exploring the parameter space to identify representative parameter values and the associated models become the principal focus of model reduction methodology. These models are then combined in various ways in order to interpolate the response. The initial exploration of the parameter space can be a forbiddingly expensive task. A different approach is proposed here that requires neither parameter sampling nor parameter space exploration. Instead, we represent the system response function as a composition of four subsystem response functions that are non-parametric with a purely parameter-dependent function. One may apply any one of a number of standard (non-parametric) model reduction strategies to reduce the subsystems independently, and then conjoin these reduced models with the underlying parameterization to obtain the overall parameterized response. Our approach has elements in common with the parameter mapping approach of Baur et al. (PAMM 14(1), 19--22 2014) but offers greater flexibility and potentially greater control over accuracy. In particular, a data-driven variation of our approach is described that exercises this flexibility through the use of limited frequency-sampling of the underlying non-parametric models. The parametric structure of our system representation allows for a priori guarantees of system stability in the resulting reduced models across the full range of parameter values. Incorporation of system theoretic error bounds allows us to determine appropriate approximation orders for the non-parametric systems sufficient to yield uniformly high accuracy across the parameter range. We illustrate our approach on a class of structural damping optimization problems and on a benchmark model of thermal conduction in a semiconductor chip. The parametric structure of our reduced system representation lends itself very well to the development of optimization strategies making use of efficient cost function surrogates. We discuss this in some detail for damping parameter and location optimization for vibrating structures.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Beattie et al_2020_Sampling-free model reduction of systems with low-rank parameterization.pdf}
}

@article{Bebendorf2010,
  title = {Adaptive Cross Approximation of Multivariate Functions},
  author = {Bebendorf, M.},
  year = {2010},
  month = jun,
  journal = {Constructive Approximation},
  volume = {34},
  number = {2},
  pages = {149--179},
  publisher = {{Springer Nature}},
  doi = {10.1007/s00365-010-9103-x},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bebendorf_2010_Adaptive cross approximation of multivariate functions.pdf}
}

@article{begleyQuantitativeAnalysis2013,
  title = {Quantitative {{Analysis}} of {{Tear Film Fluorescence}} and {{Discomfort During Tear Film Instability}} and {{Thinning}}},
  author = {Begley, Carolyn G and Simpson, Trefford and Liu, Haixia and Salvo, Eliza and Wu, Ziwei and Bradley, Arthur and Situ, Ping},
  year = {2013},
  month = apr,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {54},
  number = {4},
  pages = {2645--2653},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1552-5783},
  doi = {10.1167/iovs.12-11299},
  urldate = {2020-11-24},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Begley et al-2013-Quantitative Analysis of Tear Film Fluorescence and.pdf;/Users/driscoll/Zotero/storage/IRKCX9EK/article.html}
}

@inproceedings{bekkermanMultiwayDistributionalClustering2005,
  title = {Multi-Way Distributional Clustering via Pairwise Interactions},
  booktitle = {Proceedings of the 22nd International Conference on {{Machine}} Learning  - {{ICML}} '05},
  author = {Bekkerman, Ron and {El-Yaniv}, Ran and McCallum, Andrew},
  year = {2005},
  pages = {41--48},
  publisher = {{ACM Press}},
  address = {{Bonn, Germany}},
  doi = {10.1145/1102351.1102357},
  urldate = {2019-11-18},
  abstract = {We present a novel unsupervised learning scheme that simultaneously clusters variables of several types (e.g., documents, words and authors) based on pairwise interactions between the types, as observed in co-occurrence data. In this scheme, multiple clustering systems are generated aiming at maximizing an objective function that measures multiple pairwise mutual information between cluster variables. To implement this idea, we propose an algorithm that interleaves top-down clustering of some variables and bottom-up clustering of the other variables, with a local optimization correction routine. Focusing on document clustering we present an extensive empirical study of two-way, three-way and four-way applications of our scheme using six real-world datasets including the 20 Newsgroups (20NG) and the Enron email collection. Our multi-way distributional clustering (MDC) algorithms consistently and significantly outperform previous state-of-the-art information theoretic clustering algorithms.},
  isbn = {978-1-59593-180-1},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Bekkerman et al_2005_Multi-way distributional clustering via pairwise interactions.pdf}
}

@article{Belmonte_Cold_2011,
  title = {Cold Thermoreceptors, Unexpected Players in Tear Production and Ocular Dryness Sensations.},
  author = {Belmonte, Carlos and Gallar, Juana},
  year = {2011},
  volume = {52},
  number = {6},
  pages = {3888--92},
  issn = {1552-5783},
  doi = {10.1167/iovs.09-5119},
  pmid = {21632706}
}

@article{ben-davidMeasuresClusteringQuality2009,
  title = {Measures of {{Clustering Quality}}: {{A Working Set}} of {{Axioms}} for {{Clustering}}},
  author = {{Ben-David}, Shai and Ackerman, Margareta},
  year = {2009},
  journal = {Advances in neural information processing systems},
  pages = {121--128},
  abstract = {Aiming towards the development of a general clustering theory, we discuss abstract axiomatization for clustering. In this respect, we follow up on the work of Kleinberg, ([1]) that showed an impossibility result for such axiomatization. We argue that an impossibility result is not an inherent feature of clustering, but rather, to a large extent, it is an artifact of the specific formalism used in [1].},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Ben-David_Ackerman_2009_Measures of Clustering Quality.pdf}
}

@article{Berenger1994,
  title = {A Perfectly Matched Layer for the Absorption of Electromagnetic Waves},
  author = {Berenger, Jean-Pierre},
  year = {1994},
  month = oct,
  journal = {Journal of Computational Physics},
  volume = {114},
  number = {2},
  pages = {185--200},
  publisher = {{Elsevier BV}},
  doi = {10.1006/jcph.1994.1159},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berenger_1994_A perfectly matched layer for the absorption of electromagnetic waves.pdf}
}

@article{Berenger1996,
  title = {Three-Dimensional Perfectly Matched Layer for the Absorption of Electromagnetic Waves},
  author = {Berenger, Jean-Pierre},
  year = {1996},
  month = sep,
  journal = {Journal of Computational Physics},
  volume = {127},
  number = {2},
  pages = {363--379},
  publisher = {{Elsevier BV}},
  doi = {10.1006/jcph.1996.0181},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berenger_1996_Three-dimensional perfectly matched layer for the absorption of electromagnetic.pdf}
}

@article{bergenDetectingEarthquakesSeismic2018,
  title = {Detecting Earthquakes over a Seismic Network Using Single-Station Similarity Measures},
  author = {Bergen, Karianne J. and Beroza, Gregory C.},
  year = {2018},
  month = jun,
  journal = {Geophysical Journal International},
  volume = {213},
  number = {3},
  pages = {1984--1998},
  publisher = {{Oxford Academic}},
  issn = {0956-540X},
  doi = {10.1093/gji/ggy100},
  urldate = {2020-03-24},
  abstract = {SUMMARY.  New blind waveform-similarity-based detection methods, such as Fingerprint and Similarity Thresholding (FAST), have shown promise for detecting weak s},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/XKG4X4MP/Bergen and Beroza - 2018 - Detecting earthquakes over a seismic network using.pdf;/Users/driscoll/Zotero/storage/E9NUYGCS/4939266.html}
}

@article{Berger_EFFECT_1974,
  title = {{{EFFECT OF CONTACT LENS MOTION ON THE OXYGEN TENSION DISTRIBUTION UNDER THE LENS}}*.},
  author = {Berger, {\relax RE}},
  year = {1974},
  journal = {Optometry \& Vision Science},
  doi = {10.1097/00006324-197407000-00001},
  abstract = {Abstract A method of predicting the oxygen tension distribution under a contact lens is illustrated for some simple, but practical, lens motions. A hydrodynamic theory is used to find those regions which receive fresh tear fluid during a blink. Then a diffusion model is ...}
}

@article{Berke_The_1998,
  title = {The Kinetics of Lid Motion and Its Effects on the Tear Film.},
  author = {Berke, A and Mueller, S},
  year = {1998},
  journal = {Water Relationships in Foods},
  volume = {438},
  pages = {417--24},
  issn = {0065-2598},
  pmid = {9634916}
}

@incollection{berkeKineticsLidMotion1998,
  title = {The {{Kinetics}} of {{Lid Motion}} and Its {{Effects}} on the {{Tear Film}}},
  booktitle = {Lacrimal {{Gland}}, {{Tear Film}}, and {{Dry Eye Syndromes}} 2},
  author = {Berke, A. and Mueller, S.},
  editor = {Sullivan, David A. and Dartt, Darlene A. and Meneray, Michele A.},
  year = {1998},
  volume = {438},
  pages = {417--424},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-1-4615-5359-5_58},
  urldate = {2020-06-18},
  isbn = {978-1-4613-7445-9 978-1-4615-5359-5},
  langid = {english}
}

@article{Berland2007,
  title = {{{EXPINT}}---{{A MATLAB}} Package for Exponential Integrators},
  author = {Berland, H{\aa}vard and Skaflestad, B{\aa}rd and Wright, Will M.},
  year = {2007},
  month = mar,
  journal = {ACM Transactions on Mathematical Software},
  volume = {33},
  number = {1},
  pages = {4-es},
  publisher = {{Association for Computing Machinery (ACM)}},
  doi = {10.1145/1206040.1206044},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berland et al_2007_EXPINT—A MATLAB package for exponential integrators.pdf}
}

@article{Berljafa2017,
  title = {The {{RKFIT}} Algorithm for Nonlinear Rational Approximation},
  author = {Berljafa, Mario and G{\"u}ttel, Stefan},
  year = {2017},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {39},
  number = {5},
  pages = {A2049-A2071},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/15m1025426},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berljafa_Güttel_2017_The RKFIT algorithm for nonlinear rational approximation.pdf}
}

@article{Bernal2009,
  title = {Solving Delay and Differential Equations and through {{RBF}} and Collocation},
  author = {Bernal, Francisco and Gutierrez, Gail},
  year = {2009},
  journal = {Advances in Applied Mathematics and Mechanics},
  volume = {1},
  number = {2},
  pages = {257--272},
  abstract = {A general and easy-to-code numerical method based on radial basis func- tions (RBFs) collocation is proposed for the solution of delay differential equations (DDEs). It relies on the interpolation properties of infinitely smooth RBFs, which al- low for a large accuracy over a scattered and relatively small discretization support. Hardy's multiquadric is chosen as RBF and combined with the Residual Subsam- pling Algorithm of Driscoll and Heryudono for support adaptivity. The perfor- mance of the method is very satisfactory, as demonstrated over a cross-section of benchmark DDEs, and by comparison with existing general-purpose and special- ized numerical schemes for DDEs.},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bernal_Gutierrez_2009_Solving delay and differential equations and through RBF and collocation.pdf}
}

@article{Berrut2001,
  title = {The Linear Rational Pseudospectral Method for Boundary Value Problems},
  author = {Berrut, Jean-Paul and Baltensperger, Richard},
  year = {2001},
  journal = {Bit Numerical Mathematics},
  volume = {41},
  number = {5},
  pages = {868--879},
  publisher = {{Springer Nature}},
  doi = {10.1023/a:1021916623407},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berrut_Baltensperger_2001_The linear rational pseudospectral method for boundary value problems.pdf}
}

@article{BerrutBarycentricLagrange2004,
  title = {Barycentric {{Lagrange Interpolation}}},
  author = {Berrut, Jean-Paul and Trefethen, Lloyd N.},
  year = {2004},
  month = jan,
  journal = {SIAM Review},
  volume = {46},
  number = {3},
  pages = {501--517},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/S0036144502417715},
  urldate = {2023-10-23},
  abstract = {Vandermonde matrices are exponentially ill-conditioned, rendering the familiar ``polyval(polyfit)'' algorithm for polynomial interpolation and least-squares fitting ineffective at higher degrees. We show that Arnoldi orthogonalization fixes the problem. This amounts to on-the-fly construction of discrete orthogonal polynomials by Stieltjes orthogonalization.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berrut_Trefethen_2004_Barycentric Lagrange Interpolation2.pdf}
}

@article{BerrutRationalFunctions1988,
  title = {Rational Functions for Guaranteed and Experimentally Well-Conditioned Global Interpolation},
  author = {Berrut, J. -P.},
  year = {1988},
  month = jan,
  journal = {Computers \& Mathematics with Applications},
  volume = {15},
  number = {1},
  pages = {1--16},
  issn = {0898-1221},
  doi = {10.1016/0898-1221(88)90067-3},
  urldate = {2023-04-17},
  abstract = {Polynomial interpolation is known to be ill-conditioned if the interpolating points are not chosen in special ways; classical rational interpolation can give better results, but does not work in all cases and the corresponding functions can show poles in the interval of interpolation. We present here rational functions which guarantee well-conditioned interpolation on a real interval or a circle and cannot have any poles there. They can be evaluated at least as efficiently as the corresponding interpolation polynomials and the accuracy of their approximation to a given function often compares favorably with that of spline interpolants.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berrut_1988_Rational functions for guaranteed and experimentally well-conditioned global.pdf;/Users/driscoll/Zotero/storage/SGYXZFQX/0898122188900673.html}
}

@article{BerrutRecentAdvances2014,
  title = {Recent Advances in Linear Barycentric Rational Interpolation},
  author = {Berrut, Jean-Paul and Klein, Georges},
  year = {2014},
  month = mar,
  journal = {Journal of Computational and Applied Mathematics},
  series = {Proceedings of the {{Sixteenth International Congress}} on {{Computational}} and {{Applied Mathematics}} ({{ICCAM-2012}}), {{Ghent}}, {{Belgium}}, 9-13 {{July}}, 2012},
  volume = {259},
  pages = {95--107},
  issn = {0377-0427},
  doi = {10.1016/j.cam.2013.03.044},
  urldate = {2023-05-10},
  abstract = {Well-conditioned, stable and infinitely smooth interpolation in arbitrary nodes is by no means a trivial task, even in the univariate setting considered here; already the most important case, equispaced points, is not obvious. Certain approaches have nevertheless experienced significant developments in the last decades. In this paper we review one of them, linear barycentric rational interpolation, as well as some of its applications.},
  langid = {english},
  keywords = {Barycentric form,Differentiation,Equispaced nodes,Lebesgue constant,Linear rational interpolation,Quadrature},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berrut_Klein_2014_Recent advances in linear barycentric rational interpolation.pdf;/Users/driscoll/Zotero/storage/8B7KYN97/S0377042713001714.html}
}

@inproceedings{BerrutRecentDevelopments2005,
  title = {Recent {{Developments}} in {{Barycentric Rational Interpolation}}},
  booktitle = {Trends and {{Applications}} in {{Constructive Approximation}}},
  author = {Berrut, Jean-Paul and Baltensperger, Richard and Mittelmann, Hans D.},
  editor = {Mache, Detlef H. and Szabados, J{\'o}zsef and {de Bruin}, Marcel G.},
  year = {2005},
  series = {{{ISNM International Series}} of {{Numerical Mathematics}}},
  pages = {27--51},
  publisher = {{Birkh{\"a}user}},
  address = {{Basel}},
  doi = {10.1007/3-7643-7356-3_3},
  abstract = {In 1945, W. Taylor discovered the barycentric formula for evaluating the interpolating polynomial. In 1984, W. Werner has given first consequences of the fact that the formula usually is a rational interpolant. We review some advances since the latter paper in the use of the formula for rational interpolation.},
  isbn = {978-3-7643-7356-6},
  langid = {english},
  keywords = {interpolation,optimal interpolation,rational interpolation},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Berrut et al_2005_Recent Developments in Barycentric Rational Interpolation.pdf}
}

@article{Berzins2007,
  title = {Adaptive Polynomial Interpolation on Evenly Spaced Meshes},
  author = {Berzins, M.},
  year = {2007},
  month = jan,
  journal = {SIAM Review},
  volume = {49},
  number = {4},
  pages = {604--627},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/050625667},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Berzins_2007_Adaptive polynomial interpolation on evenly spaced meshes.pdf}
}

@article{Betcke2005,
  title = {Reviving the Method of Particular Solutions},
  author = {Betcke, Timo and Trefethen, Lloyd N.},
  year = {2005},
  month = jan,
  journal = {SIAM Review},
  volume = {47},
  number = {3},
  pages = {469--491},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/s0036144503437336},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Betcke_Trefethen_2005_Reviving the method of particular solutions.pdf}
}

@article{Bhamla_Dewetting_2015,
  title = {Dewetting and Deposition of Thin Films with Insoluble Surfactants from Curved Silicone Hydrogel Substrates},
  author = {Bhamla, Saad M and Balemans, Caroline and Fuller, Gerald G},
  year = {2015},
  volume = {449},
  pages = {428--435},
  issn = {0021-9797},
  doi = {10.1016/j.jcis.2015.01.002},
  abstract = {We investigate the stabilizing effect of insoluble surfactant monolayers on thin aqueous films. We first describe an experimental platform that enables the formation of aqueous films laden with dipalmitoylphosphatidylcholine (DPPC) monolayers on curved silicone hydrogel (SiHy) substrates. We show that these surfactant layers extend the lifetime of the aqueous films. The films eventually ``dewet'' by the nucleation and growth of dry areas and the onset of this dewetting can be controlled by the surface rheology of the DPPC layer. We thus demonstrate that increasing the interfacial rheology of the DPPC layer leads to stable films that delay dewetting. We also show that dewetting can be exploited to controllably pattern the underlying curved SiHy substrates with DPPC layers.},
  pmid = {25628055}
}

@article{Bhamla_Influence_2015,
  title = {Influence of Lipid Coatings on Surface Wettability Characteristics of Silicone Hydrogels},
  author = {Bhamla, Saad M and Nash, Walter L and Elliott, Stacey and Fuller, Gerald G},
  year = {2015},
  volume = {31},
  number = {13},
  pages = {3820--3828},
  issn = {0743-7463},
  doi = {10.1021/la503437a}
}

@article{Bialecki2010,
  title = {{{ADI}} Spectral Collocation Methods for Parabolic Problems},
  author = {Bialecki, B. and {de Frutos}, J.},
  year = {2010},
  month = jul,
  journal = {Journal of Computational Physics},
  volume = {229},
  number = {13},
  pages = {5182--5193},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.jcp.2010.03.033},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bialecki_de Frutos_2010_ADI spectral collocation methods for parabolic problems.pdf}
}

@article{BirkissonAutomaticFrechet2012,
  title = {Automatic {{Fr{\'e}chet Differentiation}} for the {{Numerical Solution}} of {{Boundary-Value Problems}}},
  author = {Birkisson, Asgeir and Driscoll, Tobin A.},
  year = {2012},
  month = aug,
  journal = {ACM Transactions on Mathematical Software},
  volume = {38},
  number = {4},
  pages = {1--29},
  issn = {00983500},
  doi = {10.1145/2331130.2331134},
  copyright = {All rights reserved},
  keywords = {Chebfun,linearization of boundary-value problems,Newton's method in function space,object-oriented Matlab},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Birkisson_Driscoll_2012_Automatic fréchet differentiation for the numerical solution of boundary-value.pdf}
}

@techreport{BirkissonAutomaticLinearity2013,
  title = {Automatic Linearity Detection},
  author = {Birkisson, Asgeir and Driscoll, Tobin A},
  year = {2013},
  number = {NA-13-04},
  institution = {{Oxford University}},
  copyright = {All rights reserved}
}

@book{bjorckNumericalMethodsLeast1996,
  title = {Numerical Methods for Least Squares Problems},
  author = {Bj{\"o}rck, {\AA}ke},
  year = {1996},
  publisher = {{SIAM}},
  address = {{Philadelphia}},
  isbn = {978-0-89871-360-2},
  lccn = {QA214 .B56 1996},
  keywords = {Equations Simultaneous,Least squares,Numerical solutions}
}

@article{bjorstadConformalMappingCircular1987,
  title = {Conformal {{Mapping}} of {{Circular Arc Polygons}}},
  author = {Bj{\o}rstad, {\relax Petter}. and Grosse, {\relax Eric}.},
  year = {1987},
  month = jan,
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume = {8},
  number = {1},
  pages = {19--32},
  issn = {0196-5204},
  doi = {10.1137/0908003},
  urldate = {2019-11-18},
  abstract = {An algorithm is described which computes the conformal mapping from the unit disk onto an arbitrary polygon having circular arcs as sides. This generalizes the Schwarz-Christoffel program of Trefethen (SIAM J. Sci. Stat. Comp., 1 (1980), pp. 82--102). Our algorithm must also determine certain parameters by solving a nonlinear least squares problem. Instead of using Gauss-Jacobi quadrature to evaluate the Schwarz-Christoffel integral, however, an ordinary differential equation solver is applied to a non-singular formulation of the Schwarzian differential equation. The construction of a conformal mapping reduces simple elliptic partial differential equations on an irregular region to similar problems on a disk, for which existing programs can compute solutions very efficiently. Typical examples arise in the modeling of conductivity past an array of conducting cylinders and electrical fields inside a waveguide.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bjørstad_Grosse_1987_Conformal Mapping of Circular Arc Polygons.pdf;/Users/driscoll/Zotero/storage/ZLE78BZY/0908003.html}
}

@techreport{BlomUseArclength1989,
  title = {On the Use of the Arclength and Curvature Monitor in a Moving-Grid Method Which Is Based on the Method of Lines},
  author = {Blom, Joke and Verwer, Jan},
  year = {1989},
  address = {{Department of Numerical Mathematics}},
  institution = {{NARCIS, NL}},
  file = {/Users/driscoll/Dropbox/library/Report/Blom_Verwer_1989_On the use of the arclength and curvature monitor in a moving-grid method which.pdf}
}

@article{Bocher_1994,
  title = {On {{Gregory-}} and Modified {{Gregory-type}} Corrections to {{Newton}}--{{Cotes}} Quadrature},
  author = {Bocher, P. and Meyer, H. De and Berghe, G. Vanden},
  year = {1994},
  month = may,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {50},
  number = {1-3},
  pages = {145--158},
  publisher = {{Elsevier BV}},
  doi = {10.1016/0377-0427(94)90296-8},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bocher et al_1994_On Gregory- and modified Gregory-type corrections to Newton–Cotes quadrature.pdf}
}

@book{bohmerDefectCorrectionMethods1984,
  title = {Defect {{Correction Methods Theory}} and {{Applications}}.},
  author = {B{\"o}hmer, K and Stetter, H. J and B{\"o}hmer, K},
  year = {1984},
  publisher = {{Springer Wien}},
  address = {{Vienna}},
  urldate = {2021-06-18},
  isbn = {978-3-7091-7023-6},
  langid = {english},
  annotation = {OCLC: 1255223037},
  file = {/Users/driscoll/Dropbox/library/Book/Böhmer et al_1984_Defect Correction Methods Theory and Applications.pdf}
}

@article{Bonanno_Measurement_1987,
  title = {Measurement of in Vivo Human Corneal Stromal {{pH}}: Open and Closed Eyes.},
  author = {Bonanno, {\relax JA} and Polse, {\relax KA}},
  year = {1987},
  volume = {28},
  number = {3},
  pages = {522--30},
  issn = {0146-0404},
  abstract = {The pH sensitive fluorescent properties of fluorescein were utilized to noninvasively measure human in vivo stromal pH in the normal open eye and following eye closure. Stromal pH after either 20 or 90 min of eye closure was 7.39 +/- 0.01 (n = 12, +/- SEM) and returned to 7.54 within 10-15 min of opening the eye, t1/2 = 3 min. Eye closure was simulated by exposing the eye to a gas mixture of 7.1\% O2, 6.7\% CO2, balance N2, which was passed through tight-fitting goggles. This gas mixture resulted in a steady-state stromal pH of 7.29 +/- 0.02 within 10-15 min, t1/2 = 2.2 min. The time course of the return of stromal pH to open eye levels after removal of the goggles, t1/2 = 2.3 min, was similar to that after eye opening. The extent of the pH change however, was 0.1 pH units greater with the test gas. Exposure of the eyes to 5\% CO2 (CO2 concentration of blood) and balance air, produced a stromal pH of 7.38 + 0.01 (n = 6, +/- SEM), which closely matches that following eye closure suggesting that conjunctival [CO2] is 5\% and is the major component controlling stromal pH when the eyes are closed.},
  pmid = {3557865}
}

@article{Bornemann2010,
  title = {Accuracy and Stability of Computing High-Order Derivatives of Analytic Functions by Cauchy Integrals},
  author = {Bornemann, Folkmar},
  year = {2010},
  month = jul,
  journal = {Foundations of Computational Mathematics},
  volume = {11},
  number = {1},
  pages = {1--63},
  publisher = {{Springer Nature}},
  doi = {10.1007/s10208-010-9075-z},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bornemann_2010_Accuracy and stability of computing high-order derivatives of analytic.pdf}
}

@article{Bos2016,
  title = {Trivariate Polynomial Approximation on {{Lissajous}} Curves},
  author = {Bos, L. and Marchi, S. De and Vianello, M.},
  year = {2016},
  month = may,
  journal = {IMA Journal of Numerical Analysis},
  volume = {37},
  number = {1},
  pages = {519--541},
  publisher = {{Oxford University Press (OUP)}},
  doi = {10.1093/imanum/drw013},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bos et al_2016_Trivariate polynomial approximation on Lissajous curves.pdf}
}

@article{Boyd2002,
  title = {A Comparison of Numerical Algorithms for Fourier Extension of the First, Second, and Third Kinds},
  author = {Boyd, John P.},
  year = {2002},
  month = may,
  journal = {Journal of Computational Physics},
  volume = {178},
  number = {1},
  pages = {118--160},
  publisher = {{Elsevier BV}},
  doi = {10.1006/jcph.2002.7023}
}

@article{Boyd2003,
  title = {A {{Legendre-pseudospectral}} Method for Computing Travelling Waves with Corners (Slope Discontinuities) in One Space Dimension with Application to {{Whitham}}'s Equation Family},
  author = {Boyd, John P.},
  year = {2003},
  month = jul,
  journal = {Journal of Computational Physics},
  volume = {189},
  number = {1},
  pages = {98--110},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0021-9991(03)00203-1},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Boyd_2003_A Legendre-pseudospectral method for computing travelling waves with corners.pdf}
}

@article{Boyd2009,
  title = {Truncated Gaussian {{RBF}} Differences Are Always Inferior to Finite Differences of the Same Stencil Width},
  author = {Boyd, John P. and Wang, Lei},
  year = {2009},
  journal = {Communications in Computational Physics},
  volume = {5},
  number = {1},
  pages = {42--60},
  abstract = {Radial basis functions (RBFs) can be used to approximate derivatives and solve differential equations in several ways. Here, we compare one important scheme to ordinary finite differences by a mixture of numerical experiments and theoretical Fourier analysis, that is, by deriving and discussing analytical formulas for the er- ror in differentiating exp(ikx) for arbitrary k.`Truncated RBF differences'' are derived from the same strategy as Fourier and Chebyshev pseudospectral methods: Differen- tiation of the Fourier, Chebyshev or RBF interpolant generates a differentiation ma- trix that maps the grid point values or samples of a function u(x) into the values of its derivative on the grid. For Fourier and Chebyshev interpolants, the action of the differentiation matrix can be computed indirectly but efficiently by the Fast Fourier Transform (FFT). For RBF functions, alas, the FFT is inapplicable and direct use of the dense differentiation matrix on a grid of N points is prohibitively expensive (O(N2)) unless N is tiny. However, for Gaussian RBFs, which are exponentially localized, there is another option, which is to truncate the dense matrix to a banded matrix, yielding ``truncated RBF differences''. The resulting formulas are identical in form to finite dif- ferences except for the difference weights. On a grid of spacing h with the RBF as {$\varphi$}(x)=exp(-{$\alpha$}2(x/h)2),},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Boyd_Wang_2009_Truncated gaussian RBF differences are always inferior to finite differences of.pdf}
}

@article{Braakman_Transport_2016,
  title = {Transport across {{Schlemm}}'s Canal Endothelium and the Blood-Aqueous Barrier},
  author = {Braakman, Sietse T and Moore, James E and Ethier, Ross C and Overby, Darryl R},
  year = {2016},
  volume = {146},
  pages = {17--21},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2015.11.026},
  abstract = {The majority of trabecular outflow likely crosses Schlemm's canal (SC) endothelium through micron-sized pores, and SC endothelium provides the only continuous cell layer between the anterior chamber and episcleral venous blood. SC endothelium must therefore be sufficiently porous to facilitate outflow, while also being sufficiently restrictive to preserve the blood-aqueous barrier and prevent blood and serum proteins from entering the eye. To understand how SC endothelium satisfies these apparently incompatible functions, we examined how the diameter and density of SC pores affects retrograde diffusion of serum proteins across SC endothelium, i.e. from SC lumen into the juxtacanalicular tissue (JCT). Opposing retrograde diffusion is anterograde bulk flow velocity of aqueous humor passing through pores, estimated to be approximately 5 mm/s. As a result of this relatively large through-pore velocity, a mass transport model predicts that upstream (JCT) concentrations of larger solutes such as albumin are less than 1\% of the concentration in SC lumen. However, smaller solutes such as glucose are predicted to have nearly the same concentration in the JCT and SC. In the hypothetical case that, rather than micron-sized pores, SC formed 65 nm fenestrae, as commonly observed in other filtration-active endothelia, the predicted concentration of albumin in the JCT would increase to approximately 50\% of that in SC. These results suggest that the size and density of SC pores may have developed to allow SC endothelium to maintain the blood-aqueous barrier while simultaneously facilitating aqueous humor outflow.},
  pmid = {26689753}
}

@article{brandFastLowrankModifications2006,
  title = {Fast Low-Rank Modifications of the Thin Singular Value Decomposition},
  author = {Brand, Matthew},
  year = {2006},
  month = may,
  journal = {Linear Algebra and its Applications},
  series = {Special {{Issue}} on {{Large Scale Linear}} and {{Nonlinear Eigenvalue Problems}}},
  volume = {415},
  number = {1},
  pages = {20--30},
  issn = {0024-3795},
  doi = {10.1016/j.laa.2005.07.021},
  urldate = {2022-05-25},
  abstract = {This paper develops an identity for additive modifications of a singular value decomposition (SVD) to reflect updates, downdates, shifts, and edits of the data matrix. This sets the stage for fast and memory-efficient sequential algorithms for tracking singular values and subspaces. In conjunction with a fast solution for the pseudo-inverse of a submatrix of an orthogonal matrix, we develop a scheme for computing a thin SVD of streaming data in a single pass with linear time complexity: A rank-r thin SVD of a p{\texttimes}q matrix can be computed in O(pqr) time for r{$\leq$}min(p,q).},
  langid = {english},
  keywords = {Sequential updating,Singular value decomposition,Subspace tracking},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Brand-2006-Fast low-rank modifications of the thin singular value decomposition.pdf;/Users/driscoll/Zotero/storage/J9TYRHF7/S0024379505003812.html}
}

@misc{Braun_Solute_2015,
  title = {Solute Dynamics and Imaging in the Tear Film on an Eye-Shaped Domain},
  author = {j Braun, Richard and Li, Longfei and Henshaw, William and Driscoll, Tobin A and E., P., King-Smith},
  year = {2015},
  copyright = {All rights reserved}
}

@article{BraunDataAnalysis2022,
  title = {Data and {{Analysis}} from {{Tear Breakup}} ({{TBU}}) in {{Normal Subjects}}},
  author = {Braun, Richard J and Driscoll, Tobin A and Sinopoli, Dominck and Dorsch, Julianna and Hammond, Caroline and Luke, Rayanne A and Begley, Carolyn G},
  year = {2022},
  month = jun,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {63},
  number = {7},
  pages = {3950 --  A0230},
  issn = {1552-5783},
  abstract = {A custom computer system was used to generate a large amount of data to estimate evaporation, osmosis, and different types of flow within regions of TBU in tear films (TF) for normal subjects. A convolutional neural network (CNN) automatically identified TBU and non-TBU in fluorescent (FL) images gathered in vivo. FL intensity data in those regions was extracted for fitting by three ordinary differential equations (ODE) models for TBU. Model parameters were optimized to best fit the FL data in order to identify the mechanisms active within TBU regions.    The FL intensity data was originally recorded from 25 normal subjects with 20 trials taken over two visits (Awisi-Gyau, Indiana University PhD thesis, 2020). We extract the experimental FL image data from the centers of TBU regions identified by the CNN. The data were fit with the ODE models using parameters representing evaporation rate (v), steady tangential flow (strain) rate (a), or decaying flow (b1) with decay rate (b2). A least squares minimization of the difference between experimental and computed intensities determined the parameters. Initial FL concentration and localized film thickness was estimated as in previous work (Wu et al IOVS 2015, 56:4211; Luke et al Bull Math Biol 2020, 82:71). All programs were custom using Python, Julia and/or Matlab.    Extraction resulted in N=467 usable instances of TBU from 15 subjects. Evaporation rates fall near or within experimental ranges. Statistical distributions of thickness and osmolarity were computed for individual subjects and for the population. Findings include: (i) The population of normals exhibited a range of mechanisms active in TBU instances. (ii) Individual subjects exhibited different mechanisms in different instances of TBU, even within a single trial. (iii) Individual subjects could in some cases be distinguished from each other based on the distribution of parameters responsible for their TBUs (Fig 1). (iv) Osmolarity increases with increasing evaporation rate at less than a linear rate (Fig 2).    Intensity decay in TBU areas yielded new data on the mechanisms of TBU in many instances. Quantitative estimates for TBU parameters were variable within and between subjects. The data provides a valuable baseline for the mechanisms and spatial distribution of TBU in normal subjects.  This abstract was presented at the 2022 ARVO Annual Meeting, held in Denver, CO, May 1-4, 2022, and virtually.     Scatter plots for flow parameter (b1) vs. evaporation rate (v).      Final osmolarity (ce) vs. evaporation rate (v).},
  copyright = {All rights reserved},
  keywords = {No DOI found},
  file = {/Users/driscoll/Zotero/storage/7DEX83ZS/article.html}
}

@article{BraunDynamicsMechanisms2021,
  title = {Dynamics and Mechanisms for Tear Breakup ({{TBU}}) on the Ocular Surface},
  author = {Braun, Richard J. and Luke, Rayanne A. and Driscoll, Tobin A. and Begley, Carolyn G.},
  year = {2021},
  journal = {Mathematical Biosciences and Engineering},
  volume = {18},
  number = {mbe-18-05-262},
  pages = {5146--5175},
  issn = {1551-0018},
  doi = {10.3934/mbe.2021262},
  urldate = {2021-09-09},
  abstract = {{$<$}abstract{$><$}p{$>$}The human tear film is rapidly established after each blink, and is essential for clear vision and eye health. This paper reviews mathematical models and theories for the human tear film on the ocular surface, with an emphasis on localized flows where the tear film may fail. The models attempt to identify the important physical processes, and their parameters, governing the tear film in health and disease.{$<$}/p{$><$}/abstract{$>$}},
  copyright = {2021 The Author(s)},
  langid = {english},
  annotation = {Cc\_license\_type: cc\_by Primary\_atype: Mathematical Biosciences and Engineering Subject\_term: Review Subject\_term\_id: Review},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Braun et al-2021-Dynamics and mechanisms for tear breakup (TBU) on the ocular surface.pdf;/Users/driscoll/Zotero/storage/6AFYFXJ7/mbe.html}
}

@article{braunDynamicsTear2012,
  title = {Dynamics of the {{Tear Film}}},
  author = {Braun, Richard J.},
  year = {2012},
  month = jan,
  journal = {Annual Review of Fluid Mechanics},
  volume = {44},
  number = {1},
  pages = {267--297},
  issn = {0066-4189, 1545-4479},
  doi = {10.1146/annurev-fluid-120710-101042},
  urldate = {2020-04-03},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Braun-2012-Dynamics of the Tear Film.pdf}
}

@article{BraunKing-Smith15,
  title = {Dynamics and Function of the Tear Film in Relation to the Blink Cycle.},
  author = {Braun, R. J. and {King-Smith}, P. E. and Begley, C. G. and Li, Longfei and Gewecke, N. R.},
  year = {2015},
  journal = {Progress in Retinal and Eye Research},
  volume = {45},
  pages = {132--164},
  doi = {10.1016/j.preteyeres.2014.11.001}
}

@incollection{braunMathematicalModels2019,
  title = {Mathematical {{Models}} of the {{Tear Film}}},
  booktitle = {Ocular {{Fluid Dynamics}}: {{Anatomy}}, {{Physiology}}, {{Imaging Techniques}}, and {{Mathematical Modeling}}},
  author = {Braun, Richard J and Driscoll, Tobin A and Begley, Carolyn G},
  year = {2019},
  month = nov,
  pages = {387--432},
  publisher = {{Springer-Birkhauser}},
  copyright = {All rights reserved},
  file = {/Users/driscoll/Dropbox/library/Book Section/Braun_Driscoll_Begley-2019-Mathematical Models of the Tear Film.pdf}
}

@inproceedings{BraunModelsTear2018,
  title = {Models for {{Tear Break Up Dynamics}} and {{Imaging}}},
  booktitle = {7th {{European Conference}} on {{Computational Fluid Dynamics}}},
  author = {Braun, Richard J and Zhong, Lan and Driscoll, Tobin A and Begley, Carolyn G and Antwi, Deborah and {King-Smith}, P Ewen},
  year = {2018},
  month = jun,
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{BraunModelTear2014,
  title = {A {{Model}} for {{Tear Film Thinning With Osmolarity}} and {{Fluorescein}}},
  author = {Braun, Richard J. and Gewecke, Nicholas R. and Begley, Carolyn G. and {King-Smith}, P. Ewen and Siddique, Javed I.},
  year = {2014},
  month = feb,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {55},
  number = {2},
  pages = {1133--1142},
  issn = {1552-5783},
  doi = {10.1167/iovs.13-12773},
  urldate = {2022-03-10},
  abstract = {We developed a mathematical model predicting dynamic changes in fluorescent intensity during tear film thinning in either dilute or quenching regimes and we model concomitant changes in tear film osmolarity.    We solved a mathematical model for the thickness, osmolarity, fluorescein concentration, and fluorescent intensity as a function of time, assuming a flat and spatially uniform tear film.    The tear film thins to a steady-state value that depends on the relative importance of the rates of evaporation and osmotic supply, and the resulting increase of osmolarity and fluorescein concentrations are calculated. Depending on the initial thickness, the rate of osmotic supply and the tear film thinning rate, the osmolarity increase may be modest or it may increase by as much as a factor of eight or more from isosmotic levels. Regarding fluorescent intensity, the quenching regime occurs for initial concentrations at or above the critical fluorescein concentration where efficiency dominates, while lower concentrations show little change in fluorescence with tear film thinning.    Our model underscores the importance of using fluorescein concentrations at or near the critical concentration clinically so that quenching reflects tear film thinning and breakup. In addition, the model predicts that, depending on tear film and osmotic factors, the osmolarity within the corneal compartment of the tear film may increase markedly during tear film thinning, well above levels that cause marked discomfort.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Braun et al-2014-A Model for Tear Film Thinning With Osmolarity and Fluorescein.pdf;/Users/driscoll/Zotero/storage/LW9IUDYR/article.html}
}

@inproceedings{BraunRecentProgress2008,
  title = {Recent Progress on {{Modeling}} the {{Human Tear Film}}},
  booktitle = {{{APS Division}} of {{Fluid Dynamics Meeting Abstracts}}},
  author = {Braun, Richard and McFadden, Jeff and Ranganathan, Usha and Driscoll, Tobin and {King-Smith}, Ewen},
  year = {2008},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@inproceedings{BraunSoluteDynamics2015,
  title = {Solute {{Dynamics}} and {{Imaging}} in the {{Tear Film}} on an {{Eye-shaped Domain}}},
  booktitle = {{{APS Meeting Abstracts}}},
  author = {Braun, {\relax RJ} and Li, Longfei and Henshaw, William and Driscoll, Tobin and {King-Smith}, {\relax PE}},
  year = {2015},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{BraunTearBreakup2023,
  title = {Tear {{Breakup}} ({{TBU}}) {{Analysis}} with {{Fluorescence}} ({{FL}}) and {{Thermal}} ({{TH}}) Imaging},
  author = {Braun, Richard J and Driscoll, Tobin and Begley, Carolyn and Situ, Ping and Tichenor, Anna and Luke, Rayanne},
  year = {2023},
  month = jun,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {64},
  number = {8},
  pages = {186--186},
  issn = {1552-5783},
  urldate = {2024-01-30},
  abstract = {Analyzing TBU with two imaging modalities, FL and TH, has the potential to greatly aid determination of mechanism and dynamics of TBU in the tear film (TF). We have recently shown that FL imaging can be used to quantify mechanisms of TBU for individual and groups of subjects. TH imaging can augment that capability with independent inputs that refine parameter identification in TBU.    Following instillation of 2{\textmu}l of 2\% FL, 10 subjects kept one eye open for as long as possible, a procedure known as sustained tear exposure (STARE) while the TF was simultaneously imaged with FL and TH cameras. We extracted the FL and TH image data from manually chosen TBU regions. The data were fit with the ordinary differential equation (DE) models for the TF thickness, osmolarity and FL concentrations using parameters representing evaporation rate amd variable tangential flow (strain) rate. The TF equations are coupled to a partial DE model for the interior eye temperature. Initial FL concentration and localized TF thickness were estimated as in previous work (Wu et al IOVS 2015, 56:4211; Luke et al Bull Math Biol 2020, 82:71). All programs were custom using Julia and/or Matlab.    Preliminary results produce multiple usable instances of TBU from each subject (e.g. Figs. 1 \&amp; 2). Evaporation rates and other fell within experimental ranges. Temperature differences across the tear film were tiny, as in previous results (e.g., Dursch et al OVS 2018, 95:5--12). Just four parameters (evaporation rate, convective cooling, \&amp; 2 for flow) appear to be sufficient to fit the two types of data well.    FL intensity decay, together with temperature decay at the TF surface, can yield quantitative insight into TBU dynamics and parameters. Since these quantities cannot currently be measured directly, these results provide theoretical estimates driven by data which provide a better understanding of the sensory stimuli presented to the ocular surface during TBU. Quantifying these stimuli may lead to better understanding of sensory response.  This abstract was presented at the 2023 ARVO Annual Meeting, held in New Orleans, LA, April 23-27, 2023.     Fig 1: Sample math model FL intensity answers (I(t)) with experiment (Iexp(t)). The thickness (h), osmolarity (c) and FL concentration (f) are also shown, all as functions of time t.      Fig 2: Eye temperature results for the same case as Figure 1. The TF/cornea interface is located at y=0. T0 \&amp; T(h,t) are the corneal and TF surface temperatures, respectively.},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{BraunTearFilm2018,
  title = {On Tear Film Breakup ({{TBU}}): Dynamics and Imaging},
  shorttitle = {On Tear Film Breakup ({{TBU}})},
  author = {Braun, Richard J and Driscoll, Tobin A and Begley, Carolyn G and {King-Smith}, P Ewen and Siddique, Javed I},
  year = {2018},
  month = jun,
  journal = {Mathematical Medicine and Biology},
  volume = {35},
  number = {2},
  pages = {145--180},
  issn = {1477-8599},
  doi = {10.1093/imammb/dqw023},
  urldate = {2020-10-13},
  abstract = {We report the results of some recent experiments to visualize tear film dynamics. We then study a mathematical model for tear film thinning and tear film breakup (TBU), a term from the ocular surface literature. The thinning is driven by an imposed tear film thinning rate which is input from in vivo measurements. Solutes representing osmolarity and fluorescein are included in the model. Osmolarity causes osmosis from the model ocular surface, and the fluorescein is used to compute the intensity corresponding closely to in vivo observations. The imposed thinning can be either one-dimensional or axisymmetric, leading to streaks or spots of TBU, respectively. For a spatially-uniform (flat) film, osmosis would cease thinning and balance mass lost due to evaporation; for these space-dependent evaporation profiles TBU does occur because osmolarity diffuses out of the TBU into the surrounding tear film, in agreement with previous results. The intensity pattern predicted based on the fluorescein concentration is compared with the computed thickness profiles; this comparison is important for interpreting in vivo observations. The non-dimensionalization introduced leads to insight about the relative importance of the competing processes; it leads to a classification of large vs small TBU regions in which different physical effects are dominant. Many regions of TBU may be considered small, revealing that the flow inside the film has an appreciable influence on fluorescence imaging of the tear film.},
  copyright = {All rights reserved},
  pmcid = {PMC5998802},
  pmid = {28339681},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Braun et al-2018-On tear film breakup (TBU).pdf;/Users/driscoll/Dropbox/library/Journal Article/Braun et al-2018-On tear film breakup (TBU)2.pdf}
}

@article{BraunThinFilm2012,
  title = {Thin Film Dynamics on a Prolate Spheroid with Application to the Cornea},
  author = {Braun, {\relax RJ} and Usha, R and McFadden, {\relax GB} and Driscoll, Tobin A and Cook, {\relax LP} and {King-Smith}, Peter Ewen},
  year = {2012},
  journal = {Journal of Engineering Mathematics},
  volume = {73},
  number = {1},
  pages = {121--138},
  doi = {10.1007/s10665-011-9482-4},
  copyright = {All rights reserved}
}

@book{brenanNumericalSolutionInitialvalue1996,
  title = {Numerical Solution of Initial-Value Problems in Differential-Algebraic Equations},
  author = {Brenan, Kathryn E. and Campbell, S. L. and Petzold, Linda R.},
  year = {1996},
  series = {Classics in Applied Mathematics},
  number = {14},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  isbn = {978-0-89871-353-4},
  lccn = {QA378 .B73 1996},
  keywords = {Initial value problems,Numerical solutions}
}

@article{Brennan_Corneal_2005,
  title = {Corneal Oxygenation during Contact Lens Wear: Comparison of Diffusion and {{EOP}}-based Flux Models},
  author = {Brennan, Noel A},
  year = {2005},
  volume = {88},
  number = {2},
  pages = {103--108},
  issn = {1444-0938},
  doi = {10.1111/j.1444-0938.2005.tb06675.x},
  abstract = {Purpose: The aim of this study was to compare corneal oxygen flux values derived from an oxygen diffusion model, with estimates from a model in which equivalent oxygen percentage (EOP) values were substituted for the post-lens tear film oxygen tension in Fick's law. Methods: A previously described five-layer corneal oxygen diffusion model was found to artefactually allow theoretical oxygen consumption, when the predicted oxygen tension fell to zero. Consequently, an eight-layer diffusion model was constructed, with consumption set to zero at points within the cornea, where predicted oxygen tension falls to zero. Post-lens tear layer thickness was corrected to more contemporary estimates. The eight-layer and EOP-based anterior corneal oxygen flux estimates were compared across the range of commonly encountered contact lens Dk/t values. Results: The eight-layer model overcomes deficiencies in the five-layer model and provides predicted values that are remarkably similar to the EOP-based model. Open and closed eye anterior corneal oxygen flux in the absence of contact lens wear was estimated at 7.8 and 7.6 {$\mu$}L/cm2/hr for the open eye and 6.0 and 6.1 {$\mu$}L/cm2/hr for closed eye for the diffusion and EOP-based models, respectively. Conclusions: The diffusion model supports the EOP model in that there is minimal oxygen benefit to be gained by increasing Dk/t above the Holden-Mertz criteria of 24 and 87 times 10-9 (cm/sec) (ml02/ml.mmHg) during open and closed eye wear, respectively. The eight-layer model is suitable for further definition of corneal oxygenation during contact lens wear.}
}

@book{brittonEssentialMathematicalBiology2003,
  title = {Essential Mathematical Biology},
  author = {Britton, N. F.},
  year = {2003},
  series = {Springer Undergraduate Mathematics Series},
  publisher = {{Springer}},
  address = {{London ; New York}},
  isbn = {978-1-85233-536-6},
  lccn = {QH323.5 .B745 2003},
  keywords = {Biomathematics}
}

@article{BrKS07,
  title = {Model Problems for the Tear Film in a Blink Cycle: {{Single}} Equation Models},
  author = {Braun, R.J. and {King-Smith}, P.E.},
  year = {2007},
  journal = {J. Fluid Mech.},
  volume = {586},
  pages = {465--90},
  doi = {10.1017/s002211200700701x}
}

@article{bronGradingCorneal2003,
  title = {Grading of Corneal and Conjunctival Staining in the Context of Other Dry Eye Tests},
  author = {Bron, Anthony J. and Evans, Victoria E. and Smith, Janine A.},
  year = {2003},
  month = oct,
  journal = {Cornea},
  volume = {22},
  number = {7},
  pages = {640--650},
  issn = {0277-3740},
  doi = {10.1097/00003226-200310000-00008},
  abstract = {PURPOSE: To describe the Oxford Scheme for grading ocular surface staining in dry eye and to discuss optimization of stain detection using various dyes and filters. Also, to propose a sequence of testing for dry eye diagnosis. METHODS: The grading of corneal and conjunctival staining is described, using the Oxford Scheme, including biomicroscopy, optical filters, illumination conditions, and the characteristics of and instillation techniques used for, selected clinical dyes. RESULTS: A series of panels, labeled A-E, in order of increasing severity, reproducing the staining patterns encountered in dry eye, are used as a guide to grade the degree of staining seen in the patient. The amount of staining seen in each panel, represented by punctate dots, increases by 0.5 of the log of the number of dots between panels B to E. The use of the vital dyes fluorescein, lissamine green, and rose Bengal is described; fluorescein and lissamine green, used in conjunction with appropriate absorption filters, are recommended for use in clinical trials. The placement of staining in relation to the sequence of other diagnostic tests is discussed. CONCLUSIONS: The monitoring and assessment of corneal and conjunctival staining can be greatly enhanced by the use of a grading scale, controlled instillation of dyes, and standard evaluation techniques. This is of particular benefit in clinical trials, where ocular surface staining is commonly employed as an outcome measure},
  langid = {english},
  pmid = {14508260},
  keywords = {Coloring Agents,Conjunctiva,Contrast Media,Cornea,Dry Eye Syndromes,Fluorescein,Fluorescent Dyes,Humans,Lissamine Green Dyes,Rose Bengal,Staining and Labeling}
}

@article{Brooks1998,
  title = {Markov Chain {{Monte Carlo}} Method and Its Application},
  author = {Brooks, Stephen},
  year = {1998},
  month = mar,
  journal = {Journal of the Royal Statistical Society: Series D (The Statistician)},
  volume = {47},
  number = {1},
  pages = {69--100},
  publisher = {{Wiley-Blackwell}},
  doi = {10.1111/1467-9884.00117},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Brooks_1998_Markov chain Monte Carlo method and its application.pdf}
}

@article{broschBlinkCharacterization2017,
  title = {Blink Characterization Using Curve Fitting and Clustering Algorithms},
  author = {Brosch, Joseph K and Wu, Ziwei and Begley, Carolyn G and Driscoll, Tobin A and Braun, Richard J},
  year = {2017},
  journal = {Journal for Modeling in Ophthalmology},
  volume = {1},
  number = {3},
  pages = {60--81},
  doi = {10.35119/maio.v1i3.38},
  copyright = {All rights reserved}
}

@inproceedings{broschSimulationThin2016,
  title = {Simulation of {{Thin Film Equations}} on an {{Eye-Shaped Domain}} with {{Moving Boundary}}},
  booktitle = {{{APS March Meeting Abstracts}}},
  author = {Brosch, Joseph and Driscoll, Tobin and Braun, Richard},
  year = {2016},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{Brown1971,
  title = {Deflation Techniques for the Calculation of Further Solutions of a Nonlinear System},
  author = {Brown, Kenneth M. and Gearhart, William B.},
  year = {1971},
  month = jan,
  journal = {Numerische Mathematik},
  volume = {16},
  number = {4},
  pages = {334--342},
  publisher = {{Springer Nature}},
  doi = {10.1007/bf02165004},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Brown_Gearhart_1971_Deflation techniques for the calculation of further solutions of a nonlinear.pdf}
}

@article{Bruce_Analysis_2001,
  title = {Analysis of Tear Film Breakup on {{Etafilcon A}} Hydrogel Lenses},
  author = {Bruce, Adrian S and Mainstone, Julia C and Golding, Timothy R},
  year = {2001},
  volume = {22},
  number = {24},
  pages = {3249--3256},
  issn = {0142-9612},
  doi = {10.1016/s0142-9612(01)00162-4},
  abstract = {Purpose: There is a need to understand better the biomaterial characteristics responsible for tear film stability during hydrogel lens wear. The underlying cause of pre-lens tear film instability may be indicated by the distribution of sites of breakup. The purpose of this study was to compare the distribution of rupture sites during wear of a common biomaterial to that without lenses. Methods: A videokeratography unit, the Topographic Modeling SystemTM, was used to capture an image of the tear film at the moment of breakup. Forty measurements were made for each of ten subjects, and the resultant rupture site distributions evaluated. The pre-lens tear film breakup locations were studied for Acuvue (Etafilcon A) disposable contact lenses using the same technique. Results: There was a statistically significant trend for pre-corneal tear film breaks to occur more commonly in parameniscal zones than in areas overlying the central cornea (ANOVA, p=0.002). With the Etafilcon A lenses, a significant difference in breakup frequency between the two regions was not observed. Conclusions: The pre-corneal tear film findings are consistent with the meniscus model of tear film stability; however, the biomaterial surface characteristics of Etafilcon A give other factors a more dominant role in tear film rupture.},
  pmid = {11700796}
}

@article{brunaInfluenceNonpolar2014,
  title = {The Influence of Non-Polar Lipids on Tear Film Dynamics},
  author = {Bruna, M. and Breward, C.~J.~W.},
  year = {2014},
  month = may,
  journal = {Journal of Fluid Mechanics},
  volume = {746},
  pages = {565--605},
  issn = {0022-1120, 1469-7645},
  doi = {10.1017/jfm.2014.106},
  urldate = {2020-07-11},
  abstract = {Abstract             In this paper we examine the effect that physiological non-polar lipids, residing on the surface of an aqueous tear film, have on the film evolution. In our model we track the evolution of the thickness of the non-polar lipid layer, the thickness of the aqueous layer and the concentration of polar lipids which reside at the interface between the two. We also utilise a force balance in the non-polar lipid layer in order to determine its velocity. We show how to obtain previous models in the literature from our model by making particular choices of the parameters. We see the formation of boundary layers in some of these submodels, across which the concentration of polar lipid and the non-polar lipid velocity and film thickness vary. We solve our model numerically for physically realistic parameter values, and we find that the evolution of the aqueous layer and the polar lipid layer are similar to that described by previous authors. However, there are interesting dynamics for the non-polar lipid layer. The effects of altering the key parameters are highlighted and discussed. In particular, we see that the Marangoni number plays a key role in determining how far over the eye the non-polar lipid spreads.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bruna_Breward-2014-The influence of non-polar lipids on tear film dynamics.pdf}
}

@article{bruntonDiscoveringGoverningEquations2016,
  title = {Discovering Governing Equations from Data by Sparse Identification of Nonlinear Dynamical Systems},
  author = {Brunton, Steven L. and Proctor, Joshua L. and Kutz, J. Nathan},
  year = {2016},
  month = apr,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {113},
  number = {15},
  pages = {3932--3937},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1517384113},
  urldate = {2020-08-07},
  abstract = {Extracting governing equations from data is a central challenge in many diverse areas of science and engineering. Data are abundant whereas models often remain elusive, as in climate science, neuroscience, ecology, finance, and epidemiology, to name only a few examples. In this work, we combine sparsity-promoting techniques and machine learning with nonlinear dynamical systems to discover governing equations from noisy measurement data. The only assumption about the structure of the model is that there are only a few important terms that govern the dynamics, so that the equations are sparse in the space of possible functions; this assumption holds for many physical systems in an appropriate basis. In particular, we use sparse regression to determine the fewest terms in the dynamic governing equations required to accurately represent the data. This results in parsimonious models that balance accuracy with model complexity to avoid overfitting. We demonstrate the algorithm on a wide range of problems, from simple canonical systems, including linear and nonlinear oscillators and the chaotic Lorenz system, to the fluid vortex shedding behind an obstacle. The fluid example illustrates the ability of this method to discover the underlying dynamics of a system that took experts in the community nearly 30 years to resolve. We also show that this method generalizes to parameterized systems and systems that are time-varying or have external forcing.},
  chapter = {Physical Sciences},
  copyright = {{\copyright}  . Freely available online through the PNAS open access option.},
  langid = {english},
  pmid = {27035946},
  keywords = {dynamical systems,machine learning,optimization,sparse regression,system identification},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Brunton_Proctor_Kutz-2016-Discovering governing equations from data by sparse.pdf;/Users/driscoll/Zotero/storage/KFG2PMFY/3932.html}
}

@inproceedings{Bu2009,
  title = {Semi-Implicit {{Krylov}} Deferred Correction Methods for Ordinary Differential Equations},
  booktitle = {{{AMATH}}'09 Proceedings of the 15th American Conference on Applied Mathematics},
  author = {Bu, S. and Huang, J. and Minion, M. L.},
  year = {2009},
  pages = {95--100},
  publisher = {{World Scientific and Engineering Academy and Society (WSEAS)}},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Bu et al_2009_Semi-implicit Krylov deferred correction methods for ordinary differential.pdf}
}

@misc{BudisaRationalApproximation2022,
  title = {Rational Approximation Preconditioners for Multiphysics Problems},
  author = {Budisa, Ana and Hu, Xiaozhe and Kuchta, Miroslav and Mardal, Kent-Andre and Zikatanov, Ludmil},
  year = {2022},
  month = nov,
  number = {arXiv:2209.11659},
  eprint = {2209.11659},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  urldate = {2023-04-12},
  abstract = {We consider a class of mathematical models describing multiphysics phenomena interacting through interfaces. On such interfaces, the traces of the fields lie (approximately) in the range of a weighted sum of two fractional differential operators. We use a rational function approximation to precondition such operators. We first demonstrate the robustness of the approximation for ordinary functions given by weighted sums of fractional exponents. Additionally, we present more realistic examples utilizing the proposed preconditioning techniques in interface coupling between Darcy and Stokes equations.},
  archiveprefix = {arxiv},
  keywords = {65F08 65F60,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Budisa et al_2022_Rational approximation preconditioners for multiphysics problems.pdf;/Users/driscoll/Zotero/storage/IYW3XKVC/2209.html}
}

@article{Bungartz2004,
  title = {Sparse Grids},
  author = {Bungartz, Hans-Joachim and Griebel, Michael},
  year = {2004},
  month = may,
  journal = {Acta Numerica},
  volume = {13},
  pages = {147--269},
  publisher = {{Cambridge University Press (CUP)}},
  doi = {10.1017/s0962492904000182},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Bungartz_Griebel_2004_Sparse grids.pdf}
}

@book{burdenNumericalAnalysis2001,
  title = {Numerical Analysis},
  author = {Burden, Richard L. and Faires, J. Douglas},
  year = {2001},
  edition = {7th ed},
  publisher = {{Brooks/Cole}},
  address = {{Australia ; Pacific Grove, CA}},
  isbn = {978-0-534-38216-2},
  lccn = {QA297 .B84 2001},
  keywords = {Numerical analysis}
}

@incollection{caiNewtonKrylovSchwarzMethodsCFD1994,
  title = {Newton-{{Krylov-Schwarz Methods}} in {{CFD}}},
  booktitle = {Numerical Methods for the {{Navier-Stokes}} Equations: {{Proceedings}} of the {{International Workshop Held}} at {{Heidelberg}}, {{October}} 25--28, 1993},
  author = {Cai, X.-C. and Gropp, W. D. and Keyes, D. E. and Tidriri, M. D.},
  editor = {Hebeker, Friedrich-Karl and Rannacher, Rolf and Wittum, Gabriel},
  year = {1994},
  series = {Notes on {{Numerical Fluid Mechanics}} ({{NNFM}})},
  pages = {17--30},
  publisher = {{Vieweg+Teubner Verlag}},
  address = {{Wiesbaden}},
  doi = {10.1007/978-3-663-14007-8_3},
  urldate = {2020-04-02},
  abstract = {SummaryNewton-Krylov methods are potentially well suited for the implicit solution of nonlinear problems whenever it is unreasonable to compute or store a true Jacobian. Krylov-Schwarz iterative methods are well suited for the parallel implicit solution of multidimensional systems of boundary value problems that arise in CFD. They provide good data locality so that even a high-latency workstation network can be employed as a parallel machine. We call the combination of these two methods Newton-Krylov-Schwarz and report numerical experiments on some algorithmic and implementation aspects: the use of mixed discretization schemes in the (implicitly defined) Jacobian and its preconditioner, the selection of the differencing parameter in the formation of the action of the Jacobian, the use of a coarse grid in additive Schwarz preconditioning, and workstation network implementation. Three model problems are considered: a convection-diffusion problem, the full potential equation, and the Euler equations.},
  isbn = {978-3-663-14007-8},
  langid = {english}
}

@article{CaiNonlinearlyPreconditioned2002,
  title = {Nonlinearly {{Preconditioned Inexact Newton Algorithms}}},
  author = {Cai, Xiao-Chuan. and Keyes, David E.},
  year = {2002},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {24},
  number = {1},
  pages = {183--200},
  issn = {1064-8275},
  doi = {10.1137/s106482750037620x},
  urldate = {2019-10-08},
  abstract = {Inexact Newton algorithms are commonly used for solving large sparse nonlinear system of equations \$F(u\^{}\{{\textbackslash}ast\})=0\$ arising, for example, from the discretization of partial differential equations. Even with global strategies such as linesearch or trust region, the methods often stagnate at local minima of \${\textbackslash}{\textbar}F{\textbackslash}{\textbar}\$, especially for problems with unbalanced nonlinearities, because the methods do not have built-in machinery to deal with the unbalanced nonlinearities. To find the same solution \$u\^{}\{{\textbackslash}ast\}\$, one may want to solve instead an equivalent nonlinearly preconditioned system \$\{{\textbackslash}cal F\}(u\^{}\{{\textbackslash}ast\})=0\$ whose nonlinearities are more balanced. In this paper, we propose and study a nonlinear additive Schwarz-based parallel nonlinear preconditioner and show numerically that the new method converges well even for some difficult problems, such as high Reynolds number flows, where a traditional inexact Newton method fails.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cai_Keyes_2002_Nonlinearly Preconditioned Inexact Newton Algorithms.pdf;/Users/driscoll/Zotero/storage/34E72YTW/S106482750037620X.html}
}

@article{CaiPhysicsinformedNeural2021,
  title = {Physics-Informed Neural Networks ({{PINNs}}) for Fluid Mechanics: A Review},
  shorttitle = {Physics-Informed Neural Networks ({{PINNs}}) for Fluid Mechanics},
  author = {Cai, Shengze and Mao, Zhiping and Wang, Zhicheng and Yin, Minglang and Karniadakis, George Em},
  year = {2021},
  month = dec,
  journal = {Acta Mechanica Sinica},
  volume = {37},
  number = {12},
  pages = {1727--1738},
  issn = {1614-3116},
  doi = {10.1007/s10409-021-01148-1},
  urldate = {2023-12-12},
  abstract = {Despite the significant progress over the last 50 years in simulating flow problems using numerical discretization of the Navier--Stokes equations (NSE), we still cannot incorporate seamlessly noisy data into existing algorithms, mesh-generation is complex, and we cannot tackle high-dimensional problems governed by parametrized NSE. Moreover, solving inverse flow problems is often prohibitively expensive and requires complex and expensive formulations and new computer codes. Here, we review flow physics-informed learning, integrating seamlessly data and mathematical models, and implement them using physics-informed neural networks (PINNs). We demonstrate the effectiveness of PINNs for inverse problems related to three-dimensional wake flows, supersonic flows, and biomedical flows.},
  langid = {english},
  keywords = {Biomedical flows,Inverse problems,Physics-informed learning,PINNs,Supersonic flows},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cai et al_2021_Physics-informed neural networks (PINNs) for fluid mechanics.pdf}
}

@article{caiTwostageImageSegmentation2013,
  title = {A Two-Stage Image Segmentation Method Using a Convex Variant of the {{Mumford}}--{{Shah}} Model and Thresholding},
  author = {Cai, Xiaohao and Chan, Raymond and Zeng, Tieyong},
  year = {2013},
  journal = {SIAM Journal on Imaging Sciences},
  volume = {6},
  number = {1},
  pages = {368--390},
  doi = {10.1137/120867068},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cai et al_2013_A two-stage image segmentation method using a convex variant of the.pdf;/Users/driscoll/Zotero/storage/NP5ZFI3X/120867068.html}
}

@article{Campbell1996,
  title = {Convergence Estimates for Solution of Integral Equations with {{GMRES}}},
  author = {Campbell, S. L. and Ipsen, I. C. F. and Kelley, C. T. and Meyer, C. D. and Xue, Z. Q.},
  year = {1996},
  journal = {Journal of Integral Equations and Applications},
  volume = {8},
  doi = {10.1216/jiea/1181075914},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Campbell et al_1996_Convergence estimates for solution of integral equations with GMRES.pdf}
}

@book{canutoSpectralMethodsFluid1988,
  title = {Spectral {{Methods}} in {{Fluid Dynamics}}},
  author = {Canuto, Claudio and Hussaini, M. Yousuff and Quarteroni, Alfio and Zang, Thomas A},
  year = {1988},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  urldate = {2020-06-18},
  abstract = {This textbook presents the modern unified theory of spectral methods and their implementation in the numerical analysis of partial differential equations occuring in fluid dynamical problems of transition, turbulence, and aerodynamics. It provides the engineer with the tools and guidance necessary to apply the methods successfully, and it furnishes the mathematician with a comprehensive, rigorous theory of the subject. All of the essential components of spectral algorithms currently employed for large-scale computations in fluid mechanics are described in detail. Some specific applications are linear stability, boundary layer calculations, direct simulations of transition and turbulence, and compressible Euler equations. The authors also present complete algorithms for Poisson's equation, linear hyperbolic systems, the advection diffusion equation, isotropic turbulence, and boundary layer transition. Some recent developments stressed in the book are iterative techniques (including the spectral multigrid method), spectral shock-fitting algorithms, and spectral multidomain methods. The book addresses graduate students and researchers in fluid dynamics and applied mathematics as well as engineers working on problems of practical importance.},
  isbn = {978-3-540-52205-8},
  langid = {english},
  annotation = {OCLC: 851380830}
}

@inproceedings{CaoChooseTransformer2021,
  title = {Choose a {{Transformer}}: {{Fourier}} or {{Galerkin}}},
  shorttitle = {Choose a {{Transformer}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Cao, Shuhao},
  year = {2021},
  month = nov,
  urldate = {2023-07-03},
  abstract = {In this paper, we apply the self-attention from the state-of-the-art Transformer in Attention Is All You Need for the first time to a data-driven operator learning problem related to partial differential equations. An effort is put together to explain the heuristics of, and to improve the efficacy of the attention mechanism. By employing the operator approximation theory in Hilbert spaces, it is demonstrated for the first time that the softmax normalization in the scaled dot-product attention is sufficient but not necessary. Without softmax, the approximation capacity of a linearized Transformer variant can be proved to be comparable to a Petrov-Galerkin projection layer-wise, and the estimate is independent with respect to the sequence length. A new layer normalization scheme mimicking the Petrov-Galerkin projection is proposed to allow a scaling to propagate through attention layers, which helps the model achieve remarkable accuracy in operator learning tasks with unnormalized data. Finally, we present three operator learning experiments, including the viscid Burgers' equation, an interface Darcy flow, and an inverse interface coefficient identification problem. The newly proposed simple attention-based operator learner, Galerkin Transformer, shows significant improvements in both training cost and evaluation accuracy over its softmax-normalized counterparts.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Cao_2021_Choose a Transformer.pdf}
}

@article{CareyGradingFunctions1985,
  title = {Grading {{Functions}} and {{Mesh Redistribution}}},
  author = {Carey, Graham F. and Dinh, Hung T.},
  year = {1985},
  month = oct,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {22},
  number = {5},
  pages = {1028--1040},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1429},
  doi = {10.1137/0722061},
  urldate = {2023-02-10},
  abstract = {This paper considers several moving mesh partial differential equations that are related to the equidistribution principle. Several of these are new, and some correspond to discrete moving mesh equations that have been used by others. Their stability is analyzed and it is seen that a key term for most of these moving mesh PDEs is a source-like term that measures the level of equidistribution. It is shown that under weak assumptions mesh crossing cannot occur for most of them. Finally, numerical experiments for these various moving mesh PDEs are performed to study their relative properties.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Carey_Dinh_1985_Grading Functions and Mesh Redistribution.pdf}
}

@book{carlsonClinicalProcedures2004,
  title = {Clinical Procedures for Ocular Examination},
  editor = {Carlson, Nancy B. and Kurtz, Daniel},
  year = {2004},
  edition = {3rd ed},
  publisher = {{McGraw-Hill, Medical Pub. Div}},
  address = {{New York}},
  isbn = {978-0-07-137078-3},
  lccn = {RE75 .C474 2004},
  keywords = {diagnosis,Diseases Diagnosis,Examination,Eye,Eye Diseases,instrumentation,methods,Optometry,Vision Tests}
}

@article{Carlsson2009,
  title = {Topology and Data},
  author = {Carlsson, G.},
  year = {2009},
  journal = {Bulletin of the American Mathematical Society},
  volume = {46},
  number = {2},
  pages = {255--308},
  doi = {10.1090/S0273-0979-09-01249-X},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Carlsson_2009_Topology and data.pdf}
}

@article{Carpenter1996,
  title = {Spectral Methods on Arbitrary Grids},
  author = {Carpenter, Mark H and Gottlieb, David},
  year = {1996},
  journal = {Journal of Computational physics},
  volume = {129},
  number = {1},
  pages = {74--86},
  publisher = {{Elsevier}},
  doi = {10.1006/jcph.1996.0234},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Carpenter_Gottlieb_1996_Spectral methods on arbitrary grids.pdf}
}

@article{carrierSingularPerturbationTheory1970,
  title = {Singular {{Perturbation Theory}} and {{Geophysics}}},
  author = {Carrier, G. F.},
  year = {1970},
  month = apr,
  journal = {SIAM Review},
  volume = {12},
  number = {2},
  pages = {175--193},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/1012041},
  urldate = {2020-06-18},
  langid = {english}
}

@article{Casciola2007,
  title = {The Regularizing Properties of Anisotropic Radial Basis Functions},
  author = {Casciola, G. and Montefusco, L.B. and Morigi, S.},
  year = {2007},
  month = jul,
  journal = {Applied Mathematics and Computation},
  volume = {190},
  number = {2},
  pages = {1050--1062},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.amc.2006.11.128},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Casciola et al_2007_The regularizing properties of anisotropic radial basis functions.pdf}
}

@article{cashDeferredCorrectionMethod1991,
  title = {A {{Deferred Correction Method}} for {{Nonlinear Two-Point Boundary Value Problems}}: {{Implementation}} and {{Numerical Evaluation}}},
  shorttitle = {A {{Deferred Correction Method}} for {{Nonlinear Two-Point Boundary Value Problems}}},
  author = {Cash, J. R. and Wright, M. H.},
  year = {1991},
  month = jul,
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume = {12},
  number = {4},
  pages = {971--989},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0196-5204},
  doi = {10.1137/0912052},
  urldate = {2022-08-15},
  abstract = {A deferred correction method for the numerical solution of nonlinear two-point boundary value problems has been derived and analyzed in two recent papers by the first author. The method is based on mono-implicit Runge--Kutta formulas and is specially designed to deal efficiently with problems whose solutions contain nonsmooth parts---in particular, singular perturbation problems of boundary layer or turning point type. This paper briefly describes an implementation of the method and gives the results of extensive numerical testing on a set of nonlinear problems that includes both smooth and increasingly stiff (and difficult) problems. Results on the test set are also given using the available codes COLSYS and COLNEW. Although the intent is not to make a formal comparison, the code described appears to be competitive in speed and storage requirements on these problems.},
  keywords = {65L10,65L20,deferred correction,software evaluation,two-point boundary value problems},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cash_Wright-1991-A Deferred Correction Method for Nonlinear Two-Point Boundary Value Problems.pdf}
}

@misc{centerforhistoryandnewmediaZoteroQuickStart,
  title = {Zotero {{Quick Start Guide}}},
  author = {{Center for History and New Media}},
  howpublished = {http://zotero.org/support/quick\_start\_guide}
}

@article{CerretaniEtal14,
  title = {Tear Dynamics in Healthy and Dry Eyes},
  author = {Cerretani, C. F. and Radke, C. J.},
  year = {2014},
  journal = {Current Eye Research},
  volume = {39},
  pages = {580--595},
  doi = {10.3109/02713683.2013.859274}
}

@article{Cervino2003,
  title = {On the Extension of the Complex-Step Derivative Technique to Pseudospectral Algorithms},
  author = {Cervi{\~n}o, Laura I. and Bewley, Thomas R.},
  year = {2003},
  month = may,
  journal = {Journal of Computational Physics},
  volume = {187},
  number = {2},
  pages = {544--549},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0021-9991(03)00123-2},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cerviño_Bewley_2003_On the extension of the complex-step derivative technique to pseudospectral.pdf}
}

@article{Chan1985,
  title = {Fourier Methods with Extended Stability Intervals for the Korteweg--de Vries Equation},
  author = {Chan, Tony F. and Kerkhoven, Tom},
  year = {1985},
  month = jun,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {22},
  number = {3},
  pages = {441--454},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/0722026}
}

@article{Chan1992,
  title = {Some Applications of the Rank Revealing {{QR}} Factorization},
  author = {Chan, Tony F. and Hansen, Per Christian},
  year = {1992},
  month = may,
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume = {13},
  number = {3},
  pages = {727--741},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/0913043},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Chan_Hansen_1992_Some applications of the rank revealing QR factorization.pdf}
}

@article{Chandrasekaran2005,
  title = {A Fast Adaptive Solver for Hierarchically Semiseparable Representations},
  author = {Chandrasekaran, S. and Gu, M. and Lyons, W.},
  year = {2005},
  month = dec,
  journal = {Calcolo},
  volume = {42},
  number = {3-4},
  pages = {171--185},
  publisher = {{Springer Nature}},
  doi = {10.1007/s10092-005-0103-3},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Chandrasekaran et al_2005_A fast adaptive solver for hierarchically semiseparable representations.pdf}
}

@article{Chandrasekaran2006,
  title = {A Fast {{ULV}} Decomposition Solver for Hierarchically Semiseparable Representations},
  author = {Chandrasekaran, S. and Gu, M. and Pals, T.},
  year = {2006},
  month = jan,
  journal = {SIAM Journal on Matrix Analysis and Applications},
  volume = {28},
  number = {3},
  pages = {603--622},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/s0895479803436652}
}

@article{chanTotalVariationTight2019,
  title = {Total {{Variation}} and {{Tight Frame Image Segmentation}} with {{Intensity Inhomogeneity}}},
  author = {Chan, Raymond and Yang, Hongfei and Zeng, Tieyong},
  year = {2019},
  month = apr,
  journal = {arXiv:1904.01760 [eess]},
  eprint = {1904.01760},
  primaryclass = {eess},
  urldate = {2019-10-23},
  abstract = {Image segmentation is an important task in the domain of computer vision and medical imaging. In natural and medical images, intensity inhomogeneity, i.e. the varying image intensity, occurs often and it poses considerable challenges for image segmentation. In this paper, we propose an efficient variational method for segmenting images with intensity inhomogeneity. The method is inspired by previous works on two-stage segmentation and variational Retinex. Our method consists of two stages. In the first stage, we decouple the image into reflection and illumination parts by solving a convex energy minimization model with either total variation or tight-frame regularisation. In the second stage, we segment the original image by thresholding on the reflection part, and the inhomogeneous intensity is estimated by the smoothly varying illumination part. We adopt a primal dual algorithm to solve the convex model in the first stage, and the convergence is guaranteed. Numerical experiments clearly show that our method is robust and efficient to segment both natural and medical images.},
  archiveprefix = {arxiv},
  keywords = {Electrical Engineering and Systems Science - Image and Video Processing,No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Chan et al_2019_Total Variation and Tight Frame Image Segmentation with Intensity Inhomogeneity.pdf;/Users/driscoll/Zotero/storage/9H4IKZIV/1904.html}
}

@article{Charalambides2009,
  title = {Gegenbauer Tau Methods with and without Spurious Eigenvalues},
  author = {Charalambides, Marios and Waleffe, Fabian},
  year = {2009},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {47},
  number = {1},
  pages = {48--68},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/070704228}
}

@article{Chatelin1981,
  title = {The Spectral Approximation of Linear Operators with Applications to the Computation of Eigenelements of Differential and Integral Operators},
  author = {Chatelin, Fran{\c c}oise},
  year = {1981},
  month = oct,
  journal = {SIAM Review},
  volume = {23},
  number = {4},
  pages = {495--522},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/1023099}
}

@article{chatterjeeIntroductionProperOrthogonal2000,
  title = {An Introduction to the Proper Orthogonal Decomposition},
  author = {Chatterjee, Anindya},
  year = {2000},
  journal = {Current Science},
  volume = {78},
  number = {7},
  eprint = {24103957},
  eprinttype = {jstor},
  pages = {808--817},
  publisher = {{Temporary Publisher}},
  issn = {0011-3891},
  urldate = {2020-08-07},
  abstract = {A tutorial is presented on the Proper Orthogonal Decomposition (POD), which finds applications in computationally processing large amounts of high-dimensional data with the aim of obtaining low-dimensional descriptions that capture much of the phenomena of interest. The discrete version of the POD, which is the singular value decomposition (SVD) of matrices, is described in some detail. The continuous version of the POD is outlined. Low-rank approximations to data using the SVD are discussed. The SVD and the eigenvalue decomposition are compared. Two geometric interpretations of the SVD/POD are given. Computational strategies (using standard software) are mentioned. Two numerical examples are provided: one shows low-rank approximations of a surface, and the other demonstrates simple a posteriori analysis of data from a simulated vibroimpact system. Some relevant computer code is supplied.},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Chatterjee-2000-An introduction to the proper orthogonal decomposition.pdf}
}

@article{ChaturantabutNonlinearModel2010,
  title = {Nonlinear {{Model Reduction}} via {{Discrete Empirical Interpolation}}},
  author = {Chaturantabut, Saifon and Sorensen, Danny C.},
  year = {2010},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {32},
  number = {5},
  pages = {2737--2764},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/090766498},
  urldate = {2023-02-20},
  abstract = {This paper introduces a new framework for constructing the discrete empirical interpolation method ({\textbackslash}sf DEIM) projection operator. The interpolation node selection procedure is formulated using the QR factorization with column pivoting, and it enjoys a sharper error bound for the {\textbackslash}sf DEIM projection error. Furthermore, for a subspace \${\textbackslash}mathcal\{U\}\$ given as the range of an orthonormal \$\{{\textbackslash}mathsf U\}\$, the {\textbackslash}sf DEIM projection does not change if \$\{{\textbackslash}mathsf U\}\$ is replaced by \$\{{\textbackslash}mathsf U\} {\textbackslash}Omega\$ with arbitrary unitary matrix \${\textbackslash}Omega\$. In a large-scale setting, the new approach allows modifications that use only randomly sampled rows of \$\{{\textbackslash}mathsf U\}\$, but with the potential of producing good approximations with corresponding probabilistic error bounds. Another salient feature of the new framework is that robust and efficient software implementation is easily developed, based on readily available high performance linear algebra packages.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Chaturantabut_Sorensen_2010_Nonlinear Model Reduction via Discrete Empirical Interpolation.pdf}
}

@article{Chehab2004,
  title = {Time Explicit Schemes and Spatial Finite Differences Splittings},
  author = {Chehab, Jean-Paul and Costa, Bruno},
  year = {2004},
  month = apr,
  journal = {Journal of Scientific Computing},
  volume = {20},
  number = {2},
  pages = {159--189},
  publisher = {{Springer Nature}},
  doi = {10.1023/b:jomp.0000008719.48134.4f}
}

@article{ChenErrorEquidistribution1994,
  title = {Error {{Equidistribution}} and {{Mesh Adaptation}}},
  author = {Chen, Ke},
  year = {1994},
  month = jul,
  journal = {SIAM Journal on Scientific Computing},
  volume = {15},
  number = {4},
  pages = {798--818},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/0915050},
  urldate = {2023-02-10},
  abstract = {In this paper we introduce a moving mesh method for solving PDEs in two dimensions. It can be viewed as a higher-dimensional generalization of the moving mesh PDE (MMPDE) strategy developed in our previous work for one-dimensional problems [W. Huang, Y. Ren, and R. D. Russell, SIAM J. Numer. Anal., 31 (1994), pp. 709--730]. The MMPDE is derived from a gradient flow equation which arises using a mesh adaptation functional in turn motivated from the theory of harmonic maps. Geometrical interpretations are given for the gradient equation and functional, and basic properties of this MMPDE are discussed. Numerical examples are presented where the method is used both for mesh generation and for solving time-dependent PDEs. The results demonstrate the potential of the mesh movement strategy to concentrate the mesh points so as to adapt to special problem features and to also preserve a suitable level of mesh orthogonality.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Chen_1994_Error Equidistribution and Mesh Adaptation.pdf}
}

@book{cheneyNumericalMathematicsComputing2012,
  title = {Numerical {{Mathematics}} and {{Computing}}},
  author = {Cheney, E. Ward and Kincaid, David R.},
  year = {2012},
  month = may,
  publisher = {{Cengage Learning}},
  abstract = {Authors Ward Cheney and David Kincaid show students of science and engineering the potential computers have for solving numerical problems and give them ample opportunities to hone their skills in programming and problem solving. NUMERICAL MATHEMATICS AND COMPUTING, 7th Edition also helps students learn about errors that inevitably accompany scientific computations and arms them with methods for detecting, predicting, and controlling these errors.Important Notice: Media content referenced within the product description or the product text may not be available in the ebook version.},
  googlebooks = {tDyYdqyZjSEC},
  isbn = {978-1-133-10371-4},
  langid = {english},
  keywords = {Mathematics / General}
}

@misc{ChenFastExplainable2022,
  title = {Fast and Explainable Clustering Based on Sorting},
  author = {Chen, Xinye and G{\"u}ttel, Stefan},
  year = {2022},
  month = feb,
  number = {arXiv:2202.01456},
  eprint = {2202.01456},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2202.01456},
  urldate = {2024-02-05},
  abstract = {We introduce a fast and explainable clustering method called CLASSIX. It consists of two phases, namely a greedy aggregation phase of the sorted data into groups of nearby data points, followed by the merging of groups into clusters. The algorithm is controlled by two scalar parameters, namely a distance parameter for the aggregation and another parameter controlling the minimal cluster size. Extensive experiments are conducted to give a comprehensive evaluation of the clustering performance on synthetic and real-world datasets, with various cluster shapes and low to high feature dimensionality. Our experiments demonstrate that CLASSIX competes with state-of-the-art clustering algorithms. The algorithm has linear space complexity and achieves near linear time complexity on a wide range of problems. Its inherent simplicity allows for the generation of intuitive explanations of the computed clusters.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Chen_Güttel_2022_Fast and explainable clustering based on sorting.pdf;/Users/driscoll/Zotero/storage/TAT7LP4N/2202.html}
}

@article{Cheng2005,
  title = {On the Compression of Low Rank Matrices},
  author = {Cheng, H. and Gimbutas, Z. and Martinsson, P. G. and Rokhlin, V.},
  year = {2005},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {26},
  number = {4},
  pages = {1389--1404},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/030602678},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cheng et al_2005_On the compression of low rank matrices.pdf}
}

@inproceedings{chengBiclusteringExpressionData2000,
  title = {Biclustering of Expression Data.},
  booktitle = {Ismb},
  author = {Cheng, Yizong and Church, George M.},
  year = {2000},
  volume = {8},
  pages = {93--103},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Cheng_Church_2000_Biclustering of expression data.pdf}
}

@misc{ChenNeuralOrdinary2019,
  title = {Neural {{Ordinary Differential Equations}}},
  author = {Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  year = {2019},
  month = dec,
  number = {arXiv:1806.07366},
  eprint = {1806.07366},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1806.07366},
  urldate = {2022-12-06},
  abstract = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a black-box differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing flows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Chen et al_2019_Neural Ordinary Differential Equations.pdf;/Users/driscoll/Zotero/storage/LPYDILJ5/1806.html}
}

@misc{ChenOperatorLearning2023,
  title = {Operator {{Learning}} for {{Continuous Spatial-Temporal Model}} with {{A Hybrid Optimization Scheme}}},
  author = {Chen, Chuanqi and Wu, Jin-Long},
  year = {2023},
  month = nov,
  number = {arXiv:2311.11798},
  eprint = {2311.11798},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2311.11798},
  urldate = {2023-12-12},
  abstract = {Partial differential equations are often used in the spatial-temporal modeling of complex dynamical systems in many engineering applications. In this work, we build on the recent progress of operator learning and present a data-driven modeling framework that is continuous in both space and time. A key feature of the proposed model is the resolution-invariance with respect to both spatial and temporal discretizations. To improve the long-term performance of the calibrated model, we further propose a hybrid optimization scheme that leverages both gradient-based and derivative-free optimization methods and efficiently trains on both short-term time series and long-term statistics. We investigate the performance of the spatial-temporal continuous learning framework with three numerical examples, including the viscous Burgers' equation, the Navier-Stokes equations, and the Kuramoto-Sivashinsky equation. The results confirm the resolution-invariance of the proposed modeling framework and also demonstrate stable long-term simulations with only short-term time series data. In addition, we show that the proposed model can better predict long-term statistics via the hybrid optimization scheme with a combined use of short-term and long-term data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Chen_Wu_2023_Operator Learning for Continuous Spatial-Temporal Model with A Hybrid.pdf;/Users/driscoll/Zotero/storage/3BYGQQ7C/2311.html}
}

@inproceedings{chenyangxuGradientVectorFlow1997,
  title = {Gradient Vector Flow: A New External Force for Snakes},
  shorttitle = {Gradient Vector Flow},
  booktitle = {Proceedings of {{IEEE Computer Society Conference}} on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {{Chenyang Xu} and Prince, J. L.},
  year = {1997},
  month = jun,
  pages = {66--71},
  issn = {1063-6919},
  doi = {10.1109/cvpr.1997.609299},
  abstract = {Snakes, or active contours, are used extensively in computer vision and image processing applications, particularly to locate object boundaries. Problems associated with initialization and poor convergence to concave boundaries, however, have limited their utility. This paper develops a new external force for active contours, largely solving both problems. This external force, which we call gradient vector flow (GVF) is computed as a diffusion of the gradient vectors of a gray-level or binary edge map derived from the image. The resultant field has a large capture range and forces active contours into concave regions. Examples on simulated images and one real image are presented.},
  keywords = {active contours,Active contours,Application software,binary edge map,Computational modeling,computer vision,Convergence,external force,gradient vector flow,Image edge detection,image processing,Image processing,Image segmentation,initialization,object boundaries,real image,Shape,simulated images,snakes,Tracking,Vectors},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Chenyang Xu_Prince-1997-Gradient vector flow.pdf;/Users/driscoll/Zotero/storage/QYLKPWG5/609299.html}
}

@inproceedings{cheungDecomposingTimeSeries2015,
  title = {Decomposing Time Series Data by a Non-Negative Matrix Factorization Algorithm with Temporally Constrained Coefficients},
  booktitle = {2015 37th {{Annual International Conference}} of the {{IEEE Engineering}} in {{Medicine}} and {{Biology Society}} ({{EMBC}})},
  author = {Cheung, V. C. K. and Devarajan, K. and Severini, G. and Turolla, A. and Bonato, P.},
  year = {2015},
  month = aug,
  pages = {3496--3499},
  doi = {10.1109/EMBC.2015.7319146},
  abstract = {The non-negative matrix factorization algorithm (NMF) decomposes a data matrix into a set of non-negative basis vectors, each scaled by a coefficient. In its original formulation, the NMF assumes the data samples and dimensions to be independently distributed, making it a less-than-ideal algorithm for the analysis of time series data with temporal correlations. Here, we seek to derive an NMF that accounts for temporal dependencies in the data by explicitly incorporating a very simple temporal constraint for the coefficients into the NMF update rules. We applied the modified algorithm to 2 multi-dimensional electromyographic data sets collected from the human upper-limb to identify muscle synergies. We found that because it reduced the number of free parameters in the model, our modified NMF made it possible to use the Akaike Information Criterion to objectively identify a model order (i.e., the number of muscle synergies composing the data) that is more functionally interpretable, and closer to the numbers previously determined using ad hoc measures.},
  keywords = {Akaike Information Criterion,Algorithms,coefficient temporal constraint,Data mining,Data models,Distributed databases,electromyography,Electromyography,human upper limb,Humans,independently distributed data dimensions,independently distributed data samples,matrix decomposition,Matrix decomposition,medical signal processing,Models Theoretical,multidimensional electromyographic data sets,muscle synergy identification,Muscles,NMF,NMF update rules,nonnegative basis vectors,nonnegative matrix factorization algorithm,numerical analysis,temporal correlations,temporally constrained coefficients,Time Factors,time series,Time series analysis,time series data analysis,time series data decomposition,vector coefficient,vectors},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Cheung et al_2015_Decomposing time series data by a non-negative matrix factorization algorithm.pdf;/Users/driscoll/Zotero/storage/28EY66CT/7319146.html}
}

@article{Chhabra_Modeling_2009,
  title = {Modeling Corneal Metabolism and Oxygen Transport during Contact Lens Wear},
  author = {Chhabra, Mahendra and Prausnitz, John M and Radke, Clayton J},
  year = {2009},
  volume = {86},
  number = {5},
  pages = {454--466},
  issn = {1040-5488},
  doi = {10.1097/opx.0b013e31819f9e70},
  abstract = {Purpose. A metabolic model is developed for cornea-contact-lens system to elucidate the role of glucose metabolism in oxygenation of the cornea and to gauge the role that contact lens oxygen transmissibility plays in avoiding hypoxia-induced corneal abnormalities for extended wear applications. Methods. Oxygen transport through the cornea and contact lens system is typically described by oxygen diffusion with reactive loss. Oxygen in the cornea, however, interacts with other metabolic species, specifically glucose, lactate ion, bicarbonate ion, hydrogen ion, and carbon dioxide via aerobic glycolysis (Krebs or tricarboxylic acid cycle) and anaerobic glycolysis. Here, corneal aerobic and anaerobic metabolic reactions are incorporated into a six-layer (endothelium, stroma, epithelium, postlens tear film, contact lens, and prelens tear film) steady-state continuum reaction-diffusion model to quantify oxygen transport. We also define a new index, the oxygen deficiency factor (ODF), for gauging corneal oxygenation. As opposed to other current gauges of hypoxia, ODF is a local and sensitive measure of both the extent and severity of corneal oxygen deprivation. Results. We calculate not only oxygenation of the cornea but also its coupled glucose, lactate, and acidosis behavior. For the first time, the metabolic shift from aerobic to anaerobic glycolysis is explicitly incorporated into the transport and consumption of oxygen in the cornea on closed-eye contact lens wear. Adoption of enzymatic Monod kinetics for the metabolic reactions permits realistic assessment of local species concentrations throughout the cornea. We find that anerobic-produced lactate transports out of the cornea into the anterior chamber, whereas buffering bicarbonate ion transports into the comea from the anterior chamber. Conclusions. The coupling of oxygen with other reactive species in corneal metabolism provides useful insight into the transport of oxygen in cornea-contact-lens system. Specifically, we find that in addition to oxygen depletion and acidosis in the cornea, lactate concentration increases while glucose and bicarbonate concentrations decrease from the endothelium toward the epithelium. Unlike other indices of corneal oxygenation, ODF is sensitive specifically to regions of cornea with local oxygen deficiency. Accordingly, ODF is a useful physiologic index to assess the extent and severity of hypoxia in the cornea.},
  pmid = {19357551}
}

@article{choReliabilityTear1992,
  title = {Reliability of the {{Tear Break-Up Time Technique}} of {{Assessing Tear Stability}} and the {{Locations}} of the {{Tear Break-Up}} in {{Hong Kong Chinese}}:},
  shorttitle = {Reliability of the {{Tear Break-Up Time Technique}} of {{Assessing Tear Stability}} and the {{Locations}} of the {{Tear Break-Up}} in {{Hong Kong Chinese}}},
  author = {Cho, Pauline and Brown, Brian and Chan, Ivy and Conway, Robert and Yap, Maurice},
  year = {1992},
  month = nov,
  journal = {Optometry and Vision Science},
  volume = {69},
  number = {11},
  pages = {879--885},
  issn = {1040-5488},
  doi = {10.1097/00006324-199211000-00007},
  urldate = {2021-01-04},
  langid = {english}
}

@article{choTearBreakup1998,
  title = {Tear Break-up Time: Clinical Procedures and Their Effects},
  shorttitle = {Tear Break-up Time},
  author = {Cho, Pauline and Leung, Lawrence and Lam, Ada and Choi, Alex},
  year = {1998},
  journal = {Ophthalmic and Physiological Optics},
  volume = {18},
  number = {4},
  pages = {319--324},
  issn = {1475-1313},
  doi = {10.1046/j.1475-1313.1998.00385.x},
  urldate = {2020-11-24},
  abstract = {Three successive (representative) values of fluorescein-instillation TBUT (tear break-up time) were obtained from a group of young Hong Kong (HK)-Chinese. The median TBUT1, TBUT2 and TBUT3 were 3.2, 3.8 and 4.5 sec, respectively. Wilcoxon signed-rank tests showed that TBUT1 was significantly different from TBUT2 and TBUT3, but there was no difference between TBUT2 and TBUT3. It is therefore important, when measuring the TBUT, to specify which TBUT value was taken as the representative TBUT. Fluorescein was reapplied about six min after the first application, and the TBUT value re-determined (TBUTR). The median TBUTR was not significantly different from TBUT1. The subjects were requested to return another day and TBUT values (TBUTW) were determined, with the subjects opening their eyes as wide as possible, such that the palpebral aperture size was increased. The mean{\textpm}SD normal palpebral aperture size was 10.0{\textpm}1.3 mm, and the mean{\textpm}SD palpebral aperture size with the eyes wide open was 11.4{\textpm}1.5 mm. The median TBUTW (3.6 sec) was significantly longer than the median TBUT1 (3.0 sec), but this difference appeared to be due to the extremely long TBUTW of one subject; no significant difference was found between the median TBUTW (3.4 sec) and TBUT1 (2.8 sec) when data from this subject were excluded. There was no significant correlation between changes in palpebral size and TBUT value.},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/6AIK8KYA/j.1475-1313.1998.00385.html}
}

@article{choudhuryMembraneMucin2021,
  title = {Tear-Film Breakup: {{The}} Role of Membrane-Associated Mucin Polymers},
  shorttitle = {Tear-Film Breakup},
  author = {Choudhury, Anjishnu and Dey, Mohar and Dixit, Harish N. and Feng, James J.},
  year = {2021},
  month = jan,
  journal = {Physical Review E},
  volume = {103},
  number = {1},
  pages = {013108},
  issn = {2470-0045, 2470-0053},
  doi = {10.1103/PhysRevE.103.013108},
  urldate = {2022-08-05},
  langid = {english}
}

@article{Christlieb2010,
  title = {Implicit Parallel Time Integrators},
  author = {Christlieb, Andrew and Ong, Benjamin},
  year = {2010},
  month = dec,
  journal = {Journal of Scientific Computing},
  volume = {49},
  number = {2},
  pages = {167--179},
  publisher = {{Springer Nature}},
  doi = {10.1007/s10915-010-9452-4}
}

@article{Christov1990,
  title = {A {{Fourier-series}} Method for Solving Soliton Problems},
  author = {Christov, C. I. and Bekyarov, K. L.},
  year = {1990},
  month = jul,
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume = {11},
  number = {4},
  pages = {631--647},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/0911037}
}

@article{Chu2009,
  title = {A Direct Matrix Method for Computing Analytical {{Jacobians}} of Discretized Nonlinear Integro-Differential Equations},
  author = {Chu, Kevin T.},
  year = {2009},
  month = aug,
  journal = {Journal of Computational Physics},
  volume = {228},
  number = {15},
  pages = {5526--5538},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.jcp.2009.04.031},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Chu_2009_A direct matrix method for computing analytical Jacobians of discretized.pdf}
}

@article{chunObjectiveAssessment2014,
  title = {Objective {{Assessment}} of {{Corneal Staining Using Digital Image Analysis}}},
  author = {Chun, Yeoun Sook and Yoon, Woong Bae and Kim, Kwang Gi and Park, In Ki},
  year = {2014},
  month = dec,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {55},
  number = {12},
  pages = {7896--7903},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1552-5783},
  doi = {10.1167/iovs.14-15618},
  urldate = {2020-11-24},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Chun et al-2014-Objective Assessment of Corneal Staining Using Digital.pdf;/Users/driscoll/Zotero/storage/S7U4UPB4/article.html}
}

@misc{chuRBFFDDiscretizationNavierStokes2022,
  title = {{{RBF-FD}} Discretization of the {{Navier-Stokes}} Equations Using Staggered Nodes},
  author = {Chu, Tianyi and Schmidt, Oliver T.},
  year = {2022},
  month = jun,
  number = {arXiv:2206.06495},
  eprint = {2206.06495},
  primaryclass = {physics},
  publisher = {{arXiv}},
  urldate = {2022-08-01},
  abstract = {A semi-implicit fractional-step method that uses a staggered node layout and radial basis function-finite differences (RBF-FD) to solve the incompressible Navier-Stokes equations is developed. Polyharmonic splines (PHS) with polynomial augmentation (PHS+poly) are used to construct the global differentiation matrices. A systematic parameter study identifies a combination of stencil size, PHS exponent, and polynomial degree that minimizes the truncation error for a wave-like test function on scattered nodes. Classical modified wavenumber analysis is extended to RBF-FDs on heterogeneous node distributions and used to confirm that the accuracy of the selected 28-point stencil is comparable to that of spectral-like, 6th-order Pad{\textbackslash}'e-type finite differences. The Navier-Stokes solver is demonstrated on two benchmark problems, internal flow in a lid-driven cavity in the Reynolds number regime \$10\^{}2 {\textbackslash}leq {\textbackslash}mathrm\{Re\}{\textbackslash}leq 10\^{}4\$, and open flow around a cylinder at \${\textbackslash}mathrm\{Re\}= 100\$ and \$200\$. The combination of grid staggering and careful parameter selection facilitates accurate and stable simulations at significantly lower resolutions than previously reported, using more compact RBF-FD stencils, without special treatment near solid walls, and without the need for hyperviscosity or other means of regularization.},
  archiveprefix = {arxiv},
  keywords = {Physics - Computational Physics,Physics - Fluid Dynamics},
  file = {/Users/driscoll/Dropbox/library/Preprint/Chu_Schmidt-2022-RBF-FD discretization of the Navier-Stokes equations using staggered nodes.pdf;/Users/driscoll/Zotero/storage/TIPCNG7I/2206.html}
}

@article{Clenshaw1960,
  title = {A Method for Numerical Integration on an Automatic Computer},
  author = {Clenshaw, C. W. and Curtis, A. R.},
  year = {1960},
  month = dec,
  journal = {Numerische Mathematik},
  volume = {2},
  number = {1},
  pages = {197--205},
  publisher = {{Springer Nature}},
  doi = {10.1007/bf01386223},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Clenshaw_Curtis_1960_A method for numerical integration on an automatic computer.pdf}
}

@article{cohenPolynomialPerfidious1994,
  title = {Is the Polynomial so Perfidious?},
  author = {Cohen, A.M.},
  year = {1994},
  month = jul,
  journal = {Numerische Mathematik},
  volume = {68},
  number = {2},
  pages = {225--238},
  issn = {0945-3245},
  doi = {10.1007/s002110050058},
  urldate = {2020-06-18},
  abstract = {Wilkinson, in [1], has given a comprehensive account of the numericaldifficulties of working with polynomials on a floating point computer. Theobject of this note is to attempt to rehabilitate the polynomial to a certainextent. In particular it is shown here that polynomial deflation can beperformed satisfactorily by a method akin to `backward recursion'. Erroranalyses and examples are given to illustrate the stability of theprocess.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cohen-1994-Is the polynomial so perfidious.pdf}
}

@article{Collins2004,
  title = {A Barcode Shape Descriptor for Curve Point Cloud Data},
  author = {Collins, Anne and Zomorodian, Afra and Carlsson, Gunnar and Guibas, Leonidas J.},
  year = {2004},
  month = dec,
  journal = {Computers {{\&}} Graphics},
  volume = {28},
  number = {6},
  pages = {881--894},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.cag.2004.08.015},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Collins et al_2004_A barcode shape descriptor for curve point cloud data.pdf}
}

@article{CollinsCurvatureFlow2004,
  title = {Curvature Flow in Conformal Mapping},
  author = {Collins, Charles R and Driscoll, Tobin A and Stephenson, Kenneth},
  year = {2004},
  journal = {Computational Methods and Function Theory},
  volume = {3},
  number = {1},
  pages = {325--347},
  doi = {10.1007/bf03321041},
  copyright = {All rights reserved},
  keywords = {file-import-09-09-29}
}

@book{connIntroductionDerivativeFreeOptimization2009,
  title = {Introduction to {{Derivative-Free Optimization}}},
  author = {Conn, Andrew R. and Scheinberg, Katya and Vicente, Luis N.},
  year = {2009},
  month = apr,
  publisher = {{SIAM}},
  abstract = {The absence of derivatives, often combined with the presence of noise or lack of smoothness, is a major challenge for optimization. This book explains how sampling and model techniques are used in derivative-free methods and how these methods are designed to efficiently and rigorously solve optimization problems. Although readily accessible to readers with a modest background in computational mathematics, it is also intended to be of interest to researchers in the field. Introduction to Derivative-Free Optimization is the first contemporary comprehensive treatment of optimization without derivatives. This book covers most of the relevant classes of algorithms from direct search to model-based approaches. It contains a comprehensive description of the sampling and modeling tools needed for derivative-free optimization; these tools allow the reader to better analyze the convergent properties of the algorithms and identify their differences and similarities.},
  googlebooks = {tGbUshriSyYC},
  isbn = {978-0-89871-668-9},
  langid = {english},
  keywords = {Business & Economics / Finance / General,Mathematics / Applied,Mathematics / Linear & Nonlinear Programming}
}

@article{ConstantineDiscoveringActive2015,
  title = {Discovering an Active Subspace in a Single-Diode Solar Cell Model},
  author = {Constantine, Paul G. and Zaharatos, Brian and Campanelli, Mark},
  year = {2015},
  month = jul,
  journal = {Statistical Analysis and Data Mining: The ASA Data Science Journal},
  volume = {8},
  number = {5-6},
  pages = {264--273},
  publisher = {{Wiley-Blackwell}},
  doi = {10.1002/sam.11281},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Constantine et al_2015_Discovering an active subspace in a single-diode solar cell model.pdf}
}

@article{cooleyAlgorithmMachineCalculation1965,
  title = {An Algorithm for the Machine Calculation of Complex {{Fourier}} Series},
  author = {Cooley, James W. and Tukey, John W.},
  year = {1965},
  journal = {Mathematics of Computation},
  volume = {19},
  number = {90},
  pages = {297--301},
  issn = {0025-5718, 1088-6842},
  doi = {10.1090/s0025-5718-1965-0178586-1},
  urldate = {2020-06-18},
  abstract = {Advancing research. Creating connections.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cooley_Tukey_1965_An algorithm for the machine calculation of complex Fourier series.pdf;/Users/driscoll/Zotero/storage/FVXX2TD9/home.html}
}

@article{cordascoCommunityDetectionSemiSynchronous2011,
  title = {Community {{Detection}} via {{Semi-Synchronous Label Propagation Algorithms}}},
  author = {Cordasco, Gennaro and Gargano, Luisa},
  year = {2011},
  month = mar,
  journal = {arXiv:1103.4550 [physics]},
  eprint = {1103.4550},
  primaryclass = {physics},
  doi = {10.1504/..045103},
  urldate = {2022-04-13},
  abstract = {A recently introduced novel community detection strategy is based on a label propagation algorithm (LPA) which uses the diffusion of information in the network to identify communities. Studies of LPAs showed that the strategy is effective in finding a good community structure. Label propagation step can be performed in parallel on all nodes (synchronous model) or sequentially (asynchronous model); both models present some drawback, e.g., algorithm termination is nor granted in the first case, performances can be worst in the second case. In this paper, we present a semi-synchronous version of LPA which aims to combine the advantages of both synchronous and asynchronous models. We prove that our models always converge to a stable labeling. Moreover, we experimentally investigate the effectiveness of the proposed strategy comparing its performance with the asynchronous model both in terms of quality, efficiency and stability. Tests show that the proposed protocol does not harm the quality of the partitioning. Moreover it is quite efficient; each propagation step is extremely parallelizable and it is more stable than the asynchronous model, thanks to the fact that only a small amount of randomization is used by our proposal.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Social and Information Networks,Invalid DOI,Physics - Physics and Society},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cordasco_Gargano-2011-Community Detection via Semi-Synchronous Label Propagation Algorithms.pdf;/Users/driscoll/Zotero/storage/RL7GMW5X/1103.html}
}

@book{corlessGraduateIntroductionNumerical2013,
  title = {A {{Graduate Introduction}} to {{Numerical Methods}}: {{From}} the {{Viewpoint}} of {{Backward Error Analysis}}},
  shorttitle = {A {{Graduate Introduction}} to {{Numerical Methods}}},
  author = {Corless, Robert M. and Fillion, Nicolas},
  year = {2013},
  month = dec,
  publisher = {{Springer Science \& Business Media}},
  abstract = {This book provides an extensive introduction to numerical computing from the viewpoint of backward error analysis. The intended audience includes students and researchers in science, engineering and mathematics. The approach taken is somewhat informal owing to the wide variety of backgrounds of the readers, but the central ideas of backward error and sensitivity (conditioning) are systematically emphasized. The book is divided into four parts: Part I provides the background preliminaries including floating-point arithmetic, polynomials and computer evaluation of functions; Part II covers numerical linear algebra; Part III covers interpolation, the FFT and quadrature; and Part IV covers numerical solutions of differential equations including initial-value problems, boundary-value problems, delay differential equations and a brief chapter on partial differential equations.The book contains detailed illustrations, chapter summaries and a variety of exercises as well some Matlab codes provided online as supplementary material.``I really like the focus on backward error analysis and condition. This is novel in a textbook and a practical approach that will bring welcome attention." Lawrence F. ShampineA Graduate Introduction to Numerical Methods and Backward Error Analysis'' has been selected by Computing Reviews as a notable book in computing in 2013. Computing Reviews Best of 2013 list consists of book and article nominations from reviewers, CR category editors, the editors-in-chief of journals, and others in the computing community.},
  googlebooks = {hte4BAAAQBAJ},
  isbn = {978-1-4614-8453-0},
  langid = {english},
  keywords = {Computers / Computer Science,Mathematics / Applied,Mathematics / Counting & Numeration,Mathematics / Number Systems,Mathematics / Numerical Analysis,Mathematics / Probability & Statistics / Stochastic Processes}
}

@misc{CostaAAAleastSquares2021,
  title = {{{AAA-least}} Squares Rational Approximation and Solution of {{Laplace}} Problems},
  author = {Costa, Stefano and Trefethen, Lloyd N.},
  year = {2021},
  month = jul,
  number = {arXiv:2107.01574},
  eprint = {2107.01574},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2107.01574},
  urldate = {2023-06-14},
  abstract = {A two-step method for solving planar Laplace problems via rational approximation is introduced. First complex rational approximations to the boundary data are determined by AAA approximation, either globally or locally near each corner or other singularity. The poles of these approximations outside the problem domain are then collected and used for a global least-squares fit to the solution. Typical problems are solved in a second of laptop time to 8-digit accuracy, all the way up to the corners, and the conjugate harmonic function is also provided. The AAA-least squares combination also offers a new method for avoiding spurious poles in other rational approximation problems, and for greatly speeding them up in cases with many singularities. As a special case, AAA-LS approximation leads to a powerful method for computing the Hilbert transform or Dirichlet-to-Neumann map.},
  archiveprefix = {arxiv},
  keywords = {41A20 30E10 44A15 65N35,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Costa_Trefethen_2021_AAA-least squares rational approximation and solution of Laplace problems.pdf;/Users/driscoll/Zotero/storage/QWFH4LGJ/2107.html}
}

@incollection{CostaAAAleastSquares2023,
  title = {{{AAA-least}} Squares Rational Approximation and Solution of {{Laplace}} Problems},
  booktitle = {European {{Congress}} of {{Mathematics}}},
  author = {Costa, Stefano and Trefethen, Lloyd N.},
  editor = {Hujdurovi{\'c}, Ademir and Kutnar, Klavdija and Maru{\v s}i{\v c}, Dragan and Miklavi{\v c}, {\v S}tefko and Pisanski, Toma{\v z} and {\v S}parl, Primo{\v z}},
  year = {2023},
  month = jul,
  edition = {1},
  pages = {511--534},
  publisher = {{EMS Press}},
  doi = {10.4171/8ecm/16},
  urldate = {2023-10-05},
  isbn = {978-3-9854705-1-8 978-3-9854755-1-3},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Book Section/Costa_Trefethen_2023_AAA-least squares rational approximation and solution of Laplace problems.pdf}
}

@misc{CostaSolvingLaplace2020,
  title = {Solving {{Laplace}} Problems with the {{AAA}} Algorithm},
  author = {Costa, Stefano},
  year = {2020},
  month = jan,
  number = {arXiv:2001.09439},
  eprint = {2001.09439},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2001.09439},
  urldate = {2023-06-14},
  abstract = {We present a novel application of the recently developed AAA algorithm to the solution of Laplace 2D problems; an application to conformal mapping is also shown as a particular case. These classes of problems have also been addressed by means of dedicated software implementations based on rational function approximation, with unprecedented speed and accuracy. Still we show how the AAA algorithm, conceived to be a flexible and domain independent method, is capable of addressing these situations within a unified framework.},
  archiveprefix = {arxiv},
  keywords = {41A20 (Primary) 65E05 (Secondary),Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Costa_2020_Solving Laplace problems with the AAA algorithm.pdf;/Users/driscoll/Zotero/storage/K8E6GI66/2001.html}
}

@article{craigTFOSDEWS2017,
  title = {{{TFOS DEWS II Definition}} and {{Classification Report}}},
  author = {Craig, Jennifer P. and Nichols, Kelly K. and Akpek, Esen K. and Caffery, Barbara and Dua, Harminder S. and Joo, Choun-Ki and Liu, Zuguo and Nelson, J. Daniel and Nichols, Jason J. and Tsubota, Kazuo and Stapleton, Fiona},
  year = {2017},
  month = jul,
  journal = {The Ocular Surface},
  series = {{{TFOS International Dry Eye WorkShop}} ({{DEWS II}})},
  volume = {15},
  number = {3},
  pages = {276--283},
  issn = {1542-0124},
  doi = {10.1016/j.jtos.2017.05.008},
  urldate = {2020-11-24},
  abstract = {The goals of the TFOS DEWS II Definition and Classification Subcommittee were to create an evidence-based definition and a contemporary classification system for dry eye disease (DED). The new definition recognizes the multifactorial nature of dry eye as a disease where loss of homeostasis of the tear film is the central pathophysiological concept. Ocular symptoms, as a broader term that encompasses reports of discomfort or visual disturbance, feature in the definition and the key etiologies of tear film instability, hyperosmolarity, and ocular surface inflammation and damage were determined to be important for inclusion in the definition. In the light of new data, neurosensory abnormalities were also included in the definition for the first time. In the classification of DED, recent evidence supports a scheme based on the pathophysiology where aqueous deficient and evaporative dry eye exist as a continuum, such that elements of each are considered in diagnosis and management. Central to the scheme is a positive diagnosis of DED with signs and symptoms, and this is directed towards management to restore homeostasis. The scheme also allows consideration of various related manifestations, such as non-obvious disease involving ocular surface signs without related symptoms, including neurotrophic conditions where dysfunctional sensation exists, and cases where symptoms exist without demonstrable ocular surface signs, including neuropathic pain. This approach is not intended to override clinical assessment and judgment but should prove helpful in guiding clinical management and research.},
  langid = {english},
  keywords = {Aqueous deficient,Classification,Definition,Dry eye disease,Evaporative,Mechanism},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Craig et al-2017-TFOS DEWS II Definition and Classification Report.pdf;/Users/driscoll/Zotero/storage/9N6XTIJL/S1542012417301192.html}
}

@article{Creech_Dispersive_2001,
  title = {Dispersive Mixing in the Posterior Tear Film under a Soft Contact Lens},
  author = {Creech, {\relax JL} and Chauhan, A and Radke, {\relax CJ}},
  year = {2001},
  volume = {40},
  number = {14},
  pages = {3015--3026},
  issn = {0888-5885},
  doi = {10.1021/ie000596z}
}

@article{Cruz_Spontaneous_2011,
  title = {Spontaneous Eyeblink Activity.},
  author = {Cruz, Antonio A and Garcia, Denny M and Pinto, Carolina T and Cechetti, Sheila P},
  year = {2011},
  journal = {The ocular surface},
  volume = {9},
  number = {1},
  pages = {29--41},
  issn = {1542-0124},
  abstract = {Spontaneous blinking is essential for maintaining a healthy ocular surface and clarity of vision. The spontaneous blink rate (SBR) is believed to reflect a complex interaction between peripheral influences mediated by the eye surface and the central dopaminergic activity. The SBR is thus extremely variable and dependent on a variety of psychological and medical conditions. Many different methods have been employed to measure the SBR and the upper eyelid kinematics during a blink movement. Each has its own merits and drawbacks, and the choice of a specific method should be tailored to the specific needs of the investigation. Although the sequence of muscle events that leads to a blink has been fully described, knowledge about the neural control of spontaneous blinking activity is not complete. The tear film is dynamically modified between blinks, and abnormalities of the blink rate have an obvious influence on the ocular surface.},
  pmid = {21338567}
}

@article{Cui_Micrometer_2012,
  title = {Micrometer-{{Scale}} Contact Lens Movements Imaged by Ultrahigh-Resolution Optical Coherence Tomography},
  author = {Cui, Lele and Shen, Meixiao and Wang, Michael R and Wang, Jianhua},
  year = {2012},
  volume = {153},
  number = {2},
  pages = {275-283.e1},
  issn = {0002-9394},
  doi = {10.1016/j.ajo.2011.06.023},
  abstract = {PurposeTo dynamically evaluate contact lens movement and ocular surface shape using ultrahigh-resolution and ultralong-scan-depth optical coherence tomography (OCT).DesignClinical research study of a laboratory technique.MethodsFour different types of soft contact lenses were tested on the left eye of 10 subjects (6 male and 4 female). Lens edges at primary gaze and temporal and nasal gazes were imaged by ultrahigh-resolution OCT. Excursion lag was obtained as the distance between the lens edge at primary gaze and immediately after the eye was quickly turned either nasally or temporally. The inferior lens edges were imaged continuously to track vertical movements during blinking. Ultralong-scan-depth OCT provided quantifiable images of the ocular surface, and the contour was acquired using custom software.ResultsExcursion lag at the horizontal meridian was 366  134 {$\mu$}m at temporal gaze and 320  137 {$\mu$}m at nasal gaze (P \{{$>$}\} .05). The lens uplift at the vertical meridian was 342  155 {$\mu$}m after blinking. There were significant differences in horizontal lags and vertical movements among different lenses (P \{{$<$}\} .05). Horizontal lags were correlated with radii of curvatures and sagittal heights at 6-mm and 14-mm horizontal meridian (P \{{$<$}\} .05). The blink-induced lens uplift first lowered by 104  8 {$\mu$}m, and then lifted 342  155 {$\mu$}m after the blink.ConclusionsUltrahigh-resolution and ultralong-scan-depth OCT can assess micrometer-scale lens movements and ocular surface contours. Both lens design and ocular surface shape affected lens movements.},
  pmcid = {PMC3264818},
  pmid = {21920493}
}

@article{CullenClarke2019,
  title = {A Fast, Spectrally Accurate Homotopy Based Numerical Method for Solving Nonlinear Differential Equations},
  author = {Cullen, Andrew C. and Clarke, Simon R.},
  year = {2019},
  volume = {385},
  pages = {106--118},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2019.01.057},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cullen_Clarke_2019_A fast, spectrally accurate homotopy based numerical method for solving.pdf;/Users/driscoll/Zotero/storage/X7F2Q2HY/CullenClarke2019 - A Fast, Spectrally Accurate Homotopy Based Numerical Method for Solving Nonlinear Differential Equations.pdf}
}

@article{CuomoScientificMachine2022,
  title = {Scientific {{Machine Learning Through Physics}}--{{Informed Neural Networks}}: {{Where}} We Are and {{What}}'s {{Next}}},
  shorttitle = {Scientific {{Machine Learning Through Physics}}--{{Informed Neural Networks}}},
  author = {Cuomo, Salvatore and Di Cola, Vincenzo Schiano and Giampaolo, Fabio and Rozza, Gianluigi and Raissi, Maziar and Piccialli, Francesco},
  year = {2022},
  month = sep,
  journal = {Journal of Scientific Computing},
  volume = {92},
  number = {3},
  pages = {88},
  issn = {0885-7474, 1573-7691},
  doi = {10.1007/s10915-022-01939-z},
  urldate = {2023-11-02},
  abstract = {Abstract             Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode model equations, like Partial Differential Equations (PDE), as a component of the neural network itself. PINNs are nowadays used to solve PDEs, fractional equations, integral-differential equations, and stochastic PDEs. This novel methodology has arisen as a multi-task learning framework in which a NN must fit observed data while reducing a PDE residual. This article provides a comprehensive review of the literature on PINNs: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla PINN, as well as many other variants, such as physics-constrained neural networks (PCNN), variational hp-VPINN, and conservative PINN (CPINN). The study indicates that most research has focused on customizing the PINN through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which PINNs have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method (FEM), advancements are still possible, most notably theoretical issues that remain unresolved.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Cuomo et al_2022_Scientific Machine Learning Through Physics–Informed Neural Networks.pdf}
}

@misc{DandekarBayesianNeural2022,
  title = {Bayesian {{Neural Ordinary Differential Equations}}},
  author = {Dandekar, Raj and Chung, Karen and Dixit, Vaibhav and Tarek, Mohamed and {Garcia-Valadez}, Aslan and Vemula, Krishna Vishal and Rackauckas, Chris},
  year = {2022},
  month = feb,
  number = {arXiv:2012.07244},
  eprint = {2012.07244},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2012.07244},
  urldate = {2023-12-12},
  abstract = {Recently, Neural Ordinary Differential Equations has emerged as a powerful framework for modeling physical simulations without explicitly defining the ODEs governing the system, but instead learning them via machine learning. However, the question: "Can Bayesian learning frameworks be integrated with Neural ODE's to robustly quantify the uncertainty in the weights of a Neural ODE?" remains unanswered. In an effort to address this question, we primarily evaluate the following categories of inference methods: (a) The No-U-Turn MCMC sampler (NUTS), (b) Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) and (c) Stochastic Langevin Gradient Descent (SGLD). We demonstrate the successful integration of Neural ODEs with the above Bayesian inference frameworks on classical physical systems, as well as on standard machine learning datasets like MNIST, using GPU acceleration. On the MNIST dataset, we achieve a posterior sample accuracy of 98.5\% on the test ensemble of 10,000 images. Subsequently, for the first time, we demonstrate the successful integration of variational inference with normalizing flows and Neural ODEs, leading to a powerful Bayesian Neural ODE object. Finally, considering a predator-prey model and an epidemiological system, we demonstrate the probabilistic identification of model specification in partially-described dynamical systems using universal ordinary differential equations. Together, this gives a scientific machine learning tool for probabilistic estimation of epistemic uncertainties.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Dandekar et al_2022_Bayesian Neural Ordinary Differential Equations.pdf;/Users/driscoll/Zotero/storage/Q2Y57IZX/2012.html}
}

@article{dappenWindtunnelWallCorrections1987,
  title = {Wind-Tunnel Wall Corrections on a Two-Dimensional Plate by Conformalmapping},
  author = {Dappen, Heinz},
  year = {1987},
  month = nov,
  journal = {AIAA Journal},
  volume = {25},
  number = {11},
  pages = {1527--1530},
  issn = {0001-1452, 1533-385X},
  doi = {10.2514/3.9819},
  urldate = {2019-11-18},
  langid = {english}
}

@article{Daras2001,
  title = {Composed Pad{\'e}-Type Approximation},
  author = {Daras, Nicholas J.},
  year = {2001},
  month = sep,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {134},
  number = {1-2},
  pages = {95--112},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0377-0427(00)00531-8},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Daras_2001_Composed padé-type approximation.pdf}
}

@article{daugmanHowIris2004,
  title = {How Iris Recognition Works},
  author = {Daugman, J.},
  year = {2004},
  month = jan,
  journal = {IEEE Transactions on Circuits and Systems for Video Technology},
  volume = {14},
  number = {1},
  pages = {21--30},
  issn = {1558-2205},
  doi = {10.1109/tcsvt.2003.818350},
  abstract = {Algorithms developed by the author for recognizing persons by their iris patterns have now been tested in many field and laboratory trials, producing no false matches in several million comparison tests. The recognition principle is the failure of a test of statistical independence on iris phase structure encoded by multi-scale quadrature wavelets. The combinatorial complexity of this phase information across different persons spans about 249 degrees of freedom and generates a discrimination entropy of about 3.2 b/mm/sup 2/ over the iris, enabling real-time decisions about personal identity with extremely high confidence. The high confidence levels are important because they allow very large databases to be searched exhaustively (one-to-many "identification mode") without making false matches, despite so many chances. Biometrics that lack this property can only survive one-to-one ("verification") or few comparisons. The paper explains the iris recognition algorithms and presents results of 9.1 million comparisons among eye images from trials in Britain, the USA, Japan, and Korea.},
  keywords = {biometrics,biometrics (access control),decision theory,Demodulation,discrimination entropy,entropy,Entropy,Image databases,image matching,iris pattern recognition,iris phase structure,iris recognition,Iris recognition,Ligaments,Lighting,multi-scale quadrature wavelet coding,one-to-many identification mode,one-to-one identification mode,Pattern matching,Pattern recognition,personal identity,Pigmentation,statistical analysis,statistical independence,Testing,transform coding,verification,wavelet transforms},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Daugman-2004-How iris recognition works.pdf;/Users/driscoll/Zotero/storage/QUQ6DWXC/1262028.html}
}

@article{daugmanNewMethods2007,
  title = {New {{Methods}} in {{Iris Recognition}}},
  author = {Daugman, John},
  year = {2007},
  month = oct,
  journal = {IEEE Transactions on Systems, Man and Cybernetics, Part B (Cybernetics)},
  volume = {37},
  number = {5},
  pages = {1167--1175},
  issn = {1083-4419},
  doi = {10.1109/tsmcb.2007.903540},
  urldate = {2020-11-29},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Daugman-2007-New Methods in Iris Recognition.pdf}
}

@book{davisInterpolationApproximation1963,
  title = {Interpolation and {{Approximation}}},
  author = {Davis, Philip J.},
  year = {1963},
  publisher = {{Blaisdell Publishing Company}},
  googlebooks = {PlZ14wO2gfsC},
  langid = {english}
}

@book{davisMethodsNumericalIntegration2014,
  title = {Methods of {{Numerical Integration}}},
  author = {Davis, Philip J. and Rabinowitz, Philip},
  year = {2014},
  month = may,
  publisher = {{Academic Press}},
  abstract = {Methods of Numerical Integration, Second Edition describes the theoretical and practical aspects of major methods of numerical integration. Numerical integration is the study of how the numerical value of an integral can be found. This book contains six chapters and begins with a discussion of the basic principles and limitations of numerical integration. The succeeding chapters present the approximate integration rules and formulas over finite and infinite intervals. These topics are followed by a review of error analysis and estimation, as well as the application of functional analysis to numerical integration. A chapter describes the approximate integration in two or more dimensions. The final chapter looks into the goals and processes of automatic integration, with particular attention to the application of Tschebyscheff polynomials.This book will be of great value to theoreticians and computer programmers.},
  googlebooks = {mbLiBQAAQBAJ},
  isbn = {978-1-4832-6428-8},
  langid = {english},
  keywords = {Mathematics / Calculus,Mathematics / Mathematical Analysis}
}

@book{debergComputationalGeometryAlgorithms2008,
  title = {Computational {{Geometry}}: {{Algorithms}} and {{Applications}}},
  shorttitle = {Computational {{Geometry}}},
  author = {{de Berg}, Mark and Cheong, Otfried and {van Kreveld}, Marc and Overmars, Mark},
  year = {2008},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-77974-2},
  urldate = {2020-08-24},
  isbn = {978-3-540-77973-5 978-3-540-77974-2},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Book/de Berg et al-2008-Computational Geometry.pdf}
}

@book{deboorPracticalGuideSplines1978,
  title = {A {{Practical Guide}} to {{Splines}}},
  author = {{de Boor}, Carl},
  year = {1978},
  publisher = {{Springer-Verlag}},
  googlebooks = {7YjBQgAACAAJ},
  isbn = {978-3-540-90356-7},
  langid = {english}
}

@article{DeLilloComputationMultiply2006,
  title = {Computation of {{Multiply Connected Schwarz-Christoffel Maps}} for {{Exterior Domains}}},
  author = {DeLillo, Thomas K. and Driscoll, Tobin A. and Elcrat, Alan R. and Pfaltzgraff, John A.},
  year = {2006},
  month = dec,
  journal = {Computational Methods and Function Theory},
  volume = {6},
  number = {2},
  pages = {301--315},
  issn = {1617-9447, 2195-3724},
  doi = {10.1007/BF03321616},
  urldate = {2013-06-20},
  copyright = {All rights reserved},
  file = {/Users/driscoll/Dropbox/library/Journal Article/DeLillo et al_2006_Computation of Multiply Connected Schwarz-Christoffel Maps for Exterior Domains.pdf}
}

@article{delilloNumericalConformalMapping1993,
  title = {Numerical {{Conformal Mapping Methods}} for {{Exterior Regions}} with {{Corners}}},
  author = {DeLillo, Thomas K. and Elcrat, Alan R.},
  year = {1993},
  month = oct,
  journal = {Journal of Computational Physics},
  volume = {108},
  number = {2},
  pages = {199--208},
  issn = {0021-9991},
  doi = {10.1006/jcph.1993.1175},
  urldate = {2019-11-18},
  abstract = {The main purpose of this paper is to present a method for computing the conformal map between the exterior of the unit disk and the exterior of a simple closed curve with corners. The method may be regarded as a generalization of the Schwarz-Christoffel transformation and is derived from the integral equation of Timman. Some comparison is made with other methods such as a version of Timman's equation with corners, Fornberg's method with explicit corner removers, Davis' method, and CONFPACK. The method proves to be quite flexible and robust.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/DeLillo_Elcrat_1993_Numerical Conformal Mapping Methods for Exterior Regions with Corners.pdf;/Users/driscoll/Zotero/storage/C3RY9Z85/S0021999183711757.html}
}

@article{DeLilloRadialCircular2008,
  title = {Radial and Circular Slit Maps of Unbounded Multiply Connected Circle Domains},
  author = {DeLillo, T.K and Driscoll, T.A and Elcrat, A.R and Pfaltzgraff, J.A},
  year = {2008},
  month = jul,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {464},
  number = {2095},
  pages = {1719--1737},
  issn = {1364-5021},
  doi = {10.1098/rspa.2008.0006},
  abstract = {Infinite product formulae for conformally mapping an unbounded multiply connected circle domain to an unbounded canonical radial or circular slit domain, or to domains with both radial and circular slit boundary components are derived and implemented numerically and graphically. The formulae are generated by analytic continuation with the reflection principle. Convergence of the infinite products is proved for domains with sufficiently well-separated boundary components. Some recent progress in the numerical implementation of infinite product mapping formulae is presented.},
  copyright = {All rights reserved},
  file = {/Users/driscoll/Dropbox/library/Journal Article/DeLillo et al_2008_Radial and circular slit maps of unbounded multiply connected circle domains.pdf}
}

@article{DeMarchi2009,
  title = {New Cubature Formulae and Hyperinterpolation in Three Variables},
  author = {De Marchi, Stefano and Vianello, Marco and Xu, Yuan},
  year = {2009},
  month = jan,
  journal = {BIT Numerical Mathematics},
  volume = {49},
  number = {1},
  pages = {55--73},
  publisher = {{Springer Nature}},
  doi = {10.1007/s10543-009-0210-7},
  file = {/Users/driscoll/Dropbox/library/Journal Article/De Marchi et al_2009_New cubature formulae and hyperinterpolation in three variables.pdf}
}

@article{DengExponentialAsymptotics2023,
  title = {Exponential Asymptotics of Woodpile Chain Nanoptera Using Numerical Analytic Continuation},
  author = {Deng, Guo and Lustri, Christopher J.},
  year = {2023},
  journal = {Studies in Applied Mathematics},
  volume = {150},
  number = {2},
  pages = {520--557},
  issn = {1467-9590},
  doi = {10.1111/sapm.12548},
  urldate = {2023-10-05},
  abstract = {Traveling waves in woodpile chains are typically nanoptera, which are composed of a central solitary wave and exponentially small oscillations. These oscillations have been studied using exponential asymptotic methods, which typically require an explicit form for the leading-order behavior. For many nonlinear systems, such as granular woodpile chains, it is not possible to calculate the leading-order solution explicitly. We show that accurate asymptotic approximations can be obtained using numerical approximation in place of the exact leading-order behavior. We calculate the oscillation behavior for Toda woodpile chains, and compare the results to exponential asymptotics based on previous methods from the literature: long-wave approximation and tanh-fitting. We then use numerical analytic continuation methods based on Pad{\'e} approximants and the adaptive Antoulas--Anderson (AAA) method. These methods are shown to produce accurate predictions of the amplitude of the oscillations and the mass ratios for which the oscillations vanish. Exponential asymptotics using an AAA approximation for the leading-order behavior is then applied to study granular woodpile chains, including chains with Hertzian interactions---this method is able to calculate behavior that could not be accurately approximated in previous studies.},
  copyright = {{\copyright} 2022 The Authors. Studies in Applied Mathematics published by Wiley Periodicals LLC.},
  langid = {english},
  keywords = {AAA approximation,analytic continuation,exponential asymptotics,nanoptera},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Deng_Lustri_2023_Exponential asymptotics of woodpile chain nanoptera using numerical analytic2.pdf;/Users/driscoll/Zotero/storage/7K8L7HL9/sapm.html}
}

@article{DengFastTreecode2012,
  ids = {dengFastTreecodeMultiquadric2012a},
  title = {A {{Fast Treecode}} for {{Multiquadric Interpolation}} with {{Varying Shape Parameters}}},
  author = {Deng, Quan and Driscoll, Tobin A.},
  year = {2012},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {34},
  number = {2},
  pages = {A1126--A1140},
  issn = {1064-8275},
  doi = {10.1137/110836225},
  abstract = {A treecode algorithm is presented for the fast evaluation of multiquadric radial basis function (RBF) approximations. The method is a dual approach to one presented by Krasny and Wang, which applies far-field expansions to clusters of RBF centers (source points). The new approach clusters evaluation points instead and is therefore easily able to cope with basis functions that have different multiquadric shape parameters. The new treecode is able to evaluate an approximation on N centers at M points in \$O((N+M) {\textbackslash}backslash log M)\$ time in the ideal case when evaluation points are uniformly distributed. When coupled with a two-level restricted additive Schwarz preconditioner for GMRES iterations, the treecode is well suited for use within an adaptive RBF iteration, previously described by Driscoll and Heryudono, as is demonstrated by experiments on test functions.},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {41A58,65D05,65F10,radial basis function interpolation,restricted additive Schwarz method,treecode}
}

@article{dengHeatTransfer2014,
  title = {Heat Transfer and Tear Film Dynamics over Multiple Blink Cycles},
  author = {Deng, Quan and Braun, {\relax RJ} and Driscoll, Tobin A},
  year = {2014},
  journal = {Physics of Fluids},
  volume = {26},
  number = {7},
  pages = {071901},
  doi = {10.1063/1.4887341},
  copyright = {All rights reserved},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Deng_Braun_Driscoll-2014-Heat transfer and tear film dynamics over multiple blink.pdf}
}

@inproceedings{dengModelProblem2012,
  title = {A {{Model Problem}} for {{Tear Film Distribution}} on a {{Moving Rectangular Domain}}},
  booktitle = {{{APS Meeting Abstracts}}},
  author = {Deng, Quan and Driscoll, Tobin and Braun, Richard},
  year = {2012},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{DengModelTear2013,
  ids = {dengModelTearFilm2013},
  title = {A Model for the Tear Film and Ocular Surface Temperature for Partial Blinks},
  author = {Deng, Quan and Braun, Richard J. and Driscoll, T. A. and {King-Smith}, P. E.},
  year = {2013},
  journal = {Interfacial Phenomena and Heat Transfer},
  volume = {1},
  number = {4},
  pages = {357--381},
  publisher = {{Begell House}},
  doi = {10.1615/interfacphenomheattransfer.v1.i4.40},
  copyright = {All rights reserved},
  keywords = {blinking,ocular surface temperature,spectral collocation,tear film},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Deng et al_2013_A model for the tear film and ocular surface temperature for partial blinks.pdf}
}

@article{DereviankoESPRITESPIRA2023,
  title = {From {{ESPRIT}} to {{ESPIRA}}: Estimation of Signal Parameters by Iterative Rational Approximation},
  shorttitle = {From {{ESPRIT}} to {{ESPIRA}}},
  author = {Derevianko, Nadiia and Plonka, Gerlind and Petz, Markus},
  year = {2023},
  month = apr,
  journal = {IMA Journal of Numerical Analysis},
  volume = {43},
  number = {2},
  pages = {789--827},
  issn = {0272-4979},
  doi = {10.1093/imanum/drab108},
  urldate = {2023-10-05},
  abstract = {We introduce a new method for Estimation of Signal Parameters based on Iterative Rational Approximation (ESPIRA) for sparse exponential sums. Our algorithm uses the AAA algorithm for rational approximation of the discrete Fourier transform of the given equidistant signal values. We show that ESPIRA can be interpreted as a matrix pencil method (MPM) applied to Loewner matrices. These Loewner matrices are closely connected with the Hankel matrices that are usually employed for signal recovery. Due to the construction of the Loewner matrices via an adaptive selection of index sets, the MPM is stabilized. ESPIRA achieves similar recovery results for exact data as ESPRIT and the MPM, but with less computational effort. Moreover, ESPIRA strongly outperforms ESPRIT and the MPM for noisy data and for signal approximation by short exponential sums.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Derevianko et al_2023_From ESPRIT to ESPIRA.pdf;/Users/driscoll/Zotero/storage/YDFPDKLE/6525860.html}
}

@article{Descombes2011,
  title = {Schwarz Waveform Relaxation Methods for Systems of Semi-Linear Reaction-Diffusion Equations},
  author = {Descombes, St{\'e}phane and Dolean, Victorita and Gander, Martin J.},
  year = {2011},
  pages = {423--430},
  issn = {1439-7358},
  doi = {10.1007/978-3-642-11304-8_49}
}

@book{Deuflhard2011,
  title = {Newton Methods for Nonlinear Problems},
  author = {Deuflhard, Peter},
  year = {2011},
  publisher = {{Springer Berlin Heidelberg}},
  doi = {10.1007/978-3-642-23899-4},
  file = {/Users/driscoll/Dropbox/library/Book/Deuflhard_2011_Newton methods for nonlinear problems.pdf}
}

@article{DEWS,
  title = {Report of the {{International Dry Eye WorkShop}} ({{DEWS}})},
  author = {{Anonymous}},
  year = {2007},
  journal = {Ocular Surface},
  volume = {5},
  pages = {65--204},
  date-modified = {2014-05-26 15:51:58 +0000},
  keywords = {No DOI found}
}

@book{DFound,
  title = {Biomedical Foundations of Ophthalmology},
  author = {{Duane} and {T.D.} and Jaeger, E.A.},
  year = {1982},
  publisher = {{Harper and Row}}
}

@article{Doane_Interaction_1980,
  title = {Interaction of Eyelids and Tears in Corneal Wetting and the Dynamics of the Normal Human Eyeblink},
  author = {Doane, Marshall G},
  year = {1980},
  volume = {89},
  number = {4},
  pages = {507--516},
  issn = {0002-9394},
  doi = {10.1016/0002-9394(80)90058-6}
}

@incollection{Doane_The,
  title = {The Preocular Tear Film},
  author = {Doane, Marshall G}
}

@article{Doane89,
  title = {An Instrument for in Vivo Tear Film Interferometry},
  author = {Doane, M.G.},
  year = {1989},
  volume = {66},
  pages = {383--8}
}

@misc{Doi101016,
  title = {Doi:10.1016/j.Cell.2005.08.029 {\textbar} {{Elsevier Enhanced Reader}}},
  shorttitle = {Doi},
  doi = {10.1016/j.cell.2005.08.029},
  urldate = {2021-02-08},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Web Page/doi.pdf;/Users/driscoll/Zotero/storage/7PXBDMBB/S0092867405008664.html}
}

@article{Dolean2016,
  title = {Nonlinear Preconditioning: How to Use a Nonlinear Schwarz Method to Precondition Newton's Method},
  author = {Dolean, V. and Gander, M. J. and Kheriji, W. and Kwok, F. and Masson, R.},
  year = {2016},
  volume = {38},
  pages = {A3357-A3380},
  issn = {1064-8275},
  doi = {10.1137/15m102887x}
}

@article{Don1997,
  title = {Accuracy Enhancement for Higher Derivatives Using Chebyshev Collocation and a Mapping Technique},
  author = {Don, Wai Sun and Solomonoff, Alex},
  year = {1997},
  month = jul,
  journal = {SIAM Journal on Scientific Computing},
  volume = {18},
  number = {4},
  pages = {1040--1055},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/s1064827594274607},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Don_Solomonoff_1997_Accuracy enhancement for higher derivatives using chebyshev collocation and a.pdf}
}

@article{Dongarra1996,
  title = {Chebyshev Tau-{{QZ}} Algorithm Methods for Calculating Spectra of Hydrodynamic Stability Problems},
  author = {Dongarra, J.J. and Straughan, B. and Walker, D.W.},
  year = {1996},
  month = dec,
  journal = {Applied Numerical Mathematics},
  volume = {22},
  number = {4},
  pages = {399--434},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0168-9274(96)00049-9},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Dongarra et al_1996_Chebyshev tau-QZ algorithm methods for calculating spectra of hydrodynamic.pdf}
}

@misc{DosovitskiyImageWorth2021,
  title = {An {{Image}} Is {{Worth}} 16x16 {{Words}}: {{Transformers}} for {{Image Recognition}} at {{Scale}}},
  shorttitle = {An {{Image}} Is {{Worth}} 16x16 {{Words}}},
  author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  year = {2021},
  month = jun,
  number = {arXiv:2010.11929},
  eprint = {2010.11929},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2010.11929},
  urldate = {2023-06-30},
  abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Dosovitskiy et al_2021_An Image is Worth 16x16 Words.pdf;/Users/driscoll/Zotero/storage/G9W6F77H/2010.html}
}

@article{Doughty_Contact_2011,
  title = {Contact Lens Wear and the Goblet Cells of the Human Conjunctiva-{{A}} Review.},
  author = {Doughty, Michael J},
  year = {2011},
  volume = {34},
  number = {4},
  pages = {157--63},
  issn = {1367-0484},
  doi = {10.1016/j.clae.2011.04.004},
  abstract = {To review the reported effects of contact lens wear on the goblet cells of the human conjunctiva.},
  pmid = {21601508}
}

@article{Doughty_Further_2002,
  title = {Further Assessment of Gender-and Blink Pattern-Related Differences in the Spontaneous Eyeblink Activity in Primary Gaze in Young Adult Humans},
  author = {Doughty, {\relax MJ}},
  year = {2002},
  journal = {Optometry \& Vision Science},
  doi = {10.1097/00006324-200207000-00013},
  abstract = {Purpose. To further assess the spontaneous eyeblink rate (SEBR) in primary gaze in young adults to further define the causes of variance in this activity. Methods. Nonconcealed video recordings were made of 61 white adults (30 males), aged 18 to 28 years, while silently ...}
}

@article{Doughty_Further_2006,
  title = {Further Analysis of the Human Spontaneous Eye Blink Rate by a Cluster {{Analysis-Based}} Approach to Categorize Individuals with `{{Normal}}' versus `{{Frequent}}' Eye Blink Activity},
  author = {Doughty, Michael J and Naase, Taher},
  year = {2006},
  volume = {32},
  number = {6},
  pages = {294},
  issn = {1542-2321},
  doi = {10.1097/01.icl.0000224359.32709.4d},
  abstract = {Purpose. To further analyze the possible causes of variability in spontaneous eye blink activity in apparently healthy humans. Methods. One hundred men, aged between 23 and 57 years and with no significant eye disease, were questioned on the number of ocular symptoms they experienced (one, two, three, and so forth). Five-minute video recordings were made of the eyes in primary gaze and in silence between 11:00 and 17:00 hours. The spontaneous eye blink rate (SEBR) and palpebral aperture features were assessed from the video recordings. The central corneal threshold touch sensitivity was then assessed with a Cochet-Bonnet aesthesiometer. Results. The average SEBR was 13.8  9.7 blinks per minute (range, 2.8--48 blinks per minute), but the distribution was heterogeneous and skewed to higher values. The SEBR was not obviously dependent on the time of day that the recordings were made, on the number of mild symptoms that the subjects reported, or on the central corneal sensitivity (P{$\geq$}0.6). Analysis of SEBR in relation to age showed a possible weak association (P=0.082, r = 0.175), but SEBR showed absolutely no correlation with palpebral aperture height (P=0.546). A hierarchic cluster analysis clearly resolved the distribution of SEBR values into two distinct groups (P\{{$<$}\}0.001, F ratio = 222). Conclusions. Spontaneous eye blink activity can be rather different between healthy individuals, even under a single experimental condition. These differences do not appear to be caused by the time of day, mild symptoms, corneal sensitivity, age, or palpebral aperture features. In line with previous metaanalyses, it is therefore proposed that individuals could be grouped as to whether they have ``normal'' eye blink activity or be classified as having ``frequent'' eye blink activity. The latter group would include those who had an SEBR greater than 20 blinks per minute when assessed in primary eye gaze and in silence.},
  pmid = {17099391}
}

@article{DriscollAAARational2023,
  title = {{{AAA}} Rational Approximation on a Continuum},
  author = {Driscoll, Tobin A. and Nakatsukasa, Yuji and Trefethen, Lloyd N.},
  year = {2023},
  month = may,
  journal = {SIAM Journal on Scientific Computing},
  pages = {to appear},
  urldate = {2023-05-08},
  copyright = {All rights reserved},
  keywords = {41A20 65D15,Mathematics - Numerical Analysis,No DOI found}
}

@article{DriscollAAARational2023a,
  title = {{{AAA}} Rational Approximation on a Continuum},
  author = {Driscoll, Toby and Nakatsukasa, Yuji and Trefethen, Lloyd N.},
  year = {2023},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2305.03677},
  urldate = {2024-02-26},
  abstract = {AAA rational approximation has normally been carried out on a discrete set, typically hundreds or thousands of points in a real interval or complex domain. Here we introduce a continuum AAA algorithm that discretizes a domain adaptively as it goes. This enables fast computation of high-accuracy rational approximations on domains such as the unit interval, the unit circle, and the imaginary axis, even in some cases where resolution of singularities requires exponentially clustered sample points, support points, and poles. Prototype MATLAB (or Octave) and Julia codes aaax, aaaz, and aaai are provided for these three special domains; the latter two are equivalent by a Moebius transformation. Execution is very fast since the matrices whose SVDs are computed have only three times as many rows as columns. The codes include a AAA-Lawson option for improvement of a AAA approximant to minimax, so long as the accuracy is well above machine precision. The result returned is pole-free in the approximation domain.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {41A20 65D15,FOS: Mathematics,Numerical Analysis (math.NA)},
  file = {/Users/driscoll/Dropbox/library/Preprint/Driscoll et al_2023_AAA rational approximation on a continuum.pdf}
}

@misc{DriscollAAARational2023arx,
  title = {{{AAA}} Rational Approximation on a Continuum},
  author = {Driscoll, Toby and Nakatsukasa, Yuji and Trefethen, Lloyd N.},
  year = {2023},
  month = may,
  number = {arXiv:2305.03677},
  eprint = {2305.03677},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  urldate = {2023-05-08},
  abstract = {AAA rational approximation has normally been carried out on a discrete set, typically hundreds or thousands of points in a real interval or complex domain. Here we introduce a continuum AAA algorithm that discretizes a domain adaptively as it goes. This enables fast computation of high-accuracy rational approximations on domains such as the unit interval, the unit circle, and the imaginary axis, even in some cases where resolution of singularities requires exponentially clustered sample points, support points, and poles. Prototype MATLAB (or Octave) and Julia codes aaax, aaaz, and aaai are provided for these three special domains; the latter two are equivalent by a Moebius transformation. Execution is very fast since the matrices whose SVDs are computed have only three times as many rows as columns. The codes include a AAA-Lawson option for improvement of a AAA approximant to minimax, so long as the accuracy is well above machine precision. The result returned is pole-free in the approximation domain.},
  archiveprefix = {arxiv},
  copyright = {All rights reserved},
  keywords = {41A20 65D15,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Zotero/storage/EXEYTPJD/2305.html}
}

@article{DriscollAdaptiveResidual2007,
  title = {Adaptive Residual Subsampling Methods for Radial Basis Function Interpolation and Collocation Problems},
  author = {Driscoll, Tobin A. and Heryudono, Alfa R. H.},
  year = {2007},
  month = mar,
  journal = {Computers \& Mathematics with Applications},
  volume = {53},
  number = {6},
  pages = {927--939},
  issn = {0898-1221},
  doi = {10.1016/j.camwa.2006.06.005},
  urldate = {2022-10-27},
  abstract = {We construct a new adaptive algorithm for radial basis functions (RBFs) method applied to interpolation, boundary-value, and initial-boundary-value problems with localized features. Nodes can be added and removed based on residuals evaluated at a finer point set. We also adapt the shape parameters of RBFs based on the node spacings to prevent the growth of the conditioning of the interpolation matrix. The performance of the method is shown in numerical examples in one and two space dimensions with nontrivial domains.},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {Adaptive,Collocation,Interpolation,Radial basis functions,Residual subsampling},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Driscoll_Heryudono_2007_Adaptive residual subsampling methods for radial basis function interpolation2.pdf;/Users/driscoll/Zotero/storage/ZD8EBP2G/S0898122107000454.html}
}

@article{DriscollAlgorithm7561996,
  title = {Algorithm 756: {{A MATLAB}} Toolbox for {{Schwarz-Christoffel}} Mapping},
  author = {Driscoll, Tobin A},
  year = {1996},
  journal = {ACM Transactions on Mathematical Software (TOMS)},
  volume = {22},
  number = {2},
  pages = {168--186},
  doi = {10.1145/229473.229475},
  copyright = {All rights reserved}
}

@article{DriscollAlgorithm8432005,
  title = {Algorithm 843: Improvements to the {{Schwarz-Christoffel}} Toolbox for {{MATLAB}}},
  author = {Driscoll, Tobin A},
  year = {2005},
  journal = {ACM Transactions on Mathematical Software (TOMS)},
  volume = {31},
  number = {2},
  pages = {239--251},
  doi = {10.1145/1067967.1067971},
  copyright = {All rights reserved}
}

@techreport{DriscollApproximationsCanonical2004,
  title = {Approximations in Canonical Electrostatic {{MEMS}} Models},
  author = {Driscoll, Tobin A and Pelesko, John A},
  year = {2004},
  institution = {{University of Delaware}},
  copyright = {All rights reserved}
}

@article{DriscollAutomaticDetection2021,
  title = {Automatic Detection of the Cornea Location in Video Captures of Fluorescence},
  author = {Driscoll, Tobin and Braun, Richard J. and Begley, Carolyn G.},
  year = {2021},
  month = sep,
  journal = {Modeling and Artificial Intelligence in Ophthalmology},
  volume = {3},
  number = {1},
  pages = {55--70},
  issn = {2772-9605},
  doi = {10.35119/maio.v3i1.113},
  urldate = {2021-09-17},
  abstract = {Purpose: Fluorescence imaging is a valuable tool for studying tear film dynamics andcorneal staining. Automating the quantification of fluorescence images is a challenging necessary step for making connections to mathematical models. A significant partof the challenge is identifying the region of interest, specifically the cornea, for collected data with widely varying characteristics. Methods: The gradient of pixel intensity at the cornea--sclera limbus is used as the objective of standard optimization to find a circle that best represents the cornea. Results of the optimization in one image are used as initial conditions in the next imageof a sequence. Additional initial conditions are chosen heuristically. The algorithm iscoded in open-source software. Results: The algorithm was first applied to 514 videos of 26 normal subjects, for a total of over 87,000 images. Only in 12 of the videos does the standard deviation in thedetected corneal radius exceed 1\% of the image height, and only 3 exceeded 2\%. The algorithm was applied to a sample of images from a second study with 142 dry-eye subjects. Significant staining was present in a substantial number of these images. Visual inspection and statistical analysis show good resuls for both normal and dry-eye images. Conclusion: The new algorithm is highly effective over a wide range of tear film andcorneal staining images collected at different times and locations.},
  copyright = {Copyright (c) 2021 Tobin Driscoll, Richard J. Braun, Carolyn G. Begley},
  langid = {english},
  keywords = {tear film breakup},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Driscoll et al_2021_Automatic detection of the cornea location in video captures of fluorescence.pdf}
}

@article{DriscollAutomaticSpectral2010,
  title = {Automatic Spectral Collocation for Integral, Integro-Differential, and Integrally Reformulated Differential Equations},
  author = {Driscoll, Tobin A.},
  year = {2010},
  month = aug,
  journal = {Journal of Computational Physics},
  volume = {229},
  number = {17},
  pages = {5980--5998},
  issn = {00219991},
  doi = {10.1016/j.jcp.2010.04.029},
  copyright = {All rights reserved},
  keywords = {Chebfun,foundations}
}

@article{DriscollBlockPseudospectral1998,
  ids = {driscollBlockPseudospectralMethod1998a},
  title = {A {{Block Pseudospectral Method}} for {{Maxwell}}'s {{Equations}}: {{I}}. {{One-Dimensional Case}}},
  author = {Driscoll, T. A. and Fornberg, B.},
  year = {1998},
  journal = {J. Comput. Phys.},
  volume = {140},
  pages = {1--19},
  doi = {10.1006/jcph.1998.5883},
  copyright = {All rights reserved},
  keywords = {file-import-09-09-29}
}

@article{DriscollBlockPseudospectral1999,
  title = {Block Pseudospectral Methods for {{Maxwell}}'s Equations {{II}}: {{Two-dimensional}}, Discontinuous-Coefficient Case},
  author = {Driscoll, Tobin A and Fornberg, Bengt},
  year = {1999},
  journal = {SIAM Journal on Scientific Computing},
  volume = {21},
  number = {3},
  pages = {1146--1167},
  doi = {10.1137/s106482759833320x},
  copyright = {All rights reserved}
}

@book{DriscollChebfunGuide2014,
  title = {Chebfun Guide},
  author = {Driscoll, Tobin A and Hale, Nicholas and Trefethen, Lloyd N},
  year = {2014},
  publisher = {{Pafnuty Publications, Oxford}},
  copyright = {All rights reserved}
}

@misc{DriscollChebfunPDEs2012,
  title = {Chebfun for {{PDEs}}},
  author = {Driscoll, Tobin},
  year = {2012},
  address = {{Banff International Research Station for Mathematical Innovation and Discovery}},
  copyright = {All rights reserved}
}

@article{DriscollChebopSystem2008,
  title = {The Chebop System for Automatic Solution of Differential Equations},
  author = {Driscoll, Tobin A and Bornemann, Folkmar and Trefethen, Lloyd N},
  year = {2008},
  journal = {BIT Numerical Mathematics},
  volume = {48},
  number = {4},
  pages = {701--723},
  doi = {10.1007/s10543-008-0198-4},
  copyright = {All rights reserved},
  keywords = {adaptivity,automatic solution,Chebfun,chebop,Chebyshev,spectral}
}

@phdthesis{DriscollComparisonComputational1991,
  title = {Comparison of {{Computational Efficiency}} and {{Sensitivity}} of {{Several Solution Algorithms}} for the {{Linear-quadratic Optimal Control Problem}}},
  author = {Driscoll, Tobin A},
  year = {1991},
  copyright = {All rights reserved},
  school = {Pennsylvania State University}
}

@misc{DriscollComplexRegionsJl2019,
  title = {{{ComplexRegions}}.Jl: {{A Julia}} Package for Regions in the Complex Plane},
  author = {Driscoll, Tobin A},
  year = {2019},
  copyright = {All rights reserved}
}

@article{DriscollComplexRegionsJl2019a,
  title = {{{ComplexRegions}}.Jl: {{A Julia}} Package for Regions in the Complex Plane},
  shorttitle = {{{ComplexRegions}}.Jl},
  author = {Driscoll, Tobin},
  year = {2019},
  month = dec,
  journal = {Journal of Open Source Software},
  volume = {4},
  number = {44},
  pages = {1811},
  issn = {2475-9066},
  doi = {10.21105/joss.01811},
  urldate = {2022-02-11},
  copyright = {All rights reserved},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Driscoll-2019-ComplexRegions.pdf}
}

@article{DriscollCompositeRunge2002,
  ids = {driscollCompositeRungeKutta2002a},
  title = {A {{Composite Runge}}--{{Kutta Method}} for the {{Spectral Solution}} of {{Semilinear PDEs}}},
  author = {Driscoll, Tobin A.},
  year = {2002},
  month = nov,
  journal = {Journal of Computational Physics},
  volume = {182},
  number = {2},
  pages = {357--367},
  issn = {00219991},
  doi = {10.1006/jcph.2002.7127},
  copyright = {All rights reserved}
}

@article{DriscollComputationalConformal1999,
  title = {Computational {{Conformal Mapping}} (Book Review)},
  author = {Driscoll, Tobin A},
  year = {1999},
  journal = {SIAM Review},
  volume = {41},
  number = {4},
  pages = {832--834},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@inproceedings{DriscollComputationalEfficiency1992,
  title = {Computational Efficiency of a Functional Expansion Algorithm for Linear Quadratic Optimal Control},
  booktitle = {Proceedings of the 31st {{IEEE Conference}} on {{Decision}} and {{Control}}},
  author = {Driscoll, {\relax TA} and Dzielski, {\relax JE}},
  year = {1992},
  pages = {143--144},
  publisher = {{IEEE}},
  doi = {10.1109/cdc.1992.371773},
  copyright = {All rights reserved}
}

@inproceedings{DriscollConformalMapping1994,
  title = {Conformal Mapping and Convergence of {{Krylov}} Iterations},
  author = {Driscoll, T. A.},
  year = {1994},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@techreport{DriscollConformalMapping1994a,
  title = {Conformal Mapping and Convergence of {{Krylov}} Iterations},
  author = {Driscoll, {\relax TA} and Trefethen, {\relax LN}},
  year = {1994},
  institution = {{Front Range Scientific Computations, Inc., Boulder, CO (United States {\dots}}},
  copyright = {All rights reserved}
}

@misc{driscollCorneaDetection2021,
  title = {Cornea Detection Software Package for {{Julia}}},
  author = {Driscoll, Tobin A},
  year = {2021},
  month = jan,
  copyright = {All rights reserved}
}

@misc{driscollCrashCourseMatlab2003,
  title = {A Crash Course in {{Matlab}}},
  author = {Driscoll, Tobin A},
  year = {2003},
  publisher = {{Department of Mathematical Sciences, University of Delaware, Newark {\dots}}}
}

@techreport{DriscollDomainDecomposition1996,
  title = {Domain Decomposition Methods for Conformal Mapping and Eigenvalue Problems},
  author = {Driscoll, Tobin Allen},
  year = {1996},
  institution = {{Cornell University}},
  copyright = {All rights reserved}
}

@article{DriscollEigenmodesIsospectral1997a,
  title = {Eigenmodes of {{Isospectral Drums}}},
  author = {Driscoll, Tobin A.},
  year = {1997},
  month = jan,
  journal = {SIAM Review},
  volume = {39},
  number = {1},
  pages = {1--17},
  issn = {0036-1445},
  doi = {10.1137/S0036144595285069},
  copyright = {All rights reserved}
}

@article{DriscollFittingODE2023,
  title = {Fitting {{ODE}} Models of Tear Film Breakup},
  author = {Driscoll, Tobin A. and Braun, Richard J. and Luke, Rayanne A. and Sinopoli, Dominick and Phatak, Aashish and Dorsch, Julianna and Begley, Carolyn G. and {Awisi-Gyau}, Deborah},
  year = {2023},
  month = sep,
  journal = {Modeling and Artificial Intelligence in Ophthalmology},
  volume = {5},
  number = {1},
  pages = {1--36},
  doi = {10.35119/maio.v5i1.128},
  urldate = {2023-09-09},
  abstract = {\&lt;p\&gt;\&lt;em\&gt;Purpose:\&lt;/em\&gt; Several elements are developed to quantitatively determine the contribution of different physical and chemical effects to tear breakup (TBU) in subjects with no self-reported history of dry eye (DED) or other ocular surface disease. Fluorescence (FL) imaging is employed to visualize the tear film (TF) and to determine TF thinning and potential TBU.\&lt;/p\&gt;\&lt;p\&gt;\&lt;em\&gt;Methods:\&lt;/em\&gt; An automated system using a convolutional neural network that was trained and tested on more than 50,000 images from FL imaging experiments was deployed. The trained system could identify multiple TBU instances in each trial. Once identified, extracted FL intensity data was fit by mathematical models that included tangential flow along the eye, evaporation, osmosis, and FL intensity of emission from the TF. The mathematical models consisted of systems of ordinary differential equations for the aqueous layer thickness, osmolarity, and the FL concentration; they are a local approximation to TF thinning and/or TBU dynamics. FL intensity was computed using the resulting thickness and FL concentration. Optimizing the fit of the models to the FL intensity data determined the mechanism(s) driving each instance of TBU and produced an estimate of the osmolarity within TBU.\&lt;/p\&gt;\&lt;p\&gt;\&lt;em\&gt;Results:\&lt;/em\&gt; Initial estimates for FL concentration and initial TF thickness agree well with prior results. Fits were produced for \&lt;em\&gt;N\&lt;/em\&gt; = 467 instances of potential TBU from 15 non-DED subjects. The results showed a distribution of causes of TBU in these healthy subjects, as reflected by estimated flow and evaporation rates, which appear to agree well with previously published data. Final osmolarity depended strongly on the TBU mechanism, generally increasing with evaporation rate but complicated by the dependence on flow.\&lt;/p\&gt;\&lt;p\&gt;\&lt;em\&gt;Conclusion:\&lt;/em\&gt; The method has the potential to classify TBU instances based on the mechanism and dynamics, and to estimate the final osmolarity at the TBU locus. The results suggest that it might be possible to classify individual subjects and provide a baseline for comparison and potential classification of DED subjects.\&lt;/p\&gt;},
  chapter = {Original Articles},
  copyright = {All rights reserved},
  keywords = {FOS: Mathematics,No DOI found,Numerical Analysis (math.NA)}
}

@book{DriscollFundamentalsNumerical2018,
  title = {Fundamentals of {{Numerical Computation}}},
  author = {Driscoll, Tobin A. and Braun, Richard J.},
  year = {2018},
  series = {Other Titles in Applied Mathematics},
  number = {154},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  copyright = {All rights reserved},
  isbn = {978-1-61197-507-9},
  lccn = {QA297 .D75 2018},
  keywords = {Data processing,Numerical analysis}
}

@techreport{DriscollImprovedSchwarzChrisoffel2003,
  title = {An Improved {{Schwarz-Chrisoffel Toolbox}} for {{MATLAB}}},
  author = {Driscoll, Tobin A},
  year = {2003},
  institution = {{Mathematical Sciences Department}},
  copyright = {All rights reserved}
}

@article{DriscollInterpolationLimit2002,
  title = {Interpolation in the Limit of Increasingly Flat Radial Basis Functions},
  author = {Driscoll, Tobin A and Fornberg, Bengt},
  year = {2002},
  journal = {Computers \& Mathematics with Applications},
  volume = {43},
  number = {3-5},
  pages = {413--422},
  doi = {10.1016/s0898-1221(01)00295-4},
  copyright = {All rights reserved},
  keywords = {basis,functions,Radial}
}

@article{DriscollIsospectralShapes2003a,
  title = {Isospectral Shapes with {{Neumann}} and Alternating Boundary Conditions},
  author = {Driscoll, Tobin A and Gottlieb, {\relax HPW}},
  year = {2003},
  journal = {Physical Review E},
  volume = {68},
  number = {1},
  pages = {016702},
  doi = {10.1103/physreve.68.016702},
  copyright = {All rights reserved}
}

@book{DriscollLearningMATLAB2009a,
  title = {Learning {{MATLAB}}},
  author = {Driscoll, T. A.},
  year = {2009},
  publisher = {{Society for Industrial and Applied Mathematics}},
  address = {{Philadelphia}},
  copyright = {All rights reserved}
}

@techreport{DriscollMatrixIterations1996,
  title = {Matrix Iterations: The Six Gaps between Potential Theory and Convergence},
  author = {Driscoll, Tobin A and Toh, Kim-Chuan and Trefethen, Lloyd N},
  year = {1996},
  institution = {{Cornell University}},
  copyright = {All rights reserved}
}

@article{DriscollNewDirections2016,
  title = {New Directions in Numerical Computation},
  author = {Driscoll, Tobin A and S{\"u}li, Endre and Townsend, Alex},
  year = {2016},
  journal = {Notices of the American Mathematical Society},
  volume = {63},
  number = {4},
  pages = {398--400},
  doi = {10.1090/noti1363},
  copyright = {All rights reserved}
}

@article{DriscollNonoverlappingDomain1999,
  ids = {driscollNonoverlappingDomainDecomposition1999a},
  title = {A {{Nonoverlapping Domain Decomposition Method}} for {{Symm}}'s {{Equation}} for {{Conformal Mapping}}},
  author = {Driscoll, Tobin A.},
  year = {1999},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {36},
  number = {3},
  pages = {922--934},
  issn = {0036-1429},
  doi = {10.1137/S0036142997324162},
  abstract = {Symm's equation is a first-kind integral equation for computing conformal maps of simply connected regions. The package CONFPACK solves Symm's equation by an indirect boundary element method using an accurate corner representation. This solution technique is extended here to include nonoverlapping domain decomposition. Degrees of freedom are introduced on one or more interfaces and different unknowns are used, leading to a system of second-kind equations. The corresponding linear system can be expressed in Schur complement form. The accurate treatment of corners is preserved in the new formulation. The results of serial and parallel MATLAB implementations of the new algorithm show significant speedups as the number of unknowns grows.},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {30C30,31A10,65N38,65N55,boundary elements,conformal mapping,domain decomposition,Symm's equation}
}

@article{DriscollNoteNonsymmetric2000,
  title = {Note on Nonsymmetric Finite Differences for {{Maxwell}}'s Equations},
  author = {Driscoll, Tobin A and Fornberg, Bengt},
  year = {2000},
  journal = {Journal of Computational Physics},
  volume = {161},
  number = {2},
  pages = {723--727},
  doi = {10.1006/jcph.2000.6524},
  copyright = {All rights reserved}
}

@article{DriscollNumericalConformal1998,
  title = {Numerical Conformal Mapping Using Cross-Ratios and {{Delaunay}} Triangulation},
  author = {Driscoll, Tobin A and Vavasis, Stephen A},
  year = {1998},
  journal = {SIAM Journal on Scientific Computing},
  volume = {19},
  number = {6},
  pages = {1783--1803},
  doi = {10.1137/s1064827596298580},
  copyright = {All rights reserved}
}

@inproceedings{DriscollNumericalExamination2003,
  title = {Numerical Examination of a Model of Thermo-Acoustic Instabilites in Lean, Pre-Mixed Combustors.},
  booktitle = {{{APS Division}} of {{Fluid Dynamics Meeting Abstracts}}},
  author = {Driscoll, Tobin and Rossi, Louis},
  year = {2003},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@misc{DriscollOpenSource2015,
  title = {An Open Source Software Project for Numerical Conformal Mapping},
  author = {Driscoll, Tobin},
  year = {2015},
  address = {{Banff International Research Station for Mathematical Innovation and Discovery}},
  copyright = {All rights reserved}
}

@article{DriscollOptimalDomain2014,
  title = {Optimal Domain Splitting for Interpolation by {{Chebyshev}} Polynomials},
  author = {Driscoll, Tobin A and Weideman, {\relax JAC}},
  year = {2014},
  journal = {SIAM Journal on Numerical Analysis},
  volume = {52},
  number = {4},
  pages = {1913--1927},
  doi = {10.1137/130919428},
  copyright = {All rights reserved}
}

@article{DriscollPadebasedAlgorithm2001,
  ids = {driscollPadebasedAlgorithmOvercoming2001a},
  title = {A {{Pad{\'e}-based}} Algorithm for Overcoming the {{Gibbs}} Phenomenon},
  author = {Driscoll, T. A. and Fornberg, B.},
  year = {2001},
  journal = {Numerical Algorithms},
  volume = {26},
  number = {1},
  pages = {77--92},
  doi = {10.1023/A:1016648530648},
  copyright = {All rights reserved}
}

@incollection{DriscollPadebasedInterpretation2007,
  title = {Pade-Based Interpretation and Correction of the {{Gibbs}} Phenomenon},
  booktitle = {Advances in the {{Gibbs Phenomenon}}, Ed. by {{A}}. {{Jerri}}},
  author = {Driscoll, Tobin A and Fornberg, Bengt},
  year = {2007},
  publisher = {{Sigma Sampling Publishing}},
  address = {{Potsdam, NY}},
  copyright = {All rights reserved}
}

@article{DriscollPotentialTheory1998a,
  title = {From {{Potential Theory}} to {{Matrix Iterations}} in {{Six Steps}}},
  author = {Driscoll, Tobin A. and Toh, Kim-Chuan and Trefethen, Lloyd N.},
  year = {1998},
  month = jan,
  journal = {SIAM Review},
  volume = {40},
  number = {3},
  pages = {547--578},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/S0036144596305582},
  urldate = {2019-03-18},
  copyright = {All rights reserved},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/XLTGARGG/Driscoll et al. - 1998 - From Potential Theory to Matrix Iterations in Six .pdf}
}

@article{DriscollPracticalGuide2004,
  title = {A {{Practical Guide}} to {{Boundary Element Methods With}} the {{Software Library BEMLIB}}. {{By C}}. {{P OZRIKIDIS}}. {{CRC Press}}, 2002. 440 Pp. {{ISBN}} 1584 883235. \$99.95 (Hardback)},
  author = {Driscoll, Tobin},
  year = {2004},
  journal = {Journal of Fluid Mechanics},
  volume = {505},
  pages = {378--379},
  doi = {10.1017/s0022112004008201},
  copyright = {All rights reserved}
}

@techreport{DriscollPseudospectraWave1993,
  title = {Pseudospectra of the Wave Operator with an Absorbing Boundary},
  author = {Driscoll, Tobin A and Trefethen, Lloyd N},
  year = {1993},
  institution = {{Cornell University}},
  copyright = {All rights reserved}
}

@article{DriscollPseudospectraWave1996a,
  title = {Pseudospectra for the Wave Equation with an Absorbing Boundary},
  author = {Driscoll, Tobin A. and Trefethen, Lloyd N.},
  year = {1996},
  month = apr,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {69},
  number = {1},
  pages = {125--142},
  issn = {03770427},
  doi = {10.1016/0377-0427(95)00021-6},
  copyright = {All rights reserved}
}

@article{DriscollRectangularSpectral2015,
  title = {Rectangular Spectral Collocation},
  author = {Driscoll, Tobin A and Hale, Nicholas},
  year = {2015},
  journal = {IMA Journal of Numerical Analysis},
  volume = {36},
  number = {1},
  pages = {108--132},
  doi = {10.1093/imanum/dru062},
  copyright = {All rights reserved}
}

@book{DriscollSchwarzChristoffel2002,
  title = {Schwarz--{{Christoffel Mapping}}},
  author = {Driscoll, Tobin A and Trefethen, Lloyd N},
  year = {2002},
  publisher = {{Cambridge University Press}},
  copyright = {All rights reserved},
  isbn = {978-0-521-80726-5}
}

@misc{DriscollSchwarzChristoffelToolbox1994,
  title = {Schwarz-{{Christoffel Toolbox}} for {{MATLAB}}},
  author = {Driscoll, Tobin A},
  year = {1994},
  copyright = {All rights reserved}
}

@techreport{DriscollSchwarzChristoffelToolbox1994a,
  title = {Schwarz-{{Christoffel Toolbox User}}'s {{Guide}}},
  author = {Driscoll, Tobin A},
  year = {1994},
  institution = {{Cornell University}},
  copyright = {All rights reserved}
}

@article{DriscollSearchingRare2007a,
  title = {Searching for {{Rare Growth Factors Using Multicanonical Monte Carlo Methods}}},
  author = {Driscoll, Tobin A. and Maki, Kara L.},
  year = {2007},
  month = jan,
  journal = {SIAM Review},
  volume = {49},
  number = {4},
  pages = {673--692},
  issn = {0036-1445},
  doi = {10.1137/050637662},
  abstract = {The growth factor of a matrix quantifies the amount of potential error growth possible when a linear system is solved using Gaussian elimination with row pivoting. While it is an easy matter [N. J. Higham and D. J. Higham, SIAM J. Matrix Anal. Appl., 10 (1989), pp. 155--164] to construct examples of \$n{\textbackslash}backslash times n\$ matrices having any growth factor up to the maximum of \$2\^{}\{n-1\}\$, the weight of experience and analysis [N. J. Higham, Accuracy and Stability of Numerical Algorithms, SIAM, Philadelphia, 1996], [L. N. Trefethen and R. S. Schreiber, SIAM J. Matrix Anal. Appl., 11 (1990), pp. 335--360], [L. N. Trefethen and I. D. Bau, Numerical Linear Algebra, SIAM, Philadelphia, 1997] suggest that matrices with exponentially large growth factors are exceedingly rare. Here we show how to conduct numerical experiments on random matrices using a multicanonical Monte Carlo method to explore the tails of growth factor probability distributions. Our results suggest, for example, that the occurrence of an \$8{\textbackslash}backslash times 8\$ matrix ...},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {15A52,65C05,65C40,65F05,Gaussian elimination,growth factors,Markov chain Monte Carlo,multicanonical Monte Carlo}
}

@article{driscollSimulationParabolic2018,
  title = {Simulation of Parabolic Flow on an Eye-Shaped Domain with Moving Boundary},
  author = {Driscoll, Tobin A and Braun, Richard J and Brosch, Joseph K},
  year = {2018},
  journal = {Journal of Engineering Mathematics},
  volume = {111},
  number = {1},
  pages = {111--126},
  doi = {10.1007/s10665-018-9957-7},
  copyright = {All rights reserved}
}

@inproceedings{DriscollUsesBerenger1998,
  title = {Uses of the {{Berenger PML}} in {{Pseudospectral Methods}} for {{Maxwell}}'s {{Equations}}},
  booktitle = {{{IUTAM Symposium}} on {{Computational Methods}} for {{Unbounded Domains}}},
  author = {Driscoll, Tobin A and Fornberg, Bengt},
  year = {1998},
  pages = {95--102},
  publisher = {{Springer, Dordrecht}},
  doi = {10.1007/978-94-015-9095-2_10},
  copyright = {All rights reserved}
}

@misc{DriscollVibrationsIsospectral1995,
  title = {Vibrations of {{Isospectral Drums}}},
  author = {Driscoll, T. A. and Land, B.},
  year = {1995},
  copyright = {All rights reserved}
}

@inbook{duIndependentComponentAnalysis2019,
  title = {Independent {{Component Analysis}}},
  booktitle = {Neural {{Networks}} and {{Statistical Learning}}},
  author = {Du, Ke-Lin and Swamy, M. N. S.},
  year = {2019},
  pages = {447--482},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/978-1-4471-7452-3_15},
  urldate = {2020-01-21},
  collaborator = {Du, Ke-Lin and Swamy, M. N. S.},
  isbn = {978-1-4471-7451-6 978-1-4471-7452-3},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Book Section/Du_Swamy_2019_Independent Component Analysis.pdf}
}

@incollection{duke-elderCornea1961,
  title = {The Cornea},
  booktitle = {The {{Anatomy}} of the {{Visual System}}},
  author = {{Duke-Elder}, S. and Wybar, K. C.},
  year = {1961},
  series = {System of {{Ophthalmology}}},
  volume = {2},
  pages = {92--94},
  publisher = {{Henry Kimpton}},
  address = {{London}}
}

@misc{DupontAugmentedNeural2019,
  title = {Augmented {{Neural ODEs}}},
  author = {Dupont, Emilien and Doucet, Arnaud and Teh, Yee Whye},
  year = {2019},
  month = oct,
  number = {arXiv:1904.01681},
  eprint = {1904.01681},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  urldate = {2023-02-06},
  abstract = {We show that Neural Ordinary Differential Equations (ODEs) learn representations that preserve the topology of the input space and prove that this implies the existence of functions Neural ODEs cannot represent. To address these limitations, we introduce Augmented Neural ODEs which, in addition to being more expressive models, are empirically more stable, generalize better and have a lower computational cost than Neural ODEs.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Dupont et al_2019_Augmented Neural ODEs.pdf;/Users/driscoll/Zotero/storage/474R78BN/1904.html}
}

@article{DurschFLandThermal2017,
  title = {Tear-{{Film Evaporation Rate}} from {{Simultaneous Ocular-Surface Temperature}} and {{Tear-Breakup Area}}},
  author = {Dursch, Thomas J. and Li, Wing and Taraz, Baseem and Lin, Meng C. and Radke, Clayton J.},
  year = {2018},
  month = jan,
  journal = {Optometry and Vision Science},
  volume = {95},
  number = {1},
  pages = {5--12},
  issn = {1538-9235, 1040-5488},
  doi = {10.1097/OPX.0000000000001156},
  urldate = {2022-08-05},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Dursch et al-2018-Tear-Film Evaporation Rate from Simultaneous Ocular-Surface Temperature and.pdf}
}

@article{DurstewitzReconstructingComputational2023,
  title = {Reconstructing Computational System Dynamics from Neural Data with Recurrent Neural Networks},
  author = {Durstewitz, Daniel and Koppe, Georgia and Thurm, Max Ingo},
  year = {2023},
  month = nov,
  journal = {Nature Reviews Neuroscience},
  volume = {24},
  number = {11},
  pages = {693--710},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/s41583-023-00740-7},
  urldate = {2023-11-02},
  abstract = {Computational models in neuroscience usually take the form of systems of differential equations. The behaviour of such systems is the subject of dynamical systems theory. Dynamical systems~theory provides a powerful mathematical toolbox for analysing neurobiological processes and has been a mainstay of computational neuroscience for decades. Recently, recurrent neural networks (RNNs) have become a popular machine learning tool for studying the non-linear dynamics of neural and behavioural processes by emulating an underlying system of differential equations. RNNs have been routinely trained on similar behavioural tasks to those used for animal subjects to generate hypotheses about the underlying computational mechanisms. By contrast, RNNs can also be trained on the measured physiological and behavioural data, thereby directly inheriting their temporal and geometrical properties. In this way they become a formal surrogate for the experimentally probed system that can be further analysed, perturbed and simulated. This powerful approach is called dynamical system reconstruction. In this Perspective, we focus on recent trends in artificial intelligence and machine learning in this exciting and rapidly expanding field, which may be less well known in neuroscience. We discuss formal prerequisites, different model architectures and training approaches for RNN-based dynamical system reconstructions, ways to evaluate and validate model performance, how to interpret trained models in a neuroscience context, and current challenges.},
  copyright = {2023 Springer Nature Limited},
  langid = {english},
  keywords = {Dynamical systems,Learning algorithms},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Durstewitz et al_2023_Reconstructing computational system dynamics from neural data with recurrent.pdf}
}

@article{DzielskiErrorBound1993,
  title = {Error Bound on the Solution of a Linear Differential Equation in {{Chebyshev}} Series},
  author = {Dzielski, J. E. and Driscoll, Tobin A.},
  year = {1993},
  month = jul,
  journal = {International Journal of Systems Science},
  volume = {24},
  number = {7},
  pages = {1317--1327},
  issn = {0020-7721},
  doi = {10.1080/00207729308949562},
  copyright = {All rights reserved}
}

@book{Easley2010,
  title = {Networks, Crowds, and Markets: Reasoning about a Highly Connected World},
  author = {Easley, David and Kleinberg, Jon},
  year = {2010},
  publisher = {{Cambridge University Press}},
  file = {/Users/driscoll/Dropbox/library/Book/Easley_Kleinberg_2010_Networks, crowds, and markets.pdf}
}

@inproceedings{eggertTransformationinvariantRepresentationNMF2004,
  title = {Transformation-Invariant Representation and {{NMF}}},
  booktitle = {2004 {{IEEE International Joint Conference}} on {{Neural Networks}} ({{IEEE Cat}}. {{No}}.{{04CH37541}})},
  author = {Eggert, J. and Wersing, H. and Korner, E.},
  year = {2004},
  month = jul,
  volume = {4},
  pages = {2535-2539 vol.4},
  doi = {10.1109/IJCNN.2004.1381038},
  abstract = {Non-negative matrix factorization (NMF) is a method for the decomposition of multivariate data into strictly positive activations and basis vectors. Here, instead of using unstructured data vectors, we assume that something is known in advance about the type of transformations that either the input data or the basis vectors may undergo. This would be the case e.g. if we assume input vectors that are translationally shifted versions of each other, but it applies to any other transformations as well. The key idea is that we factorize the data into activations and basis vectors modulo the transformations. We show that this can be done by extending NMF in a natural way. The gained factorization thus provides a transformation-invariant and compact encoding that is optimal for the given transformation constraints.},
  keywords = {Brain modeling,compact encoding,data-science,Image coding,Image reconstruction,image representation,learning (artificial intelligence),matrix decomposition,multivariate data decomposition,neural nets,NMF,nonnegative matrix factorization,Principal component analysis,transformation-invariant representation},
  file = {/Users/driscoll/Zotero/storage/46HXXX8E/Eggert et al. - 2004 - Transformation-invariant representation and NMF.pdf;/Users/driscoll/Zotero/storage/9XU34W5Z/authors.html}
}

@misc{eisenstatStableFastAlgorithm1993,
  title = {A Stable and Fast Algorithm for Updating the Singular Value Decomposition},
  author = {Eisenstat, Stanley C. and Gu, Ming},
  year = {1993},
  series = {Tech. {{Report}}},
  number = {YALEU/DCS/RR-966},
  address = {{Yale University Department of Computer Science}},
  file = {/Users/driscoll/Dropbox/library/Preprint/Eisenstat_Gu-1993-A stable and fast algorithm for updating the singular value decomposition.pdf}
}

@article{elbayadPervasiveAttention2D2018,
  title = {Pervasive {{Attention}}: {{2D Convolutional Neural Networks}} for {{Sequence-to-Sequence Prediction}}},
  shorttitle = {Pervasive {{Attention}}},
  author = {Elbayad, Maha and Besacier, Laurent and Verbeek, Jakob},
  year = {2018},
  month = nov,
  journal = {arXiv:1808.03867 [cs]},
  eprint = {1808.03867},
  primaryclass = {cs},
  urldate = {2020-10-24},
  abstract = {Current state-of-the-art machine translation systems are based on encoder-decoder architectures, that first encode the input sequence, and then generate an output sequence based on the input encoding. Both are interfaced with an attention mechanism that recombines a fixed encoding of the source tokens based on the decoder state. We propose an alternative approach which instead relies on a single 2D convolutional neural network across both sequences. Each layer of our network re-codes source tokens on the basis of the output sequence produced so far. Attention-like properties are therefore pervasive throughout the network. Our model yields excellent results, outperforming state-of-the-art encoder-decoder systems, while being conceptually simpler and having fewer parameters.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Elbayad et al_2018_Pervasive Attention.pdf;/Users/driscoll/Zotero/storage/XATDS7QS/1808.html}
}

@article{Elman2018,
  title = {Collocation Methods for Exploring Perturbations in Linear Stability Analysis},
  author = {Elman, Howard C. and Silvester, David J.},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {40},
  number = {4},
  pages = {A2667-A2693},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/17m1117689},
  keywords = {collocation,pseudospectra,stability}
}

@article{Evensen2009,
  title = {The Ensemble {{Kalman}} Filter for Combined State and Parameter Estimation},
  author = {Evensen, G.},
  year = {2009},
  month = jun,
  journal = {IEEE Control Systems Magazine},
  volume = {29},
  number = {3},
  pages = {83--104},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  doi = {10.1109/mcs.2009.932223},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Evensen_2009_The ensemble Kalman filter for combined state and parameter estimation.pdf}
}

@article{Evinger_Eyelid_1991,
  title = {Eyelid Movements. {{Mechanisms}} and Normal Data.},
  author = {Evinger, Craig and Manning, Karen A and Sibony, Patrick A},
  year = {1991},
  volume = {32},
  number = {2},
  pages = {387--400},
  abstract = {Abstract This study provides a comprehensive description of upper eyelid movement in normal human subjects. Using the magnetic search coil technique to monitor lid position and modified skin electrodes to record orbicularis oculi electromyographic (EMG) activity, the ...},
  pmid = {1993591}
}

@techreport{Fabio2001tr,
  title = {From Point Cloud to Surface: The Modeling and Visualisation Problem},
  author = {Fabio, R},
  year = {2001},
  institution = {{XXXIV-5/W10-2001International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences--vol}},
  file = {/Users/driscoll/Dropbox/library/Report/Fabio_2001_From point cloud to surface.pdf}
}

@inproceedings{Fabjawska2012,
  title = {Normalized Cuts and Watersheds for Image Segmentation},
  booktitle = {{{IET}} Conference on Image Processing ({{IPR}} 2012)},
  author = {Fabjawska, A.},
  year = {2012},
  publisher = {{IET}},
  doi = {10.1049/cp.2012.0440},
  abstract = {We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Fabjawska_2012_Normalized cuts and watersheds for image segmentation.pdf}
}

@misc{FaroughiPhysicsGuidedPhysicsInformed2023,
  title = {Physics-{{Guided}}, {{Physics-Informed}}, and {{Physics-Encoded Neural Networks}} in {{Scientific Computing}}},
  author = {Faroughi, Salah A. and Pawar, Nikhil and Fernandes, Celio and Raissi, Maziar and Das, Subasish and Kalantari, Nima K. and Mahjour, Seyed Kourosh},
  year = {2023},
  month = feb,
  number = {arXiv:2211.07377},
  eprint = {2211.07377},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2211.07377},
  urldate = {2023-12-12},
  abstract = {Recent breakthroughs in computing power have made it feasible to use machine learning and deep learning to advance scientific computing in many fields, including fluid mechanics, solid mechanics, materials science, etc. Neural networks, in particular, play a central role in this hybridization. Due to their intrinsic architecture, conventional neural networks cannot be successfully trained and scoped when data is sparse, which is the case in many scientific and engineering domains. Nonetheless, neural networks provide a solid foundation to respect physics-driven or knowledge-based constraints during training. Generally speaking, there are three distinct neural network frameworks to enforce the underlying physics: (i) physics-guided neural networks (PgNNs), (ii) physics-informed neural networks (PiNNs), and (iii) physics-encoded neural networks (PeNNs). These methods provide distinct advantages for accelerating the numerical modeling of complex multiscale multi-physics phenomena. In addition, the recent developments in neural operators (NOs) add another dimension to these new simulation paradigms, especially when the real-time prediction of complex multi-physics systems is required. All these models also come with their own unique drawbacks and limitations that call for further fundamental research. This study aims to present a review of the four neural network frameworks (i.e., PgNNs, PiNNs, PeNNs, and NOs) used in scientific computing research. The state-of-the-art architectures and their applications are reviewed, limitations are discussed, and future research opportunities in terms of improving algorithms, considering causalities, expanding applications, and coupling scientific and deep learning solvers are presented. This critical review provides researchers and engineers with a solid starting point to comprehend how to integrate different layers of physics into neural networks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Faroughi et al_2023_Physics-Guided, Physics-Informed, and Physics-Encoded Neural Networks in.pdf;/Users/driscoll/Zotero/storage/XXDXPKZF/2211.html}
}

@article{FaselEnsembleSINDyRobust2022,
  title = {Ensemble-{{SINDy}}: {{Robust}} Sparse Model Discovery in the Low-Data, High-Noise Limit, with Active Learning and Control},
  shorttitle = {Ensemble-{{SINDy}}},
  author = {Fasel, U. and Kutz, J. N. and Brunton, B. W. and Brunton, S. L.},
  year = {2022},
  month = apr,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {478},
  number = {2260},
  pages = {20210904},
  issn = {1364-5021, 1471-2946},
  doi = {10.1098/rspa.2021.0904},
  urldate = {2023-11-02},
  abstract = {Sparse model identification enables the discovery of nonlinear dynamical systems purely from data; however, this approach is sensitive to noise, especially in the low-data limit. In this work, we leverage the statistical approach of bootstrap aggregating (bagging) to robustify the sparse identification of~the nonlinear dynamics (SINDy) algorithm. First, an ensemble of SINDy models is identified from subsets of limited and noisy data. The aggregate model statistics are then used to produce inclusion probabilities of the candidate functions, which enables uncertainty quantification and probabilistic forecasts. We apply this ensemble-SINDy (E-SINDy) algorithm to several synthetic and real-world datasets and demonstrate substantial improvements to the accuracy and robustness of model discovery from extremely noisy and limited data. For example, E-SINDy uncovers partial differential equations models from data with more than twice as much measurement noise as has been previously reported. Similarly, E-SINDy learns the Lotka Volterra dynamics from remarkably limited data of yearly lynx and hare pelts collected from 1900 to 1920. E-SINDy is computationally efficient, with similar scaling as standard SINDy. Finally, we show that ensemble statistics from E-SINDy can be exploited for active learning and improved model predictive control.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Fasel et al_2022_Ensemble-SINDy.pdf}
}

@article{FatoneFunaroManzini2019a,
  title = {A Semi-Lagrangian Spectral Method for the {{Vlasov}}--{{Poisson}} System Based on Fourier, Legendre and Hermite Polynomials},
  author = {Fatone, Lorella and Funaro, Daniele and Manzini, Gianmarco},
  year = {2019},
  volume = {1},
  pages = {333--360},
  issn = {2096-6385},
  doi = {10.1007/s42967-019-00027-8}
}

@book{FattPhysiologyEye2013,
  title = {Physiology of the {{Eye}}: {{An Introduction}} to the {{Vegetative Functions}}},
  author = {Fatt, Irving and Weissman, Barry A},
  year = {2013},
  edition = {2nd},
  publisher = {{Elsevier Science}},
  address = {{Burlington}},
  abstract = {Physiology of the Eye: An Introduction to the Vegetative Functions, Second Edition discusses the fundamental concept of the operating process of the visual system. The book is comprised 10 chapters that cover the functions and properties of the parts of the ocular system. The text first provides a review of ocular anatomy, and then proceeds to covering parts, including aqueous humor, vitreous body, and lens. The next two chapters deal with various concerns in cornea, such as swelling pressure and metabolism. Chapter 8 discusses the sclera, while Chapter 9 tackles the retina. The last chapter t ...},
  isbn = {978-0-7506-9085-0 978-1-4831-6369-7},
  langid = {english},
  annotation = {OCLC: 897026952},
  file = {/Users/driscoll/Dropbox/library/Book/Fatt_Weissman-2013-Physiology of the Eye An Introduction to the Vegetative Functions.pdf}
}

@article{felzenszwalbEfficientGraphbasedImage2004,
  title = {Efficient Graph-Based Image Segmentation},
  author = {Felzenszwalb, Pedro F. and Huttenlocher, Daniel P.},
  year = {2004},
  journal = {International Journal of Computer Vision},
  volume = {59},
  number = {2},
  pages = {167--181},
  doi = {10.1023/b:visi.0000022288.19776.77},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Felzenszwalb_Huttenlocher_2004_Efficient graph-based image segmentation.pdf}
}

@article{FilipRationalMinimax2018,
  title = {Rational {{Minimax Approximation}} via {{Adaptive Barycentric Representations}}},
  author = {Filip, Silviu-Ioan and Nakatsukasa, Yuji and Trefethen, Lloyd N. and Beckermann, Bernhard},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {40},
  number = {4},
  pages = {A2427-A2455},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/17M1132409},
  urldate = {2023-04-12},
  abstract = {We introduce a new algorithm for approximation by rational functions on a real or complex set of points, implementable in 40 lines of MATLAB and requiring no user input parameters.  Even on a disk or interval the algorithm may outperform existing methods, and on more complicated domains it is especially competitive.  The core ideas are (1) representation of the rational approximant in barycentric form with interpolation at certain support points and (2) greedy selection of the support points to avoid exponential instabilities.  The name AAA stands for ``adaptive Antoulas--Anderson'' in honor of the authors who introduced a scheme based on (1).  We present the core algorithm with a MATLAB code and nine applications and describe variants targeted at problems of different kinds. Comparisons are made with vector fitting, RKFIT, and other existing methods for rational approximation.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Filip et al_2018_Rational Minimax Approximation via Adaptive Barycentric Representations.pdf}
}

@inproceedings{Finnie-AnsleyRobotsAre2022,
  title = {The {{Robots Are Coming}}: {{Exploring}} the {{Implications}} of {{OpenAI Codex}} on {{Introductory Programming}}},
  shorttitle = {The {{Robots Are Coming}}},
  booktitle = {Proceedings of the 24th {{Australasian Computing Education Conference}}},
  author = {{Finnie-Ansley}, James and Denny, Paul and Becker, Brett A. and {Luxton-Reilly}, Andrew and Prather, James},
  year = {2022},
  month = feb,
  series = {{{ACE}} '22},
  pages = {10--19},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/3511861.3511863},
  urldate = {2023-09-26},
  abstract = {Recent advances in artificial intelligence have been driven by an exponential growth in digitised data. Natural language processing, in particular, has been transformed by machine learning models such as OpenAI's GPT-3 which generates human-like text so realistic that its developers have warned of the dangers of its misuse. In recent months OpenAI released Codex, a new deep learning model trained on Python code from more than 50 million GitHub repositories. Provided with a natural language description of a programming problem as input, Codex generates solution code as output. It can also explain (in English) input code, translate code between programming languages, and more. In this work, we explore how Codex performs on typical introductory programming problems. We report its performance on real questions taken from introductory programming exams and compare it to results from students who took these same exams under normal conditions, demonstrating that Codex outscores most students. We then explore how Codex handles subtle variations in problem wording using several published variants of the well-known ``Rainfall Problem'' along with one unpublished variant we have used in our teaching. We find the model passes many test cases for all variants. We also explore how much variation there is in the Codex generated solutions, observing that an identical input prompt frequently leads to very different solutions in terms of algorithmic approach and code length. Finally, we discuss the implications that such technology will have for computing education as it continues to evolve, including both challenges and opportunities.},
  isbn = {978-1-4503-9643-1},
  keywords = {academic integrity,AI,artificial intelligence,code generation,code writing,Codex,copilot,CS1,deep learning,GitHub,GPT-3,introductory programming,machine learning,neural networks,novice programming,OpenAI},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Finnie-Ansley et al_2022_The Robots Are Coming.pdf}
}

@article{floaterBarycentricRationalInterpolation2007,
  title = {Barycentric Rational Interpolation with No Poles and High Rates of Approximation},
  author = {Floater, Michael S. and Hormann, Kai},
  year = {2007},
  month = aug,
  journal = {Numerische Mathematik},
  volume = {107},
  number = {2},
  pages = {315--331},
  issn = {0945-3245},
  doi = {10.1007/s00211-007-0093-y},
  urldate = {2022-03-13},
  abstract = {It is well known that rational interpolation sometimes gives better approximations than polynomial interpolation, especially for large sequences of points, but it is difficult to control the occurrence of poles. In this paper we propose and study a family of barycentric rational interpolants that have no real poles and arbitrarily high approximation orders on any real interval, regardless of the distribution of the points. These interpolants depend linearly on the data and include a construction of Berrut as a special case.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Floater_Hormann_2007_Barycentric rational interpolation with no poles and high rates of approximation2.pdf;/Users/driscoll/Zotero/storage/9E4NXBEV/Floater and Hormann - 2007 - Barycentric rational interpolation with no poles a.pdf}
}

@article{flyerRolePolynomialsRBFFD2016,
  title = {On the Role of Polynomials in {{RBF-FD}} Approximations: {{I}}. {{Interpolation}} and Accuracy},
  shorttitle = {On the Role of Polynomials in {{RBF-FD}} Approximations},
  author = {Flyer, Natasha and Fornberg, Bengt and Bayona, Victor and Barnett, Gregory A.},
  year = {2016},
  month = sep,
  journal = {Journal of Computational Physics},
  volume = {321},
  pages = {21--38},
  issn = {00219991},
  doi = {10.1016/j.jcp.2016.05.026},
  urldate = {2022-08-01},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Flyer et al-2016-On the role of polynomials in RBF-FD approximations.pdf}
}

@incollection{foppaKermackMcKendrickSeminal2017,
  title = {4 - {{W}}.{{O}}. {{Kermack}} and {{A}}.{{G}}. {{McKendrick}}: {{A}} Seminal Contribution to the Mathematical Theory of Epidemics (1927)},
  shorttitle = {4 - {{W}}.{{O}}. {{Kermack}} and {{A}}.{{G}}. {{McKendrick}}},
  booktitle = {A {{Historical Introduction}} to {{Mathematical Modeling}} of {{Infectious Diseases}}},
  author = {Foppa, Ivo M.},
  editor = {Foppa, Ivo M.},
  year = {2017},
  month = jan,
  pages = {59--87},
  publisher = {{Academic Press}},
  address = {{Boston}},
  doi = {10.1016/B978-0-12-802260-3.00004-3},
  urldate = {2020-06-18},
  abstract = {Kermack and McKendrick's 1927 paper is considered one of the most influential papers of mathematical epidemiology, but the famous ``Kermack--McKendrick model'' is just a simplified special case of the more general model. They first introduce a general discrete-time difference equation model for a homogeneous population. They then modify this model to be adapted to continuous time. They comment on the unsolvability of this kind of model, but derive expressions for the proportion infected. The well-known special case of the model according to which all parameters are constant is discussed at the end of the paper and clearly, despite its fame, represents only a small fraction of the paper's achievements. The reader is guided through all relevant derivations and calculations.},
  isbn = {978-0-12-802260-3},
  langid = {english},
  keywords = {Continuous time,Discrete time,Mathematical model,Ordinary differential equation,Proportion infected},
  file = {/Users/driscoll/Zotero/storage/NSV69NLQ/B9780128022603000043.html}
}

@article{foracchiaLuminosityContrast2005,
  title = {Luminosity and Contrast Normalization in Retinal Images},
  author = {Foracchia, Marco and Grisan, Enrico and Ruggeri, Alfredo},
  year = {2005},
  month = jun,
  journal = {Medical Image Analysis},
  volume = {9},
  number = {3},
  pages = {179--190},
  issn = {1361-8415},
  doi = {10.1016/j.media.2004.07.001},
  urldate = {2020-10-15},
  abstract = {Retinal images are routinely acquired and assessed to provide diagnostic evidence for many important diseases, e.g. diabetes or hypertension. Because of the acquisition process, very often these images are non-uniformly illuminated and exhibit local luminosity and contrast variability. This problem may seriously affect the diagnostic process and its outcome, especially if an automatic computer-based procedure is used to derive diagnostic parameters. We propose here a new method to normalize luminosity and contrast in retinal images, both intra- and inter-image. The method is based on the estimation of the luminosity and contrast variability in the background part of the image and the subsequent compensation of this variability in the whole image. The application of this method on 33 fundus images showed an average 19\% (max. 45\%) reduction of luminosity variability and an average 34\% (max. 85\%) increment of image contrast, with a remarkable improvement, e.g., over low-pass correction. The proposed image normalization technique will definitely improve automatic fundus images analysis but will also be very useful to eye specialists in their visual examination of retinal images.},
  langid = {english},
  keywords = {Background correction,Low-pass correction,Luminosity,Normalization,Retinal imaging},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Foracchia_Grisan_Ruggeri-2005-Luminosity and contrast normalization in retinal images.pdf;/Users/driscoll/Zotero/storage/X9M9J6XN/S1361841504000556.html}
}

@article{formaggiaNumericalModeling1D2006,
  title = {Numerical Modeling of {{1D}} Arterial Networks Coupled with a Lumped Parameters Description of the Heart},
  author = {Formaggia, Luca and Lamponi, Daniele and Tuveri, Massimiliano and Veneziani, Alessandro},
  year = {2006},
  month = oct,
  journal = {Computer Methods in Biomechanics and Biomedical Engineering},
  volume = {9},
  number = {5},
  pages = {273--288},
  issn = {1025-5842},
  doi = {10.1080/10255840600857767},
  urldate = {2020-01-02},
  abstract = {The investigations on the pressure wave propagation along the arterial network and its relationships with vascular physiopathologies can be supported nowadays by numerical simulations. One dimensional (1D) mathematical models, based on systems of two partial differential equations for each arterial segment suitably matched at bifurcations, can be simulated with low computational costs and provide useful insights into the role of wave reflections. Some recent works have indeed moved in this direction. The specific contribution of the present paper is to illustrate a 1D numerical model numerically coupled with a model for the heart action. Typically, the action of the heart on the arterial system is modelled as a boundary condition at the entrance of the aorta. However, the left ventricle (LV) and the vascular network are a strongly coupled single mechanical system. This coupling can be relevant in the numerical description of pressure waves propagation, particularly when dealing with pathological situations. In this work, we propose a simple lumped parameter model for the heart and show how it can be coupled numerically with a 1D model for the arteries. Numerical results actually confirm the relevant impact of the heart-arteries coupling in realistic simulations.},
  pmid = {17132614},
  keywords = {1D,Cardiovascular network,Lumped parameter models,Numerical modeling},
  file = {/Users/driscoll/Dropbox/library/Computer Methods in Biomechanics and Biomedical Engineering/2006/Formaggia et al_2006_Numerical modeling of 1D arterial networks coupled with a lumped parameters.pdf;/Users/driscoll/Zotero/storage/99JJ2YYP/10255840600857767.html}
}

@article{Fornasiero_Post_2006,
  title = {Post-Lens Tear-Film Depletion Due to Evaporative Dehydration of a Soft Contact Lens},
  author = {Fornasiero, F and Prausnitz, J.M. and Radke, C.J.},
  year = {2006},
  volume = {275},
  number = {1-2},
  pages = {229--243},
  issn = {0376-7388},
  doi = {10.1016/j.memsci.2005.09.047},
  abstract = {For a soft-contact-lens (SCL) wearer, corneal health and comfort are strongly influenced by water transport through the polymeric materials used in lens fabrication. In particular, evaporative water loss at the anterior lens surface is a potential cause of contact-lens dehydration and of post-lens tear-film depletion, which in turn, may lead to discomfort, dryness syndrome, and/or lens adhesion.We present a solution--diffusion model for transport of water through soft-contact-lens materials to mimic evaporative dehydration from a contact lens during blinking and to access possible SCL adhesion to the corneal surface under a variety of environmental conditions (e.g., wind speed and relative humidity). To describe the water-transport process, we use an extended version of the Maxwell--Stefan multicomponent diffusion equation for species that differ starkly in size (i.e., water and the polymer matrix). To describe thermodynamic properties of the soft-contact-lens/water mixture, we use a modified Flory--Rehner theory for polymer solutions. The proposed transport model is applied to two typical SCL materials: a low-water-content (38wt.\%) polymacon SCL (SofLens{\textregistered} 38), and a high-water-content (70wt.\%) hilafilcon A SCL (SofLens™ One Day).We calculate that a SCL on the eye loses water within a few minutes from lens insertion until it reaches a periodic steady state, with an average water content a few percent lower than the initial saturated water content. When the external relative humidity is low and the wind speed is high, the periodic-steady net flux of water from the post-lens tear film (PoLTF) through the contact lens toward the environment is comparable to the supply of water to the PoLTF from the eye anterior chamber. Thus, PoLTF depletion may occur at these conditions, leading to undesired, reduced SCL on-eye movement or, perhaps, to SCL adhesion on the ocular surface. Also, our calculations show that, at the most dehydrating conditions, the high-water-content hilafilcon A lens is more prone to dehydration and PoLTF depletion than is the low-water-content polymacon lens with the same thickness. However, at the least dehydrating conditions this trend is reversed. Relative humidity, wind speed, and lens thickness significantly influence SCL dehydration.}
}

@book{Fornberg2015,
  title = {A Primer on Radial Basis Functions with Applications to the Geosciences},
  author = {Fornberg, Bengt and Flyer, Natasha},
  year = {2015},
  publisher = {{SIAM}}
}

@article{fornbergCambridgeMonographsApplied1996,
  title = {Cambridge Monographs on Applied and Computational Mathematics},
  author = {Fornberg, Bengt and Mansfield, Elizabeth Louise and Watanabe, Sumio and Brunner, Hermann and Dey, Tamal K and Hydon, Peter E and Stuart, Andrew and Humphries, {\relax AR} and {Ben-Artzi}, Matania and Falcovitz, Joseph and others},
  year = {1996},
  journal = {A practical guide to pseudospectral methods},
  keywords = {No DOI found}
}

@article{fornbergFastGeneration2D2015,
  title = {Fast Generation of 2-{{D}} Node Distributions for Mesh-Free {{PDE}} Discretizations},
  author = {Fornberg, Bengt and Flyer, Natasha},
  year = {2015},
  month = apr,
  journal = {Computers \& Mathematics with Applications},
  volume = {69},
  number = {7},
  pages = {531--544},
  issn = {0898-1221},
  doi = {10.1016/j.camwa.2015.01.009},
  urldate = {2022-07-27},
  abstract = {Many applications require that nodes be scattered locally quasi-uniformly within 2-D regions or on curved surfaces in 3-D space, while obeying some prescribed spatially varying density function. This study focuses on creating variable density node layouts that are suitable for mesh-free discretizations of PDEs. Another application is `dithering' to simulate half-tone images. The method is an `advancing-front type' scheme, inspired by the physical process of dropping of variable sized grains into a bucket.},
  langid = {english},
  keywords = {Mesh-free discretizations,Node/point generation algorithms,PDEs,RBF-FD},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Fornberg_Flyer-2015-Fast generation of 2-D node distributions for mesh-free PDE discretizations.pdf;/Users/driscoll/Zotero/storage/5CCCL3WE/S0898122115000334.html}
}

@article{FornbergFastSpectral1999,
  ids = {fornbergFastSpectralAlgorithm1999},
  title = {A Fast Spectral Algorithm for Nonlinear Wave Equations with Linear Dispersion},
  author = {Fornberg, Bengt and Driscoll, Tobin A},
  year = {1999},
  journal = {Journal of Computational Physics},
  volume = {155},
  number = {2},
  pages = {456--467},
  doi = {10.1006/jcph.1999.6351},
  copyright = {All rights reserved},
  keywords = {file-import-09-09-29}
}

@article{fornbergGenerationFiniteDifference1988,
  title = {Generation of Finite Difference Formulas on Arbitrarily Spaced Grids},
  author = {Fornberg, Bengt},
  year = {1988},
  journal = {Mathematics of Computation},
  volume = {51},
  number = {184},
  pages = {699--706},
  issn = {0025-5718, 1088-6842},
  doi = {10.1090/S0025-5718-1988-0935077-0},
  urldate = {2022-08-26},
  abstract = {Simple recursions are derived for calculating the weights in compact finite difference formulas for any order of derivative and to any order of accuracy on one-dimensional grids with arbitrary spacing. Tables are included for some special cases (of equispaced grids).},
  langid = {english},
  keywords = {Finite difference coefficients,high-order accuracy},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Fornberg-1988-Generation of finite difference formulas on arbitrarily spaced grids.pdf;/Users/driscoll/Zotero/storage/QHAIZN3Z/S0025-5718-1988-0935077-0.html}
}

@article{FornbergObservationsBehavior2002a,
  title = {Observations on the Behavior of Radial Basis Function Approximations near Boundaries},
  author = {Fornberg, Bengt and Driscoll, Tobin A and Wright, Grady and Charles, Richard},
  year = {2002},
  journal = {Computers \& Mathematics with Applications},
  volume = {43},
  number = {3-5},
  pages = {473--490},
  doi = {10.1016/s0898-1221(01)00299-1},
  copyright = {All rights reserved}
}

@book{fornbergPracticalGuidePseudospectral1998,
  title = {A {{Practical Guide}} to {{Pseudospectral Methods}}},
  author = {Fornberg, Bengt},
  year = {1998},
  month = oct,
  publisher = {{Cambridge University Press}},
  abstract = {During the past two decades, pseudospectral methods have emerged as successful, and often superior, alternatives to better known computational procedures, such as finite difference and finite element methods of numerical solution, in several key application areas. These areas include computational fluid dynamics, wave motion, and weather forecasting. This book explains how, when and why this pseudospectral approach works. In order to make the subject accessible to students as well as researchers and engineers, the author presents the subject using illustrations, examples, heuristic explanations, and algorithms rather than rigorous theoretical arguments. This book will be of interest to graduate students, scientists, and engineers interested in applying pseudospectral methods to real problems.},
  googlebooks = {IqJoihDba3gC},
  isbn = {978-0-521-64564-5},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis,Science / Mechanics / Fluids}
}

@article{fornbergSolvingPDEsRadial2015,
  title = {Solving {{PDEs}} with Radial Basis Functions},
  author = {Fornberg, Bengt and Flyer, Natasha},
  year = {2015},
  month = may,
  journal = {Acta Numerica},
  volume = {24},
  pages = {215--258},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492914000130},
  urldate = {2022-07-27},
  abstract = {Finite differences provided the first numerical approach that permitted large-scale simulations in many applications areas, such as geophysical fluid dynamics. As accuracy and integration time requirements gradually increased, the focus shifted from finite differences to a variety of different spectral methods. During the last few years, radial basis functions, in particular in their `local' RBF-FD form, have taken the major step from being mostly a curiosity approach for small-scale PDE `toy problems' to becoming a major contender also for very large simulations on advanced distributed memory computer systems. Being entirely mesh-free, RBF-FD discretizations are also particularly easy to implement, even when local refinements are needed. This article gives some background to this development, and highlights some recent results.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Fornberg_Flyer-2015-Solving PDEs with radial basis functions.pdf}
}

@article{fornbergStableCalculationGaussianbased2013,
  title = {Stable Calculation of {{Gaussian-based RBF-FD}} Stencils},
  author = {Fornberg, Bengt and Lehto, Erik and Powell, Collin},
  year = {2013},
  month = feb,
  journal = {Computers \& Mathematics with Applications},
  volume = {65},
  number = {4},
  pages = {627--637},
  issn = {0898-1221},
  doi = {10.1016/j.camwa.2012.11.006},
  urldate = {2022-07-25},
  abstract = {Traditional finite difference (FD) methods are designed to be exact for low degree polynomials. They can be highly effective on Cartesian-type grids, but may fail for unstructured node layouts. Radial basis function-generated finite difference (RBF-FD) methods overcome this problem and, as a result, provide a much improved geometric flexibility. The calculation of RBF-FD weights involves a shape parameter {$\varepsilon$}. Small values of {$\varepsilon~$}(corresponding to near-flat RBFs) often lead to particularly accurate RBF-FD formulas. However, the most straightforward way to calculate the weights (RBF-Direct) becomes then numerically highly ill-conditioned. In contrast, the present algorithm remains numerically stable all the way into the {$\varepsilon\rightarrow$}0 limit. Like the RBF-QR algorithm, it uses the idea of finding a numerically well-conditioned basis function set in the same function space as is spanned by the ill-conditioned near-flat original Gaussian RBFs. By exploiting some properties of the incomplete gamma function, it transpires that the change of basis can be achieved without dealing with any infinite expansions. Its strengths and weaknesses compared with the Contour-Pad{\'e}, RBF-RA,~and RBF-QR algorithms are discussed.},
  langid = {english},
  keywords = {Gaussians,Ill-conditioning,Radial basis functions,RBF,RBF-FD,RBF-GA},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Fornberg et al-2013-Stable calculation of Gaussian-based RBF-FD stencils.pdf;/Users/driscoll/Zotero/storage/P5YV39TJ/S0898122112006529.html}
}

@article{fornbergStableComputationsGaussian2011,
  title = {Stable {{Computations}} with {{Gaussian Radial Basis Functions}}},
  author = {Fornberg, Bengt and Larsson, Elisabeth and Flyer, Natasha},
  year = {2011},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {33},
  number = {2},
  pages = {869--892},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/09076756X},
  urldate = {2022-07-26},
  abstract = {Radial basis function (RBF) approximation is an extremely powerful tool for representing smooth functions in nontrivial geometries since the method is mesh-free and can be spectrally accurate. A perceived practical obstacle is that the interpolation matrix becomes increasingly ill-conditioned as the RBF shape parameter becomes small, corresponding to flat RBFs. Two stable approaches that overcome this problem exist: the Contour-Pad{\'e} method and the RBF-QR method. However, the former is limited to small node sets, and the latter has until now been formulated only for the surface of the sphere. This paper focuses on an RBF-QR formulation for node sets in one, two, and three dimensions. The algorithm is stable for arbitrarily small shape parameters. It can be used for thousands of node points in two dimensions and still more in three dimensions. A sample MATLAB code for the two-dimensional case is provided.},
  keywords = {65D05,65D15,65F35,ill-conditioning,radial basis function,shape parameter,stable},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Fornberg et al_2011_Stable Computations with Gaussian Radial Basis Functions.pdf}
}

@article{Fox1962,
  title = {Chebyshev Methods for Ordinary Differential Equations},
  author = {Fox, L.},
  year = {1962},
  month = apr,
  journal = {The Computer Journal},
  volume = {4},
  number = {4},
  pages = {318--331},
  publisher = {{Oxford University Press (OUP)}},
  doi = {10.1093/comjnl/4.4.318},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Fox_1962_Chebyshev methods for ordinary differential equations.pdf}
}

@article{Fran,
  title = {Ocular Surface Epithelial Thickness Evaluation with Spectra Domain Optical Coherence Tomography},
  author = {{Francoz} and M., Karamoko, Baudouin, C., I. and Labbe, A.},
  year = {2011},
  month = nov,
  journal = {Investigative Opthalmology and Visual Science},
  volume = {52},
  number = {12},
  pages = {9116--123},
  keywords = {No DOI found}
}

@article{Freeman2014,
  title = {Active Learning Increases Student Performance in Science, Engineering, and Mathematics},
  author = {Freeman, S. and Eddy, S. L. and McDonough, M. and Smith, M. K. and Okoroafor, N. and Jordt, H. and Wenderoth, M. P.},
  year = {2014},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {111},
  number = {23},
  pages = {8410--8415},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1319030111},
  keywords = {teaching},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Freeman et al_2014_Active learning increases student performance in science, engineering, and.pdf}
}

@article{gaierCapacitanceConformalModule1979,
  title = {Capacitance and the Conformal Module of Quadrilaterals},
  author = {Gaier, D},
  year = {1979},
  month = jul,
  journal = {Journal of Mathematical Analysis and Applications},
  volume = {70},
  number = {1},
  pages = {236--239},
  issn = {0022-247X},
  doi = {10.1016/0022-247x(79)90086-6},
  urldate = {2019-11-18},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gaier_1979_Capacitance and the conformal module of quadrilaterals.pdf;/Users/driscoll/Zotero/storage/CS8D7EFB/0022247X79900866.html}
}

@article{Gander2000,
  title = {Adaptive Quadrature---Revisited},
  author = {Gander, Walter and Gautschi, Walter},
  year = {2000},
  journal = {BIT. Numerical Mathematics},
  volume = {40},
  number = {1},
  pages = {84--101},
  issn = {0006-3835},
  doi = {10.1023/a:1022318402393},
  mrnumber = {1759036},
  keywords = {65D30},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gander_Gautschi_2000_Adaptive quadrature—revisited.pdf}
}

@article{GaoPhyGeoNetPhysicsinformed2021,
  title = {{{PhyGeoNet}}: {{Physics-informed}} Geometry-Adaptive Convolutional Neural Networks for Solving Parameterized Steady-State {{PDEs}} on Irregular Domain},
  shorttitle = {{{PhyGeoNet}}},
  author = {Gao, Han and Sun, Luning and Wang, Jian-Xun},
  year = {2021},
  month = mar,
  journal = {Journal of Computational Physics},
  volume = {428},
  pages = {110079},
  issn = {00219991},
  doi = {10.1016/j.jcp.2020.110079},
  urldate = {2023-11-02},
  abstract = {Semantic Scholar extracted view of "PhyGeoNet: Physics-informed geometry-adaptive convolutional neural networks for solving parameterized steady-state PDEs on irregular domain" by Han Gao et al.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gao et al_2021_PhyGeoNet.pdf}
}

@article{Gerstner1998,
  title = {Numerical Algorithms},
  author = {Gerstner, Thomas and Griebel, Michael},
  year = {1998},
  journal = {Numerical Algorithms},
  volume = {18},
  number = {3/4},
  pages = {209--232},
  publisher = {{Springer Nature}},
  doi = {10.1023/a:1019129717644},
  keywords = {complexity,curse of dimension,multivariate numerical quadrature,Smolyak's construction,sparse grids},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gerstner_Griebel_1998_Numerical algorithms.pdf}
}

@article{Ghili2017,
  title = {Least Squares Approximation of Polynomial Chaos Expansions with Optimized Grid Points},
  author = {Ghili, Saman and Iaccarino, Gianluca},
  year = {2017},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {39},
  number = {5},
  pages = {A1991-A2019},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/15m1028303},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Ghili_Iaccarino_2017_Least squares approximation of polynomial chaos expansions with optimized grid.pdf}
}

@article{GhristStaggeredTime2000,
  title = {Staggered Time Integrators for Wave Equations},
  author = {Ghrist, Michelle and Fornberg, Bengt and Driscoll, Tobin A},
  year = {2000},
  journal = {SIAM Journal on Numerical Analysis},
  volume = {38},
  number = {3},
  pages = {718--741},
  doi = {10.1137/s0036142999351777},
  copyright = {All rights reserved},
  keywords = {file-import-09-09-29}
}

@article{GilbardOsmolarityTear1978,
  title = {Osmolarity of {{Tear Microvolumes}} in {{Keratoconjunctivitis Sicca}}},
  author = {Gilbard, Jeffrey P. and Farris, R. Linsy and Santamaria, II, Jaime},
  year = {1978},
  month = apr,
  journal = {Archives of Ophthalmology},
  volume = {96},
  number = {4},
  pages = {677--681},
  issn = {0003-9950},
  doi = {10.1001/archopht.1978.03910050373015},
  urldate = {2023-02-13},
  abstract = {{$\bullet$} Determinations of tear film osmolarity were performed to evaluate their usefulness in diagnosing keratoconjunctivitis sicca (KCS) and to evaluate the possible role of elevated tear osmolarity in this disorder's pathogenesis. Tear samples were obtained using a new technique that virtually eliminates the problems of reflex tearing and sample evaporation. The tear osmolarity of 36 samples obtained from 31 normal eyes averaged 302 {\textpm} 6.3 (SD) mOsm/liter; 38 samples obtained from 30 KCS eyes averaged 343 {\textpm} 32.3 (SD) mOsm/liter. The sensitivity of a single measurement was 94.7\% and the specificity was 93.7\%. Tear samples taken on separate occasions from one normal subject ranged between 295 and 309 mOsm/liter; those obtained from a KCS patient ranged between 312 and 424 mOsm/liter. Hyperosmolarity of the tear film in KCS may play an important role in inducing the disease seen in the cornea and conjunctiva.},
  file = {/Users/driscoll/Zotero/storage/UQ4R7M3M/632566.html}
}

@article{gillisWhyHowNonnegative2014,
  title = {The {{Why}} and {{How}} of {{Nonnegative Matrix Factorization}}},
  author = {Gillis, Nicolas},
  year = {2014},
  month = jan,
  journal = {arXiv:1401.5226 [cs, math, stat]},
  eprint = {1401.5226},
  primaryclass = {cs, math, stat},
  urldate = {2019-03-18},
  abstract = {Nonnegative matrix factorization (NMF) has become a widely used tool for the analysis of high-dimensional data as it automatically extracts sparse and meaningful features from a set of nonnegative data vectors. We first illustrate this property of NMF on three applications, in image processing, text mining and hyperspectral imaging --this is the why. Then we address the problem of solving NMF, which is NP-hard in general. We review some standard NMF algorithms, and also present a recent subclass of NMF problems, referred to as near-separable NMF, that can be solved efficiently (that is, in polynomial time), even in the presence of noise --this is the how. Finally, we briefly describe some problems in mathematics and computer science closely related to NMF via the nonnegative rank.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning,Mathematics - Optimization and Control,No DOI found,Statistics - Machine Learning},
  file = {/Users/driscoll/Zotero/storage/S2GRQSLF/Gillis - 2014 - The Why and How of Nonnegative Matrix Factorizatio.pdf;/Users/driscoll/Zotero/storage/XJ62F4NM/1401.html}
}

@article{Gillman2014,
  title = {A Direct Solver with {{O}}({{N}}) Complexity for Variable Coefficient Elliptic {{PDEs}} Discretized via a High-Order Composite Spectral Collocation Method},
  author = {Gillman, A. and Martinsson, P. G.},
  year = {2014},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {36},
  number = {4},
  pages = {A2023-A2046},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/130918988},
  abstract = {A numerical method for solving elliptic PDEs with variable co- efficients on two-dimensional domains is presented. The method is based on high-order composite spectral approximations and is designed for problems with smooth solutions. The resulting system of linear equations is solved using a direct (as opposed to iterative) solver that has optimal O(N) complexity for all stages of the computation when applied to problems with non-oscillatory solutions such as the Laplace and the Stokes equations. Numerical examples demonstrate that the scheme is capable of computing solutions with relative accuracy of 10-10 or bet- ter, even for challenging problems such as highly oscillatory Helmholtz problems and convection-dominated convection diffusion equations. In terms of speed, it is demonstrated that a problem with a non-oscillatory solution that was discretized using 108 nodes was solved in 115 minutes on a personal work-station with two quad-core 3.3GHz CPUs. Since the solver is direct, and the ``solution operator'' fits in RAM, any solves beyond the first are very fast. In the example with 108}
}

@inproceedings{girshickFastRCNN2015,
  title = {Fast {{R-CNN}}},
  booktitle = {2015 {{IEEE International Conference}} on {{Computer Vision}} ({{ICCV}})},
  author = {Girshick, Ross},
  year = {2015},
  month = dec,
  pages = {1440--1448},
  issn = {2380-7504},
  doi = {10.1109/iccv.2015.169},
  abstract = {This paper proposes a Fast Region-based Convolutional Network method (Fast R-CNN) for object detection. Fast R-CNN builds on previous work to efficiently classify object proposals using deep convolutional networks. Compared to previous work, Fast R-CNN employs several innovations to improve training and testing speed while also increasing detection accuracy. Fast R-CNN trains the very deep VGG16 network 9x faster than R-CNN, is 213x faster at test-time, and achieves a higher mAP on PASCAL VOC 2012. Compared to SPPnet, Fast R-CNN trains VGG16 3x faster, tests 10x faster, and is more accurate. Fast R-CNN is implemented in Python and C++ (using Caffe) and is available under the open-source MIT License at https://github.com/rbgirshick/fast-rcnn.},
  keywords = {C++,Caffe,Computer architecture,fast R-CNN,fast region-based convolutional network method,Feature extraction,feedforward neural nets,object detection,Object detection,Open source software,open-source MIT License,Pipelines,Proposals,Python,Training,VGG16 network},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Girshick_2015_Fast R-CNN.pdf;/Users/driscoll/Zotero/storage/973L4Y8L/7410526.html}
}

@article{GirvanCommunityStructure2002,
  title = {Community Structure in Social and Biological Networks},
  author = {Girvan, M. and Newman, M. E. J.},
  year = {2002},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {99},
  number = {12},
  pages = {7821--7826},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.122653799},
  urldate = {2023-05-02},
  abstract = {A number of recent studies have focused on the statistical properties of networked systems such as social networks and the Worldwide Web. Researchers have concentrated particularly on a few properties that seem to be common to many networks: the small-world property, power-law degree distributions, and network transitivity. In this article, we highlight another property that is found in many networks, the property of community structure, in which network nodes are joined together in tightly knit groups, between which there are only looser connections. We propose a method for detecting such communities, built around the idea of using centrality indices to find community boundaries. We test our method on computer-generated and real-world graphs whose community structure is already known and find that the method detects this known structure with high sensitivity and reliability. We also apply the method to two networks whose community structure is not well known---a collaboration network and a food web---and find that it detects significant and informative community divisions in both cases.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Girvan_Newman_2002_Community structure in social and biological networks.pdf}
}

@article{GoanoGeneralConformalmapping2001,
  ids = {goanoGeneralConformalmappingApproach2001},
  title = {A General Conformal-Mapping Approach to the Optimum Electrode Design of Coplanar Waveguides with Arbitrary Cross Section},
  author = {Goano, Michele and Bertazzi, Francesco and Caravelli, Paolo and Ghione, Giovanni and Driscoll, Tobin A},
  year = {2001},
  journal = {IEEE Transactions on Microwave Theory and Techniques},
  volume = {49},
  number = {9},
  pages = {1573--1580},
  doi = {10.1109/22.942569},
  copyright = {All rights reserved}
}

@article{Goel_Aqueous_2010,
  title = {Aqueous Humor Dynamics: A Review.},
  author = {Goel, Manik and Picciani, Renata G and Lee, Richard K and Bhattacharya, Sanjoy K},
  year = {2010},
  volume = {4},
  number = {1},
  pages = {52--9},
  issn = {1874-3641},
  doi = {10.2174/1874364101004010052},
  abstract = {Glaucoma is a family of optic neuropathies which cause irreversible but potentially preventable vision loss. Vision loss in most forms of glaucoma is related to elevated IOP with subsequent injury to the optic nerve. Secretion of aqueous humor and regulation of its outflow are physiologically important processes for maintaining IOP in the normal range. Thus, understanding the complex mechanisms that regulate aqueous humor circulation is essential for management of glaucoma. The two main structures related to aqueous humor dynamics are the ciliary body and the trabecular meshwork (TM). Three mechanisms are involved in aqueous humor formation: diffusion, ultrafiltration and active secretion. Active secretion is the major contributor to aqueous humor formation. The aqueous humor flow in humans follows a circadian rhythm, being higher in the morning than at night. The aqueous humor leaves the eye by passive flow via two pathways - the trabecular meshwork and the uveoscleral pathway. In humans, 75\% of the resistance to aqueous humor outflow is localized within the TM with the juxtacanalicular portion of the TM being the main site of outflow resistance. Glycosaminoglycan deposition in the TM extracellular matrix (ECM) has been suggested to be responsible for increased outflow resistance at this specific site whereas others have suggested deposition of proteins, such as cochlin, obstruct the aqueous humor outflow through the TM. The uveoscleral outflow pathway is relatively independent of the intraocular pressure and the proportion of aqueous humor exiting the eye via the uveoscleral pathway decreases with age.},
  pmcid = {PMC3032230},
  pmid = {21293732}
}

@article{GoldingBruce97,
  title = {Relationship between Tear-Meniscus Parameters and Tear-Film Breakup},
  author = {Golding, T. R. and Bruce, A. S. and Mainstone, J. C.},
  year = {1997},
  journal = {Cornea},
  volume = {16},
  pages = {649--661},
  doi = {10.1097/00003226-199711000-00009}
}

@article{Golub1969,
  title = {Calculation of {{Gauss}} Quadrature Rules},
  author = {Golub, Gene H. and Welsch, John H.},
  year = {1969},
  month = may,
  journal = {Mathematics of Computation},
  volume = {23},
  number = {106},
  pages = {221--221},
  publisher = {{American Mathematical Society (AMS)}},
  doi = {10.1090/s0025-5718-69-99647-1},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Golub_Welsch_1969_Calculation of Gauss quadrature rules.pdf}
}

@article{Golub1973,
  title = {The Differentiation of Pseudo-Inverses and Nonlinear Least Squares Problems Whose Variables Separate},
  author = {Golub, G. H. and Pereyra, V.},
  year = {1973},
  month = apr,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {10},
  number = {2},
  pages = {413--432},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/0710036},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Golub_Pereyra_1973_The differentiation of pseudo-inverses and nonlinear least squares problems.pdf}
}

@article{Golub2003,
  title = {Separable Nonlinear Least Squares: The Variable Projection Method and Its Applications},
  author = {Golub, Gene and Pereyra, Victor},
  year = {2003},
  month = feb,
  journal = {Inverse Problems},
  volume = {19},
  number = {2},
  pages = {R1-R26},
  publisher = {{IOP Publishing}},
  doi = {10.1088/0266-5611/19/2/201},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Golub_Pereyra_2003_Separable nonlinear least squares.pdf}
}

@article{golubHistoryConjugateGradient1989,
  title = {Some {{History}} of the {{Conjugate Gradient}} and {{Lanczos Algorithms}}: 1948--1976},
  shorttitle = {Some {{History}} of the {{Conjugate Gradient}} and {{Lanczos Algorithms}}},
  author = {Golub, Gene H. and O'Leary, Dianne P.},
  year = {1989},
  month = mar,
  journal = {SIAM Review},
  volume = {31},
  number = {1},
  pages = {50--102},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/1031003},
  urldate = {2020-06-18},
  abstract = {This paper gives some of the history of the conjugate gradient and Lanczos algorithms and an annotated bibliography for the period 1948-1976},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Golub_O’Leary-1989-Some History of the Conjugate Gradient and Lanczos.pdf;/Users/driscoll/Zotero/storage/2W2ID99U/1031003.html}
}

@book{golubMatrixComputations1996,
  title = {Matrix {{Computations}}},
  author = {Golub, Gene H. and Van Loan, Charles F.},
  year = {1996},
  month = oct,
  edition = {3rd},
  publisher = {{JHU Press}},
  abstract = {Revised and updated, the third edition of Golub and Van Loan's classic text in computer science provides essential information about the mathematical background and algorithmic skills required for the production of numerical software. This new edition includes thoroughly revised chapters on matrix multiplication problems and parallel matrix computations, expanded treatment of CS decomposition, an updated overview of floating point arithmetic, a more accurate rendition of the modified Gram-Schmidt process, and new material devoted to GMRES, QMR, and other methods designed to handle the sparse unsymmetric linear system problem.},
  googlebooks = {mlOa7wPX6OYC},
  isbn = {978-0-8018-5414-9},
  langid = {english},
  keywords = {Mathematics / Algebra / Linear,Mathematics / Applied}
}

@article{GopalNewLaplace2019,
  title = {New {{Laplace}} and {{Helmholtz}} Solvers},
  author = {Gopal, Abinand and Trefethen, Lloyd N.},
  year = {2019},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {21},
  pages = {10223--10225},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1904139116},
  urldate = {2023-06-14},
  abstract = {Numerical algorithms based on rational functions are introduced that solve the Laplace and Helmholtz equations on 2D domains with corners quickly and accurately, despite the corner singularities.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gopal_Trefethen_2019_New Laplace and Helmholtz solvers.pdf}
}

@article{GopalRepresentationConformal2019,
  title = {Representation of Conformal Maps by Rational Functions},
  author = {Gopal, Abinand and Trefethen, Lloyd N.},
  year = {2019},
  month = jun,
  journal = {Numerische Mathematik},
  volume = {142},
  number = {2},
  pages = {359--382},
  issn = {0945-3245},
  doi = {10.1007/s00211-019-01023-z},
  urldate = {2023-04-12},
  abstract = {The traditional view in numerical conformal mapping is that once the boundary correspondence function has been found, the map and its inverse can be evaluated by contour integrals. We propose that it is much simpler, and 10--1000 times faster, to represent the maps by rational functions computed by the AAA algorithm. To justify this claim, first we prove a theorem establishing root-exponential convergence of rational approximations near corners in a conformal map, generalizing a result of D. J. Newman in 1964. This leads to the new algorithm for approximating conformal maps of polygons. Then we turn to smooth domains and prove a sequence of four theorems establishing that in any conformal map of the unit circle onto a region with a long and slender part, there must be a singularity or loss of univalence exponentially close to the boundary, and polynomial approximations cannot be accurate unless of exponentially high degree. This motivates the application of the new algorithm to smooth domains, where it is again found to be highly effective.},
  langid = {english},
  keywords = {30C30,41A20,65E05},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gopal_Trefethen_2019_Representation of conformal maps by rational functions.pdf}
}

@article{GopalSolvingLaplace2019,
  title = {Solving {{Laplace Problems}} with {{Corner Singularities}} via {{Rational Functions}}},
  author = {Gopal, Abinand and Trefethen, Lloyd N.},
  year = {2019},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {57},
  number = {5},
  pages = {2074--2094},
  issn = {0036-1429, 1095-7170},
  doi = {10.1137/19m125947x},
  urldate = {2019-11-01},
  abstract = {A new method is introduced for solving Laplace problems on two-dimensional regions with corners by approximation of boundary data by the real part of a rational function with fixed poles exponentially clustered near each corner. Greatly extending a result of D. J. Newman in 1964 in approximation theory, we first prove that such approximations can achieve root-exponential convergence for a wide range of problems, all the way up to the corner singularities. We then develop a numerical method to compute approximations via linear least-squares fitting on the boundary. Typical problems are solved in {$<$} 1s on a desktop to 8-digit accuracy, with the accuracy guaranteed in the interior by the maximum principle. The computed solution is represented globally by a single formula, which can be evaluated in a few microseconds at each point.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gopal_Trefethen_2019_Solving Laplace Problems with Corner Singularities via Rational Functions2.pdf}
}

@article{GoseaAlgorithmsRational2021,
  title = {Algorithms for the {{Rational Approximation}} of {{Matrix-Valued Functions}}},
  author = {Gosea, Ion Victor and G{\"u}ttel, Stefan},
  year = {2021},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {43},
  number = {5},
  pages = {A3033-A3054},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/20M1324727},
  urldate = {2023-04-12},
  abstract = {We introduce a new algorithm for approximation by rational functions on a real or complex set of points, implementable in 40 lines of MATLAB and requiring no user input parameters.  Even on a disk or interval the algorithm may outperform existing methods, and on more complicated domains it is especially competitive.  The core ideas are (1) representation of the rational approximant in barycentric form with interpolation at certain support points and (2) greedy selection of the support points to avoid exponential instabilities.  The name AAA stands for ``adaptive Antoulas--Anderson'' in honor of the authors who introduced a scheme based on (1).  We present the core algorithm with a MATLAB code and nine applications and describe variants targeted at problems of different kinds. Comparisons are made with vector fitting, RKFIT, and other existing methods for rational approximation.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gosea_Güttel_2021_Algorithms for the Rational Approximation of Matrix-Valued Functions.pdf}
}

@article{Grasedyck2003,
  title = {Construction and Arithmetics of {{H}} -{{Matrices}}},
  author = {Grasedyck, Lars and Hackbusch, Wolfgang},
  year = {2003},
  month = aug,
  journal = {Computing},
  volume = {70},
  number = {4},
  pages = {295--334},
  publisher = {{Springer Nature}},
  doi = {10.1007/s00607-003-0019-1},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Grasedyck_Hackbusch_2003_Construction and arithmetics of H -Matrices.pdf}
}

@misc{grasedyckLiteratureSurveyLowrank2013,
  title = {A Literature Survey of Low-Rank Tensor Approximation Techniques},
  author = {Grasedyck, Lars and Kressner, Daniel and Tobler, Christine},
  year = {2013},
  month = feb,
  number = {arXiv:1302.7121},
  eprint = {1302.7121},
  primaryclass = {quant-ph},
  publisher = {{arXiv}},
  urldate = {2022-06-13},
  abstract = {During the last years, low-rank tensor approximation has been established as a new tool in scientific computing to address large-scale linear and multilinear algebra problems, which would be intractable by classical techniques. This survey attempts to give a literature overview of current developments in this area, with an emphasis on function-related tensors.},
  archiveprefix = {arxiv},
  keywords = {15A69 (Primary) 65F10 65F15 (Secondary),Mathematics - Numerical Analysis,Quantum Physics},
  file = {/Users/driscoll/Dropbox/library/Preprint/Grasedyck et al-2013-A literature survey of low-rank tensor approximation techniques.pdf;/Users/driscoll/Zotero/storage/VIPDXGZM/1302.html}
}

@article{Grcar2011,
  title = {John von Neumanns Analysis of Gaussian Elimination and the Origins of Modern Numerical Analysis},
  author = {Grcar, Joseph F.},
  year = {2011},
  month = jan,
  journal = {SIAM Review},
  volume = {53},
  number = {4},
  pages = {607--682},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/080734716}
}

@article{GrcarMathematicsTurned2010,
  title = {Mathematics Turned inside out: The Intensive Faculty versus the Extensive Faculty},
  author = {Grcar, Joseph F.},
  year = {2010},
  month = aug,
  journal = {Higher Education},
  volume = {61},
  number = {6},
  pages = {693--720},
  publisher = {{Springer Nature}},
  doi = {10.1007/s10734-010-9358-y},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Grcar_2010_Mathematics turned inside out.pdf}
}

@article{greengardPotentialFlowChannels1990,
  title = {Potential {{Flow}} in {{Channels}}},
  author = {Greengard, L.},
  year = {1990},
  month = jul,
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume = {11},
  number = {4},
  pages = {603--620},
  issn = {0196-5204},
  doi = {10.1137/0911035},
  urldate = {2019-11-18},
  abstract = {A method is presented for calculating potential flows in infinite channels. Given a collection of N sources in the channel and a zero normal flow boundary condition, the method requires an amount  of work proportional to N to evaluate the induced velocity field at each source position. It is accurate to within machine precision and for its performance does not depend on the distribution of the sources. Like the Fast Multipole Method developed by Greengard and Rokhlin [J. Comput. Phys., 73 (1987), pp. 325--348], it is based on a recursive subdivision of space, knowledge of the governing Green's function, and the use of asymptotic representations of the potential field. Previous schemes have been based either on conformal mapping, which experiences numerical difficulties with the domain boundary, or direct evaluation of Green's function. Both require \$O(N\^{}2 )\$ work.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Greengard_1990_Potential Flow in Channels.pdf;/Users/driscoll/Zotero/storage/MYKQLA7N/0911035.html}
}

@article{Greer2006216,
  title = {Fourth Order Partial Differential Equations on General Geometries},
  author = {Greer, J. B. and Bertozzi, A. L. and Sapiro, G.},
  year = {2006},
  journal = {Journal of Computational Physics},
  volume = {216},
  number = {1},
  pages = {216--246},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2005.11.031}
}

@inproceedings{Gressa,
  title = {Efficient Representation and Extraction of 2-Manifold Isosurfaces Using Kd-Trees},
  booktitle = {11th Pacific Conference {{onComputer}} Graphics and Applications, 2003. Proceedings.},
  author = {Gress, A. and Klein, R.},
  publisher = {{IEEE Comput. Soc}},
  doi = {10.1109/pccga.2003.1238278},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Gress_Klein_Efficient representation and extraction of 2-manifold isosurfaces using kd-trees.pdf}
}

@article{groverNode2vecScalableFeature2016,
  title = {Node2vec: {{Scalable Feature Learning}} for {{Networks}}},
  shorttitle = {Node2vec},
  author = {Grover, Aditya and Leskovec, Jure},
  year = {2016},
  month = jul,
  journal = {arXiv:1607.00653 [cs, stat]},
  eprint = {1607.00653},
  primaryclass = {cs, stat},
  urldate = {2022-04-28},
  abstract = {Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks,No DOI found,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Grover_Leskovec-2016-node2vec.pdf;/Users/driscoll/Zotero/storage/4U6IPQ59/1607.html}
}

@article{GuDeepNeural2023,
  title = {Deep {{Neural Networks}} for {{Solving Large Linear Systems Arising}} from {{High-Dimensional Problems}}},
  author = {Gu, Yiqi and Ng, Michael K.},
  year = {2023},
  month = oct,
  journal = {SIAM Journal on Scientific Computing},
  volume = {45},
  number = {5},
  pages = {A2356-A2381},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/22M1488132},
  urldate = {2024-02-21},
  abstract = {.In this paper, based on the physics-informed neural networks (PINNs) framework, a meshfree method using the deep neural network approach is developed for solving two kinds of two-phase interface problems governed by different dynamic partial differential equations on either side of the stationary interface with the jump and high-contrast coefficients. The first type of two-phase interface problem is the fluid-fluid (two-phase flow) interface problem modeled by Navier--Stokes equations with high-contrast physical parameters across the interface. The second one is the fluid-structure interaction problem modeled by Navier--Stokes equations on one side of the interface and the structural equation on the other side, where the fluid and the structure interact with each other via the kinematic and dynamic interface conditions across the interface. Following the PINNs framework, the DNN/meshfree method is respectively developed for two kinds of two-phase interface problems by approximating the solutions using different DNN's structures in different subdomains and reformulating the interface problems as least-squares minimization problems based on a space-time sampling-point set (as the training dataset). Mathematically, the approximation error analyses are carried out for both interface problems, revealing an intrinsic strategy for efficiently sampling points to improve the accuracy. In addition, compared with traditional discretization approaches (e.g., finite element/volume/difference methods), the proposed DNN/meshfree method and its error analysis technique can be smoothly extended to many other dynamic interface problems with stationary interfaces. Numerical experiments illustrate the accuracy of the proposed method for the presented two-phase interface problems and validate theoretical results to some extent through two numerical examples.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gu_Ng_2023_Deep Neural Networks for Solving Large Linear Systems Arising from.pdf}
}

@article{guidoboniCardiovascularFunctionBallistocardiogram2019,
  title = {Cardiovascular {{Function}} and {{Ballistocardiogram}}: {{A Relationship Interpreted}} via {{Mathematical Modeling}}},
  shorttitle = {Cardiovascular {{Function}} and {{Ballistocardiogram}}},
  author = {Guidoboni, Giovanna and Sala, Lorenzo and Enayati, Moein and Sacco, Riccardo and Szopos, Marcela and Keller, James M. and Popescu, Mihail and Despins, Laurel and Huxley, Virginia H. and Skubic, Marjorie},
  year = {2019},
  month = oct,
  journal = {IEEE Transactions on Biomedical Engineering},
  volume = {66},
  number = {10},
  pages = {2906--2917},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/tbme.2019.2897952},
  urldate = {2019-12-10},
  abstract = {Objective: To develop quantitative methods for the clinical interpretation of the ballistocardiogram (BCG). Methods: A closed-loop mathematical model of the cardiovascular system is proposed to theoretically simulate the mechanisms generating the BCG signal, which is then compared with the signal acquired via accelerometry on a suspended bed. Results: Simulated arterial pressure waveforms and ventricular functions are in good qualitative and quantitative agreement with those reported in the clinical literature. Simulated BCG signals exhibit the typical I, J, K, L, M, and N peaks and show good qualitative and quantitative agreement with experimental measurements. Simulated BCG signals associated with reduced contractility and increased stiffness of the left ventricle exhibit different changes that are characteristic of the specific pathological condition. Conclusion: The proposed closed-loop model captures the predominant features of BCG signals and can predict pathological changes on the basis of fundamental mechanisms in cardiovascular physiology. Significance: This paper provides a quantitative framework for the clinical interpretation of BCG signals and the optimization of BCG sensing devices. The present paper considers an average human body and can potentially be extended to include variability among individuals.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Guidoboni et al_2019_Cardiovascular function and ballistocardiogram (Case Conflict (1)).pdf}
}

@book{guidoboniOcularFluid2019,
  title = {Ocular {{Fluid Dynamics}}: {{Anatomy}}, {{Physiology}}, {{Imaging Techniques}}, and {{Mathematical Modeling}}},
  shorttitle = {Ocular {{Fluid Dynamics}}},
  editor = {Guidoboni, Giovanna and Harris, Alon and Sacco, Riccardo},
  year = {2019},
  series = {Modeling and {{Simulation}} in {{Science}}, {{Engineering}} and {{Technology}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-25886-3},
  urldate = {2019-12-06},
  copyright = {All rights reserved},
  isbn = {978-3-030-25885-6 978-3-030-25886-3},
  langid = {english}
}

@article{Gutkin2003,
  title = {Can Billiard Eigenstates Be Approximated by Superpositions of Plane Waves?},
  author = {Gutkin, Boris},
  year = {2003},
  month = jul,
  journal = {Journal of Physics A: Mathematical and General},
  volume = {36},
  number = {32},
  pages = {8603--8622},
  publisher = {{IOP Publishing}},
  doi = {10.1088/0305-4470/36/32/304},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Gutkin_2003_Can billiard eigenstates be approximated by superpositions of plane waves.pdf}
}

@book{habermanElementaryAppliedPartial1998,
  title = {Elementary {{Applied Partial Differential Equations}}: {{With Fourier Series}} and {{Boundary Value Problems}}},
  shorttitle = {Elementary {{Applied Partial Differential Equations}}},
  author = {Haberman, Richard},
  year = {1998},
  publisher = {{Prentice Hall}},
  abstract = {KEY BENEFIT Emphasizing physical interpretations of mathematical solutions, this book introduces applied mathematics and presents partial differential equations. KEY TOPICS Leading readers from simple exercises through increasingly powerful mathematical techniques, this book discusses hear flow and vibrating strings and membranes, for a better understand of the relationship between mathematics and physical problems. It also emphasizes problem solving and provides a thorough approach to solutions. The third edition of , Elementary Applied Partial Differential Equations; With Fourier Series and Boundary Value Problems has been revised to include a new chapter covering dispersive waves. It also includes new sections covering fluid flow past a circular cylinder; reflection and refraction of light and sound waves; the finite element method; partial differential equations with spherical geometry; eigenvalue problems with a continuous and discrete spectrum; and first-order nonlinear partial differential equations. An essential reference for any technical or mathematics professional.},
  googlebooks = {FKRwQgAACAAJ},
  isbn = {978-0-13-263807-4},
  langid = {english},
  keywords = {Mathematics / Differential Equations / General}
}

@article{hahnConversationDonaldMarquardt1995,
  title = {A {{Conversation}} with {{Donald Marquardt}}},
  author = {Hahn, Gerald J.},
  year = {1995},
  month = nov,
  journal = {Statistical Science},
  volume = {10},
  number = {4},
  pages = {377--393},
  publisher = {{Institute of Mathematical Statistics}},
  issn = {0883-4237, 2168-8745},
  doi = {10.1214/ss/1177009871},
  urldate = {2020-06-18},
  abstract = {Project Euclid - mathematics and statistics online},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hahn-1995-A Conversation with Donald Marquardt.pdf;/Users/driscoll/Zotero/storage/R8V3EFL5/1177009871.html}
}

@book{haindlVisualTextureAccurate2013,
  title = {Visual Texture: Accurate Material Appearance Measurement, Representation and Modeling},
  shorttitle = {Visual Texture},
  author = {Haindl, Michal and Filip, Ji{\v r}{\'i}},
  year = {2013},
  series = {Advances in Computer Vision and Pattern Recognition},
  publisher = {{Springer}},
  address = {{London ; New York}},
  abstract = {Although the field of texture processing is now well-established, research in this area remains predominantly restricted to texture analysis and simple and approximate static textures. This comprehensive text/reference presents a survey of the state of the art in multidimensional, physically-correct visual texture modeling. Starting from basic principles and building upon the fundamentals to the latest advanced methods, the book brings together research from computer vision, pattern recognition, computer graphics, virtual and augmented reality. The text assumes a graduate-level understanding of statistics and probability theory, and a knowledge of basic computer graphics principles, but is accessible to newcomers to the field. Topics and features:Reviews the entire process of texture synthesis, including material appearance representation, measurement, analysis, compression, modeling, editing, visualization, and perceptual evaluationExplains the derivation of the most common representations of visual texture, discussing their properties, advantages, and limitationsDescribes a range of techniques for the measurement of visual texture, including BRDF, SVBRDF, BTF and BSSRDFInvestigates the visualization of textural information, from texture mapping and mip-mapping to illumination- and view-dependent data interpolationExamines techniques for perceptual validation and analysis, covering both standard pixel-wise similarity measures and also methods of visual psychophysicsReviews the applications of visual textures, from visual scene analysis in image processing and medical applications, to high-quality visualizations for cultural heritage and the automotive industryResearchers, lecturers, students and practitioners will all find this book an invaluable reference on the rapidly developing new field of texture modeling.--},
  isbn = {978-1-4471-4901-9},
  langid = {english},
  lccn = {TA1650 .H35 2013},
  keywords = {Optical pattern recognition,Visual texture recognition},
  annotation = {OCLC: ocn841366203},
  file = {/Users/driscoll/Dropbox/library/Book/Haindl_Filip_2013_Visual texture.pdf}
}

@unpublished{Hairer2009,
  title = {An Introduction to Stochastic {{PDEs}}},
  author = {Hairer, Martin},
  year = {2009},
  annotation = {Lecture notes},
  file = {/Users/driscoll/Dropbox/library/Manuscript/Hairer_2009_An introduction to stochastic PDEs.pdf}
}

@book{hairerSolvingOrdinaryDifferential2008,
  title = {Solving {{Ordinary Differential Equations I}}: {{Nonstiff Problems}}},
  shorttitle = {Solving {{Ordinary Differential Equations I}}},
  author = {Hairer, Ernst and N{\o}rsett, Syvert P. and Wanner, Gerhard},
  year = {2008},
  month = apr,
  publisher = {{Springer Science \& Business Media}},
  abstract = {This book deals with methods for solving nonstiff ordinary differential equations. The first chapter describes the historical development of the classical theory, and the second chapter includes a modern treatment of Runge-Kutta and extrapolation methods. Chapter three begins with the classical theory of multistep methods, and concludes with the theory of general linear methods. The reader will benefit from many illustrations, a historical and didactic approach, and computer programs which help him/her learn to solve all kinds of ordinary differential equations. This new edition has been rewritten and new material has been included.},
  googlebooks = {F93u7VcSRyYC},
  isbn = {978-3-540-56670-0},
  langid = {english},
  keywords = {Mathematics / Calculus,Mathematics / Mathematical Analysis,Mathematics / Number Systems,Mathematics / Numerical Analysis}
}

@article{halbachUnderstandingModernMagnets2008,
  title = {Understanding {{Modern Magnets}} through {{Conformal Mapping}}},
  author = {Halbach, K.},
  year = {2008},
  month = aug,
  urldate = {2020-10-24},
  abstract = {Author(s): Halbach, K.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/undefined/2008/Halbach_2008_Understanding Modern Magnets through Conformal Mapping.pdf;/Users/driscoll/Zotero/storage/VBCLM45T/1m0835fq.html}
}

@article{hanischCoclusteringBiologicalNetworks2002,
  title = {Co-Clustering of Biological Networks and Gene Expression Data},
  author = {Hanisch, D. and Zien, A. and Zimmer, R. and Lengauer, T.},
  year = {2002},
  month = jul,
  journal = {Bioinformatics},
  volume = {18},
  number = {Suppl 1},
  pages = {S145-S154},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/18.suppl_1.s145},
  urldate = {2019-11-18},
  abstract = {Motivation: Large scale gene expression data are often analysed by clustering genes based on gene expression data alone, though a priori knowledge in the form of biological networks is available. The use of this additional information promises to improve exploratory analysis considerably.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hanisch et al_2002_Co-clustering of biological networks and gene expression data.pdf}
}

@article{Hann_Imaging_2011,
  title = {Imaging the Aqueous Humor Outflow Pathway in Human Eyes by Three-Dimensional Micro-Computed Tomography ({{3D}} Micro-{{CT}})},
  author = {Hann, Cheryl R and Bentley, Michael D and Vercnocke, Andrew and Ritman, Erik L and Fautsch, Michael P},
  year = {2011},
  volume = {92},
  number = {2},
  pages = {104--111},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2010.12.010},
  abstract = {The site of outflow resistance leading to elevated intraocular pressure in primary open-angle glaucoma is believed to be located in the region of Schlemm's canal inner wall endothelium, its basement membrane and the adjacent juxtacanalicular tissue. Evidence also suggests collector channels and intrascleral vessels may have a role in intraocular pressure in both normal and glaucoma eyes. Traditional imaging modalities limit the ability to view both proximal and distal portions of the trabecular outflow pathway as a single unit. In this study, we examined the effectiveness of three-dimensional micro-computed tomography (3D micro-CT) as a potential method to view the trabecular outflow pathway. Two normal human eyes were used: one immersion fixed in 4\% paraformaldehyde and one with anterior chamber perfusion at 10 mmHg followed by perfusion fixation in 4\% paraformaldehyde/2\% glutaraldehyde. Both eyes were postfixed in 1\% osmium tetroxide and scanned with 3D micro-CT at 2 {$\mu$}m or 5 {$\mu$}m voxel resolution. In the immersion fixed eye, 24 collector channels were identified with an average orifice size of 27.5  5 {$\mu$}m. In comparison, the perfusion fixed eye had 29 collector channels with a mean orifice size of 40.5  13 {$\mu$}m. Collector channels were not evenly dispersed around the circumference of the eye. There was no significant difference in the length of Schlemm's canal in the immersed versus the perfused eye (33.2 versus 35.1 mm). Structures, locations and size measurements identified by 3D micro-CT were confirmed by correlative light microscopy. These findings confirm 3D micro-CT can be used effectively for the non-invasive examination of the trabecular meshwork, Schlemm's canal, collector channels and intrascleral vasculature that comprise the distal outflow pathway. This imaging modality will be useful for non-invasive study of the role of the trabecular outflow pathway as a whole unit.},
  pmcid = {PMC3034776},
  pmid = {21187085}
}

@book{hansenLeastSquaresData2013,
  title = {Least {{Squares Data Fitting}} with {{Applications}}},
  author = {Hansen, Per Christian and Pereyra, V{\'i}ctor and Scherer, Godela},
  year = {2013},
  month = jan,
  publisher = {{JHU Press}},
  abstract = {As one of the classical statistical regression techniques, and often the first to be taught to new students, least squares fitting can be a very effective tool in data analysis. Given measured data, we establish a relationship between independent and dependent variables so that we can use the data predictively. The main concern of Least Squares Data Fitting with Applications is how to do this on a computer with efficient and robust computational methods for linear and nonlinear relationships. The presentation also establishes a link between the statistical setting and the computational issues.In a number of applications, the accuracy and efficiency of the least squares fit is central, and Per Christian Hansen, V{\'i}ctor Pereyra, and Godela Scherer survey modern computational methods and illustrate them in fields ranging from engineering and environmental sciences to geophysics. Anyone working with problems of linear and nonlinear least squares fitting will find this book invaluable as a hands-on guide, with accessible text and carefully explained problems.Included are{$\bullet$} an overview of computational methods together with their properties and advantages{$\bullet$} topics from statistical regression analysis that help readers to understand and evaluate the computed solutions{$\bullet$} many examples that illustrate the techniques and algorithmsLeast Squares Data Fitting with Applications can be used as a textbook for advanced undergraduate or graduate courses and professionals in the sciences and in engineering.},
  googlebooks = {8IrZe3QX0LQC},
  isbn = {978-1-4214-0786-9},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / General}
}

@misc{HaoPhysicsInformedMachine2023,
  title = {Physics-{{Informed Machine Learning}}: {{A Survey}} on {{Problems}}, {{Methods}} and {{Applications}}},
  shorttitle = {Physics-{{Informed Machine Learning}}},
  author = {Hao, Zhongkai and Liu, Songming and Zhang, Yichi and Ying, Chengyang and Feng, Yao and Su, Hang and Zhu, Jun},
  year = {2023},
  month = mar,
  number = {arXiv:2211.08064},
  eprint = {2211.08064},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2211.08064},
  urldate = {2023-12-12},
  abstract = {Recent advances of data-driven machine learning have revolutionized fields like computer vision, reinforcement learning, and many scientific and engineering domains. In many real-world and scientific problems, systems that generate data are governed by physical laws. Recent work shows that it provides potential benefits for machine learning models by incorporating the physical prior and collected data, which makes the intersection of machine learning and physics become a prevailing paradigm. By integrating the data and mathematical physics models seamlessly, it can guide the machine learning model towards solutions that are physically plausible, improving accuracy and efficiency even in uncertain and high-dimensional contexts. In this survey, we present this learning paradigm called Physics-Informed Machine Learning (PIML) which is to build a model that leverages empirical data and available physical prior knowledge to improve performance on a set of tasks that involve a physical mechanism. We systematically review the recent development of physics-informed machine learning from three perspectives of machine learning tasks, representation of physical prior, and methods for incorporating physical prior. We also propose several important open research problems based on the current trends in the field. We argue that encoding different forms of physical prior into model architectures, optimizers, inference algorithms, and significant domain-specific applications like inverse engineering design and robotic control is far from being fully explored in the field of physics-informed machine learning. We believe that the interdisciplinary research of physics-informed machine learning will significantly propel research progress, foster the creation of more effective machine learning models, and also offer invaluable assistance in addressing long-standing problems in related disciplines.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Hao et al_2023_Physics-Informed Machine Learning.pdf;/Users/driscoll/Zotero/storage/AL8WBYP7/2211.html}
}

@article{HarrisonBegley08,
  title = {Menisci and Fullness of the Blink in Dry Eye},
  author = {Harrison, W. W. and Begley, C. G. and Liu, H. and Chen, M. and Garcia, M. and Smith, J. A.},
  year = {2008},
  journal = {Optometry and Vision Science},
  volume = {85},
  pages = {706--714},
  doi = {10.1097/opx.0b013e318181ae02},
  date-added = {2013-02-11 16:49:32 +0000},
  date-modified = {2013-02-11 16:54:08 +0000}
}

@article{hashemiLeastSquaresSpectralMethods2022,
  title = {Least-{{Squares Spectral Methods}} for {{ODE Eigenvalue Problems}}},
  author = {Hashemi, Behnam and Nakatsukasa, Yuji},
  year = {2022},
  month = oct,
  journal = {SIAM Journal on Scientific Computing},
  volume = {44},
  number = {5},
  pages = {A3244-A3264},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/21M1445934},
  urldate = {2022-11-01},
  abstract = {We develop spectral methods for ODEs and operator eigenvalue problems that are based on a least-squares formulation of the problem. The key tool is a method for rectangular generalized eigenvalue problems, which we extend to quasimatrices and objects combining quasimatrices and matrices. The strength of the approach is its flexibility that lies in the quasimatrix formulation allowing the basis functions to be chosen arbitrarily, a good choice (e.g., those obtained by solving nearby problems) leading to rapid convergence, and often giving high accuracy. We also show how our algorithm can easily be modified to solve problems with eigenvalue-dependent boundary conditions, and discuss reformulations as an integral equation, which often improves the accuracy.},
  keywords = {47A75,65F15,65F25,65N35,least-squares method,operator eigenvalue problems,quasimatrix,rectangular matrix pencils,spectral methods},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hashemi_Nakatsukasa_2022_Least-Squares Spectral Methods for ODE Eigenvalue Problems.pdf}
}

@book{Hastie2009,
  title = {The Elements of Statistical Learning},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  publisher = {{Springer New York}},
  doi = {10.1007/978-0-387-84858-7},
  file = {/Users/driscoll/Dropbox/library/Book/Hastie et al_2009_The elements of statistical learning.pdf}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The Elements of Statistical Learning: Data Mining, Inference, and Prediction},
  shorttitle = {The Elements of Statistical Learning},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, J. H.},
  year = {2009},
  series = {Springer Series in Statistics},
  edition = {2nd ed},
  publisher = {{Springer}},
  address = {{New York, NY}},
  isbn = {978-0-387-84857-0 978-0-387-84858-7},
  lccn = {Q325.5 .H39 2009},
  keywords = {Bioinformatics,Computational intelligence,Data mining,Forecasting,Inference,Machine learning,Methodology,Statistics},
  file = {/Users/driscoll/Dropbox/library/Book/Hastie et al_2009_The elements of statistical learning2.pdf}
}

@article{HautSolvingBurgers2013,
  title = {Solving {{Burgers'}} Equation Using Optimal Rational Approximations},
  author = {Haut, Terry and Beylkin, Gregory and Monz{\'o}n, Lucas},
  year = {2013},
  month = jan,
  journal = {Applied and Computational Harmonic Analysis},
  volume = {34},
  number = {1},
  pages = {83--95},
  issn = {1063-5203},
  doi = {10.1016/j.acha.2012.03.004},
  urldate = {2023-04-12},
  abstract = {We solve viscous Burgers' equation using a fast and accurate algorithm---referred to here as the reduction algorithm---for computing near optimal rational approximations. Given a proper rational function with n poles, the reduction algorithm computes (for a desired L{$\infty$}-approximation error) a rational approximation of the same form, but with a (near) optimally small number m{$\ll$}n of poles. Although it is well known that (nonlinear) optimal rational approximations are much more efficient than linear representations of functions via a fixed basis (e.g. wavelets), their use in numerical computations has been limited by a lack of efficient, robust, and accurate algorithms. The reduction algorithm presented here computes reliably (near) optimal rational approximations with high accuracy (e.g., {$\approx$}10-14) and a complexity that is essentially linear in the number n of original poles. A key tool is a recently developed algorithm for computing small con-eigenvalues of Cauchy matrices with high relative accuracy, an impossible task for standard algorithms without extended precision. Using the reduction algorithm, we develop a numerical calculus for rational representations of functions. Indeed, while operations such as multiplication and convolution increase the number of poles in the representation, we use the reduction algorithm to maintain an optimally small number of poles. To demonstrate the efficiency, robustness, and accuracy of our approach, we solve Burgers' equation with small viscosity {$\nu$}. It is well known that its solutions exhibit moving transition regions of width O({$\nu$}), so that this equation provides a stringent test for adaptive PDE solvers. We show that optimal rational approximations capture the solutions with high accuracy using a small number of poles. In particular, we solve the equation with local accuracy {$\epsilon$}=10-9 for viscosity as small as {$\nu$}=10-5.},
  langid = {english},
  keywords = {Burgers equation,Con-eigenvalue problem,High relative accuracy algorithms,Nonlinear approximations,Optimal rational approximations},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Haut et al_2013_Solving Burgersʼ equation using optimal rational approximations.pdf;/Users/driscoll/Zotero/storage/YPKI9EWA/S1063520312000437.html}
}

@inproceedings{HeDeepResidual2016,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  year = {2016},
  month = jun,
  pages = {770--778},
  publisher = {{IEEE}},
  address = {{Las Vegas, NV, USA}},
  doi = {10.1109/CVPR.2016.90},
  urldate = {2022-08-12},
  isbn = {978-1-4673-8851-1},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/He et al-2016-Deep Residual Learning for Image Recognition.pdf}
}

@article{HeLuDingEtAl2017a,
  title = {Multi-Way Multi-Level Kernel Modeling for Neuroimaging Classification},
  author = {He, Lifang and Lu, Chun-Ta and Ding, Hao and Wang, Shen and Shen, Linlin and Yu, Philip S. and Ragin, Ann B.},
  year = {2017},
  doi = {10.1109/cvpr.2017.724}
}

@article{heMaskRCNN2018,
  title = {Mask {{R-CNN}}},
  author = {He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  year = {2018},
  month = jan,
  journal = {arXiv:1703.06870 [cs]},
  eprint = {1703.06870},
  primaryclass = {cs},
  urldate = {2020-08-07},
  abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without bells and whistles, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code has been made available at: https://github.com/facebookresearch/Detectron},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/He et al_2018_Mask R-CNN.pdf;/Users/driscoll/Zotero/storage/CFCEY46J/1703.html}
}

@article{HerremansResolutionSingularities2023,
  title = {Resolution of {{Singularities}} by {{Rational Functions}}},
  author = {Herremans, Astrid and Huybrechs, Daan and Trefethen, Lloyd N.},
  year = {2023},
  month = dec,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {61},
  number = {6},
  pages = {2580--2600},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1429},
  doi = {10.1137/23M1551821},
  urldate = {2024-01-19},
  abstract = {A new method is introduced for solving Laplace problems on two-dimensional regions with corners by approximation of boundary data by the real part of a rational function with fixed poles exponentially clustered near each corner.  Greatly extending a result of D. J. Newman in 1964 in approximation theory, we first prove that such approximations can achieve root-exponential convergence for a wide range of problems, all the way up to the corner singularities. We then develop a numerical method to compute approximations via linear least-squares fitting on the boundary.  Typical problems are solved in \${$<$}1\$s on a desktop to 8-digit accuracy, with the accuracy guaranteed in the interior by the maximum principle.  The computed solution is represented globally by a single formula, which can be evaluated in a few microseconds at each point.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Herremans et al_2023_Resolution of Singularities by Rational Functions.pdf}
}

@article{Heryudono_Adaptive_2008,
  title = {Adaptive Radial Basis Function Methods for the Numerical Solution of Partial Differential Equations, with Application to the Simulation of the Human Tear Film},
  author = {Heryudono, {\relax ARH}},
  year = {2008},
  abstract = {This thesis deals with meshless adaptive numerical methods for solving partial differential equations. Specifically, the type of meshless method used is the radial basis function (RBF) method. We did numerous numerical experiments, built the algorithm from scratch, ...},
  keywords = {No DOI found}
}

@article{HeryudonoRadialBasis2010,
  title = {Radial {{Basis Function Interpolation}} on {{Irregular Domain}} through {{Conformal Transplantation}}},
  author = {Heryudono, Alfa R. H. and Driscoll, Tobin A.},
  year = {2010},
  month = jun,
  journal = {Journal of Scientific Computing},
  volume = {44},
  number = {3},
  pages = {286--300},
  issn = {0885-7474},
  doi = {10.1007/s10915-010-9380-3},
  copyright = {All rights reserved}
}

@article{HeryudonoSingleequationModels2007,
  title = {Single-Equation Models for the Tear Film in a Blink Cycle: {{Realistic}} Lid Motion.},
  author = {Heryudono, Alfa and Braun, Richard J and Driscoll, Tobin A and Maki, Kara L and Cook, {\relax Lp}amela and PE, King-Smith},
  year = {2007},
  journal = {Mathematical Medicine and Biology-a Journal of The Ima},
  volume = {24},
  number = {4},
  pages = {347--77},
  issn = {1477-8599},
  doi = {10.1093/imammb/dqm004},
  abstract = {We consider model problems for the tear film over multiple blink cycles that utilize a single equation for the tear film; the single non-linear partial differential equation that governs the film thickness arises from lubrication theory. The two models that we consider arise from considering the absence of naturally occurring surfactant and the case when the surfactant is strongly affecting the surface tension. The film is considered on a time-varying domain length with specified film thickness and volume flux at each end; only one end of the domain is moving, which is analogous to the upper eyelid moving with each blink. Realistic lid motion from observed blinks is included in the model with end fluxes specified to more closely match the blink cycle than those previously reported. Numerical computations show quantitative agreement with in vivo tear film thickness measurements under partial blink conditions. A transition between periodic and non-periodic solutions has been estimated as a function of closure fraction and this may be a criterion for what is effectively a full blink according to fluid dynamics.},
  copyright = {All rights reserved},
  pmid = {17947253},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Heryudono et al-2007-Single-equation models for the tear film in a blink cycle2.pdf;/Users/driscoll/Dropbox/library/Journal Article/Heryudono et al-2007-Single-equation models for the tear film in a blink cycle3.pdf}
}

@article{hestenesMethodsConjugateGradients1952,
  title = {Methods of Conjugate Gradients for Solving Linear Systems},
  author = {Hestenes, M.R. and Stiefel, E.},
  year = {1952},
  month = dec,
  journal = {Journal of Research of the National Bureau of Standards},
  volume = {49},
  number = {6},
  pages = {409},
  issn = {0091-0635},
  doi = {10.6028/jres.049.044},
  urldate = {2020-06-18},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hestenes_Stiefel-1952-Methods of conjugate gradients for solving linear systems.pdf;/Users/driscoll/Dropbox/library/Journal Article/Hestenes_Stiefel-1952-Methods of conjugate gradients for solving linear systems2.pdf}
}

@article{Heys_Computational_2002,
  title = {Computational Evaluation of the Role of Accommodation in Pigmentary Glaucoma.},
  author = {Heys, Jeffrey J and Barocas, Victor H},
  year = {2002},
  journal = {Investigative Ophthalmology and Visual Science},
  volume = {43},
  number = {3},
  pages = {700--8},
  issn = {0146-0404},
  abstract = {Accommodation has been proposed as the cause of the bowing of the posterior iris that occurs in eyes with pigmentary dispersion syndrome. A mathematical model of the anterior eye is needed to explore the elastohydrodynamic effects of accommodation on both the aqueous humor dynamics and the contour of the iris.},
  pmid = {11867587}
}

@book{highamAccuracyStabilityNumerical2002,
  title = {Accuracy and {{Stability}} of {{Numerical Algorithms}}: {{Second Edition}}},
  shorttitle = {Accuracy and {{Stability}} of {{Numerical Algorithms}}},
  author = {Higham, Nicholas J.},
  year = {2002},
  month = jan,
  publisher = {{SIAM}},
  abstract = {Accuracy and Stability of Numerical Algorithms gives a thorough, up-to-date treatment of the behavior of numerical algorithms in finite precision arithmetic. It combines algorithmic derivations, perturbation theory, and rounding error analysis, all enlivened by historical perspective and informative quotations. This second edition expands and updates the coverage of the first edition (1996) and includes numerous improvements to the original material. Two new chapters treat symmetric indefinite systems and skew-symmetric systems, and nonlinear systems and Newton\&\#39;s method. Twelve new sections include coverage of additional error bounds for Gaussian elimination, rank revealing LU factorizations, weighted and constrained least squares problems, and the fused multiply-add operation found on some modern computer architectures.},
  googlebooks = {7J52J4GrsJkC},
  isbn = {978-0-89871-802-7},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / Mathematical Analysis,Mathematics / Number Systems,Mathematics / Numerical Analysis}
}

@article{highamDeepLearningIntroduction2019,
  title = {Deep {{Learning}}: {{An Introduction}} for {{Applied Mathematicians}}},
  shorttitle = {Deep {{Learning}}},
  author = {Higham, Catherine F. and Higham, Desmond J.},
  year = {2019},
  month = jan,
  journal = {SIAM Review},
  volume = {61},
  number = {3},
  pages = {860--891},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/18m1165748},
  urldate = {2020-07-07},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Higham_Higham_2019_Deep Learning.pdf}
}

@inproceedings{HochmanFastAAAFast2017,
  title = {{{FastAAA}}: {{A}} Fast Rational-Function Fitter},
  shorttitle = {{{FastAAA}}},
  booktitle = {2017 {{IEEE}} 26th {{Conference}} on {{Electrical Performance}} of {{Electronic Packaging}} and {{Systems}} ({{EPEPS}})},
  author = {Hochman, Amit},
  year = {2017},
  month = oct,
  pages = {1--3},
  issn = {2165-4115},
  doi = {10.1109/EPEPS.2017.8329756},
  abstract = {FastAAA is an algorithm for fitting rational-functions to a set of N data samples. In each step of the algorithm, it computes an order n fit via a fast, O(Nn), update of the previous order n - 1 fit. The algorithm stops at the first order that yields an acceptable error. The errors of the fits of orders 1... n, are evaluated in O(Nn2) operations. If the data can be represented exactly with n poles, the algorithm is guaranteed to stop after n iterations (in exact arithmetic). It is possible to fit p rational-functions, sharing the same set of poles, to p sets of data, in O(pNn2) operations. The stability of the poles and Hermitian symmetry of the fit can be guaranteed.},
  keywords = {Approximation algorithms,Computational modeling,Connectors,Eigenvalues and eigenfunctions,Interpolation,Matlab,Time-domain analysis},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Hochman_2017_FastAAA.pdf;/Users/driscoll/Zotero/storage/2YPP82IN/8329756.html}
}

@article{hochstenbachJacobiDavidsonType2001,
  title = {A {{Jacobi--Davidson Type SVD Method}}},
  author = {Hochstenbach, Michiel E.},
  year = {2001},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {23},
  number = {2},
  pages = {606--628},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/S1064827500372973},
  urldate = {2022-06-03},
  abstract = {We discuss a new method for the iterative computation of a portion of the singular values and vectors of a large sparse matrix. Similar to the Jacobi--Davidson method for the eigenvalue problem, we compute in each step a correction by (approximately) solving a correction equation. We give a few variants of this Jacobi--Davidson SVD (JDSVD) method with their theoretical properties. It is shown that the JDSVD can be seen as an accelerated (inexact) Newton scheme. We experimentally compare the method with some other iterative SVD methods.},
  keywords = {(inexact) accelerated Newton,65F15,65F35,augmented matrix,correction equation,improving singular values,Jacobi--Davidson,norm,singular value decomposition (SVD),singular values,singular vectors},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hochstenbach-2001-A Jacobi--Davidson Type SVD Method.pdf}
}

@article{HokansonSimultaneousIdentification2023,
  title = {Simultaneous {{Identification}} and {{Denoising}} of {{Dynamical Systems}}},
  author = {Hokanson, Jeffrey M. and Iaccarino, Gianluca and Doostan, Alireza},
  year = {2023},
  month = aug,
  journal = {SIAM Journal on Scientific Computing},
  volume = {45},
  number = {4},
  pages = {A1413-A1437},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/22M1486303},
  urldate = {2023-09-06},
  abstract = {.We present a novel physics-informed system identification method to construct a passive linear time-invariant system. In more detail, for a given quadratic energy functional, measurements of the input, state, and output of a system in the time domain, we find a realization that approximates the data well while guaranteeing that the energy functional satisfies a dissipation inequality. To this end, we use the framework of port-Hamiltonian (pH) systems and modify the dynamic mode decomposition, respectively, operator inference, to be feasible for continuous-time pH systems. We propose an iterative numerical method to solve the corresponding least-squares minimization problem. We construct an effective initialization of the algorithm by studying the least-squares problem in a weighted norm, for which we present the analytical minimum-norm solution. The efficiency of the proposed method is demonstrated with several numerical examples.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hokanson et al_2023_Simultaneous Identification and Denoising of Dynamical Systems.pdf}
}

@inproceedings{holtersGeneralizedMethodDerivation2015,
  title = {A Generalized Method for the Derivation of Non-Linear State-Space Models from Circuit Schematics},
  booktitle = {2015 23rd {{European Signal Processing Conference}} ({{EUSIPCO}})},
  author = {Holters, Martin and Zolzer, Udo},
  year = {2015},
  month = aug,
  pages = {1073--1077},
  publisher = {{IEEE}},
  address = {{Nice}},
  doi = {10.1109/eusipco.2015.7362548},
  urldate = {2019-12-05},
  abstract = {Digital emulation of analog circuits for musical audio processing, like synthesizers, guitar effect pedals, or vintage amplifiers, is an ongoing research topic. David Yeh proposed to use the nodal DK method to derive a non-linear state-space system from a circuit schematic in a very systematic way. However, this approach has some drawbacks and limitations, especially with respect to the modeling of individual circuit elements. Therefore, in this paper, we present an alternative that is more flexible than the nodal DK method and hopefully allows for easier integration of almost arbitrary element models. This flexibility and generality in our opinion outweighs the relatively small cost associated with it in terms of increased matrix sizes. We therefore believe the proposed method to be a useful tool for circuit simulation.},
  isbn = {978-0-9928626-3-3},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Holters_Zolzer_2015_A generalized method for the derivation of non-linear state-space models from.pdf}
}

@article{Hon2003,
  title = {An Adaptive Greedy Algorithm for Solving Large {{RBF}} Collocation Problems},
  author = {Hon, Y.C. and Schaback, R. and Zhou, X.},
  year = {2003},
  journal = {Numerical Algorithms},
  volume = {32},
  number = {1},
  pages = {13--25},
  publisher = {{Springer Nature}},
  doi = {10.1023/a:1022253303343},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hon et al_2003_An adaptive greedy algorithm for solving large RBF collocation problems.pdf}
}

@article{HongOptimallyWeighted2023,
  title = {Optimally {{Weighted PCA}} for {{High-Dimensional Heteroscedastic Data}}},
  author = {Hong, David and Yang, Fan and Fessler, Jeffrey A. and Balzano, Laura},
  year = {2023},
  month = mar,
  journal = {SIAM Journal on Mathematics of Data Science},
  volume = {5},
  number = {1},
  pages = {222--250},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/22M1470244},
  urldate = {2023-04-26},
  abstract = {We propose distributed solutions to the problem of Robust Subspace Recovery (RSR). Our setting assumes a huge dataset in an ad hoc network without a central processor, where each node has access only to one chunk of the dataset. Furthermore, part of the whole dataset lies around a low-dimensional subspace and the other part is composed of outliers that lie away from that subspace. The goal is to recover the underlying subspace for the whole dataset, without transferring the data itself between the nodes. We first apply the Consensus Based Gradient method to the Geometric Median Subspace algorithm for RSR. For this purpose, we propose an iterative solution for the local dual minimization problem and establish its r-linear convergence. We then explain how to distributedly implement the Reaper and Fast Median Subspace algorithms for RSR. The proposed algorithms display competitive performance on both synthetic and real data.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hong et al_2023_Optimally Weighted PCA for High-Dimensional Heteroscedastic Data.pdf}
}

@misc{hormannBarycentricInterpolation,
  title = {Barycentric Interpolation},
  author = {Hormann, Kai},
  file = {/Users/driscoll/Dropbox/library/Document/Hormann_Barycentric interpolation.pdf}
}

@article{houghIntegralEquationMethod1983,
  title = {An Integral Equation Method for the Numerical Conformal Mapping of Interior, Exterior and Doubly-Connected Domains},
  author = {Hough, D. M. and Papamichael, N.},
  year = {1983},
  month = oct,
  journal = {Numerische Mathematik},
  volume = {41},
  number = {3},
  pages = {287--307},
  issn = {0945-3245},
  doi = {10.1007/bf01418327},
  urldate = {2019-11-18},
  abstract = {SummaryA numerical method, based on the integral equation formulation of Symm, is described for computing approximations to the mapping functions which accomplish the following conformal maps: (a) the mapping of a domain interior to a closed Jordan curve onto the interior of the unit disc, (b) the mapping of a domain exterior to a closed Jordan curve onto the exterior of the unit disc, (c) the mapping of a doubly-connected domain bounded by two closed Jordan curves onto a circular annulus. The numerical method is based on approximating the unknown source density by cubic splines and ``singular'' functions, and is particularly suited for the mapping of difficult domains having sharp corners.},
  langid = {english},
  keywords = {65R20:CR: 5.18,AMS (MOS): 30C30},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hough_Papamichael_1983_An integral equation method for the numerical conformal mapping of interior,.pdf}
}

@article{Huang_Accommodative_2006,
  title = {Accommodative Microfluctuations and Iris Contour},
  author = {Huang, Eric C and Barocas, Victor H},
  year = {2006},
  volume = {6},
  number = {5},
  pages = {653--60},
  doi = {10.1167/6.5.10},
  abstract = {Mechanical interaction between aqueous humor, iris, and intraocular structures can alter the iris profile from its normal curvature. In particular, significant changes to the iris profile occur during accommodation as the anterior lens movement forces the iris into greater posterior bowing. We extended a previous mathematical model of the anterior segment and investigated the response of this coupled fluid--solid system due to accommodative microfluctuations. The results showed that the system response exhibited the same waveform as the stimulus for small-amplitude microfluctuations generally associated with the high-frequency component. Low-frequency microfluctuations with relatively larger amplitudes elicited a response different from the stimulus, indicating that the forces generated by the lens movement significantly affected the aqueous--iris mechanical interaction.},
  pmid = {16881796}
}

@article{Huang_Active_2004,
  title = {Active Iris Mechanics and Pupillary Block: {{Steady-State}} Analysis and Comparison with Anatomical Risk Factors},
  author = {Huang, Eric C and Barocas, Victor H},
  year = {2004},
  volume = {32},
  number = {9},
  pages = {1276--1285},
  issn = {0090-6964},
  doi = {10.1114/b:abme.0000039361.17029.da},
  abstract = {Primary angle-closure glaucoma arises when the iris physically obstructs outflow of aqueous humor, increasing the intraocular pressure and damaging the optic nerve. Pupillary block, the predominant mechanism for angle closure, is believed to be driven by mechanical interaction between the aqueous humor and the iris. We performed steady-state simulations of this coupled fluid--solid system, including an active sphincter to control pupil constriction. Model results compared favorably against Mapstone's pupil-blocking force analysis. We also evaluated anatomical risk factors and quantified their contributions to pupillary block and angle closure. The results showed that greater lens curvature and shorter iris--zonule distance contribute significantly to pupillary block and the associated narrowing of the angle. Surprisingly, the model predicted that maximum pupillary block and angle closure occur at the minimum pupil dilation, contradicting the clinical observation that angle closure is most severe in dark conditions. This discrepancy suggests the involvement of one or more phenomena not captured by our current model.},
  pmid = {15493514}
}

@article{hudsonMotorLearningReveals2012,
  title = {Motor Learning Reveals the Existence of Multiple Codes for Movement Planning},
  author = {Hudson, Todd E. and Landy, Michael S.},
  year = {2012},
  month = nov,
  journal = {Journal of Neurophysiology},
  volume = {108},
  number = {10},
  pages = {2708--2716},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00355.2012},
  urldate = {2019-10-14},
  abstract = {Coordinate systems for movement planning are comprised of an anchor point (e.g., retinocentric coordinates) and a representation (encoding) of the desired movement. One of two representations is often assumed: a final-position code describing desired limb endpoint position and a vector code describing movement direction and extent. The existence of movement-planning systems using both representations is controversial. In our experiments, participants completed reaches grouped by target location (providing practice for a final-position code) and the same reaches grouped by movement vector (providing vector-code practice). Target-grouped reaches resulted in the isotropic (circular) distribution of errors predicted for position-coded reaches. The identical reaches grouped by vector resulted in error ellipses aligned with the reach direction, as predicted for vector-coded reaches. Manipulating only recent movement history to provide better learning for one or the other movement code, we provide definitive evidence that both movement representations are used in the identical task.},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/4ISWN5TV/Hudson and Landy - 2012 - Motor learning reveals the existence of multiple c.pdf;/Users/driscoll/Zotero/storage/YG9CM2NM/Hudson and Landy - 2012 - Motor learning reveals the existence of multiple c.pdf}
}

@article{HuybrechsAAAInterpolation2023,
  title = {{{AAA}} Interpolation of Equispaced Data},
  author = {Huybrechs, Daan and Trefethen, Lloyd N.},
  year = {2023},
  month = mar,
  journal = {BIT Numerical Mathematics},
  volume = {63},
  number = {2},
  pages = {21},
  issn = {1572-9125},
  doi = {10.1007/s10543-023-00959-x},
  urldate = {2023-04-12},
  abstract = {We propose AAA rational approximation as a method for interpolating or approximating smooth functions from equispaced samples. Although it is always better to approximate from large numbers of samples if they are available, whether equispaced or not, this method often performs impressively even when the sampling grid is coarse. In most cases it gives more accurate approximations than other methods. We support this claim with a review and discussion of nine classes of existing methods in the light of general properties of approximation theory as well as the ``impossibility theorem'' for equispaced approximation. We make careful use of numerical experiments, which are summarized in a sequence of nine figures. Among our new contributions is the observation, summarized in Fig. ~7, that methods such as polynomial least-squares and Fourier extension may be either exponentially accurate and exponentially unstable, or less accurate and stable, depending on implementation.},
  langid = {english},
  keywords = {41A20,65D05,65D15,AAA approximation,Equally spaced data,Impossibility theorem,Rational approximation},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Huybrechs_Trefethen_2023_AAA interpolation of equispaced data.pdf}
}

@misc{HuybrechsSigmoidFunctions2023,
  title = {Sigmoid Functions and Multiscale Resolution of Singularities},
  author = {Huybrechs, Daan and Trefethen, Lloyd N.},
  year = {2023},
  month = mar,
  number = {arXiv:2303.01967},
  eprint = {2303.01967},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2303.01967},
  urldate = {2024-02-06},
  abstract = {In this short, conceptual paper we observe that essentially the same mathematics applies in three contexts with disparate literatures: (1) sigmoidal and RBF approximation of smooth functions, (2) rational approximation of analytic functions near singularities, and (3) \$hp\$ mesh refinement for solution of PDEs. The relationship of (1) and (2) is as simple as the change of variables \$s = {\textbackslash}log(x)\$, and our informal mnemonic for this relationship is ``sigmoid = log(ratapprox).''},
  archiveprefix = {arxiv},
  keywords = {41A20 65D15 68T07,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Huybrechs_Trefethen_2023_Sigmoid functions and multiscale resolution of singularities.pdf;/Users/driscoll/Zotero/storage/NNGY8K2P/2303.html}
}

@article{hyvarinenaapoEmergencePhaseShiftInvariant2000,
  title = {Emergence of {{Phase-}} and {{Shift-Invariant Features}} by {{Decomposition}} of {{Natural Images}} into {{Independent Feature Subspaces}}},
  author = {Hyv{\"a}rinenAapo and HoyerPatrik},
  year = {2000},
  month = jul,
  journal = {Neural Computation},
  urldate = {2020-01-13},
  abstract = {Olshausen and Field (1996) applied the principle of independence maximization by sparse coding to extract features from natural images. This leads to the emergence of oriented linear filters that h...},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/HyvärinenAapo_HoyerPatrik_2000_Emergence of Phase- and Shift-Invariant Features by Decomposition of Natural.pdf}
}

@article{hyvarinenFastISAFastFixedpoint2006,
  title = {{{FastISA}}: {{A}} Fast Fixed-Point Algorithm for {{Independent Subspace Analysis}}},
  author = {Hyvarinen, Aapo and Koster, Urs},
  year = {2006},
  pages = {6},
  abstract = {Independent Subspace Analysis (ISA; Hyvarinen \& Hoyer, 2000) is an extension of ICA. In ISA, the components are divided into subspaces and components in different subspaces are assumed independent, whereas components in the same subspace have dependencies.In this paper we describe a fixed-point algorithm for ISA estimation, formulated in analogy to FastICA. In particular we give a proof of the quadratic convergence of the algorithm, and present simulations that confirm the fast convergence, but also show that the method is prone to convergence to local minima.},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hyvarinen_Koster_2006_FastISA.pdf}
}

@article{hyvarinenIndependentComponentAnalysis2000,
  title = {Independent Component Analysis: Algorithms and Applications},
  shorttitle = {Independent Component Analysis},
  author = {Hyv{\"a}rinen, A. and Oja, E.},
  year = {2000},
  month = jun,
  journal = {Neural Networks},
  volume = {13},
  number = {4},
  pages = {411--430},
  issn = {0893-6080},
  doi = {10.1016/s0893-6080(00)00026-5},
  urldate = {2020-01-17},
  abstract = {A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of non-Gaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject.},
  langid = {english},
  keywords = {Blind signal separation,Factor analysis,Independent component analysis,Projection pursuit,Representation,Source separation},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hyvärinen_Oja_2000_Independent component analysis.pdf;/Users/driscoll/Zotero/storage/QWGIX8CQ/S0893608000000265.html}
}

@article{hyvarinenIndependentComponentAnalysis2013,
  title = {Independent Component Analysis: Recent Advances},
  shorttitle = {Independent Component Analysis},
  author = {Hyv{\"a}rinen, Aapo},
  year = {2013},
  month = feb,
  journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {371},
  number = {1984},
  pages = {20110534},
  doi = {10.1098/rsta.2011.0534},
  urldate = {2020-01-21},
  abstract = {Independent component analysis is a probabilistic method for learning a linear transform of a random vector. The goal is to find components that are maximally independent and non-Gaussian (non-normal). Its fundamental difference to classical multi-variate statistical methods is in the assumption of non-Gaussianity, which enables the identification of original, underlying components, in contrast to classical methods. The basic theory of independent component analysis was mainly developed in the 1990s and summarized, for example, in our monograph in~2001.~Here, we provide an overview of some recent developments in the theory since the year 2000. The main topics are: analysis of causal relations, testing independent components, analysing multiple datasets (three-way data), modelling dependencies between the components and improved methods for estimating the basic model.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Hyvärinen_2013_Independent component analysis.pdf;/Users/driscoll/Zotero/storage/QN4J299N/rsta.2011.html}
}

@book{hyvarinenNaturalImageStatistics2009,
  title = {Natural {{Image Statistics}}},
  author = {Hyv{\"a}rinen, Aapo and Hurri, Jarmo and Hoyer, Patrik O.},
  editor = {Viergever, Max and Borgefors, Gunilla and Deriche, Rachid and Huang, Thomas S. and Ikeuchi, Katsushi and Jiang, Tianzi and Klette, Reinhard and Leonardis, Ales and Peitgen, Heinz-Otto and Tsotsos, John K.},
  year = {2009},
  series = {Computational {{Imaging}} and {{Vision}}},
  volume = {39},
  publisher = {{Springer London}},
  address = {{London}},
  doi = {10.1007/978-1-84882-491-1},
  urldate = {2020-01-10},
  isbn = {978-1-84882-490-4 978-1-84882-491-1},
  file = {/Users/driscoll/Dropbox/library/Book/Hyvärinen et al_2009_Natural Image Statistics.pdf}
}

@book{igualIntroductionDataScience2017,
  title = {Introduction to {{Data Science}}},
  author = {Igual, Laura and Segu{\'i}, Santi},
  year = {2017},
  series = {Undergraduate {{Topics}} in {{Computer Science}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-50017-1},
  urldate = {2021-10-12},
  isbn = {978-3-319-50016-4 978-3-319-50017-1},
  file = {/Users/driscoll/Dropbox/library/Book/Igual_Seguí_2017_Introduction to Data Science.pdf}
}

@article{ImplicitRiemannianTrustRegion,
  title = {An {{Implicit Riemannian Trust-Region Method}} for the {{Symmetric Generalized Eigenvalue Problem}}},
  doi = {10.1007/11758501_32}
}

@unpublished{Indyk,
  title = {Algorithms for Nearest Neighbor Search},
  author = {Indyk, Piotr},
  annotation = {presentation},
  file = {/Users/driscoll/Dropbox/library/Manuscript/Indyk_Algorithms for nearest neighbor search.pdf}
}

@book{iserlesFirstCourseNumerical1996,
  title = {A {{First Course}} in the {{Numerical Analysis}} of {{Differential Equations}}},
  author = {Iserles, Arieh},
  year = {1996},
  month = jan,
  publisher = {{Cambridge University Press}},
  abstract = {This book presents a rigorous account of the fundamentals of numerical analysis of both ordinary and partial differential equations. The point of departure is mathematical but the exposition strives to maintain a balance among theoretical, algorithmic and applied aspects of the subject. In detail, topics covered include numerical solution of ordinary differential equations by multistep and Runge-Kutta methods; finite difference and finite elements techniques for the Poisson equation; a variety of algorithms to solve large, sparse algebraic systems; and methods for parabolic and hyperbolic differential equations and techniques of their analysis. The book is accompanied by an appendix that presents brief back-up in a number of mathematical topics.},
  googlebooks = {7Zofw3SFTWIC},
  isbn = {978-0-521-55655-2},
  langid = {english},
  keywords = {Mathematics / Differential Equations / General,Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis}
}

@misc{IshikawaUniversalApproximation2022,
  title = {Universal Approximation Property of Invertible Neural Networks},
  author = {Ishikawa, Isao and Teshima, Takeshi and Tojo, Koichi and Oono, Kenta and Ikeda, Masahiro and Sugiyama, Masashi},
  year = {2022},
  month = apr,
  number = {arXiv:2204.07415},
  eprint = {2204.07415},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2204.07415},
  urldate = {2023-12-12},
  abstract = {Invertible neural networks (INNs) are neural network architectures with invertibility by design. Thanks to their invertibility and the tractability of Jacobian, INNs have various machine learning applications such as probabilistic modeling, generative modeling, and representation learning. However, their attractive properties often come at the cost of restricting the layer designs, which poses a question on their representation power: can we use these models to approximate sufficiently diverse functions? To answer this question, we have developed a general theoretical framework to investigate the representation power of INNs, building on a structure theorem of differential geometry. The framework simplifies the approximation problem of diffeomorphisms, which enables us to show the universal approximation properties of INNs. We apply the framework to two representative classes of INNs, namely Coupling-Flow-based INNs (CF-INNs) and Neural Ordinary Differential Equations (NODEs), and elucidate their high representation power despite the restrictions on their architectures.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Ishikawa et al_2022_Universal approximation property of invertible neural networks.pdf;/Users/driscoll/Zotero/storage/D7U6APIX/2204.html}
}

@article{ismailAdjointbasedInverseAnalysis2013,
  title = {Adjoint-Based Inverse Analysis of Windkessel Parameters for Patient-Specific Vascular Models},
  author = {Ismail, Mahmoud and Wall, Wolfgang A. and Gee, Michael W.},
  year = {2013},
  month = jul,
  journal = {Journal of Computational Physics},
  volume = {244},
  pages = {113--130},
  issn = {00219991},
  doi = {10.1016/j.jcp.2012.10.028},
  urldate = {2015-07-29},
  langid = {english},
  keywords = {HLHS,Inverse problem},
  file = {/Users/driscoll/Zotero/storage/IBHKUBXS/1-s2.0-S0021999112006298-main.pdf}
}

@article{JacobiTearFilm2011,
  title = {Tear {{Film Osmolarity Measurements}} in {{Dry Eye Disease Using Electrical Impedance Technology}}},
  author = {Jacobi, Christina and Jacobi, Arnd and Kruse, Friedrich E. and Cursiefen, Claus},
  year = {2011},
  month = dec,
  journal = {Cornea},
  volume = {30},
  number = {12},
  pages = {1289},
  issn = {0277-3740},
  doi = {10.1097/ICO.0b013e31821de383},
  urldate = {2023-02-13},
  abstract = {Purpose:~         Tear film hyperosmolarity is recognized as an important pathogenetic factor in dry eye syndrome, but difficulties in its measurement have limited its utility in the recent past. This prospective, nonrandomized, clinical single-center study investigates the osmolarity in tear samples of patients with keratoconjunctivitis sicca compared with healthy controls.         Methods:~         One hundred thirty-three patients [aged 58 years (51--64 years), 86 women and 47 men] with moderate to severe keratoconjunctivitis sicca and 95 controls [aged 52 years (48--61 years), 55 women and 40 men] were enrolled in the trial. Tear samples were collected directly from the inferior lateral tear meniscus. Inclusion criteria were a tear breakup time of less than 5 seconds, a Schirmer test with anesthesia less than 5 mm, and positive symptoms (Ocular Surface Disease Index score {$>$} 83). Tear film osmolarity was analyzed by the TearLab osmometer.         Results:~         In our study, patients with moderate to severe keratoconjunctivitis sicca showed a tear film osmolarity of 320 mOsmol/L (301--324 mOsmol/L). The results of the control group were 301 mOsmol/L (298--304 mOsmol/L). Our results revealed a significantly higher tear film osmolarity in patients with moderate to severe keratoconjunctivitis sicca compared with the control group. The sensitivity was 87\%, and the specificity was 81\%.         Conclusions:~         Our results approved the referent value in moderate to severe dry eye of approximately 316 mOsmol/L, as described in the literature. The results showed a significantly higher tear film osmolarity in patients with severe keratoconjunctivitis sicca compared with the healthy controls. Testing tear film osmolarity can be a very effective objective diagnostic tool in the diagnosis of dry eye disease.},
  langid = {american},
  file = {/Users/driscoll/Zotero/storage/CUZTZWVW/Tear_Film_Osmolarity_Measurements_in_Dry_Eye.1.html}
}

@misc{jadonVideoSummarization,
  title = {Video Summarization},
  author = {Jadon, Shruti},
  abstract = {In this project we use both keyframe extraction and video skimming for video summarization. For static keyframe extraction, we extract low level features using uniform sampling, image histograms, SIFT and image features from Convolutional Neural Network (CNN) trained on ImageNet. We also use different clustering methods including K-means and Gaussian clustering. We use video skims around the selected keyframes to make the summary fore fluid and comprehensible for humans. We take inspiration from the VSUMM method which is a prominent method in video summarization. \#\#Methods Used: Uniform Sampling Image histogram Scale Invariant Feature Transform VSUMM: This technique has been one of the fundamental techniques in video summarization in the unsupervised setup. The algorithm uses the standard K-means algorithm to cluster features extracted from each frame. Color histograms are proposed to be used in {\textbackslash}cite\{deAvila2011\}. Color histograms are 3-D tensors, where each pixel's values in the RGB channels determines the bin it goes into. Since each channel value ranges in 0 - 255, usually, 16 bins are taken for each channel resulting in a 16X16X16 tensor. Due to computational reasons, a simplified version of this histogram was computed, where each channel was treated separately, resulting in feature vectors for each frame belonging to R 48 . The nest step suggested for clustering is slightly different. But, the simplified color histograms give comparable performance to the true color histograms. The features extracted from VGG16 at the 2nd fully connected layer were tried, and clustered using kmeans. ResNet16 on ImageNet}
}

@article{jainDataClustering502010,
  title = {Data Clustering: 50 Years beyond {{K-means}}},
  shorttitle = {Data Clustering},
  author = {Jain, Anil K.},
  year = {2010},
  month = jun,
  journal = {Pattern Recognition Letters},
  volume = {31},
  number = {8},
  pages = {651--666},
  issn = {01678655},
  doi = {10.1016/j.patrec.2009.09.011},
  urldate = {2019-11-18},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Jain_2010_Data clustering.pdf}
}

@book{jamesIntroductionStatisticalLearning2021,
  title = {An Introduction to Statistical Learning: With Applications in {{R}}},
  shorttitle = {An Introduction to Statistical Learning},
  author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  year = {2021},
  series = {Springer Texts in Statistics},
  edition = {Second edition},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-1-07-161418-1 978-1-07-161417-4},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Book/James et al-2013-An introduction to statistical learning.pdf}
}

@book{JentzenMathematicalIntroduction,
  title = {Mathematical {{Introduction}} to {{Deep Learning}}: {{Methods}}, {{Implementations}}, and {{Theory}}},
  author = {Jentzen, Arnulf and Kuckuck, Benno and {von Wurstemberger}, Philippe},
  file = {/Users/driscoll/Dropbox/library/Book/Jentzen et al_Mathematical Introduction to Deep Learning.pdf}
}

@article{jiangWishartMechanismDifferentially2015,
  title = {Wishart {{Mechanism}} for {{Differentially Private Principal Components Analysis}}},
  author = {Jiang, Wuxuan and Xie, Cong and Zhang, Zhihua},
  year = {2015},
  month = nov,
  journal = {arXiv:1511.05680 [cs, stat]},
  eprint = {1511.05680},
  primaryclass = {cs, stat},
  urldate = {2021-06-15},
  abstract = {We propose a new input perturbation mechanism for publishing a covariance matrix to achieve \$({\textbackslash}epsilon,0)\$-differential privacy. Our mechanism uses a Wishart distribution to generate matrix noise. In particular, We apply this mechanism to principal component analysis. Our mechanism is able to keep the positive semi-definiteness of the published covariance matrix. Thus, our approach gives rise to a general publishing framework for input perturbation of a symmetric positive semidefinite matrix. Moreover, compared with the classic Laplace mechanism, our method has better utility guarantee. To the best of our knowledge, Wishart mechanism is the best input perturbation approach for \$({\textbackslash}epsilon,0)\$-differentially private PCA. We also compare our work with previous exponential mechanism algorithms in the literature and provide near optimal bound while having more flexibility and less computational intractability.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Data Structures and Algorithms,No DOI found,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Jiang et al_2015_Wishart Mechanism for Differentially Private Principal Components Analysis.pdf;/Users/driscoll/Zotero/storage/24HRYZ63/1511.html}
}

@article{JMLR:v10:chen09b,
  title = {Fast Approximate {{kNN}} Graph Construction for High Dimensional Data via Recursive Lanczos Bisection},
  author = {Chen, Jie and Fang, Haw-ren and Saad, Yousef},
  year = {2009},
  journal = {Journal of Machine Learning Research},
  volume = {10},
  number = {69},
  pages = {1989--2012},
  keywords = {No DOI found}
}

@article{Johnson_Adequacy_2010,
  title = {Adequacy of Exchanging the Content of the Anterior Chamber.},
  author = {Johnson, Mark and Caro, Nathan and Huang, Jiahn-Dar},
  year = {2010},
  volume = {91},
  number = {6},
  pages = {876--80},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2010.09.008},
  abstract = {Perfusion studies of the anterior segment of the eye frequently involve an exchange of the contents of the anterior chamber. We here determined how much fluid was necessary to pass through the upstream tubing and anterior chamber such that the contents of the anterior chamber were adequately exchanged. We used fluorescein dextran (500 kD) to assess the adequacy of exchange of enucleated porcine eyes that were washed out with varying volumes of buffer. The results were compared with two theoretical models, one that accounted for the convective dispersion that occurs in the upstream tubing while in the other, more simple model, it was assumed that the upstream tubing and anterior chamber behave essentially as a well-mixed chamber. We found that the experiment results were bounded by these two models, with the well-mixed model giving a lower bound on the rate at which the anterior chamber can be cleared. We found that exchange of the anterior chamber to reduce the concentration of a drug or tracer by 20-fold required a perfused volume three times the combined volume of the upstream tubing and anterior chamber.},
  pmcid = {PMC3025480},
  pmid = {20868681}
}

@article{JohnsonMurphy04,
  title = {Changes in the Tear Film and Ocular Surface from Dry Eye Syndrome},
  author = {Johnson, M. E. and Murphy, P. J.},
  year = {2004},
  journal = {Prog. Ret. Eye Res.},
  volume = {23},
  pages = {449--474},
  doi = {10.1016/j.preteyeres.2004.04.003},
  date-added = {2013-02-25 14:03:30 +0000},
  date-modified = {2013-02-25 14:04:40 +0000}
}

@article{JohnsonMurphy06,
  title = {Temporal Changes in the in the Tear Menisci Following a Blink},
  author = {Johnson, M. E. and Murphy, P. J.},
  year = {2006},
  journal = {Experimental Eye Research},
  volume = {83},
  pages = {517--525},
  doi = {10.1016/j.exer.2006.02.002}
}

@article{Johnstone_Effects_2014,
  title = {Effects of a {{Schlemm}} Canal Scaffold on Collector Channel Ostia in Human Anterior Segments},
  author = {Johnstone, Murray A and Saheb, Hady and Ahmed, Iqbal K and Samuelson, Thomas W and Schieber, Andrew T and Toris, Carol B},
  year = {2014},
  volume = {119},
  pages = {70--76},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2013.12.011},
  abstract = {This study evaluates the morphologic effect of the implantation of two different sizes of the Hydrus microstent on the outer wall of Schlemm's canal (SC) and collector channel (CC) ostia. Twelve human eyes were dissected at the equator removing the iris, lens, ciliary body and vitreous. The cornea was excised with a corneal trephine exposing a direct view of the angle while leaving the trabecular meshwork (TM) intact. The Hydrus delivery system was used to deliver microstents of 8 mm and 15 mm in length into SC. Following delivery, the tissues were immediately immersed in fixative. After tissue fixation, the microstents were gently lifted out of SC through the TM leaving a small slit opening in the TM. The slit opening was widened by gently dissecting the entire TM. Control eyes underwent dissection before fixation by gently removing the TM exposing the outer wall of SC. The tissues were prepared for scanning electron microscopy (SEM). The external wall of SC was imaged using SEM and were reviewed with particular attention focused on the distribution of irregular particulate matter (IPM), the shape of the CC ostia and the health of the SC endothelium. Three eyes received the 8 mm microstent, two the 15 mm microstent and 6 eyes served as controls. Five of the controls had reported histories of glaucoma while all other eyes were normal. All eyes showed evidence of removal of the trabecular meshwork revealing the external wall of SC. CCs were regularly visible in all eyes and were not obstructed, compressed or their margins disrupted. Nuclear profiles were oriented circumferentially in SC except at regions of CC ostia where they assumed a radial configuration oriented toward the lumen of the CC. The area of microstent contact with SC external wall was examined with SEM and a comparison made between the 8 and 15 mm microstent showing a smaller area of indentation with the 8 mm microstent. The indentations were generally free of particulate debris, were smooth and were devoid of nuclear profiles. In bridged areas adjacent to areas of microstent contact, CCs were identified, appearing patent and intact like those of the control eyes. The eyes receiving 8 mm and 15 mm Hydrus microstents both maintained CC ostia patency but a smaller area of external wall contact was evident from insertion of the 8 mm microstent.},
  pmid = {24374259}
}

@book{jolliffePrincipalComponentAnalysis2002,
  title = {Principal {{Component Analysis}}},
  author = {Jolliffe, I. T.},
  year = {2002},
  month = oct,
  edition = {2nd},
  publisher = {{Springer Science \& Business Media}},
  abstract = {Principal component analysis is central to the study of multivariate data. Although one of the earliest multivariate techniques it continues to be the subject of much research, ranging from new model- based approaches to algorithmic ideas from neural networks. It is extremely versatile with applications in many disciplines. The first edition of this book was the first comprehensive text written solely on principal component analysis. The second edition updates and substantially expands the original version, and is once again the definitive text on the subject. It includes core material, current research and a wide range of applications. Its length is nearly double that of the first edition. Researchers in statistics, or in other fields that use principal component analysis, will find that the book gives an authoritative yet accessible account of the subject. It is also a valuable resource for graduate courses in multivariate analysis. The book requires some knowledge of matrix algebra. Ian Jolliffe is Professor of Statistics at the University of Aberdeen. He is author or co-author of over 60 research papers and three other books. His research interests are broad, but aspects of principal component analysis have fascinated him and kept him busy for over 30 years.},
  isbn = {978-0-387-95442-4},
  langid = {english},
  keywords = {Mathematics / Probability & Statistics / General,Mathematics / Probability & Statistics / Multivariate Analysis,Mathematics / Probability & Statistics / Stochastic Processes}
}

@article{JonesMcElwain06,
  title = {The Effect of the Lipid Layer on Tear Film Behavior},
  author = {Jones, M. B. and McElwain, D. L. S. and Fulford, G. R. and Collins, M. J. and Roberts, A. P.},
  year = {2006},
  journal = {Bulletin of Mathematical Biology},
  volume = {68},
  pages = {1355--1381},
  doi = {10.1007/s11538-006-9105-9},
  date-added = {2013-02-13 14:02:48 +0000},
  date-modified = {2013-02-13 14:04:36 +0000}
}

@article{JonesPlease05,
  title = {Dynamics of Tear Film Deposition and Drainage},
  author = {Jones, M. B. and Please, C. P. and McElwain, D. L. S. and Fulford, G. R. and Roberts, A. P. and Collins, M. J.},
  year = {2005},
  volume = {22},
  pages = {265--288},
  date-added = {2013-02-13 13:59:19 +0000},
  date-modified = {2013-02-13 14:02:14 +0000}
}

@article{JossicLefevre09,
  title = {The Fluid Mechanics of Shear-Thinning Tear Substitutes},
  author = {Jossic, L. and Lefevre, P. and {de Loubens}, C. and Magnin, A. and Corre, C.},
  year = {2009},
  journal = {Journal of Non-Newtonian Fluid Mechanics},
  volume = {161},
  pages = {1--9},
  doi = {10.1016/j.jnnfm.2009.03.012},
  date-added = {2013-02-13 15:02:18 +0000},
  date-modified = {2013-02-13 15:03:48 +0000}
}

@article{kaiserMeanClusteringCoefficients2008,
  title = {Mean Clustering Coefficients: The Role of Isolated Nodes and Leafs on Clustering Measures for Small-World Networks},
  shorttitle = {Mean Clustering Coefficients},
  author = {Kaiser, Marcus},
  year = {2008},
  month = aug,
  journal = {arXiv:0802.2512 [physics, q-bio]},
  eprint = {0802.2512},
  primaryclass = {physics, q-bio},
  doi = {2008083003130700},
  urldate = {2022-04-26},
  abstract = {Many networks exhibit the small-world property of the neighborhood connectivity being higher than in comparable random networks. However, the standard measure of local neighborhood clustering is typically not defined if a node has one or no neighbors. In such cases, local clustering has traditionally been set to zero and this value influenced the global clustering coefficient. Such a procedure leads to underestimation of the neighborhood clustering in sparse networks. We propose to include \${\textbackslash}theta\$ as the proportion of leafs and isolated nodes to estimate the contribution of these cases and provide a formula for estimating a clustering coefficient excluding these cases from the Watts and Strogatz (1998 Nature 393 440-2) definition of the clustering coefficient. Excluding leafs and isolated nodes leads to values which are up to 140\% higher than the traditional values for the observed networks indicating that neighborhood connectivity is normally underestimated. We find that the definition of the clustering coefficient has a major effect when comparing different networks. For metabolic networks of 43 organisms, relations changed for 58\% of the comparisons when a different definition was applied. We also show that the definition influences small-world features and that the classification can change from non-small-world to small-world network. We discuss the use of an alternative measure, disconnectedness D, which is less influenced by leafs and isolated nodes.},
  archiveprefix = {arxiv},
  keywords = {Invalid DOI,Physics - Physics and Society,Quantitative Biology - Molecular Networks},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Kaiser-2008-Mean clustering coefficients.pdf;/Users/driscoll/Zotero/storage/RRKMBPJE/0802.html}
}

@article{Kakizaki_Punctal_2012,
  title = {Punctal and Canalicular Anatomy: {{Implications}} for Canalicular Occlusion in Severe Dry Eye},
  author = {Kakizaki, Hirohiko and Takahashi, Yasuhiro and Iwaki, Masayoshi and Nakano, Takashi and Asamoto, Ken and Ikeda, Hiroshi and Goto, Eiki and Selva, Dinesh and Leibovitch, Igal},
  year = {2012},
  volume = {153},
  number = {2},
  pages = {229-237.e1},
  issn = {0002-9394},
  doi = {10.1016/j.ajo.2011.07.010},
  abstract = {PurposeTo characterize the microscopic anatomy of the lacrimal punctum and canaliculi in relation to the tarsal plate, muscle of Riolan, and Horner muscle; and to report a novel technique to excise the horizontal canaliculus in severe dry eye patients.DesignObservational anatomic study and a retrospective case series.MethodsThe microscopic anatomy was studied in 86 eyelids of 25 cadavers (age range: 45--96 years, mean: 79.5 years). Surgery was performed on 18 canaliculi of 7 patients with dry eyes (age range: 37--69 years, mean: 59.9 years). In the microscopic study, 32 eyelids were incised sagittally, 38 eyelids were incised horizontally (1 mm from the eyelid margin), and 16 eyelids were incised parallel to the tarsal plate. All specimens were stained with Masson trichrome. In the surgical group, probe-guided horizontal canalicular excision with incision of the Horner muscle to the lateral edge of the lacrimal caruncle was performed. Both canalicular stumps were cauterized.ResultsIn the microscopic anatomic study, the punctum and the vertical canaliculus were part of the tarsal plate with the muscle of Riolan, whereas the horizontal canaliculus was surrounded by the Horner muscle. In the surgical group, all the operated canaliculi were completely occluded without recanalization 12 months postoperatively. No complications were recorded.ConclusionsBased on microscopic anatomic findings that the lacrimal punctum and the vertical canaliculus are part of the tarsal plate, and that the horizontal canaliculus is surrounded by the Horner muscle, excision of the horizontal canaliculus may be an effective technique to treat patients with severe dry eyes.},
  pmid = {21982102}
}

@article{Kaminer_Characterizing_2011,
  title = {Characterizing the Spontaneous Blink Generator: An Animal Model.},
  author = {Kaminer, Jaime and Powers, Alice S and Horn, Kyle G and Hui, Channing and Evinger, Craig},
  year = {2011},
  volume = {31},
  number = {31},
  pages = {11256--67},
  issn = {0270-6474},
  doi = {10.1523/jneurosci.6218-10.2011},
  abstract = {Although spontaneous blinking is one of the most frequent human movements, little is known about its neural basis. We developed a rat model of spontaneous blinking to identify and better characterize the spontaneous blink generator. We monitored spontaneous blinking for 55 min periods in normal conditions and after the induction of mild dry eye or dopaminergic drug challenges. The normal spontaneous blink rate was 5.3  0.3 blinks/min. Dry eye or 1 mg/kg apomorphine significantly increased and 0.1 mg/kg haloperidol significantly decreased the blink rate. Additional analyses revealed a consistent temporal organization to spontaneous blinking with a median 750 s period that was independent of the spontaneous blink rate. Dry eye and dopaminergic challenges significantly modified the regularity of the normal pattern of episodes of frequent blinking interspersed with intervals having few blinks. Dry eye and apomorphine enhanced the regularity of this pattern, whereas haloperidol reduced its regularity. The simplest explanation for our data is that the spinal trigeminal complex is a critical element in the generation of spontaneous blinks, incorporating reflex blinks from dry eye and indirect basal ganglia inputs into the blink generator. Although human subjects exhibited a higher average blink rate (17.6  2.4) than rats, the temporal pattern of spontaneous blinking was qualitatively similar for both species. These data demonstrate that rats are an appropriate model for investigating the neural basis of human spontaneous blinking and suggest that the spinal trigeminal complex is a major element in the spontaneous blink generator.},
  pmcid = {PMC3156585},
  pmid = {21813686}
}

@article{KarniadakisPhysicsinformedMachine2021,
  title = {Physics-Informed Machine Learning},
  author = {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
  year = {2021},
  month = jun,
  journal = {Nature Reviews Physics},
  volume = {3},
  number = {6},
  pages = {422--440},
  publisher = {{Nature Publishing Group}},
  issn = {2522-5820},
  doi = {10.1038/s42254-021-00314-5},
  urldate = {2023-12-12},
  abstract = {Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.},
  copyright = {2021 Springer Nature Limited},
  langid = {english},
  keywords = {_tablet,Applied mathematics,Computational science},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Karniadakis et al_2021_Physics-informed machine learning.pdf}
}

@inproceedings{karpathyLargescaleVideoClassification2014,
  title = {Large-Scale Video Classification with Convolutional Neural Networks},
  booktitle = {Proceedings of the {{IEEE}} Conference on {{Computer Vision}} and {{Pattern Recognition}}},
  author = {Karpathy, Andrej},
  year = {2014},
  pages = {1725--1732},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Karpathy_2014_Large-scale video classification with convolutional neural networks.pdf}
}

@article{kassamFourthOrderTimeSteppingStiff2005,
  title = {Fourth-{{Order Time-Stepping}} for {{Stiff PDEs}}},
  author = {Kassam, Aly-Khan and Trefethen, Lloyd N.},
  year = {2005},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {26},
  number = {4},
  pages = {1214--1233},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/S1064827502410633},
  urldate = {2022-11-22},
  langid = {english}
}

@article{Kaufman1978,
  title = {A Method for Separable Nonlinear Least Squares Problems with Separable Nonlinear Equality Constraints},
  author = {Kaufman, Linda and Pereyra, Victor},
  year = {1978},
  month = feb,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {15},
  number = {1},
  pages = {12--20},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/0715002},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Kaufman_Pereyra_1978_A method for separable nonlinear least squares problems with separable.pdf}
}

@incollection{keenerBlood2009,
  title = {Blood},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {627--681},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_3},
  urldate = {2020-01-02},
  abstract = {Blood is composed of two major ingredients: the liquid blood plasma and several types of cells suspended within the plasma. The cells constitute approximately 40\% of the total blood volume and are grouped into three major categories: erythrocytes (red blood cells), leukocytes (white blood cells), and thrombocytes (platelets). The red blood cells remain within the blood vessels, and their function is to transport oxygen and carbon dioxide. The white blood cells fight infection, and thus are able to migrate out of the blood vessels and into the tissues. Platelets are not complete cells, but are small detached fragments of much larger cells called megakaryocytes. Their principal function is to aid in blood clotting.Leukocytes themselves are subdivided into a number of categories: granulocytes (approximately 65\%), lymphocytes(30\%),monocytes(5\%), and natural killer cells. Gran-ulocytes are further subdivided into neutrophils (95\%), eosinophils, (4\%) and basophils (1\%). Neutrophils phagocytose (i.e., ingest) and destroy small foreign bodies such as bacteria, basophils help mediate inflammatory reactions by secreting histamine, while eosinophils help to destroy parasites and modulate allergic responses.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Chronic Myelogenous Leukemia,Hopf Bifurcation,Phase Portrait,Saturation Curve,Stable Steady State},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_Blood.pdf}
}

@incollection{keenerCirculatorySystem2009,
  title = {The {{Circulatory System}}},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {471--522},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_1},
  urldate = {2020-01-02},
  abstract = {The circulatory system forms a closed loop for the flow of blood that carries oxygen from the lungs to the tissues of the body and carries carbon dioxide from the tissues back to the lungs (Figs. 11.1 and 11.2). There are two pumps to overcome the resistance and maintain a constant flow. The left heart receives oxygen-rich blood from the lungs and pumps this blood into the systemic arteries. The systemic arteries form a tree of progressively smaller vessels, beginning with the aorta, branching to the small arteries, then to the arterioles, and finally to the capillaries. The exchange of gases takes place in the capillaries. Leaving the systemic capillaries, the blood enters the systemic veins, through which it flows in vessels of progressively increasing size toward the right heart. The systemic veins consist of venules, small veins, and the venae cavae. The right heart pumps blood into the pulmonary arteries, which form a tree that distributes the blood to the lungs. The smallest branches of this tree are the pulmonary capillaries, where carbon dioxide leaves and oxygen enters the blood. Leaving the pulmonary capillaries, the oxygenated blood is collected by the pulmonary veins, through which it flows back to the left heart. It takes about a minute for a red blood cell to complete this circuit.While there is an apparent structural symmetry between the pulmonary and sys temic circulations, there are significant quantitative differences in pressure and blood volume. Nevertheless, the output of the right and left sides of the heart must always balance, even though the cardiac output, or total amount of blood pumped by the heart, varies widely in response to the metabolic needs of the body. One of the goals of this chapter is to understand how the cardiac output is determined and regulated in re sponse to the metabolic needs of the body. Questions of this nature have been studied for many years, and many books have been written on the subject (see, for example, Guyton, 1963, or Reeve and Guyton, 1967. A more recent book that discusses several mathematical models of the blood and circulatory system is Ottesen et al., 2004). Here, we consider only the simplest models of the control of cardiac output. Figure 11.1 Schematic diagram of the circulatory system, showing the systemic and pulmonary circulations, the chambers of the heart, and the distribution of blood volume throughout the system. (Guyton and Hall, 1996, Fig. 14-1, p. 162.)},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Arterial Pressure,Arterial Pulse,Cardiac Output,Left Heart,Pressure Drop},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_The Circulatory System.pdf}
}

@incollection{keenerEndocrineSystem2009,
  title = {The {{Endocrine System}}},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {773--819},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_6},
  urldate = {2020-01-02},
  abstract = {Hormones control a vast array of bodily functions, including sexual reproduction and sexual development, whole-body metabolism, blood glucose levels, plasma Ca2+ concentration, and growth. Hormones are produced in, and released from, diverse places, including the hypothalamus and pituitary, the adrenal gland, the thyroid gland, the testes and ovaries, and the pancreas, and they act on target cells that are often at a considerable physical distance from the site of production. Since they are carried in the bloodstream, hormones are capable of a diffuse whole-body effect, as well as a localized effect, depending on the distance between the production site and the site of action. In many ways the endocrine system is similar to the nervous system, in that it is an intercellular signaling system in which cells communicate via cellular secretions. Hormones are, in a sense, neurotransmitters that are capable of acting on target cells throughout the body, or conversely, neurotransmitters can be thought of as hormones with a localized action.Despite the analogy with neural transmission, there are significant differences between the endocrine and nervous systems that have important ramifications for mathematical modeling. Not only is the endocrine system extremely complicated, but the data that are presently obtainable are less susceptible to quantitative analysis than, say, voltage measurements in neurons. Further, the distance between the sites of hormone production and action, and the complexities inherent in the mode of transport, make it extraordinarily difficult to construct quantitative models of hormonal control. For these reasons, models in endocrinology are less mechanistic than many of the models presented elsewhere in this book, and thus, in some ways, less realistic.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Coordinate Hyperplane,Endocrine System,GnRH Secretion,Luteinizing Hormone,Pulsatile Secretion},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_The Endocrine System.pdf}
}

@incollection{keenerGastrointestinalSystem2009,
  title = {The {{Gastrointestinal System}}},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {851--891},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_8},
  urldate = {2020-01-02},
  abstract = {Although the detailed structure ofthe gastrointestinal tract varies from region toregion, there is a common basic structure, outlined in the cross-section shown in Fig. 18.1. It is surrounded by a number of heavily innervated muscle layers, arranged both circularly and longitudinally. Contraction of these muscle layers can mix the contents of the tract and move food in a controlled manner in the appropriate direction. Beneath the muscle layer is the submucosa, consisting mostly of connective tissue, and beneath that is a thin layer of smooth muscle called the muscularis mucosae. Finally, there is the lamina propria, a layer of connective tissue containing capillaries and many kinds of secreting glands, and then a layer of epithelial cells, whose nature varies in different regions of the tract.In addition to the muscle layers, there are two principal layers of neurons; the myenteric plexus, between the longitudinal and circular muscle layers, and the sub-mucosal plexus, which lies in the submucosa. In general, stimulation of the myenteric plexus increases the rate and intensity of the rhythmic contractions of the gut, and increases the velocity of conduction of waves of excitation along the gut wall. The sub-mucosal plexus is mainly sensory, receiving signals from stretch receptors in the gut wall, and from the gut epithelium. The gastrointestinal tract is also heavily innervated, which can control the activity of the entire gut, or part of it.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Corner Layer,Couple Oscillator,Mucus Layer,Outer Solution,Phase Equation},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_The Gastrointestinal System.pdf}
}

@incollection{keenerHeart2009,
  title = {The {{Heart}}},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {523--626},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_2},
  urldate = {2020-01-02},
  abstract = {Of all of the human organs, the heart is in some sense the simplest. All it has to do is pump blood by contracting and expanding about 2.5 billion times during the lifetime of its owner. The heart is also one of the most studied organs of the body, probably because heart failure, either mechanical or electrical, remains the number one cause of death in the Western world.The heart is a four-chambered pump, consisting of two pumps arranged in series. As is described in Chapter 11, one pump (the right heart) drives blood through the lungs (the pulmonary circulation) and then back to the heart, while the other pump (the left heart) drives the oxygenated blood around the body (the systemic circulation). Coordination of the mechanical activity of the heart is provided by an electrical signal, which is the topic of study in this chapter.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Basic Cycle Length,Bidomain Model,Diastolic Interval,Oscillatory Cell,Transmembrane Current},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_The Heart.pdf}
}

@incollection{keenerInnerEar2009,
  title = {The {{Inner Ear}}},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {943--974},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_10},
  urldate = {2020-01-02},
  abstract = {The mammalian ear has three major components: the outer, middle, and inner ears (Fig. 20.1A). The outer ear consists of a cartilaginous flange, the pinna, incorporating a resonant cavity that connects to the ear canal and finally to the tympanic membrane. It performs an initial filtering of the sound waves, increasing the sound pressure gain at the tympanic membrane in the 2 to 7 kHz region. It also aids sound localization. Bats, for example, have highly developed pinnae, with a high degree of directional selectivity. Although less efficient in humans, the outer ear accounts for our ability to distinguish whether sounds come from above or below, in front or behind.The function of the middle ear is to transmit the sound vibrations from the tympanic membrane to the cochlea. Because of the much higher impedance of the cochlear fluid, the middle ear also functions as an impedance-matching device, focusing the energy of the tympanic membraneon the oval window of the cochlea. Ifnot for impedance matching, much of the energy of the sound waves in air would be reflected by the cochlear fluid. This impedance matching is carried out by the ossicles, three small bones, the malleus, incus, and stapes, that connect the tympanic membrane to the oval window. The tympanic membrane has a much higher surface area than the oval window, and the ossicles act as levers that increase the force at the expense of velocity, resulting in the required concentration of energy at the oval window.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Basilar Membrane,Hair Cell,Hopf Bifurcation,Outer Hair Cell,Tympanic Membrane},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_The Inner Ear.pdf}
}

@incollection{keenerMuscle2009,
  title = {Muscle},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {717--772},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_5},
  urldate = {2020-01-02},
  abstract = {Muscle cells resemble nerve cells in their ability to conduct action potentials along their membrane surfaces. In addition, however, muscle cells have the ability to trans late the electrical signal into a mechanical contraction, which enables the muscle cell to perform work. There are three types of muscle cells; skeletal muscle, which moves the bones of the skeleton at the joints, cardiac muscle, whose contraction enables the heart to pump blood, and smooth muscle, which is located in the walls of blood vessels and contractile visceral organs. Skeletal and cardiac muscle cells have a banded appearance under a microscope, with alternating light and dark bands, and thus they are called stri ated muscle. They have similar (though not identical) contractile mechanisms. Smooth muscle, on the other hand, is not striated, and its physiology is considerably different from the other two types of muscle.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Contractile Element,Elastic Element,Molecular Motor,Myosin Light Chain Kinase,Velocity Curve},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_Muscle.pdf}
}

@incollection{keenerRenalPhysiology2009,
  title = {Renal {{Physiology}}},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {821--850},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_7},
  urldate = {2020-01-02},
  abstract = {The kidneys perform two major functions. First, they excrete most of the end prod ucts of bodily metabolism, and second, they control the concentrations of most of the constituents of the body fluids. The main goal of this chapter is to gain some under standing of the processes by which the urine is formed and waste products removed from the bloodstream. The control of the constituents of the body fluids is discussed only secondarily.The primary operating unit of the kidney is called a nephron, of which there are about a million in each kidney (Figs. 17.1 and 17.2). Each nephron is capable of form ing urine by itself. The entrance of blood into the nephron is by the afferent arteriole, located in the renal cortex, and the tubules of the nephron and the associated peritubu lar capillaries extend deep into the renal medulla. The principal functional units of the nephron are the glomerulus, through which fluid is filtered from the blood; the juxta-glomerular apparatus, by which glomerular flow is controlled; and the long tubule, in which the filtered fluid is converted into urine.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Afferent Arteriole,Nephrogenic Diabetes Insipidus,Osmotic Pressure,Proximal Tubule,Pump Rate},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_Renal Physiology.pdf}
}

@incollection{keenerRespiration2009,
  title = {Respiration},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {683--716},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_4},
  urldate = {2020-01-02},
  abstract = {The respiratory system is responsible for gas transfer between the tissues and the out side air. Carbon dioxide that is produced by metabolism in the tissues must be moved by the blood to the lungs, where it is lost to the outside air, and oxygen that is supplied to the tissues must be extracted from the outside air by the lungs.The nose, mouth, pharynx, larynx, trachea, broncheal trees, lung air sacs and res piratory muscles are the structures that make up the respiratory system (Fig. 14.1). The nasal cavities are specialized for warming and moistening inspired air and for fil tering the air to remove large particles. The larynx, or `` voice box,'' contains the vocal folds that vibrate as air passes between them to produce sounds. Below the larynx the respiratory system divides into airways and alveoli. The airways consist of a series of branching tubes that become smaller in diameter and shorter in length as they extend deeper into the lung tissue. They terminate after about 23 levels of branches in blind sacs, the alveoli. The terminal bronchioles represent the deepest point of the bronchial tree to which inspired air can penetrate by flowing along a pressure gradient. Beyond the terminal bronchioles, simple diffusion along concentration gradients is primarily responsible for the movement of gases.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Alveolar Carbon Dioxide,Alveolar Partial Pressure,Perfusion Ratio,Terminal Bronchiole,Ventilation Rate},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_Respiration.pdf}
}

@incollection{keenerRetinaVision2009,
  title = {The {{Retina}} and {{Vision}}},
  booktitle = {Mathematical {{Physiology}}: {{II}}: {{Systems Physiology}}},
  editor = {Keener, James and Sneyd, James},
  year = {2009},
  series = {Interdisciplinary {{Applied Mathematics}}},
  pages = {893--942},
  publisher = {{Springer}},
  address = {{New York, NY}},
  doi = {10.1007/978-0-387-79388-7_9},
  urldate = {2020-01-02},
  abstract = {The visual system is arguably the most important system through which our brain gathers information about our surroundings, and forms one of our most complex physiological systems. In vertebrates, light entering the eye through the lens is detected by photosensitive pigment in the photoreceptors, converted to an electrical signal, and passed back through the layers of the retina to the optic nerve, and from there, through the visual nuclei, to the visual cortex of the brain. At each stage, the signal passes through an elaborate system of biochemical and neural feedbacks, the vast majority of which are poorly, if at all, understood.Although there is great variety in detail between the eyes of different species, a number of important features are qualitatively conserved. Perhaps the most striking of these features is the ability of the visual system to adapt to background light. As the background light level increases, the sensitivity of the visual system is decreased, which allows for operation over a huge range of light levels. From a dim starlit night to a bright sunny day, the background light level varies over 10 orders of magnitude (Hood and Finkelstein, 1986), and yet our eyes continue to operate across all these levels without becoming saturated with light. The visual system accomplishes this by ensuring that its sensitivity varies approximately inversely with the background light, a relationship known as Weber's law (Weber, 1834) and one that we discuss in detail in the next section.},
  isbn = {978-0-387-79388-7},
  langid = {english},
  keywords = {Bipolar Cell,Ganglion Cell,Guanylate Cyclase,Horseshoe Crab,Lateral Inhibition},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/2009_The Retina and Vision.pdf}
}

@book{keenerSystemsPhysiology2009,
  title = {Systems Physiology},
  author = {Keener, James and Sneyd, James and Keener, James},
  year = {2009},
  series = {Mathematical Physiology},
  edition = {2. ed},
  number = {James Keener; James Sneyd ; 2},
  publisher = {{Springer}},
  address = {{New York, NY}},
  isbn = {978-0-387-79388-7 978-0-387-79387-0},
  langid = {english},
  annotation = {OCLC: 552301677},
  file = {/Users/driscoll/Dropbox/library/Springer/2009/Keener et al_2009_Systems physiology2.pdf}
}

@article{KeithFractionalPDE2021,
  title = {A Fractional {{PDE}} Model for Turbulent Velocity Fields near Solid Walls},
  author = {Keith, Brendan and Khristenko, Ustim and Wohlmuth, Barbara},
  year = {2021},
  month = jun,
  journal = {Journal of Fluid Mechanics},
  volume = {916},
  pages = {A21},
  publisher = {{Cambridge University Press}},
  issn = {0022-1120, 1469-7645},
  doi = {10.1017/jfm.2021.182},
  urldate = {2023-04-12},
  abstract = {, This paper presents a class of turbulence models written in terms of fractional partial differential equations (FPDEs) with stochastic loads. Every solution of these FPDE models is an incompressible velocity field and the distribution of solutions is Gaussian. Interaction of the turbulence with solid walls is incorporated through the enforcement of various boundary conditions. The various boundary conditions deliver extensive flexibility in the near-wall statistics that can be modelled. Reproduction of both fully developed shear-free and uniform shear boundary layer turbulence are highlighted as two simple physical applications; the first of which is also directly validated with experimental data. The rendering of inhomogeneous synthetic turbulence inlet boundary conditions is an additional application, motivated by contemporary numerical wind tunnel simulations. Calibration of model parameters and efficient numerical methods are also conferred upon.},
  langid = {english},
  keywords = {computational methods,turbulence simulation,turbulence theory},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Keith et al_2021_A fractional PDE model for turbulent velocity fields near solid walls.pdf}
}

@article{Keller_Extracellular_2008,
  title = {Extracellular Matrix Turnover and Outflow Resistance.},
  author = {Keller, Kate E and Aga, Mini and Bradley, John M and Kelley, Mary J and Acott, Ted S},
  year = {2008},
  volume = {88},
  number = {4},
  pages = {676--82},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2008.11.023},
  abstract = {Normal homeostatic adjustment of elevated intraocular pressure (IOP) involves remodeling the extracellular matrix (ECM) of the trabecular meshwork (TM). This entails sensing elevated IOP, releasing numerous activated proteinases to degrade existing ECM and concurrent biosynthesis of replacement ECM components. To increase or decrease IOP, the quantity, physical properties and/or organization of new components should be somewhat different from those replaced in order to modify outflow resistance. ECM degradation and replacement biosynthesis in the outflow pathway must be tightly controlled and focused to retain the complex structural organization of the tissue. Recently identified podosome- or invadopodia-like structures (PILS) may aid in the focal degradation of ECM and organization of replacement components.},
  pmcid = {PMC2700052},
  pmid = {19087875}
}

@book{KelleyIterativeMethods1995,
  title = {Iterative {{Methods}} for {{Linear}} and {{Nonlinear Equations}}},
  author = {Kelley, C. T.},
  year = {1995},
  month = jan,
  publisher = {{SIAM}},
  abstract = {Linear and nonlinear systems of equations are the basis for many, if not most, of the models of phenomena in science and engineering, and their efficient numerical solution is critical to progress in these areas. This is the first book to be published on nonlinear equations since the mid-1980s. Although it stresses recent developments in this area, such as Newton-Krylov methods, considerable material on linear equations has been incorporated. This book focuses on a small number of methods and treats them in depth. The author provides a complete analysis of the conjugate gradient and generalized minimum residual iterations as well as recent advances including Newton-Krylov methods, incorporation of inexactness and noise into the analysis, new proofs and implementations of Broyden\&\#39;s method, and globalization of inexact Newton methods.},
  isbn = {978-0-89871-352-7},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / Differential Equations / General,Mathematics / Linear & Nonlinear Programming,Mathematics / Numerical Analysis,Mathematics / Optimization},
  file = {/Users/driscoll/Dropbox/library/Book/Kelley_1995_Iterative methods for linear and nonlinear equations.pdf}
}

@article{kermackContributionMathematicalTheory1927,
  title = {A Contribution to the Mathematical Theory of Epidemics},
  author = {Kermack, William Ogilvy and McKendrick, A. G. and Walker, Gilbert Thomas},
  year = {1927},
  month = aug,
  journal = {Proceedings of the Royal Society of London. Series A, Containing Papers of a Mathematical and Physical Character},
  volume = {115},
  number = {772},
  pages = {700--721},
  publisher = {{Royal Society}},
  doi = {10.1098/rspa.1927.0118},
  urldate = {2020-06-18},
  abstract = {(1) One of the most striking features in the study of epidemics is the difficulty of finding a causal factor which appears to be adequate to account for the magnitude of the frequent epidemics of disease which visit almost every population. It was with a view to obtaining more insight regarding the effects of the various factors which govern the spread of contagious epidemics that the present investigation was undertaken. Reference may here be made to the work of Ross and Hudson (1915-17) in which the same problem is attacked. The problem is here carried to a further stage, and it is considered from a point of view which is in one sense more general. The problem may be summarised as follows: One (or more) infected person is introduced into a community of individuals, more or less susceptible to the disease in question. The disease spreads from the affected to the unaffected by contact infection. Each infected person runs through the course of his sickness, and finally is removed from the number of those who are sick, by recovery or by death. The chances of recovery or death vary from day to day during the course of his illness. The chances that the affected may convey infection to the unaffected are likewise dependent upon the stage of the sickness. As the epidemic spreads, the number of unaffected members of the community becomes reduced. Since the course of an epidemic is short compared with the life of an individual, the population may be considered as remaining constant, except in as far as it is modified by deaths due to the epidemic disease itself. In the course of time the epidemic may come to an end. One of the most important probems in epidemiology is to ascertain whether this termination occurs only when no susceptible individuals are left, or whether the interplay of the various factors of infectivity, recovery and mortality, may result in termination, whilst many susceptible individuals are still present in the unaffected population. It is difficult to treat this problem in its most general aspect. In the present communication discussion will be limited to the case in which all members of the community are initially equally susceptible to the disease, and it will be further assumed that complete immunity is conferred by a single infection.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Kermack_McKendrick_Walker-1927-A contribution to the mathematical theory of epidemics.pdf;/Users/driscoll/Zotero/storage/S9NEPI6U/rspa.1927.html}
}

@article{KerzmanNumericalConformal1986,
  title = {Numerical Conformal Mapping via the {{Szeg{\"o}}} Kernel},
  author = {Kerzman, Norberto and Trummer, Manfred R.},
  year = {1986},
  month = feb,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {14},
  number = {1},
  pages = {111--123},
  issn = {0377-0427},
  doi = {10.1016/0377-0427(86)90133-0},
  urldate = {2019-11-18},
  abstract = {A new method to compute the Riemann mapping function is numerically implemented and tested on examples. The method expresses the Szeg{\"o} kernel as the solution of a second-kind integral equation. The equation has its origin in an earlier non-numerical work of Stein and one of the authors [8]. The experimental results show the algorithm to be effective and stable.},
  langid = {english},
  keywords = {Conformal mapping,integral equations,Szego kernel},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Kerzman_Trummer_1986_Numerical conformal mapping via the Szegö kernel.pdf;/Users/driscoll/Dropbox/library/Journal Article/Kerzman_Trummer_1986_Numerical conformal mapping via the Szegö kernel3.pdf;/Users/driscoll/Zotero/storage/Z3TU8WRX/0377042786901330.html}
}

@misc{Ketelaar_Tear_2015,
  title = {Tear Film Dynamics around a Rigid Model Blob},
  author = {Ketelaar, Christiaan and Zhong, Lan and Braun, Richard J and Driscoll, Tobin A and E., P., King-Smith and Begley, Carolyn G.},
  year = {2015},
  copyright = {All rights reserved}
}

@inproceedings{KetelaarTearFilm2015,
  title = {Tear {{Film Dynamics Around}} a {{Rigid Model Blob}}},
  booktitle = {{{APS Meeting Abstracts}}},
  author = {Ketelaar, Christiaan and Zhong, Lan and Braun, {\relax RJ} and Driscoll, {\relax TA} and {King-Smith}, {\relax PE} and Begley, {\relax CG}},
  year = {2015},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{khngEvaluationRelationship2008,
  title = {Evaluation of the Relationship between Corneal Diameter and Lens Diameter},
  author = {Khng, Christopher and Osher, Robert H.},
  year = {2008},
  month = mar,
  journal = {Journal of Cataract \& Refractive Surgery},
  volume = {34},
  number = {3},
  pages = {475--479},
  issn = {0886-3350},
  doi = {10.1016/j.jcrs.2007.10.043},
  urldate = {2021-03-04},
  abstract = {PURPOSE:~         To investigate the relationship between corneal diameter (white to white) (WTW) and the dimensions of the crystalline lens.         SETTING:~         Private practice, Cincinnati, Ohio, USA.         METHODS:~         Human cadaver eyes were oriented to allow caliper measurements of the horizontal and vertical corneal diameters (WTW). Globes were sectioned and reoriented so the horizontal and vertical measurements of the crystalline lens were recorded and statistically analyzed.         RESULTS:~         The mean horizontal corneal diameter was 11.46 mm, approximately 0.8 mm greater than the mean vertical corneal diameter of 10.63 mm. The mean horizontal crystalline lens diameter was 9.28 mm, nearly identical to the mean vertical diameter of 9.30 mm. The correlation between the mean corneal diameter and mean lens diameter was weak, although it was significant. There was no correlation between horizontal dimensions.         CONCLUSION:~         It was not possible to predict the dimensions of the human crystalline lens using calipers to measure the WTW corneal diameter.},
  langid = {american},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Khng_Osher_2008_Evaluation of the relationship between corneal diameter and lens diameter.pdf;/Users/driscoll/Zotero/storage/9UIVY2RS/Evaluation_of_the_relationship_between_corneal.38.html}
}

@misc{KidgerNeuralDifferential2022,
  title = {On {{Neural Differential Equations}}},
  author = {Kidger, Patrick},
  year = {2022},
  month = feb,
  number = {arXiv:2202.02435},
  eprint = {2202.02435},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2202.02435},
  urldate = {2023-12-12},
  abstract = {The conjoining of dynamical systems and deep learning has become a topic of great interest. In particular, neural differential equations (NDEs) demonstrate that neural networks and differential equation are two sides of the same coin. Traditional parameterised differential equations are a special case. Many popular neural network architectures, such as residual networks and recurrent networks, are discretisations. NDEs are suitable for tackling generative problems, dynamical systems, and time series (particularly in physics, finance, ...) and are thus of interest to both modern machine learning and traditional mathematical modelling. NDEs offer high-capacity function approximation, strong priors on model space, the ability to handle irregular data, memory efficiency, and a wealth of available theory on both sides. This doctoral thesis provides an in-depth survey of the field. Topics include: neural ordinary differential equations (e.g. for hybrid neural/mechanistic modelling of physical systems); neural controlled differential equations (e.g. for learning functions of irregular time series); and neural stochastic differential equations (e.g. to produce generative models capable of representing complex stochastic dynamics, or sampling from complex high-dimensional distributions). Further topics include: numerical methods for NDEs (e.g. reversible differential equations solvers, backpropagation through differential equations, Brownian reconstruction); symbolic regression for dynamical systems (e.g. via regularised evolution); and deep implicit models (e.g. deep equilibrium models, differentiable optimisation). We anticipate this thesis will be of interest to anyone interested in the marriage of deep learning with dynamical systems, and hope it will provide a useful reference for the current state of the art.},
  archiveprefix = {arxiv},
  keywords = {_tablet,Computer Science - Machine Learning,Mathematics - Classical Analysis and ODEs,Mathematics - Dynamical Systems,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Kidger_2022_On Neural Differential Equations.pdf;/Users/driscoll/Zotero/storage/RTGBJW6K/2202.html}
}

@article{Kiel_Ciliary_2011,
  title = {Ciliary Blood Flow and Aqueous Humor Production},
  author = {Kiel, J.W. and Hollingsworth, M and Rao, R and Chen, M and Reitsamer, H.A.},
  year = {2011},
  volume = {30},
  number = {1},
  pages = {1--17},
  issn = {1350-9462},
  doi = {10.1016/j.preteyeres.2010.08.001},
  abstract = {Aqueous humor production is a metabolically active process sustained by the delivery of oxygen and nutrients and removal of metabolic waste by the ciliary circulation. This article describes our investigations into the relationship between ciliary blood flow and aqueous humor production. The results presented indicate that there is a dynamic relationship between ciliary blood flow and aqueous humor production, with production being blood flow independent above a critical level of perfusion, and blood flow dependent below it. The results also show that the plateau portion of the relationship shifts up or down depending on the level of secretory stimulation or inhibition, and that oxygen is one critical factor provided by ciliary blood flow. Also presented is a theoretical model of ocular hydrodynamics incorporating these new findings.},
  pmcid = {PMC3010334},
  pmid = {20801226}
}

@article{Kim_Extended_2008,
  title = {Extended Delivery of Ophthalmic Drugs by Silicone Hydrogel Contact Lenses},
  author = {Kim, Jinah and Conway, Anthony and Chauhan, Anuj},
  year = {2008},
  volume = {29},
  number = {14},
  pages = {2259--2269},
  issn = {0142-9612},
  doi = {10.1016/j.biomaterials.2008.01.030},
  abstract = {We developed extended wear silicone hydrogel soft contact lenses that deliver ophthalmic drugs for an extended period of time ranging from weeks to months. Silicone hydrogels comprising of N,N-dimethylacrylamide, 3-methacryloxypropyltris(trimethylsiloxy)silane, bis-alpha,omega-(methacryloxypropyl) polydimethylsiloxane, 1-vinyl-2-pyrrolidone, and ethylene glycol dimethacrylate were prepared with varying ratios of monomers and transport of three different ophthalmic drugs, timolol, dexamethasone, and dexamethasone 21-acetate was explored. All the silicone hydrogels of 0.1mm thickness exhibit diffusion limited transport and extended release varying 20 days up to more than three months depending on the compositions of hydrophobic and hydrophilic components of silicone hydrogels. Also, there are multiple time scales in transport of at least certain molecules, which is perhaps due to the complex microstructure of these gels. The mechanical and physical properties of lenses such as ion permeability, equilibrium water content, transparency, and surface contact angles of some of the gels are suitable for contact lens application.},
  pmid = {18289662}
}

@article{KimProtectionCorneal2022,
  title = {Protection against Corneal Hyperosmolarity with Soft-Contact-Lens Wear},
  author = {Kim, Young Hyun and Nguyen, Thien and Lin, Meng C. and Peng, Cheng-Chun and Radke, Clayton J.},
  year = {2022},
  month = mar,
  journal = {Progress in Retinal and Eye Research},
  volume = {87},
  pages = {101012},
  issn = {13509462},
  doi = {10.1016/j.preteyeres.2021.101012},
  urldate = {2022-05-09},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Kim et al_2022_Protection against corneal hyperosmolarity with soft-contact-lens wear.pdf}
}

@article{KimStiffNeural2021,
  title = {Stiff Neural Ordinary Differential Equations},
  author = {Kim, Suyong and Ji, Weiqi and Deng, Sili and Ma, Yingbo and Rackauckas, Christopher},
  year = {2021},
  month = sep,
  journal = {Chaos: An Interdisciplinary Journal of Nonlinear Science},
  volume = {31},
  number = {9},
  pages = {093122},
  issn = {1054-1500, 1089-7682},
  doi = {10.1063/5.0060697},
  urldate = {2023-11-02},
  abstract = {Neural Ordinary Differential Equations (ODEs) are a promising approach to learn dynamical models from time-series data in science and engineering applications. This work aims at learning neural ODEs for stiff systems, which are usually raised from chemical kinetic modeling in chemical and biological systems. We first show the challenges of learning neural ODEs in the classical stiff ODE systems of Robertson's problem and propose techniques to mitigate the challenges associated with scale separations in stiff systems. We then present successful demonstrations in stiff systems of Robertson's problem and an air pollution problem. The demonstrations show that the usage of deep networks with rectified activations, proper scaling of the network outputs as well as loss functions, and stabilized gradient calculations are the key techniques enabling the learning of stiff neural ODEs. The success of learning stiff neural ODEs opens up possibilities of using neural ODEs in applications with widely varying time-scales, such as chemical dynamics in energy conversion, environmental engineering, and life sciences.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Kim et al_2021_Stiff neural ordinary differential equations.pdf}
}

@article{King-Smith_Four_2013,
  title = {Four Characteristics and a Model of an Effective Tear Film Lipid Layer ({{TFLL}})},
  author = {P, Ewen, King-Smith and Bailey, Melissa D and Braun, Richard J},
  year = {2013},
  volume = {11},
  number = {4},
  pages = {236--245},
  issn = {1542-0124},
  doi = {10.1016/j.jtos.2013.05.003},
  abstract = {It is proposed that a normal, effective tear film lipid layer (TFLL) should have the following four characteristics: 1) high evaporation resistance to prevent water loss and consequent hyperosmolarity; 2) respreadability, so it will return to its original state after the compression-expansion cycle of the blink; 3) fluidity sufficient to avoid blocking secretion from meibomian glands; 4) gel-like and incompressible structure that can resist forces that may tend to disrupt it. These characteristics tend to be incompatible; for example, lipids that form good evaporation barriers tend to be disrupted by compression-expansion cycles. It is noted that clues about the function and organization of the TFLL can be obtained by comparison with other biological lipid layers, such as lung surfactant and the lipid evaporation barrier of the skin. In an attempt to satisfy the conflicting characteristics, a ``multilamellar sandwich model'' of the TFLL is proposed, having features in common with the skin evaporation barrier.},
  pmid = {24112227}
}

@article{King-SmithFink06,
  title = {Interferometric Imaging of the Full Thickness of the Precorneal Tear Film},
  author = {{King-Smith}, P. E. and Fink, B. A. and Nichols, J. J. and Nichols, K. K. and Hill, R. M.},
  year = {2006},
  journal = {Journal of the Optical Society of America A, Optics and Image Science},
  volume = {23},
  pages = {2097--2104},
  doi = {10.1364/josaa.23.002097}
}

@article{King-SmithFink09,
  title = {The Contribution of Lipid Layer Movement to Tear Film Thinning and Breakup},
  author = {{King-Smith}, P. E. and Fink, B. A. and Nichols, J. J. and Nichols, K. K. and Braun, R. J. and McFadden, G. B.},
  year = {2009},
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {50},
  pages = {2747--2756},
  doi = {10.1167/iovs.08-2459},
  date-added = {2013-02-13 14:29:52 +0000},
  date-modified = {2013-02-13 14:34:14 +0000}
}

@article{King-SmithFink2004,
  title = {The Thickness of the Tear Film},
  author = {{King-Smith}, P. E. and Fink, B. A. and Hill, R. M. and Koelling, K. W. and Tiffany, J. M.},
  year = {2004},
  volume = {29},
  pages = {357--368},
  date-added = {2013-03-28 01:49:54 -0400},
  date-modified = {2014-05-26 15:39:12 +0000}
}

@article{King-SmithIOVS13a,
  title = {Tear {{Film Breakup}} and {{Structure Studied}} by {{Simultaneous Video Recording}} of {{Fluorescence}} and {{Tear Film Lipid Layer Images}}},
  author = {{King-Smith}, P. Ewen and Reuter, Kathleen S. and Braun, Richard J. and Nichols, Jason J. and Nichols, Kelly K.},
  year = {2013},
  month = jul,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {54},
  number = {7},
  pages = {4900--4909},
  issn = {1552-5783},
  doi = {10.1167/iovs.13-11878},
  urldate = {2022-08-05},
  abstract = {The thinning of the precorneal tear film between blinks and tear film breakup can be logically analyzed into contributions from three components: evaporation, flow into the cornea, and tangential flow along the corneal surface. Whereas divergent tangential flow contributes to certain types of breakup, it has been argued that evaporation is the main cause of tear thinning and breakup. Because evaporation is controlled by the tear film lipid layer (TFLL) it should therefore be expected that patterns of breakup should match patterns in the TFLL, and this hypothesis is tested in this study.    An optical system is described for simultaneous video imaging of fluorescein tear film breakup and the TFLL. Recordings were made from 85 subjects, including both with healthy and dry eyes. After instillation of 5 {$\mu$}L2\% fluorescein, subjects were asked to blink 1 second after the start of the recording and try to maintain their eyes open for the recording length of 30 or 60 seconds.    Areas of tear film thinning and breakup usually matched corresponding features in the TFLL. Whereas thinning and breakup were often matched to thin lipid, surprisingly, the corresponding lipid region was not always thinner than the surrounding lipid. Occasionally, a thin lipid region caused a corresponding region of greater fluorescence (thicker aqueous layer), due to convergent tangential flow.    Areas of tear thinning and breakup can generally be matched to corresponding regions of the TFLL as would be expected if breakup is largely due to evaporation. Surprisingly, in some examples, the corresponding lipid area was not thinner and possibly thicker than the surrounding lipid. This indicates that the lipid was a poor barrier to evaporation, perhaps because of deficiency in composition and/or structure. For example, bacterial lipases may have broken down esters into component acids and alcohols, causing a defective TFLL structure with increased evaporation.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/King-Smith et al-2013-Tear Film Breakup and Structure Studied by Simultaneous Video Recording of.pdf;/Users/driscoll/Zotero/storage/SMCXZKRZ/article.html}
}

@article{King-SmithIOVS13b,
  title = {Tear Film Images and Breakup Analyzed Using Fluorescent Quenching},
  author = {{King-Smith}, P. E. and Ramamoorthy, P. and Braun, R. J. and Nichols, J. J.},
  year = {2013},
  journal = {Investigative Ophthalmology and Visual Science},
  volume = {54},
  pages = {6003---6011},
  date-modified = {2016-12-27 02:01:28 +0000},
  keywords = {No DOI found}
}

@inproceedings{kingmaAdamMethodStochastic2014,
  title = {Adam: {{A}} Method for Stochastic Optimization},
  shorttitle = {Adam},
  booktitle = {Proceedings of the 3rd {{International Conference}} on {{Learning Representations}}},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2014},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Kingma_Ba_2014_Adam.pdf;/Users/driscoll/Zotero/storage/V75EL976/1412.html}
}

@article{KleinLinearRational2012,
  title = {Linear {{Rational Finite Differences}} from {{Derivatives}} of {{Barycentric Rational Interpolants}}},
  author = {Klein, Georges and Berrut, Jean-Paul},
  year = {2012},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {50},
  number = {2},
  pages = {643--656},
  issn = {0036-1429, 1095-7170},
  doi = {10.1137/110827156},
  urldate = {2022-03-13},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Klein_Berrut_2012_Linear Rational Finite Differences from Derivatives of Barycentric Rational.pdf;/Users/driscoll/Zotero/storage/LHNJCXMU/Klein and Berrut - 2012 - Linear Rational Finite Differences from Derivative.pdf}
}

@article{kokiopoulouTraceOptimizationEigenproblems2011,
  title = {Trace Optimization and Eigenproblems in Dimension Reduction Methods},
  author = {Kokiopoulou, E. and Chen, J. and Saad, Y.},
  year = {2011},
  month = may,
  journal = {Numerical Linear Algebra with Applications},
  volume = {18},
  number = {3},
  pages = {565--602},
  issn = {10705325},
  doi = {10.1002/nla.743},
  urldate = {2020-01-18},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Kokiopoulou et al_2011_Trace optimization and eigenproblems in dimension reduction methods.pdf;/Users/driscoll/Zotero/storage/IJ76L8FM/Kokiopoulou et al. - 2011 - Trace optimization and eigenproblems in dimension .pdf}
}

@article{Korb_Evidence_2013,
  title = {Evidence Suggesting That the Keratinized Portions of the Upper and Lower Lid Margins Do Not Make Complete Contact during Deliberate Blinking.},
  author = {Korb, Donald R and Blackie, Caroline A and N, Erin, McNally},
  year = {2013},
  volume = {32},
  number = {4},
  pages = {491--5},
  issn = {0277-3740},
  doi = {10.1097/ico.0b013e31826a1e6f},
  abstract = {To investigate whether the keratinized portions of the upper and lower eyelid margins make complete contact during deliberate blinking.},
  pmid = {23086372}
}

@article{Korb_Tear_1994,
  title = {Tear Film Lipid Layer Thickness as a Function of Blinking.},
  author = {Korb, Donald R and Baron, David F and Herman, John P and Finnemore, Victor M and Exford, Joan M and Hermosa, Jeannette and Leahy, Charles D and Glonek, Thomas and Greiner, Jack V},
  year = {1994},
  volume = {13},
  number = {4},
  pages = {354},
  issn = {0277-3740},
  doi = {10.1097/00003226-199407000-00012},
  abstract = {Alterations in the tear film lipid layer as a function of blinking were investigated using a custom-designed specular reflection monitoring system. The tear film lipid layer of 104 subjects under conditions of normal ("baseline") blinking and "forceful" blinking was quantitated on the basis of specific interference colors. Deliberate, forceful blinking was found to significantly increase the lipid layer thickness (LLT) of the tear film. The magnitude of increase was found to be correlated with the baseline LLT values; individuals with baseline LLT values of 75-150 nm demonstrated a mean increase in LLT of 33 nm following forceful blinking, whereas subjects with baseline LLT values \{{$<$}\}= 60 nm experienced a mean increase of 19 nm. The difference in the magnitude of increase between the groups was highly significant (p=0.0001). The data suggest that, in addition to playing a role in the spreading of lipid across the tear film, the blinking mechanism may be important in the maintenance of the lipid layer by augmenting the expression of lipids from the meibomian glands. (C) Lippincott-Raven Publishers.},
  pmid = {7924337}
}

@article{Kosinski2013,
  title = {Private Traits and Attributes Are Predictable from Digital Records of Human Behavior},
  author = {Kosinski, M. and Stillwell, D. and Graepel, T.},
  year = {2013},
  month = mar,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {15},
  pages = {5802--5805},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1218772110},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Kosinski et al_2013_Private traits and attributes are predictable from digital records of human.pdf}
}

@inproceedings{KrishnapriyanCharacterizingPossible2021,
  title = {Characterizing Possible Failure Modes in Physics-Informed Neural Networks},
  booktitle = {Neural {{Information Processing Systems}}},
  author = {Krishnapriyan, A. and Gholami, A. and Zhe, Shandian and Kirby, Robert M. and Mahoney, Michael W.},
  year = {2021},
  month = sep,
  urldate = {2023-11-02},
  abstract = {Recent work in scientific machine learning has developed so-called physics-informed neural network (PINN) models. The typical approach is to incorporate physical domain knowledge as soft constraints on an empirical loss function and use existing machine learning methodologies to train the model. We demonstrate that, while existing PINN methodologies can learn good models for relatively trivial problems, they can easily fail to learn relevant physical phenomena for even slightly more complex problems. In particular, we analyze several distinct situations of widespread physical interest, including learning differential equations with convection, reaction, and diffusion operators. We provide evidence that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. Importantly, we show that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN's setup makes the loss landscape very hard to optimize. We then describe two promising solutions to address these failure modes. The first approach is to use curriculum regularization, where the PINN's loss term starts from a simple PDE regularization, and becomes progressively more complex as the NN gets trained. The second approach is to pose the problem as a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. Extensive testing shows that we can achieve up to 1-2 orders of magnitude lower error with these methods as compared to regular PINN training.},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Krishnapriyan et al_2021_Characterizing possible failure modes in physics-informed neural networks.pdf}
}

@inproceedings{kumarCoregularizedMultiviewSpectral2011,
  title = {Co-Regularized {{Multi-view Spectral Clustering}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 24},
  author = {Kumar, Abhishek and Rai, Piyush and Daume, Hal},
  year = {2011},
  pages = {1413--1421},
  abstract = {In many clustering problems, we have access to multiple views of the data each of which could be individually used for clustering. Exploiting information from multiple views, one can hope to find a clustering that is more accurate than the ones obtained using the individual views. Since the true clustering would assign a point to the same cluster irrespective of the view, we can approach this problem by looking for clusterings that are consistent across the views, i.e., corresponding data points in each view should have same cluster membership. We propose a spectral clustering framework that achieves this goal by co-regularizing the clustering hypotheses, and propose two co-regularization schemes to accomplish this. Experimental comparisons with a number of baselines on two synthetic and three real-world datasets establish the efficacy of our proposed approaches.},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Kumar et al_2011_Co-regularized Multi-view Spectral Clustering.pdf}
}

@article{Kwon_High_2013,
  title = {High-Speed Camera Characterization of Voluntary Eye Blinking Kinematics},
  author = {Kwon, -A K and Shipley, {\relax RJ} and Edirisinghe, M and Ezra, {\relax DG} and Rose, G and {Best} and Cameron, {\relax RE}},
  year = {2013},
  volume = {10},
  number = {85},
  pages = {20130227--20130227},
  issn = {1742-5689},
  doi = {10.1098/rsif.2013.0227}
}

@book{lakowiczPrinciplesFluorescence2010,
  title = {Principles of Fluorescence Spectroscopy},
  author = {Lakowicz, Joseph R.},
  year = {2010},
  edition = {Third edition, corrected at 4. printing},
  publisher = {{Springer}},
  address = {{New York, NY}},
  isbn = {978-0-387-46312-4 978-0-387-31278-1},
  langid = {english},
  annotation = {OCLC: 700510097}
}

@article{Larsson2017,
  title = {A Least Squares Radial Basis Function Partition of Unity Method for Solving {{PDEs}}},
  author = {Larsson, Elisabeth and Shcherbakov, Victor and Heryudono, Alfa},
  year = {2017},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {39},
  number = {6},
  pages = {A2538-A2563},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/17m1118087},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Larsson et al_2017_A least squares radial basis function partition of unity method for solving PDEs.pdf}
}

@phdthesis{LawsonContributionsTheory1961,
  title = {Contributions to the {{Theory}} of {{Linear Least Maximum Approximations}},},
  author = {Lawson, C. L.},
  year = {1961},
  address = {{Los Angeles, CA}},
  school = {UCLA}
}

@book{layLinearAlgebraIts2012,
  title = {Linear Algebra and Its Applications},
  author = {Lay, David C.},
  year = {2012},
  edition = {4th ed},
  publisher = {{Addison-Wesley}},
  address = {{Boston}},
  isbn = {978-0-321-38517-8},
  lccn = {QA184.2 .L39 2012},
  keywords = {Algebras Linear,Textbooks},
  annotation = {OCLC: ocn693750928}
}

@article{Lee_Ultrastructure_2008,
  title = {Ultrastructure and Fluid Flow Physiology of Fetal Trabecular Meshwork Cells},
  author = {Lee, On-Tat and Wong, Joshua and Liepmann, Dorian and Lang, Tess and Lin, Shan},
  year = {2008},
  volume = {33},
  number = {10},
  pages = {849--856},
  issn = {0271-3683},
  doi = {10.1080/02713680802429210}
}

@article{Lee1997,
  title = {A Fast Adaptive Numerical Method for Stiff Two-Point Boundary Value Problems},
  author = {Lee, June-Yub and Greengard, Leslie},
  year = {1997},
  month = mar,
  journal = {SIAM Journal on Scientific Computing},
  volume = {18},
  number = {2},
  pages = {403--429},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/s1064827594272797},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Lee_Greengard_1997_A fast adaptive numerical method for stiff two-point boundary value problems.pdf}
}

@article{Lee2007,
  title = {Convergence of Increasingly Flat Radial Basis Interpolants to Polynomial Interpolants},
  author = {Lee, Yeon Ju and Yoon, Gang Joon and Yoon, Jungho},
  year = {2007},
  month = jan,
  journal = {SIAM Journal on Mathematical Analysis},
  volume = {39},
  number = {2},
  pages = {537--553},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/050642113}
}

@article{leeLearningPartsObjects1999,
  title = {Learning the Parts of Objects by Non-Negative Matrix Factorization},
  author = {Lee, Daniel D. and Seung, H. Sebastian},
  year = {1999},
  month = oct,
  journal = {Nature},
  volume = {401},
  number = {6755},
  pages = {788--791},
  issn = {1476-4687},
  doi = {10.1038/44565},
  urldate = {2019-03-18},
  abstract = {Is perception of the whole based on perception of its parts? There is psychological1 and physiological2,3 evidence for parts-based representations in the brain, and certain computational theories of object recognition rely on such representations4,5. But little is known about how brains or computers might learn the parts of objects. Here we demonstrate an algorithm for non-negative matrix factorization that is able to learn parts of faces and semantic features of text. This is in contrast to other methods, such as principal components analysis and vector quantization, that learn holistic, not parts-based, representations. Non-negative matrix factorization is distinguished from the other methods by its use of non-negativity constraints. These constraints lead to a parts-based representation because they allow only additive, not subtractive, combinations. When non-negative matrix factorization is implemented as a neural network, parts-based representations emerge by virtue of two properties: the firing rates of neurons are never negative and synaptic strengths do not change sign.},
  copyright = {1999 Nature Publishing Group},
  langid = {english},
  keywords = {NMF},
  file = {/Users/driscoll/Zotero/storage/AFLSL7Z6/Lee and Seung - 1999 - Learning the parts of objects by non-negative matr.pdf;/Users/driscoll/Zotero/storage/XQQKYKLR/44565.html}
}

@article{LeeParametervaryingNeural2022,
  title = {Parameter-Varying Neural Ordinary Differential Equations with Partition-of-Unity Networks},
  author = {Lee, Kookjin and Trask, Nathaniel},
  year = {2022},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2210.00368},
  urldate = {2023-11-02},
  abstract = {In this study, we propose parameter-varying neural ordinary differential equations (NODEs) where the evolution of model parameters is represented by partition-of-unity networks (POUNets), a mixture of experts architecture. The proposed variant of NODEs, synthesized with POUNets, learn a meshfree partition of space and represent the evolution of ODE parameters using sets of polynomials associated to each partition. We demonstrate the effectiveness of the proposed method for three important tasks: data-driven dynamics modeling of (1) hybrid systems, (2) switching linear dynamical systems, and (3) latent dynamics for dynamical systems with varying external forcing.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {FOS: Computer and information sciences,Machine Learning (cs.LG)},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Lee_Trask_2022_Parameter-varying neural ordinary differential equations with.pdf}
}

@article{Lei_Outflow_2011,
  title = {Outflow Physiology of the Mouse Eye: Pressure Dependence and Washout.},
  author = {Lei, Yuan and Overby, Darryl R and Alexandra, Boussommier-Calleja and Stamer, Daniel W and Ethier, Ross C},
  year = {2011},
  volume = {52},
  number = {3},
  pages = {1865--71},
  issn = {1552-5783},
  doi = {10.1167/iovs.10-6019},
  abstract = {Mice are commonly used in glaucoma research, but relatively little is known about aqueous outflow dynamics in the species. To facilitate future use of the mouse as a model of aqueous humor outflow, several fundamental physiological parameters were measured in the mouse eye.},
  pmcid = {PMC3101677},
  pmid = {21169533}
}

@inproceedings{leLearningHierarchicalInvariant2011,
  title = {Learning Hierarchical Invariant Spatio-Temporal Features for Action Recognition with Independent Subspace Analysis},
  booktitle = {{{CVPR}} 2011},
  author = {Le, Quoc V. and Zou, Will Y. and Yeung, Serena Y. and Ng, Andrew Y.},
  year = {2011},
  month = jun,
  pages = {3361--3368},
  publisher = {{IEEE}},
  address = {{Colorado Springs, CO, USA}},
  doi = {10.1109/cvpr.2011.5995496},
  urldate = {2020-01-10},
  isbn = {978-1-4577-0394-2},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Le et al_2011_Learning hierarchical invariant spatio-temporal features for action recognition2.pdf}
}

@inproceedings{leLearningHierarchicalInvariant2011a,
  title = {Learning Hierarchical Invariant Spatio-Temporal Features for Action Recognition with Independent Subspace Analysis},
  booktitle = {{{CVPR}} 2011},
  author = {Le, Quoc V. and Zou, Will Y. and Yeung, Serena Y. and Ng, Andrew Y.},
  year = {2011},
  month = jun,
  pages = {3361--3368},
  publisher = {{IEEE}},
  address = {{Colorado Springs, CO, USA}},
  doi = {10.1109/cvpr.2011.5995496},
  urldate = {2020-01-10},
  isbn = {978-1-4577-0394-2},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Le et al_2011_Learning hierarchical invariant spatio-temporal features for action recognition.pdf}
}

@article{lempReportNational1995,
  title = {Report of the {{National Eye Institute}}/{{Industry}} Workshop on {{Clinical Trials}} in {{Dry Eyes}}},
  author = {Lemp, M. A.},
  year = {1995},
  month = oct,
  journal = {The CLAO journal: official publication of the Contact Lens Association of Ophthalmologists, Inc},
  volume = {21},
  number = {4},
  pages = {221--232},
  issn = {0733-8902},
  langid = {english},
  pmid = {8565190},
  keywords = {Clinical Trials as Topic,Dry Eye Syndromes,Eye Proteins,Humans,Industry,Lacrimal Apparatus,Ophthalmology,Tears}
}

@article{LempTearOsmolarity2011,
  title = {Tear {{Osmolarity}} in the {{Diagnosis}} and {{Management}} of {{Dry Eye Disease}}},
  author = {Lemp, Michael A. and Bron, Anthony J. and Baudouin, Christophe and {Ben{\'i}tez del Castillo}, Jos{\'e} M. and Geffen, David and Tauber, Joe and Foulks, Gary N. and Pepose, Jay S. and Sullivan, Benjamin D.},
  year = {2011},
  month = may,
  journal = {American Journal of Ophthalmology},
  volume = {151},
  number = {5},
  pages = {792-798.e1},
  issn = {0002-9394},
  doi = {10.1016/j.ajo.2010.10.032},
  urldate = {2023-02-13},
  abstract = {Purpose To evaluate the use of tear osmolarity in the diagnosis of dry eye disease. Design A prospective, observational case series to determine the clinical usefulness of tear osmolarity and commonly used objective tests to diagnose dry eye disease. Methods A multicenter, 10-site study consisting of 314 consecutive subjects between 18 and 82 years of age. Bilateral tear osmolarity, tear film break-up time (TBUT), corneal staining, conjunctival staining, Schirmer test, and meibomian gland grading were performed. Diagnostic performance was measured against a composite index of objective measurements that classified subjects as having normal, mild or moderate, or severe dry eye. The main outcome measures were sensitivity, specificity, area under the receiver operating characteristic curve, and intereye variability. Results Of the 6 tests, tear osmolarity was found to have superior diagnostic performance. The most sensitive threshold between normal and mild or moderate subjects was found to be 308 mOsms/L, whereas the most specific was found at 315 mOsms/L. At a cutoff of 312 mOsms/L, tear hyperosmolarity exhibited 73\% sensitivity and 92\% specificity. By contrast, the other common tests exhibited either poor sensitivity (corneal staining, 54\%; conjunctival staining, 60\%; meibomian gland grading, 61\%) or poor specificity (tear film break-up time, 45\%; Schirmer test, 51\%). Tear osmolarity also had the highest area under the receiver operating characteristic curve (0.89). Intereye differences in osmolarity were found to correlate with increasing disease severity (r2 = 0.32). Conclusions Tear osmolarity is the best single metric both to diagnose and classify dry eye disease. Intereye variability is a characteristic of dry eye not seen in normal subjects.},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/WNA9GCNF/S000293941000841X.html}
}

@book{leonLinearAlgebraApplications2006,
  title = {Linear {{Algebra}} with {{Applications}}},
  author = {Leon, Steven J.},
  year = {2006},
  publisher = {{Pearson Prentice Hall}},
  abstract = {This thorough and accessible book from one of the leading figures in the field of linear algebra provides readers with both a challenging and broad understanding of linear algebra. The author infuses key concepts with their modern practical applications to offer readers examples of how mathematics is used in the real world. Topics such as linear systems theory, matrix theory, and vector space theory are integrated with real world applications to give a clear understanding of the material and the application of the concepts to solve real world problems. Each chapter contains integrated worked examples and chapter tests. The book stresses the important role geometry and visualization play in understanding linear algebra.For anyone interested in the application of linear algebra theories to solve real world problems.},
  isbn = {978-0-13-185785-8},
  langid = {english},
  keywords = {Mathematics / Algebra / Linear}
}

@article{leRealTimeLumpedParameter2013,
  title = {Real-{{Time Lumped Parameter Modeling}} of {{Cardiovascular Dynamics Using Electrocardiogram Signals}}: {{Toward Virtual Cardiovascular Instruments}}},
  shorttitle = {Real-{{Time Lumped Parameter Modeling}} of {{Cardiovascular Dynamics Using Electrocardiogram Signals}}},
  author = {Le, Trung Q. and Bukkapatnam, Satish T. S. and Komanduri, Ranga},
  year = {2013},
  month = aug,
  journal = {IEEE Transactions on Biomedical Engineering},
  volume = {60},
  number = {8},
  pages = {2350--2360},
  issn = {0018-9294, 1558-2531},
  doi = {10.1109/tbme.2013.2256423},
  urldate = {2019-12-06},
  abstract = {We present an approach to deriving a real-time, lumped parameter cardiovascular dynamics model that uses features extracted from online electrocardiogram (ECG) signal recordings to generate certain surrogate hemodynamic signals. The model represents the coupled dynamics of the heart chambers, valves, and pulmonary and systemic blood circulation loops in the form of nonlinear differential equations. The features extracted from ECG signals were used to estimate the timings and amplitudes of the atrioventricular activation input functions as well as other model parameters that capture the effect of cardiac morphological and physiological characteristics. The model was tested using hemodynamic signals from the PhysioNet MGH/MF Waveform database. The results suggest that the model can capture the salient time and frequency patterns of the measured central venous pressure, pulmonary arterial pressure, and respiratory impedance signals (R2 {$>$} 0.65). We have developed a method based on Anderson--Darling statistic and Kullback--Leibler divergence to compare the clinical measures (i.e., systolic and diastolic pressures) estimated from model waveform-extrema with those from actual measurements. The test statistics of the model waveform-extrema were statistically indistinguishable from the measured values with beat-to-beat rejection rates of 10\%. The results indicate the potential of a virtual instrument that uses the model-derived signals for clinical diagnosis in lieu of expensive instrumentation.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Le et al_2013_Real-Time Lumped Parameter Modeling of Cardiovascular Dynamics Using.pdf}
}

@article{lessardRigorousNumericsNonlinear2014,
  title = {Rigorous {{Numerics}} for {{Nonlinear Differential Equations Using Chebyshev Series}}},
  author = {Lessard, Jean-Philippe and Reinhardt, Christian},
  year = {2014},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {52},
  number = {1},
  pages = {1--22},
  issn = {0036-1429},
  doi = {10.1137/13090883x},
  urldate = {2020-03-16},
  abstract = {A computational method based on Chebyshev series to rigorously compute solutions of initial and boundary value problems of analytic nonlinear vector fields is proposed. The idea is to recast solutions as fixed points of an operator defined on a Banach space of rapidly decaying Chebyshev coefficients and to use the so-called radii polynomials to show the existence of a unique fixed point near an approximate solution. As applications, solutions of initial value problems in the Lorenz equations and symmetric connecting orbits in the Gray--Scott equation are rigorously computed. The symmetric connecting orbits are obtained by solving a boundary value problem with one of the boundary values in the stable manifold.},
  file = {/Users/driscoll/Zotero/storage/JS2U6Q8S/Lessard and Reinhardt - 2014 - Rigorous Numerics for Nonlinear Differential Equat.pdf;/Users/driscoll/Zotero/storage/V8W38QV4/13090883X.html}
}

@article{levenbergMethodSolutionCertain1944,
  title = {A Method for the Solution of Certain Non-Linear Problems in Least Squares},
  author = {Levenberg, Kenneth},
  year = {1944},
  journal = {Quarterly of Applied Mathematics},
  volume = {2},
  number = {2},
  pages = {164--168},
  issn = {0033-569X, 1552-4485},
  doi = {10.1090/qam/10666},
  urldate = {2020-06-18},
  abstract = {Advancing research. Creating connections.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Levenberg-1944-A method for the solution of certain non-linear problems in.pdf;/Users/driscoll/Zotero/storage/6LE7DNEQ/S0033-569X-1944-10666-0.html}
}

@book{levequeFiniteDifferenceMethods2007,
  title = {Finite {{Difference Methods}} for {{Ordinary}} and {{Partial Differential Equations}}: {{Steady-State}} and {{Time-Dependent Problems}}},
  shorttitle = {Finite {{Difference Methods}} for {{Ordinary}} and {{Partial Differential Equations}}},
  author = {LeVeque, Randall J.},
  year = {2007},
  month = sep,
  publisher = {{SIAM}},
  abstract = {This book introduces finite difference methods for both ordinary differential equations (ODEs) and partial differential equations (PDEs) and discusses the similarities and differences between algorithm design and stability analysis for different types of equations. A unified view of stability theory for ODEs and PDEs is presented, and the interplay between ODE and PDE analysis is stressed. The text emphasizes standard classical methods, but several newer approaches also are introduced and are described in the context of simple motivating examples. Exercises and student projects are available on the book\&\#39;s webpage, along with Matlab mfiles for implementing methods. Readers will gain an understanding of the essential ideas that underlie the development, analysis, and practical use of finite difference methods as well as the key concepts of stability theory, their relation to one another, and their practical implications. The author provides a foundation from which students can approach more advanced topics.},
  googlebooks = {qsvmsXe8Ug4C},
  isbn = {978-0-89871-629-0},
  langid = {english},
  keywords = {Mathematics / Differential Equations / General,Mathematics / Finite Mathematics,Mathematics / Mathematical Analysis}
}

@book{levequeFiniteVolumeMethods2002,
  title = {Finite {{Volume Methods}} for {{Hyperbolic Problems}}},
  author = {LeVeque, Randall J.},
  year = {2002},
  month = aug,
  publisher = {{Cambridge University Press}},
  abstract = {This book contains an introduction to hyperbolic partial differential equations and a powerful class of numerical methods for approximating their solution, (including both linear problems and nonlinear conservation laws). These equations describe a wide range of wave propagation and transport phenomena arising in nearly every scientific and engineering discipline. Several applications are described in a self-contained manner, along with much of the mathematical theory of hyperbolic problems. High-resolution versions of Godunov's method are developed, in which Riemann problems are solved to determine the local wave structure and limiters are applied to eliminate numerical oscillations. The methods were orginally designed to capture shock waves accurately, but are also useful tools for studying linear wave-progagation problems, particulary in heterogenous material. The methods studied are in the CLAWPACK software package. Source code for all the examples presented can be found on the web, along with animations of many of the simulations. This provides an excellent learning environment for understanding wave propagation phenomena and finite volume methods.},
  googlebooks = {QazcnD7GUoUC},
  isbn = {978-0-521-00924-9},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / Differential Equations / General,Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis}
}

@book{levequeNumericalMethodsConservation1992,
  title = {Numerical {{Methods}} for {{Conservation Laws}}},
  author = {LeVeque, Randall J.},
  year = {1992},
  publisher = {{Springer Science \& Business Media}},
  abstract = {These notes developed from a course on the numerical solution of conservation laws first taught at the University of Washington in the fall of 1988 and then at ETH during the following spring. The overall emphasis is on studying the mathematical tools that are essential in de veloping, analyzing, and successfully using numerical methods for nonlinear systems of conservation laws, particularly for problems involving shock waves. A reasonable un derstanding of the mathematical structure of these equations and their solutions is first required, and Part I of these notes deals with this theory. Part II deals more directly with numerical methods, again with the emphasis on general tools that are of broad use. I have stressed the underlying ideas used in various classes of methods rather than present ing the most sophisticated methods in great detail. My aim was to provide a sufficient background that students could then approach the current research literature with the necessary tools and understanding. Without the wonders of TeX and LaTeX, these notes would never have been put together. The professional-looking results perhaps obscure the fact that these are indeed lecture notes. Some sections have been reworked several times by now, but others are still preliminary. I can only hope that the errors are. not too blatant. Moreover, the breadth and depth of coverage was limited by the length of these courses, and some parts are rather sketchy.},
  googlebooks = {3WhqLPcMdPsC},
  isbn = {978-3-7643-2723-1},
  langid = {english},
  keywords = {Mathematics / Calculus,Mathematics / Counting & Numeration,Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis,Mathematics / Probability & Statistics / Stochastic Processes}
}

@article{Li_Corneal_2013,
  title = {Corneal Epithelial Permeability: {{Ethnic}} Differences between {{Asians}} and Non-{{Asians}}},
  author = {Li, Wing Y and Hsiao, Carol and Graham, Andrew D and Lin, Meng C},
  year = {2013},
  volume = {36},
  number = {5},
  pages = {215--218},
  issn = {1367-0484},
  doi = {10.1016/j.clae.2013.02.006},
  abstract = {PurposeTo ascertain whether a difference in the permeability of the corneal epithelium to fluorescein (Pdc) exists between Asians and non-Asians.MethodsFrom a multi-study database we extracted 632 records of baseline, open-eye Pdc measurements taken on both eyes of 176 subjects. Subjects were awake for a minimum of 4h before measurement, and were free of ocular disease and central corneal staining. Pdc was transformed by natural logarithm to better approximate normality for statistical tests.ResultsThe mean ln(Pdc) in the Asian group was significantly greater than in the non-Asian group [-2.34 ln(nm/s) vs. -2.58 ln(nm/s); p\{{$<$}\}0.001].ConclusionsCompared with non-Asians, Asians exhibited a less negative ln(Pdc), which translates to a higher Pdc and a more permeable corneal epithelium. We speculate that this may be related to anatomic differences responsible for greater eyelid tension in Asians.},
  pmid = {23507503}
}

@article{liAlgorithmComputingExact2005,
  title = {An Algorithm for Computing Exact Least-Trimmed Squares Estimate of Simple Linear Regression with Constraints},
  author = {Li, Lei M.},
  year = {2005},
  month = apr,
  journal = {Computational Statistics \& Data Analysis},
  volume = {48},
  number = {4},
  pages = {717--734},
  issn = {0167-9473},
  doi = {10.1016/j.csda.2004.04.003},
  urldate = {2020-11-06},
  abstract = {The least-trimmed squares estimation (LTS) is a robust solution for regression problems. On the one hand, it can achieve any given breakdown value by setting a proper trimming fraction. On the other hand, it has n-consistency and asymptotic normality under some conditions. In addition, the LTS estimator is regression, scale, and affine equivariant. In practical regression problems, we often need to impose constraints on slopes. In this paper, we describe a stable algorithm to compute the exact LTS solution for simple linear regression with constraints on the slope parameter. Without constraints, the overall complexity of the algorithm is O(n2logn) in time and O(n2) in storage. According to our numerical tests, constraints can reduce computing load substantially. In order to achieve stability, we design the algorithm in such a way that we can take advantage of well-developed sorting algorithms and softwares. We illustrate the algorithm by some examples.},
  langid = {english},
  keywords = {Breakdown value,Constraint,Least-trimmed squares,Robust,Simple regression},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Li_2005_An algorithm for computing exact least-trimmed squares estimate of simple.pdf;/Users/driscoll/Zotero/storage/ATJ7VHRT/S0167947304001082.html}
}

@article{LiBraun14,
  title = {Tear Film Dynamics with Evaporation, Wetting and Time-Dependent Flux Boundary Condition on an Eye-Shaped Domain},
  author = {Li, L. and Braun, R. J. and Maki, K. L. and Henshaw, W. D. and {King-Smith}, P. E.},
  year = {2014},
  journal = {Physics of Fluids},
  volume = {26},
  pages = {052101},
  doi = {10.1063/1.4871714},
  date-modified = {2014-05-09 02:32:43 +0000}
}

@inproceedings{LiCouplingOsmolarity2013,
  title = {Coupling {{Osmolarity Dynamics}} within {{Human Tear Film}} on an {{Eye-Shaped Domain}}},
  booktitle = {{{APS Meeting Abstracts}}},
  author = {Li, Longfei and Braun, {\relax RJ} and Driscoll, {\relax TA} and Henshaw, {\relax WD} and Banks, {\relax JW} and {King-Smith}, {\relax PE}},
  year = {2013},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{LietaertAutomaticRational2022,
  title = {Automatic Rational Approximation and Linearization of Nonlinear Eigenvalue Problems},
  author = {Lietaert, Pieter and Meerbergen, Karl and P{\'e}rez, Javier and Vandereycken, Bart},
  year = {2022},
  month = apr,
  journal = {IMA Journal of Numerical Analysis},
  volume = {42},
  number = {2},
  pages = {1087--1115},
  issn = {0272-4979},
  doi = {10.1093/imanum/draa098},
  urldate = {2023-04-12},
  abstract = {We present a method for solving nonlinear eigenvalue problems (NEPs) using rational approximation. The method uses the Antoulas--Anderson algorithm (AAA) of Nakatsukasa, S{\`e}te and Trefethen to approximate the NEP via a rational eigenvalue problem. A set-valued variant of the AAA algorithm is also presented for building low-degree rational approximations of NEPs with a large number of nonlinear functions. The rational approximation is embedded in the state-space representation of a rational polynomial by Su and Bai. This procedure perfectly fits the framework of the compact rational Krylov methods (CORK and TS-CORK), allowing solve large-scale NEPs to be efficiently solved. One advantage of our method, compared to related techniques such as NLEIGS and infinite Arnoldi, is that it automatically selects the poles and zeros of the rational approximations. Numerical examples show that the presented framework is competitive with NLEIGS and usually produces smaller linearizations with the same accuracy but with less effort for the user.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Lietaert et al_2022_Automatic rational approximation and linearization of nonlinear eigenvalue.pdf}
}

@article{LiEvaluatingWinding2020,
  title = {Evaluating {{Winding Numbers}} and {{Counting Complex Roots Through Cauchy Indices}} in {{Isabelle}}/{{HOL}}},
  author = {Li, Wenda and Paulson, Lawrence C.},
  year = {2020},
  month = feb,
  journal = {Journal of Automated Reasoning},
  volume = {64},
  number = {2},
  pages = {331--360},
  issn = {1573-0670},
  doi = {10.1007/s10817-019-09521-3},
  urldate = {2023-06-29},
  abstract = {In complex analysis, the winding number measures the number of times a path (counter-clockwise) winds around a point, while the Cauchy index can approximate how the path winds. We formalise this approximation in the Isabelle theorem prover, and provide a tactic to evaluate winding numbers through Cauchy indices. By further combining this approximation with the argument principle, we are able to make use of remainder sequences to effectively count the number of complex roots of a polynomial within some domains, such as a rectangular box and a half-plane.},
  langid = {english},
  keywords = {Cauchy index,Computer algebra,Interactive theorem proving,Isabelle/HOL,Root counting,The Routh-Hurwitz stability criterion,Winding number},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Li_Paulson_2020_Evaluating Winding Numbers and Counting Complex Roots Through Cauchy Indices in.pdf}
}

@misc{LiFourierNeural2021,
  title = {Fourier {{Neural Operator}} for {{Parametric Partial Differential Equations}}},
  author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  year = {2021},
  month = may,
  number = {arXiv:2010.08895},
  eprint = {2010.08895},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2010.08895},
  urldate = {2024-01-04},
  abstract = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/false;/Users/driscoll/Dropbox/library/Preprint/Li et al_2021_Fourier Neural Operator for Parametric Partial Differential Equations.pdf;/Users/driscoll/Zotero/storage/G33GBA8Z/2010.html}
}

@article{liIndependentSubspaceAnalysis2010,
  title = {Independent {{Subspace Analysis For Blind Signal Separation}}: {{Models And Algorithms}}},
  shorttitle = {Independent {{Subspace Analysis For Blind Signal Separation}}},
  author = {Li, R. and Wang, F.},
  year = {2010},
  month = jan,
  journal = {International Journal of Modelling and Simulation},
  volume = {30},
  number = {1},
  pages = {131--138},
  issn = {0228-6203, 1925-7082},
  doi = {10.1080/02286203.2010.11442566},
  urldate = {2020-01-10},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Li_Wang_2010_Independent Subspace Analysis For Blind Signal Separation.pdf}
}

@article{LiModelHuman2012,
  title = {A Model for the Human Tear Film with Heating from within the Eye},
  author = {Li, Longfei and Braun, R. J.},
  year = {2012},
  month = jun,
  journal = {Physics of Fluids},
  volume = {24},
  number = {6},
  pages = {062103},
  issn = {1070-6631, 1089-7666},
  doi = {10.1063/1.4723870},
  urldate = {2023-05-30},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Li_Braun_2012_A model for the human tear film with heating from within the eye.pdf}
}

@article{LimTensorsComputations2021,
  title = {Tensors in Computations},
  author = {Lim, Lek-Heng},
  year = {2021},
  month = may,
  journal = {Acta Numerica},
  volume = {30},
  pages = {555--764},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492921000076},
  urldate = {2023-10-25},
  abstract = {The notion of a tensor captures three great ideas: equivariance, multilinearity, separability. But trying to be three things at once makes the notion difficult to understand. We will explain tensors in an accessible and elementary way through the lens of linear algebra and numerical linear algebra, elucidated with examples from computational and applied mathematics.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Lim_2021_Tensors in computations.pdf}
}

@article{Lin_Soft_2003,
  title = {Soft Contact Lens Extended Wear Affects Corneal Epithelial Permeability: Hypoxic or Mechanical Etiology?},
  author = {Lin, Meng C and Soliman, Gemma N and Song, Min J and Smith, J.Patrick and Lin, Carolin T and Chen, Ying Q and Polse, Kenneth A},
  year = {2003},
  volume = {26},
  number = {1},
  pages = {11--16},
  issn = {1367-0484},
  doi = {10.1016/s1367-0484(02)00088-7},
  abstract = {Contact lens extended wear increases the permeability of epithelium to sodium fluorescein (Pdc). The exact mechanism is not known. However, changes in Pdc likely result from either corneal hypoxia or mechanical trauma, or both. We explored the effects of one-night continuous wear with either high- or low-Dk/t soft lenses on Pdc. The results show that corneal epithelial barrier function decreases significantly with both lens groups. We also observed that Asian eyes had higher Pdc after overnight wear compared to non-Asian and that for both Asian and non-Asian eyes, the elimination of corneal hypoxia did not prevent changes in epithelial permeability.}
}

@misc{liNeuralOperatorGraph2020,
  title = {Neural {{Operator}}: {{Graph Kernel Network}} for {{Partial Differential Equations}}},
  shorttitle = {Neural {{Operator}}},
  author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  year = {2020},
  month = mar,
  number = {arXiv:2003.03485},
  eprint = {2003.03485},
  primaryclass = {cs, math, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2003.03485},
  urldate = {2022-11-09},
  abstract = {The classical development of neural networks has been primarily for mappings between a finite-dimensional Euclidean space and a set of classes, or between two finite-dimensional Euclidean spaces. The purpose of this work is to generalize neural networks so that they can learn mappings between infinite-dimensional spaces (operators). The key innovation in our work is that a single set of network parameters, within a carefully designed network architecture, may be used to describe mappings between infinite-dimensional spaces and between different finite-dimensional approximations of those spaces. We formulate approximation of the infinite-dimensional mapping by composing nonlinear activation functions and a class of integral operators. The kernel integration is computed by message passing on graph networks. This approach has substantial practical consequences which we will illustrate in the context of mappings between input data to partial differential equations (PDEs) and their solutions. In this context, such learned networks can generalize among different approximation methods for the PDE (such as finite difference or finite element methods) and among approximations corresponding to different underlying levels of resolution and discretization. Experiments confirm that the proposed graph kernel network does have the desired properties and show competitive performance compared to the state of the art solvers.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Li et al_2020_Neural Operator.pdf;/Users/driscoll/Dropbox/library/Preprint/Li et al_2020_Neural Operator2.pdf;/Users/driscoll/Zotero/storage/85EYRHKQ/2003.html}
}

@article{LinScallopedChannels2006,
  title = {Scalloped {{Channels Enhance Tear Mixing Under Hydrogel Contact Lenses}}},
  author = {Lin, Meng C. and Soliman, Gemma N. and Lim, Valerie A. and Giese, Michael L. and Wofford, Laura E. and Marmo, Christopher and Radke, Clayton and Polse, Kenneth A.},
  year = {2006},
  month = dec,
  journal = {Optometry and Vision Science},
  volume = {83},
  number = {12},
  pages = {874--878},
  issn = {1538-9235},
  doi = {10.1097/01.opx.0000249978.07340.b2},
  urldate = {2022-08-31},
  abstract = {Purpose.~         Tear exchange under a soft contact lens is directly related to the amount of lateral and transverse lens motion. Hydrodynamic modeling suggests that channels placed on the back surface of a soft lens will reduce fluid resistance and increase transverse lens movement. This study measured the effect of posterior lens surface scalloped channels on tear exchange.         Methods.~         Tear exchange in the postlens tear film (PoLTF) was estimated using a fluorometer to measure the exponential depletion of high-MW fluorescein under the lens expressed as the time to deplete 95\% of dye (T95). A total of 32 subjects wore two pairs of identical lenses except that the experimental lens had 12 scalloped channels placed radially in the midperiphery of the posterior lens surface, whereas lenses without channels served as controls.         Results.~         The mean {\textpm} standard error T95 values for the channel lenses was 28 {\textpm} 2 minutes compared with 32 {\textpm} 2 minutes for the control lenses (p = 0.107). There was a marginally significant difference in T95 between two lens groups in Asian eyes (p = 0.054).         Conclusion.~         Placing scallop-shaped channels on high-H2O content soft lenses improved the postlens tear pumping in Asian eyes.},
  langid = {american},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Lin et al_2006_Scalloped Channels Enhance Tear Mixing Under Hydrogel Contact Lenses.pdf;/Users/driscoll/Zotero/storage/2CLK9XN9/Scalloped_Channels_Enhance_Tear_Mixing_Under.7.html}
}

@article{linSimulationsSingularityDynamics2006,
  title = {Simulations of Singularity Dynamics in Liquid Crystal Flows: {{A C0}} Finite Element Approach},
  shorttitle = {Simulations of Singularity Dynamics in Liquid Crystal Flows},
  author = {Lin, Ping and Liu, Chun},
  year = {2006},
  month = jun,
  journal = {Journal of Computational Physics},
  volume = {215},
  number = {1},
  pages = {348--362},
  issn = {00219991},
  doi = {10.1016/j.jcp.2005.10.027},
  urldate = {2019-11-25},
  abstract = {In this paper, we present a C0 finite element method for a 2D hydrodynamic liquid crystal model which is simpler than existing C1 element methods and mixed element formulation. The energy law is formally justified and the energy decay is used as a validation tool for our numerical computation. A splitting method combined with only a few fixed point iteration for the penalty term of the director field is applied to reduce the size of the stiffness matrix and to keep the stiffness matrix time-independent. The latter avoids solving a linear system at every time step and largely reduces the computational time, especially when direct linear system solvers are used. Our approach is verified by comparing its computational results with those obtained by C1 elements and by mixed formulation. Through numerical experiments of a few other splittings and explicit--implicit strategies, we recommend a fast and reliable algorithm for this model. A number of examples are computed to demonstrate the algorithm.},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/8MS4ZQG3/Lin and Liu - 2006 - Simulations of singularity dynamics in liquid crys.pdf}
}

@article{liOsmoDynamics2016,
  title = {Computed Tear Film and Osmolarity Dynamics on an Eye-Shaped Domain},
  author = {Li, Longfei and Braun, Richard J. and Driscoll, Tobin A. and Henshaw, William D. and Banks, Jeffrey W. and {King-Smith}, P. Ewen},
  year = {2016},
  month = jun,
  journal = {Mathematical Medicine and Biology},
  volume = {33},
  number = {2},
  pages = {123--157},
  issn = {1477-8599, 1477-8602},
  doi = {10.1093/imammb/dqv013},
  urldate = {2022-08-05},
  copyright = {All rights reserved},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Li et al-2016-Computed tear film and osmolarity dynamics on an eye-shaped domain.pdf}
}

@article{liPainLinkIBI2018,
  title = {Pain {{Sensitivity Associated With}} the {{Length}} of the {{Maximum Interblink Period}}},
  author = {Li, Wing and Lin, Meng C.},
  year = {2018},
  month = jan,
  journal = {Investigative Opthalmology \& Visual Science},
  volume = {59},
  number = {1},
  pages = {238},
  issn = {1552-5783},
  doi = {10.1167/iovs.17-22950},
  urldate = {2022-08-05},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Li_Lin-2018-Pain Sensitivity Associated With the Length of the Maximum Interblink Period.pdf}
}

@misc{LiPhysicsInformedNeural2023,
  title = {Physics-{{Informed Neural Operator}} for {{Learning Partial Differential Equations}}},
  author = {Li, Zongyi and Zheng, Hongkai and Kovachki, Nikola and Jin, David and Chen, Haoxuan and Liu, Burigede and Azizzadenesheli, Kamyar and Anandkumar, Anima},
  year = {2023},
  month = jul,
  number = {arXiv:2111.03794},
  eprint = {2111.03794},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2111.03794},
  urldate = {2023-12-12},
  abstract = {In this paper, we propose physics-informed neural operators (PINO) that combine training data and physics constraints to learn the solution operator of a given family of parametric Partial Differential Equations (PDE). PINO is the first hybrid approach incorporating data and PDE constraints at different resolutions to learn the operator. Specifically, in PINO, we combine coarse-resolution training data with PDE constraints imposed at a higher resolution. The resulting PINO model can accurately approximate the ground-truth solution operator for many popular PDE families and shows no degradation in accuracy even under zero-shot super-resolution, i.e., being able to predict beyond the resolution of training data. PINO uses the Fourier neural operator (FNO) framework that is guaranteed to be a universal approximator for any continuous operator and discretization-convergent in the limit of mesh refinement. By adding PDE constraints to FNO at a higher resolution, we obtain a high-fidelity reconstruction of the ground-truth operator. Moreover, PINO succeeds in settings where no training data is available and only PDE constraints are imposed, while previous approaches, such as the Physics-Informed Neural Network (PINN), fail due to optimization challenges, e.g., in multi-scale dynamic systems such as Kolmogorov flows.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Li et al_2023_Physics-Informed Neural Operator for Learning Partial Differential Equations.pdf;/Users/driscoll/Zotero/storage/VYIU2XX2/2111.html}
}

@article{LiShi2017,
  title = {Deep Residual Learning and {{PDEs}} on Manifold},
  author = {Li, Zhen and Shi, Zuoqiang},
  year = {2017},
  month = aug,
  eprint = {1708.05115v3},
  primaryclass = {cs.IT},
  abstract = {In this paper, we formulate the deep residual network (ResNet) as a control problem of transport equation. In ResNet, the transport equation is solved along the characteristics. Based on this observation, deep neural network is closely related to the control problem of PDEs on manifold. We propose several models based on transport equation and Hamilton-Jacobi equation. The discretization of these PDEs on point cloud is also discussed.},
  archiveprefix = {arxiv},
  keywords = {cs.IT,math.IT,No DOI found}
}

@article{LiShiSun2017,
  title = {Point Integral Method for Solving Poisson-Type Equations on Manifolds from Point Clouds with Convergence Guarantees},
  author = {Li, Zhen and Shi, Zuoqiang and Sun, Jian},
  year = {2017},
  volume = {22},
  pages = {228--258},
  issn = {1815-2406},
  doi = {10.4208/cicp.111015.250716a}
}

@misc{LiTransformerPartial2023,
  title = {Transformer for {{Partial Differential Equations}}' {{Operator Learning}}},
  author = {Li, Zijie and Meidani, Kazem and Farimani, Amir Barati},
  year = {2023},
  month = apr,
  number = {arXiv:2205.13671},
  eprint = {2205.13671},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-07-03},
  abstract = {Data-driven learning of partial differential equations' solution operators has recently emerged as a promising paradigm for approximating the underlying solutions. The solution operators are usually parameterized by deep learning models that are built upon problem-specific inductive biases. An example is a convolutional or a graph neural network that exploits the local grid structure where functions' values are sampled. The attention mechanism, on the other hand, provides a flexible way to implicitly exploit the patterns within inputs, and furthermore, relationship between arbitrary query locations and inputs. In this work, we present an attention-based framework for data-driven operator learning, which we term Operator Transformer (OFormer). Our framework is built upon self-attention, cross-attention, and a set of point-wise multilayer perceptrons (MLPs), and thus it makes few assumptions on the sampling pattern of the input function or query locations. We show that the proposed framework is competitive on standard benchmark problems and can flexibly be adapted to randomly sampled input.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Li et al_2023_Transformer for Partial Differential Equations' Operator Learning.pdf;/Users/driscoll/Zotero/storage/WA4GT9V6/2205.html}
}

@article{Little2017,
  title = {Multiscale Geometric Methods for Data Sets {{I}}: {{Multiscale SVD}}, Noise and Curvature},
  author = {Little, Anna V. and Maggioni, Mauro and Rosasco, Lorenzo},
  year = {2017},
  month = nov,
  journal = {Applied and Computational Harmonic Analysis},
  volume = {43},
  number = {3},
  pages = {504--567},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.acha.2015.09.009}
}

@article{LiuInterpretableNeural2023,
  title = {Interpretable Neural Networks: Principles and Applications},
  shorttitle = {Interpretable Neural Networks},
  author = {Liu, Zhuoyang and Xu, Feng},
  year = {2023},
  month = oct,
  journal = {Frontiers in Artificial Intelligence},
  volume = {6},
  pages = {974295},
  issn = {2624-8212},
  doi = {10.3389/frai.2023.974295},
  urldate = {2023-11-02},
  abstract = {In recent years, with the rapid development of deep learning technology, great progress has been made in computer vision, image recognition, pattern recognition, and speech signal processing. However, due to the black-box nature of deep neural networks (DNNs), one cannot explain the parameters in the deep network and why it can perfectly perform the assigned tasks. The interpretability of neural networks has now become a research hotspot in the field of deep learning. It covers a wide range of topics in speech and text signal processing, image processing, differential equation solving, and other fields. There are subtle differences in the definition of interpretability in different fields. This paper divides interpretable neural network (INN) methods into the following two directions: model decomposition neural networks, and semantic INNs. The former mainly constructs an INN by converting the analytical model of a conventional method into different layers of neural networks and combining the interpretability of the conventional model-based method with the powerful learning capability of the neural network. This type of INNs is further classified into different subtypes depending on which type of models they are derived from, i.e., mathematical models, physical models, and other models. The second type is the interpretable network with visual semantic information for user understanding. Its basic idea is to use the visualization of the whole or partial network structure to assign semantic information to the network structure, which further includes convolutional layer output visualization, decision tree extraction, semantic graph, etc. This type of method mainly uses human visual logic to explain the structure of a black-box neural network. So it is a post-network-design method that tries to assign interpretability to a black-box network structure afterward, as opposed to the pre-network-design method of model-based INNs, which designs interpretable network structure beforehand. This paper reviews recent progress in these areas as well as various application scenarios of INNs and discusses existing problems and future development directions.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Liu_Xu_2023_Interpretable neural networks.pdf}
}

@article{LiuLinkTear2009,
  title = {A {{Link}} between {{Tear Instability}} and {{Hyperosmolarity}} in {{Dry Eye}}},
  author = {Liu, Haixia and Begley, Carolyn and Chen, Minhua and Bradley, Arthur and Bonanno, Joseph and McNamara, Nancy A. and Nelson, J. Daniel and Simpson, Trefford},
  year = {2009},
  month = aug,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {50},
  number = {8},
  pages = {3671--3679},
  issn = {1552-5783},
  doi = {10.1167/iovs.08-2689},
  urldate = {2023-02-13},
  abstract = {purpose. Tear film instability and tear hyperosmolarity are considered core mechanisms in the development of dry eye. The authors hypothesize that evaporation and instability produce transient shifts in tear hyperosmolarity that lead to chronic epithelial stress, inflammation, and symptoms of ocular irritation. The purpose of this study was to provide indirect evidence of short-term hyperosmolar conditions during tear instability and to test whether the corneal epithelium responds to transient hyperosmolar stress.  methods. Five subjects kept one eye open as long as possible, and overall discomfort and sensations associated with tear break-up were scaled. Later, the same subjects used the same scales to report discomfort sensations after instillation of NaCl and sucrose hyperosmolar drops (300--1000 mOsM/kg). A two-alternative, forced-choice experiment was used to obtain osmolarity thresholds. In the second experiment, primary cultured bovine corneal epithelial cells were transiently stressed with the same range of hyperosmolar culture medium, and proinflammatory mitogen-activated protein kinase (MAPKs) were measured by Western blot analysis.  results. Tear instability led to an average discomfort rating of 6.13 and sensations of burning and stinging. These sensations also occurred with hyperosmolar solutions (thresholds, 450--460 mOsM/kg) that required 800 to 900 mOsM/kg to generate the same discomfort levels reported during tear break-up. MAPK was activated at 600 mOsM/kg of transient hyperosmolar stress.  conclusions. These experiments provide a link between hyperosmolarity and tear instability, suggesting that hyperosmolar levels in the tear film may transiently spike during tear instability, resulting in corneal inflammation and triggering sensory neurons.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Liu et al-2009-A Link between Tear Instability and Hyperosmolarity in Dry Eye.pdf;/Users/driscoll/Zotero/storage/Q2PD69YB/article.html}
}

@article{liuTemporalProgression2006,
  title = {Temporal {{Progression}} and {{Spatial Repeatability}} of {{Tear Breakup}}},
  author = {Liu, Haixia and Begley, Carolyn G. and Chalmers, Robin and Wilson, Graeme and Srinivas, Sangly P. and Wilkinson, Jenni A.},
  year = {2006},
  month = oct,
  journal = {Optometry and Vision Science},
  volume = {83},
  number = {10},
  pages = {723--730},
  issn = {1538-9235},
  doi = {10.1097/01.opx.0000237546.88464.6d},
  urldate = {2021-01-12},
  abstract = {Purpose.~         This study used image analysis to compare the temporal progression and spatial reoccurrence of the area of tear film breakup (AB) in dry eye and normal subjects.         Methods.~         Tear breakup was induced in 10 control and 10 dry eye subjects during the Staring Tear Breakup Dynamics (S-TBUD) test, which involves keeping one eye open for as long as possible, termed the maximum blink interval (MBI). Video imaging of tear film fluorescence measured the onset and progression of the AB. AB location and area were mapped. The progression of ABs from the first trial, the rate of tear breakup or dry area growth rate (DAGR), and the overlap of ABs in three successive trials 5 minutes apart were computed by custom MATLAB programs.         Results.~         The final AB before the blink was significantly greater (average, 30.7\% {\textpm} 12.5\% vs. 16.1\% {\textpm} 9.2\%) and the MBI was significantly less (average, 19.5 {\textpm} 9.0 seconds vs. 56.5 {\textpm} 38.9 seconds) among dry eye subjects compared with controls (p {$<$} 0.05, Mann-Whitney U test). The DAGR was four times greater among dry eye subjects, who also showed significantly more tear breakup in the central cornea than controls (p {$<$} 0.0001, Mann-Whitney U test). When the final image from three successive trials was overlapped, tear breakup occurred more often in the same location in three trials than would be expected by the overlap of independent points.         Conclusions.~         Structural influences such as the ``black line'' or corneal lid defects appeared to influence the recurrence of breakup in the same region. The S-TBUD quantitative image analysis technique demonstrates that the tear film of subjects with dry eye continues to rapidly destabilize after an initial first break; thus, a low TBUT was combined with a high DAGR. The central corneal region of subjects with dry eye appeared especially susceptible to increased tear breakup when compared with controls.},
  langid = {american},
  file = {/Users/driscoll/Zotero/storage/CHVBGX34/Temporal_Progression_and_Spatial_Repeatability_of.10.html}
}

@article{Logg2007,
  title = {Automated Solution of Differential Equations},
  author = {Logg, Anders},
  year = {2007},
  month = dec,
  journal = {PAMM},
  volume = {7},
  number = {1},
  pages = {1010601--1010602},
  publisher = {{Wiley-Blackwell}},
  doi = {10.1002/pamm.200700234},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Logg_2007_Automated solution of differential equations.pdf}
}

@article{Luensmann_Albumin_2008,
  title = {Albumin Adsorption to Contact Lens Materials: A Review.},
  author = {Luensmann, Doerte and Jones, Lyndon},
  year = {2008},
  volume = {31},
  number = {4},
  pages = {179--87},
  issn = {1367-0484},
  doi = {10.1016/j.clae.2008.05.004},
  abstract = {During contact lens wear, tear film components such as lipids, mucins and proteins tend to deposit on and within the lens material and may cause discomfort, reduced vision and inflammatory reactions. The tear film protein that has attracted most interest when studying contact lens deposition is the small (14 kDa), positively charged protein lysozyme. Albumin, which is a much larger protein (66 kDa) with an overall net negative charge is also of interest, and shows very different adsorption patterns to lysozyme. The concentration of albumin in the tear film is relatively low compared to the concentration in blood serum, but this value increases markedly under various conditions, including when the eye is closed, during contact lens wear and in various dry eye states. Gaining an understanding of the manner in which albumin deposits on biomaterials is of importance for contact lens wear, as well as for other medical applications where HEMA-based materials are used for implants, artificial blood vessels or drug delivery devices. This review paper summarizes the impact of individual material compositions, water content, hydrophobicity and electrostatic attraction on the adsorption behavior of the protein albumin.},
  pmid = {18603467}
}

@article{LukeFittingSimplified2021,
  title = {Fitting {{Simplified Models}} to {{Machine Learning-Identified Tear Film Breakup}}},
  author = {Luke, Rayanne A and Braun, Richard J and Driscoll, Tobin and Sinopoli, Dominick and Yawatkar, Vishruta and You, Luyang and Phatak, Aashish and Begley, Carolyn},
  year = {2021},
  month = jun,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {62},
  number = {8},
  pages = {1315--1315},
  issn = {1552-5783},
  urldate = {2023-05-09},
  abstract = {Six ordinary differential equation (ODE) tear film breakup (TBU) models are created to capture evaporation, osmosis, and different types of flow. A convolutional neural network designed after Su et al. (IEEE, 2018) and trained on over 40,000 image patches successfully identifies TBU and non-TBU in fluorescent (FL) images gathered in vivo with an accuracy of 92\%. The ODE models are fit to the automatically identified TBU FL intensity data by optimizing TBU quantities such as evaporation and tangential flow rates. Best-fit determination of TBU parameters suggests which mechanisms cause the thinning.    The FL intensity data was originally recorded from 25 normal subjects with 20 trials taken over two visits (Awisi-Gyau, Indiana University thesis, 2020). We extract the experimental FL image data from the centers of TBU regions identified by a convolutional neural network. These are fit with the models designed to mimic evaporation-driven, tangential flow-driven, and combination thinning. We estimate parameters using a least squares minimization of the difference between experimental and computed intensities using the trust region-reflective method. Theoretical intensity dependent on tear film (TF) thickness and FL concentration was based on Nichols et al (2012, IOVS, 53:5426). Separate procedures were used to estimate initial FL concentration and localized TF thickness (Wu et al, IOVS 2015, 56:4211). The fits use up to four parameters: evaporation rate v, a (steady) and b1 (decaying) extensional flow rates, and decay rate b2. All computations are via custom Python programs.    Optimal evaporation rates fall near or within experimental ranges (Nichols et al, IOVS, 2005). An example fit is shown in the Figure. The best-fit model determines that the evaporation rate is -3.25 {$\mu$}m/min and that the instance exhibits strong, outward tangential flow that decays, allowing evaporation to take over in importance.    Intensity decay in automatically identified TBU areas can readily be fit with simplified models that capture essential thinning dynamics and yield physically relevant quantities. This procedure can be applied to a wide range of instances to obtain statistical information that cannot be directly measured during breakup.  This is a 2021 ARVO Annual Meeting abstract.     Left: Automatically identified TBU instances. Right: Best-fit results for the six ODE models for the box 10 TBU (indicated by arrow in left image).},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{lukeParameterEstimation2020,
  title = {Parameter {{Estimation}} for {{Evaporation-Driven Tear Film Thinning}}},
  author = {Luke, Rayanne A. and Braun, Richard J. and Driscoll, Tobin A. and Begley, Carolyn G. and {Awisi-Gyau}, Deborah},
  year = {2020},
  month = jun,
  journal = {Bulletin of Mathematical Biology},
  volume = {82},
  number = {6},
  pages = {71},
  issn = {0092-8240, 1522-9602},
  doi = {10.1007/s11538-020-00745-8},
  urldate = {2020-06-15},
  copyright = {All rights reserved},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Luke et al-2020-Parameter Estimation for Evaporation-Driven Tear Film.pdf}
}

@article{LukeParameterEstimation2021,
  title = {Parameter {{Estimation}} for {{Mixed-Mechanism Tear Film Thinning}}},
  author = {Luke, Rayanne A. and Braun, Richard J. and Driscoll, Tobin A. and {Awisi-Gyau}, Deborah and Begley, Carolyn G.},
  year = {2021},
  month = may,
  journal = {Bulletin of Mathematical Biology},
  volume = {83},
  number = {5},
  pages = {56},
  issn = {0092-8240, 1522-9602},
  doi = {10.1007/s11538-021-00871-x},
  urldate = {2021-09-09},
  abstract = {Etiologies of tear breakup include evaporation-driven, divergent flow-driven, and a combination of these two. A mathematical model incorporating evaporation and lipid- driven tangential flow is fit to fluorescence imaging data. The lipid-driven motion is hypothesized to be caused by localized excess lipid, or ``globs.'' Tear breakup quan- tities such as evaporation rates and tangential flow rates cannot currently be directly measured during breakup. We determine such variables by fitting mathematical mod- els for tear breakup and the computed fluorescent intensity to experimental intensity data gathered in vivo. Parameter estimation is conducted via least squares minimiza- tion of the difference between experimental data and computed answers using either the trust-region-reflective or Levenberg--Marquardt algorithm. Best-fit determination of tear breakup parameters supports the notion that evaporation and divergent tangential flow can cooperate to drive breakup. The resulting tear breakup is typically faster than purely evaporative cases. Many instances of tear breakup may have similar causes, which suggests that interpretation of experimental results may benefit from considering multiple mechanisms.},
  copyright = {All rights reserved},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Luke et al-2021-Parameter Estimation for Mixed-Mechanism Tear Film Thinning2.pdf}
}

@inproceedings{LuMultilinearFactorization2017,
  title = {Multilinear {{Factorization Machines}} for {{Multi-Task Multi-View Learning}}},
  booktitle = {Proceedings of the {{Tenth ACM International Conference}} on {{Web Search}} and {{Data Mining}} - {{WSDM}} '17},
  author = {Lu, Chun-Ta and He, Lifang and Shao, Weixiang and Cao, Bokai and Yu, Philip S.},
  year = {2017},
  pages = {701--709},
  publisher = {{ACM Press}},
  address = {{Cambridge, United Kingdom}},
  doi = {10.1145/3018661.3018716},
  urldate = {2019-10-07},
  abstract = {Many real-world problems, such as web image analysis, document categorization and product recommendation, often exhibit dual-heterogeneity: heterogeneous features obtained in multiple views, and multiple tasks might be related to each other through one or more shared views. To address these Multi-Task Multi-View (MTMV) problems, we propose a tensor-based framework for learning the predictive multilinear structure from the full-order feature interactions within the heterogeneous data. The usage of tensor structure is to strengthen and capture the complex relationships between multiple tasks with multiple views. We further develop efficient multilinear factorization machines (MFMs) that can learn the task-specific feature map and the taskview shared multilinear structures, without physically building the tensor. In the proposed method, a joint factorization is applied to the full-order interactions such that the consensus representation can be learned. In this manner, it can deal with the partially incomplete data without difficulty as the learning procedure does not simply rely on any particular view. Furthermore, the complexity of MFMs is linear in the number of parameters, which makes MFMs suitable to large-scale real-world problems. Extensive experiments on four real-world datasets demonstrate that the proposed method significantly outperforms several state-ofthe-art methods in a wide variety of MTMV problems.},
  isbn = {978-1-4503-4675-7},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Lu et al_2017_Multilinear Factorization Machines for Multi-Task Multi-View Learning2.pdf}
}

@article{LuNeuralODEPharmacokinetics2021,
  title = {Neural-{{ODE}} for Pharmacokinetics Modeling and Its Advantage to Alternative Machine Learning Models in Predicting New Dosing Regimens},
  author = {Lu, James and Deng, Kaiwen and Zhang, Xinyuan and Liu, Gengbo and Guan, Yuanfang},
  year = {2021},
  month = jul,
  journal = {iScience},
  volume = {24},
  number = {7},
  pages = {102804},
  issn = {25890042},
  doi = {10.1016/j.isci.2021.102804},
  urldate = {2023-11-02},
  abstract = {Semantic Scholar extracted view of "Neural-ODE for pharmacokinetics modeling and its advantage to alternative machine learning models in predicting new dosing regimens" by James Lu et al.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Lu et al_2021_Neural-ODE for pharmacokinetics modeling and its advantage to alternative.pdf}
}

@article{luPredictionAccuracyDynamic2020,
  title = {Prediction {{Accuracy}} of {{Dynamic Mode Decomposition}}},
  author = {Lu, Hannah and Tartakovsky, Daniel M.},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {42},
  number = {3},
  pages = {A1639-A1662},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/19m1259948},
  urldate = {2020-07-03},
  abstract = {Dynamic mode decomposition (DMD), which belongs to the family of singular-value decompositions (SVDs), is a popular tool of data-driven regression. While multiple numerical tests demonstrated the power and efficiency of DMD in representing data (i.e., in the interpolation mode), applications of DMD as a predictive tool (i.e., in the extrapolation mode) are scarce. This is due, in part, to the lack of rigorous error estimators for DMD-based predictions. We provide a theoretical error estimator for DMD extrapolation of numerical solutions to linear and nonlinear parabolic equations. This error analysis allows one to monitor and control the errors associated with DMD-based temporal extrapolation of  numerical solutions to parabolic differential equations.  We use several computational experiments to verify the robustness of our error estimators and to compare the predictive ability of DMD with that of proper orthogonal decomposition (POD), another member of the SVD family. Our analysis demonstrates the importance of a proper selection of observables, as predicted by the Koopman operator theory. In all the tests considered, DMD outperformed POD in terms of efficiency due to its iteration-free feature. In some of these experiments, POD proved to be more accurate than DMD. This suggests that DMD is preferable for obtaining a fast prediction with slightly lower accuracy, while POD should be used if the accuracy is paramount.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Lu_Tartakovsky-2020-Prediction Accuracy of Dynamic Mode Decomposition.pdf;/Users/driscoll/Zotero/storage/E2N5Y2KD/19M1259948.html}
}

@article{Luxburg2007,
  title = {A Tutorial on Spectral Clustering},
  author = {{von Luxburg}, Ulrike},
  year = {2007},
  month = aug,
  journal = {Statistics and Computing},
  volume = {17},
  number = {4},
  pages = {395--416},
  publisher = {{Springer Nature}},
  doi = {10.1007/s11222-007-9033-z},
  file = {/Users/driscoll/Dropbox/library/Journal Article/von Luxburg_2007_A tutorial on spectral clustering.pdf}
}

@book{MacKay2003,
  title = {Information Theory, Inference, and Learning Algorithms},
  author = {MacKay, David J.C.},
  year = {2003},
  publisher = {{Cambridge University Press}},
  isbn = {978-0-521-64298-9},
  file = {/Users/driscoll/Dropbox/library/Book/MacKay_2003_Information theory, inference, and learning algorithms.pdf}
}

@article{MAKI_Suction_2014,
  title = {A {{New Model}} for the {{Suction Pressure Under}} a {{Contact Lens}}},
  author = {Maki, Kara L. and Ross, David S.},
  year = {2014},
  volume = {22},
  number = {02},
  pages = {235--248},
  issn = {0218-3390},
  doi = {10.1142/s021833901440004x}
}

@article{makiModelTear2019,
  title = {A Model for Tear Film Dynamics during a Realistic Blink},
  author = {Maki, Kara L and Henshaw, William D and McManus, Alex and Braun, Richard J and Chapp, Dylan M and Driscoll, Tobin A},
  year = {2019},
  journal = {Journal for Modeling in Ophthalmology},
  volume = {3},
  pages = {21--27},
  doi = {10.35119/maio.v2i3.91},
  copyright = {All rights reserved},
  file = {/Users/driscoll/Zotero/storage/2VATMXTU/Maki et al. - A model for tear film dynamics during a realistic .pdf}
}

@inproceedings{MakiOversetGrid2007,
  title = {A {{Overset Grid Method}} for {{Fourth Order Evolution Equations}} of {{Human Tear Film}}},
  booktitle = {{{APS Division}} of {{Fluid Dynamics Meeting Abstracts}}},
  author = {Maki, Kara L and Braun, {\relax RJ} and Driscoll, {\relax TA} and Heryudono, A and {King-Smith}, {\relax PE} and Fast, P},
  year = {2007},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{MakiOversetGrid2008,
  title = {An Overset Grid Method for the Study of Reflex Tearing},
  author = {Maki, K. L. and Braun, R. J. and Driscoll, T. A. and {King-Smith}, P. E.},
  year = {2008},
  journal = {Math. Med. Biol.},
  volume = {25},
  pages = {187--214},
  doi = {10.1093/imammb/dqn013},
  copyright = {All rights reserved}
}

@article{makiTearFilm2010,
  title = {Tear Film Dynamics on an Eye-Shaped Domain {{I}}: Pressure Boundary Conditions},
  shorttitle = {Tear Film Dynamics on an Eye-Shaped Domain {{I}}},
  author = {Maki, K. L. and Braun, R. J. and Henshaw, W. D. and {King-Smith}, P. E.},
  year = {2010},
  month = sep,
  journal = {Mathematical Medicine and Biology},
  volume = {27},
  number = {3},
  pages = {227--254},
  issn = {1477-8599, 1477-8602},
  doi = {10.1093/imammb/dqp023},
  urldate = {2020-07-11},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Maki et al-2010-Tear film dynamics on an eye-shaped domain I2.pdf}
}

@article{makiTearFilm2010a,
  title = {Tear Film Dynamics on an Eye-Shaped Domain. {{Part}} 2. {{Flux}} Boundary Conditions},
  author = {Maki, K. L. and Braun, R. J. and Ucciferro, P. and Henshaw, W. D. and {King-Smith}, P. E.},
  year = {2010},
  month = mar,
  journal = {Journal of Fluid Mechanics},
  volume = {647},
  pages = {361--390},
  issn = {0022-1120, 1469-7645},
  doi = {10.1017/s002211200999382x},
  urldate = {2020-04-03},
  abstract = {We model the dynamics of the human tear film during relaxation (after a blink) using lubrication theory and explore the effects of viscosity, surface tension, gravity and boundary conditions that specify the flux of tear fluid into or out of the domain. The governing nonlinear partial differential equation is solved on an overset grid by a method of lines using finite differences in space and an adaptive second-order backward difference formula solver in time. Our simulations in a two-dimensional domain are computed in the               Overture               computational framework. The flow around the boundary is sensitive to both our choice of flux boundary condition and the presence of gravity. The simulations recover features seen in one-dimensional simulations and capture some experimental observations of tear film dynamics around the lid margins. In some instances, the influx from the lacrimal gland splits with some fluid going along the upper lid towards the nasal canthus and some travelling around the temporal canthus and then along the lower lid. Tear supply can also push through some parts of the black line near the eyelid margins.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Maki et al-2010-Tear film dynamics on an eye-shaped domain2.pdf}
}

@article{MakiTheoreticalInvestigation2016,
  title = {A Theoretical Investigation of the Influence of a Blink on the Tear Film Dynamics},
  author = {Maki, Kara and Henshaw, William and Barron, Gregory and Chapp, Dylan and Braun, Richard J and Driscoll, Tobin A.},
  year = {2016},
  month = sep,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {57},
  number = {12},
  pages = {6173--6173},
  issn = {1552-5783},
  urldate = {2023-05-09},
  abstract = {The purpose of this study is to develop mathematical models to simulate the tear film dynamics on an eye-shaped domain during a realistic blink cycle.  In the model we examine the influence of the blink on tear film formation.  To our knowledge, this is the first mathematical model of tear film dynamics during blinking over the whole exposed ocular surface, and experimental methods do not yet have the capability to estimate the tear film thickness in the same detail.  Therefore, the model is expected to improve understanding of tear film formation and to make predictions that may be experimentally tested in the future.    We formulate a mathematical model for the moving eye-shaped domain via a computational least-squares fit to the lid margins from a video recording of a blink.  The result becomes the moving boundary for the simulation of tear film dynamics derived using a thin film approximation to the fluid flow inside that moving domain. The model includes surface tension, viscosity, evaporation and wetting of the ocular surface.  We then implemented a moving overset grid method to numerically approximate the thin film equations for the tear film dynamics.  The numerical approach is implemented in the Overture framework.    The formation of the tear film over the eye during the upstroke is sensitive to the speed of lid motion, as well as to boundary fluxes from lacrimal supply and punctal drainage.  A sufficiently large supply of aqueous of tear fluid under the moving lids is required for adequately coating the ocular surface.  Our results will be closely compared with prior modeling results as well as available experimental results.    A simulation of the tear film dynamics on a blinking eye-shaped domain was created and its influence on the tear film formation during the upstroke was studied.    We proposed quantities that are candidates for experimental verification.  This is an abstract that was submitted for the 2016 ARVO Annual Meeting, held in Seattle, Wash., May 1-5, 2016.},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{malikFastRandomizedMatrix2020,
  title = {Fast Randomized Matrix and Tensor Interpolative Decomposition Using {{CountSketch}}},
  author = {Malik, Osman Asif and Becker, Stephen},
  year = {2020},
  month = oct,
  journal = {Advances in Computational Mathematics},
  volume = {46},
  number = {6},
  pages = {76},
  issn = {1572-9044},
  doi = {10.1007/s10444-020-09816-9},
  urldate = {2021-03-22},
  abstract = {We propose a new fast randomized algorithm for interpolative decomposition of matrices which utilizes CountSketch. We then extend this approach to the tensor interpolative decomposition problem introduced by Biagioni et al. (J. Comput. Phys. 281(C), 116--134 (2015)). Theoretical performance guarantees are provided for both the matrix and tensor settings. Numerical experiments on both synthetic and real data demonstrate that our algorithms maintain the accuracy of competing methods, while running in less time, achieving at least an order of magnitude speedup on large matrices and tensors.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Malik_Becker_2020_Fast randomized matrix and tensor interpolative decomposition using CountSketch.pdf}
}

@article{ManganModelSelection2017,
  title = {Model Selection for Dynamical Systems via Sparse Regression and Information Criteria},
  author = {Mangan, N. M. and Kutz, J. N. and Brunton, S. L. and Proctor, J. L.},
  year = {2017},
  month = aug,
  journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
  volume = {473},
  number = {2204},
  pages = {20170009},
  publisher = {{Royal Society}},
  doi = {10.1098/rspa.2017.0009},
  urldate = {2023-06-20},
  abstract = {We develop an algorithm for model selection which allows for the consideration of a combinatorially large number of candidate models governing a dynamical system. The innovation circumvents a disadvantage of standard model selection which typically limits the number of candidate models considered due to the intractability of computing information criteria. Using a recently developed sparse identification of nonlinear dynamics algorithm, the sub-selection of candidate models near the Pareto frontier allows feasible computation of Akaike information criteria (AIC) or Bayes information criteria scores for the remaining candidate models. The information criteria hierarchically ranks the most informative models, enabling the automatic and principled selection of the model with the strongest support in relation to the time-series data. Specifically, we show that AIC scores place each candidate model in the strong support, weak support or no support category. The method correctly recovers several canonical dynamical systems, including a susceptible-exposed-infectious-recovered disease model, Burgers' equation and the Lorenz equations, identifying the correct dynamical system as the only candidate model with strong support.},
  keywords = {data-driven discovery,information criteria,model selection,nonlinear dynamics,sparse regression},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Mangan et al_2017_Model selection for dynamical systems via sparse regression and information.pdf}
}

@article{Manning_Different_1986,
  title = {Different Forms of Blinks and Their Two-Stage Control},
  author = {Manning, {\relax KA} and Evinger, C},
  year = {1986},
  journal = {Experimental Brain Research},
  doi = {10.1007/bf00340495},
  abstract = {Summary The purpose of this paper is to examine blink kinematics and the neural basis of blinks evoked reflexively by different kinds of stimuli. The kinematics of the upper lid movement and the electromyographic response of lid muscles levator palpebrae and ...}
}

@misc{MaoTrainingProcess2023,
  title = {The {{Training Process}} of {{Many Deep Networks Explores}} the {{Same Low-Dimensional Manifold}}},
  author = {Mao, Jialin and Griniasty, Itay and Teoh, Han Kheng and Ramesh, Rahul and Yang, Rubing and Transtrum, Mark K. and Sethna, James P. and Chaudhari, Pratik},
  year = {2023},
  month = jun,
  number = {arXiv:2305.01604},
  eprint = {2305.01604},
  primaryclass = {cond-mat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2305.01604},
  urldate = {2023-09-19},
  abstract = {We develop information-geometric techniques to analyze the trajectories of the predictions of deep networks during training. By examining the underlying high-dimensional probabilistic models, we reveal that the training process explores an effectively low-dimensional manifold. Networks with a wide range of architectures, sizes, trained using different optimization methods, regularization techniques, data augmentation techniques, and weight initializations lie on the same manifold in the prediction space. We study the details of this manifold to find that networks with different architectures follow distinguishable trajectories but other factors have a minimal influence; larger networks train along a similar manifold as that of smaller networks, just faster; and networks initialized at very different parts of the prediction space converge to the solution along a similar manifold.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural Networks},
  file = {/Users/driscoll/Dropbox/library/Preprint/Mao et al_2023_The Training Process of Many Deep Networks Explores the Same Low-Dimensional.pdf;/Users/driscoll/Zotero/storage/DUMKR8SE/2305.html}
}

@article{Mark_Aqueous_2010,
  title = {Aqueous Humor Dynamics in Historical Perspective},
  author = {Mark, Harry H},
  year = {2010},
  volume = {55},
  number = {1},
  pages = {89--100},
  issn = {0039-6257},
  doi = {10.1016/j.survophthal.2009.06.005},
  abstract = {In antiquity the aqueous humor was seen as essential to moisten and nourish the lens--- the actual organ of vision---and therefore any loss was believed to lead to blindness. The recuperation of the eye after some aqueous loss during cataract couching and experimental loss in animals slowly undermined this idea in the 16th and 17th centuries. In the 18th century production of aqueous from the ciliary region and its outflow from the anterior chamber, and thus its circulation, was generally accepted. Early in the 19th century the aqueous was thought to be encapsulated, but by the end of the century the general dynamic principles of aqueous flow as we know them today were experimentally and clinically confirmed. The controversy concerning its mode of production and circulation that took place early in the 20th century was resolved with the discovery of the aqueous veins and advances in molecular biology.},
  pmid = {19783023}
}

@article{marquardtAlgorithmLeastSquaresEstimation1963,
  title = {An {{Algorithm}} for {{Least-Squares Estimation}} of {{Nonlinear Parameters}}},
  author = {Marquardt, Donald W.},
  year = {1963},
  month = jun,
  journal = {Journal of the Society for Industrial and Applied Mathematics},
  volume = {11},
  number = {2},
  pages = {431--441},
  issn = {0368-4245, 2168-3484},
  doi = {10.1137/0111030},
  urldate = {2020-06-18},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Marquardt-1963-An Algorithm for Least-Squares Estimation of Nonlinear2.pdf}
}

@article{martensConformalMappingAnalyses1992,
  title = {Conformal Mapping Analyses of Microstrips with Circular and Elliptical Cross-Sections},
  author = {Martens, M.A. and Brown, R.W. and Haacke, E.M.},
  year = {1992},
  month = sep,
  journal = {IEEE Transactions on Microwave Theory and Techniques},
  volume = {40},
  number = {9},
  pages = {1836--1840},
  issn = {0018-9480, 1557-9670},
  doi = {10.1109/22.156612},
  abstract = {A conformal transformation is derived in terms of a Schwarz-Christoffel transformation involving elliptic integrals of the first and third kind. This mapping function is used to give exact solutions for TEM excitations of microstrips and coupled microstrips with circular and elliptical cross-sections. Using these maps, the uniformity of the TEM mode magnetic field inside an elliptical slotted tube transmission line is investigated.{$<>$}},
  keywords = {Capacitance,circular cross-sections,Conformal mapping,conformal mapping analysis,conformal transformation,coupled microstrips,Dielectric measurements,elliptic integrals,elliptical cross-sections,elliptical slotted tube transmission line,Fabrication,Impedance,mapping function,Metallization,Microstrip resonators,Microwave theory and techniques,Q measurement,Schwarz-Christoffel transformation,strip lines,Strips,TEM excitations,TEM mode magnetic field,transforms,waveguide theory},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Martens et al_1992_Conformal mapping analyses of microstrips with circular and elliptical.pdf;/Users/driscoll/Zotero/storage/SJEZUNJ6/156612.html}
}

@article{Martin2012,
  title = {The Extraordinary {{SVD}}},
  author = {Martin, Carla D. and Porter, Mason A.},
  year = {2012},
  journal = {The American Mathematical Monthly},
  volume = {119},
  number = {10},
  pages = {838},
  publisher = {{Mathematical Association of America}},
  doi = {10.4169/amer.math.monthly.119.10.838},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Martin_Porter_2012_The extraordinary SVD.pdf}
}

@article{MarxPauwelsWeisserEtAl2019,
  title = {Tractable Semi-Algebraic Approximation Using {{Christoffel-Darboux}} Kernel},
  author = {Marx, Swann and Pauwels, Edouard and Weisser, Tillmann and Henrion, Didier and Lasserre, Jean},
  year = {2019},
  month = apr,
  eprint = {1904.01833v1},
  primaryclass = {math.OC},
  abstract = {We provide a new method to approximate a (possibly discontinuous) function using Christoffel-Darboux kernels. Our knowledge about the unknown multivariate function is in terms of finitely many moments of the Young measure supported on the graph of the function. Such an input is available when approximating weak (or measure-valued) solution of optimal control problems, entropy solutions to non-linear hyperbolic PDEs, or using numerical integration from finitely many evaluations of the function. While most of the existing methods construct a piecewise polynomial approximation, we construct a semi-algebraic approximation whose estimation and evaluation can be performed efficiently. An appealing feature of this method is that it deals with non-smoothness implicitly so that a single scheme can be used to treat smooth or non-smooth functions without any prior knowledge. On the theoretical side, we prove pointwise convergence almost everywhere as well as convergence in the Lebesgue one norm under broad assumptions. Using more restrictive assumptions, we obtain explicit convergence rates. We illustrate our approach on various examples from control and approximation. In particular we observe empirically that our method does not suffer from the the Gibbs phenomenon when approximating discontinuous functions.},
  archiveprefix = {arxiv},
  keywords = {math.OC,No DOI found}
}

@article{MassaroliDissectingNeural2020,
  title = {Dissecting {{Neural ODEs}}},
  author = {Massaroli, Stefano and Poli, Michael and Park, Jinkyoo and Yamashita, A. and Asama, H.},
  year = {2020},
  month = feb,
  journal = {ArXiv},
  urldate = {2023-11-02},
  abstract = {Continuous deep learning architectures have recently re-emerged as variants of Neural Ordinary Differential Equations (Neural ODEs). The infinite-depth approach offered by these models theoretically bridges the gap between deep learning and dynamical systems; however, deciphering their inner working is still an open challenge and most of their applications are currently limited to the inclusion as generic black-box modules. In this work, we "open the box" and offer a system-theoretic perspective, including state augmentation strategies and robustness, with the aim of clarifying the influence of several design choices on the underlying dynamics. We also introduce novel architectures: among them, a Galerkin-inspired depth-varying parameter model and neural ODEs with data-controlled vector fields.},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Massaroli et al_2020_Dissecting Neural ODEs.pdf}
}

@techreport{mathisDeepLabCutMarkerlessPose2018,
  title = {{{DeepLabCut}}: Markerless Pose Estimation of User-Defined Body Parts with Deep Learning},
  author = {Mathis, Alexander and Mamidanna, Pranav and Cury, Kevin M and Abe, Taiga and Murthy, Venkatesh N and Mathis, Mackenzie Weygandt and Bethge, Matthias},
  year = {2018},
  institution = {{Nature Publishing Group}},
  file = {/Users/driscoll/Zotero/storage/M8Q22VS8/Mathis et al. - 2018 - DeepLabCut markerless pose estimation of user-def.pdf}
}

@article{Matthysen2018,
  title = {Function Approximation on Arbitrary Domains Using Fourier Extension Frames},
  author = {Matthysen, Roel and Huybrechs, Daan},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Numerical Analysis},
  volume = {56},
  number = {3},
  pages = {1360--1385},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/17m1134809},
  keywords = {approximation,Fourier extension}
}

@article{McCabeMultiplePhysics2023,
  title = {Multiple {{Physics Pretraining}} for {{Physical Surrogate Models}}},
  author = {McCabe, Michael and Blancard, Bruno R{\'e}galdo-Saint and Parker, Liam Holden and Ohana, Ruben and Cranmer, Miles and Bietti, Alberto and Eickenberg, Michael and Golkar, Siavash and Krawezik, Geraud and Lanusse, Francois and Pettee, Mariel and Tesileanu, Tiberiu and Cho, Kyunghyun and Ho, Shirley},
  year = {2023},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2310.02994},
  urldate = {2023-11-02},
  abstract = {We introduce multiple physics pretraining (MPP), an autoregressive task-agnostic pretraining approach for physical surrogate modeling. MPP involves training large surrogate models to predict the dynamics of multiple heterogeneous physical systems simultaneously by learning features that are broadly useful across diverse physical tasks. In order to learn effectively in this setting, we introduce a shared embedding and normalization strategy that projects the fields of multiple systems into a single shared embedding space. We validate the efficacy of our approach on both pretraining and downstream tasks over a broad fluid mechanics-oriented benchmark. We show that a single MPP-pretrained transformer is able to match or outperform task-specific baselines on all pretraining sub-tasks without the need for finetuning. For downstream tasks, we demonstrate that finetuning MPP-trained models results in more accurate predictions across multiple time-steps on new physics compared to training from scratch or finetuning pretrained video foundation models. We open-source our code and model weights trained at multiple scales for reproducibility and community experimentation.},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Artificial Intelligence (cs.AI),FOS: Computer and information sciences,Machine Learning (cs.LG),Machine Learning (stat.ML)},
  file = {/Users/driscoll/Dropbox/library/Journal Article/McCabe et al_2023_Multiple Physics Pretraining for Physical Surrogate Models.pdf}
}

@article{McClennySelfAdaptivePhysicsInformed2020,
  title = {Self-{{Adaptive Physics-Informed Neural Networks}} Using a {{Soft Attention Mechanism}}},
  author = {McClenny, L. and {Braga-Neto}, U.},
  year = {2020},
  month = sep,
  journal = {ArXiv},
  urldate = {2023-11-02},
  abstract = {Physics-Informed Neural Networks (PINNs) have emerged recently as a promising application of deep neural networks to the numerical solution of nonlinear partial differential equations (PDEs). However, the original PINN algorithm is known to suffer from stability and accuracy problems in cases where the solution has sharp spatio-temporal transitions. These stiff PDEs require an unreasonably large number of collocation points to be solved accurately. It has been recognized that adaptive procedures are needed to force the neural network to fit accurately the stubborn spots in the solution of stiff PDEs. To accomplish this, previous approaches have used fixed weights hard-coded over regions of the solution deemed to be important. In this paper, we propose a fundamentally new method to train PINNs adaptively, where the adaptation weights are fully trainable, so the neural network learns by itself which regions of the solution are difficult and is forced to focus on them, which is reminiscent of soft multiplicative-mask attention mechanism used in computer vision. The basic idea behind these Self-Adaptive PINNs is to make the weights increase where the corresponding loss is higher, which is accomplished by training the network to simultaneously minimize the losses and maximize the weights, i.e., to find a saddle point in the cost surface. We show that this is formally equivalent to solving a PDE-constrained optimization problem using a penalty-based method, though in a way where the monotonically-nondecreasing penalty coefficients are trainable. Numerical experiments with an Allen-Cahn stiff PDE, the Self-Adaptive PINN outperformed other state-of-the-art PINN algorithms in L2 error by a wide margin, while using a smaller number of training epochs. An Appendix contains additional results with Burger's and Helmholtz PDEs, which confirmed the trends observed in the Allen-Cahn experiments.},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/McClenny_Braga-Neto_2020_Self-Adaptive Physics-Informed Neural Networks using a Soft Attention Mechanism.pdf}
}

@inproceedings{McCullochDATADRIVEN2014,
  title = {{{DATA DRIVEN MATHEMATICAL MODELING OF THE SINGLE VENTRICLE ANATOMY AND PHYSIOLOGY}}},
  booktitle = {Critical {{Care Medicine}}},
  author = {McCulloch, Michael and Chen, Lei and Schleiniger, Gilberto and Driscoll, Tobin},
  year = {2014},
  volume = {42},
  pages = {A1414},
  publisher = {{LWW}},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{mcinnesUMAPUniformManifold2018,
  title = {{{UMAP}}: {{Uniform Manifold Approximation}} and {{Projection}} for {{Dimension Reduction}}},
  shorttitle = {{{UMAP}}},
  author = {McInnes, Leland and Healy, John and Melville, James},
  year = {2018},
  month = dec,
  journal = {arXiv:1802.03426 [cs, stat]},
  eprint = {1802.03426},
  primaryclass = {cs, stat},
  urldate = {2019-11-10},
  abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computational Geometry,Computer Science - Machine Learning,No DOI found,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Journal Article/McInnes et al_2018_UMAP.pdf;/Users/driscoll/Zotero/storage/U5BLVCTT/1802.html}
}

@article{McLaren_Measurement_2009,
  title = {Measurement of Aqueous Humor Flow},
  author = {W, Jay, McLaren},
  year = {2009},
  volume = {88},
  number = {4},
  pages = {641--647},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2008.10.018},
  abstract = {Aqueous humor flow, one of the primary determinants of intraocular pressure, has been measured non-invasively in the human eye since the early 1950s. Other than sleep, which decreases flow rate to approximately half of what it is during alert wakefulness, few conditions affect flow rate. Three classes of medication can suppress flow and have been used therapeutically, {$\beta$}-adrenergic antagonists, {$\alpha$}2-adrenergic agonists, and carbonic anhydrase inhibitors. Studies of the production and circulation of aqueous humor have provided a basis for understanding the fundamental dynamics of the eye as well as understanding treatments for glaucoma.},
  pmid = {19026639}
}

@article{McMonnies_Blink_2011,
  title = {Blink Efficiency: A Neglected Area of Ocular Surface Disease Management?},
  author = {W, Charles, McMonnies},
  year = {2011},
  volume = {52},
  number = {7},
  pages = {4484},
  issn = {1552-5783},
  doi = {10.1167/iovs.11-7751},
  pmid = {21700718}
}

@article{McMonnies_Incomplete_2007,
  title = {Incomplete Blinking: {{Exposure}} Keratopathy, Lid Wiper Epitheliopathy, Dry Eye, Refractive Surgery, and Dry Contact Lenses},
  author = {W, Charles, McMonnies},
  year = {2007},
  volume = {30},
  number = {1},
  pages = {37--51},
  issn = {1367-0484},
  doi = {10.1016/j.clae.2006.12.002},
  abstract = {Exposure keratopathy, including that which occurs following laser assisted keratomileusis, appears to be associated with incomplete blinking. Incomplete blinking may contribute to the signs and symptoms of lid wiper epitheliopathy. In addition, precipitation of contact lens surface deposits and other contact lens surface drying phenomena, appear to be accelerated by incomplete blinking. For the inferior cornea or contact lens surface an incomplete blink approximately doubles the interblink interval and tear evaporation time, becoming even longer as blink rates reduce for computer and reading tasks. Inadequate aqueous, mucous and lipid distribution, as well as tear thinning over the exposed ocular or contact lens surface, may further increase the rate and significance of tear break-up and evaporation following an incomplete blink. Increased tear osmolarity that is associated with accelerated tear evaporation may also contribute to tissue changes and symptoms. Behaviour modification and habit reversal methods can be employed in the provision of blink efficiency exercises that are used to overcome incomplete blinking habits, with the potential to improve lipid, mucous and aqueous distribution so that exposure keratopathy, lid wiper epitheliopathy, and any associated symptoms are alleviated and/or prevented. Similarly, improved blink efficiency may help maintain lens surface condition and alleviate dryness symptoms for contact lens wearers. Lubricant drop instillation that is combined with blink efficiency exercises may increase the therapeutic benefit to corneal, conjunctival and lid wiper epithelium, as well as improving contact lens performance. Conditions of drop instillation, that reduce reflex blinking and tearing, may increase drop contact time and therapeutic benefit.},
  pmid = {17251052}
}

@article{Meade1998,
  title = {{{ODE}} Models for the Parachute Problem},
  author = {Meade, Douglas B.},
  year = {1998},
  month = jan,
  journal = {SIAM Review},
  volume = {40},
  number = {2},
  pages = {327--332},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/s0036144596316248}
}

@article{meadeDifferentialEquationsNew1999,
  title = {Differential Equations in the New Millennium: {{The}} Parachute Problem},
  author = {Meade, Douglas B. and Struthers, A. A.},
  year = {1999},
  journal = {International Journal of Engineering Education},
  volume = {15},
  number = {6},
  pages = {417--424},
  keywords = {No DOI found}
}

@article{Miao2011,
  title = {On Identifiability of Nonlinear {{ODE}} Models and Applications in Viral Dynamics},
  author = {Miao, Hongyu and Xia, Xiaohua and Perelson, Alan S. and Wu, Hulin},
  year = {2011},
  month = jan,
  journal = {SIAM Review},
  volume = {53},
  number = {1},
  pages = {3--39},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/090757009},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Miao et al_2011_On identifiability of nonlinear ODE models and applications in viral dynamics.pdf}
}

@misc{mirzaConditionalGenerativeAdversarial2014,
  title = {Conditional {{Generative Adversarial Nets}}},
  author = {Mirza, Mehdi and Osindero, Simon},
  year = {2014},
  month = nov,
  number = {arXiv:1411.1784},
  eprint = {1411.1784},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1411.1784},
  urldate = {2022-09-07},
  abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Preprint/Mirza_Osindero_2014_Conditional Generative Adversarial Nets.pdf;/Users/driscoll/Zotero/storage/MM9HSADR/1411.html}
}

@article{Mishima65,
  title = {Some Physiological Aspects of the Precorneal Tear Film},
  author = {Mishima, S.},
  year = {1965},
  journal = {Archives of Ophthalmology},
  volume = {73},
  pages = {233--241},
  doi = {10.1001/archopht.1965.00970030235017}
}

@article{Mishima66,
  title = {Determination of Tear Volume and Tear Flow},
  author = {Mishima, S. and Gasset, A. and Klyce, S. D. and Baum, J. L.},
  year = {1966},
  journal = {Investigative Ophthalmology},
  volume = {5},
  pages = {264--276},
  keywords = {No DOI found}
}

@article{molerHistoryMATLAB2020,
  title = {A History of {{MATLAB}}},
  author = {Moler, Cleve and Little, Jack},
  year = {2020},
  month = jun,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {4},
  number = {HOPL},
  pages = {81:1--81:67},
  doi = {10.1145/3386331},
  urldate = {2020-07-30},
  abstract = {The first MATLAB (the name is short for ``Matrix Laboratory'') was not a programming language. Written in Fortran in the late 1970s, it was a simple interactive matrix calculator built on top of about a dozen subroutines from the LINPACK and EISPACK matrix software libraries. There were only 71 reserved words and built-in functions. It could be extended only by modifying the Fortran source code and recompiling it. The programming language appeared in 1984 when MATLAB became a commercial product. The calculator was reimplemented in C and significantly enhanced with the addition of user functions, toolboxes, and graphics. It was available initially on the IBM PC and clones; versions for Unix workstations and the Apple Macintosh soon followed. In addition to the matrix functions from the calculator, the 1984 MATLAB included fast Fourier transforms (FFT). The Control System Toolbox appeared in 1985 and the Signal Processing Toolbox in 1987. Built-in support for the numerical solution of ordinary differential equations also appeared in 1987. The first significant new data structure, the sparse matrix, was introduced in 1992. The Image Processing Toolbox and the Symbolic Math Toolbox were both introduced in 1993. Several new data types and data structures, including single precision floating point, various integer and logical types, cell arrays, structures, and objects were introduced in the late 1990s. Enhancements to the MATLAB computing environment have dominated development in recent years. Included are extensions to the desktop, major enhancements to the object and graphics systems, support for parallel computing and GPUs, and the ``Live Editor'', which combines programs, descriptive text, output and graphics into a single interactive, formatted document. Today there are over 60 Toolboxes, many programmed in the MATLAB language, providing extended capabilities in specialized technical fields.},
  keywords = {linear algebra,MATLAB,matrix computation},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Moler_Little-2020-A history of MATLAB.pdf}
}

@book{molerNumericalComputingMATLAB2010,
  title = {Numerical {{Computing}} with {{MATLAB}}: {{Revised Reprint}}},
  shorttitle = {Numerical {{Computing}} with {{MATLAB}}},
  author = {Moler, Cleve B.},
  year = {2010},
  month = aug,
  publisher = {{SIAM}},
  abstract = {This is a lively textbook for an introductory course in numerical methods, MATLAB, and technical computing, which emphasises the informed use of mathematical software.?Numerical Computing with MATLAB?helps readers learn about the mathematical functions in?MATLAB, how to appreciate their limitations, and how to use and modify them appropriately. The book makes extensive use of computer graphics, and provides more than 70 M-files, which can be downloaded from the text Web site www.mathworks.com/moler. Many of the numerous exercises involve modifying and extending these programs. The theory can be adapted to apply to modern problems from cryptography, touch-tone dialing, Google page-ranking, atmospheric science and image processing, as well as classical problems from physics and engineering. This book will appeal to advanced undergraduate and beginning graduate students in science and engineering. This revision includes changes and corrections made since the book was originally published in 2004.},
  googlebooks = {\_Cad7uaYcloC},
  isbn = {978-0-89871-660-3},
  langid = {english},
  keywords = {Computers / General}
}

@book{mortonNumericalSolutionPartial2005,
  title = {Numerical {{Solution}} of {{Partial Differential Equations}}: {{An Introduction}}},
  shorttitle = {Numerical {{Solution}} of {{Partial Differential Equations}}},
  author = {Morton, K. W. and Mayers, D. F.},
  year = {2005},
  month = apr,
  edition = {2nd},
  publisher = {{Cambridge University Press}},
  abstract = {This is the 2005 second edition of a highly successful and well-respected textbook on the numerical techniques used to solve partial differential equations arising from mathematical models in science, engineering and other fields. The authors maintain an emphasis on finite difference methods for simple but representative examples of parabolic, hyperbolic and elliptic equations from the first edition. However this is augmented by new sections on finite volume methods, modified equation analysis, symplectic integration schemes, convection-diffusion problems, multigrid, and conjugate gradient methods; and several sections, including that on the energy method of analysis, have been extensively rewritten to reflect modern developments. Already an excellent choice for students and teachers in mathematics, engineering and computer science departments, the revised text includes more latest theoretical and industrial developments.},
  googlebooks = {GW6\_AwAAQBAJ},
  isbn = {978-1-139-44320-3},
  langid = {english},
  keywords = {Business & Economics / Investments & Securities / General,Mathematics / Applied,Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis}
}

@book{murphyMachineLearningProbabilistic2021,
  title = {Machine Learning: A Probabilistic Perspective},
  shorttitle = {Machine Learning},
  author = {Murphy, Kevin P},
  year = {2021},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA}},
  isbn = {978-0-262-04466-0},
  langid = {english},
  annotation = {OCLC: 1255636989},
  file = {/Users/driscoll/Dropbox/library/Book/Murphy-2021-Machine learning.pdf}
}

@article{Nakamori_Blinking_1997,
  title = {Blinking Is Controlled Primarily by Ocular Surface Conditions},
  author = {Nakamori, K and Odawara, M and Nakajima, T and Mizutani, T},
  year = {1997},
  journal = {American journal of {\dots}},
  abstract = {Purpose To investigate the relation between blinking and ocular surface conditions and to introduce and examine a new index, the maximum blink interval. Methods In a prospective study, the blink rate of subjects under relaxed conditions was determined from a video ...},
  keywords = {No DOI found}
}

@article{Nakatsukasa2014,
  title = {Computing the Common Zeros of Two Bivariate Functions via {{B{\'e}zout}} Resultants},
  author = {Nakatsukasa, Yuji and Noferini, Vanni and Townsend, Alex},
  year = {2014},
  month = may,
  journal = {Numerische Mathematik},
  volume = {129},
  number = {1},
  pages = {181--209},
  publisher = {{Springer Nature}},
  doi = {10.1007/s00211-014-0635-z}
}

@article{NakatsukasaAAAAlgorithm2018a,
  title = {The {{AAA Algorithm}} for {{Rational Approximation}}},
  author = {Nakatsukasa, Yuji and S{\`e}te, Olivier and Trefethen, Lloyd N.},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {40},
  number = {3},
  pages = {A1494-A1522},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/16m1106122},
  urldate = {2020-07-14},
  abstract = {We introduce a new algorithm for approximation by rational functions on a real or complex set of points, implementable in 40 lines of MATLAB and requiring no user input parameters.  Even on a disk or interval the algorithm may outperform existing methods, and on more complicated domains it is especially competitive.  The core ideas are (1) representation of the rational approximant in barycentric form with interpolation at certain support points and (2) greedy selection of the support points to avoid exponential instabilities.  The name AAA stands for ``adaptive Antoulas--Anderson'' in honor of the authors who introduced a scheme based on (1).  We present the core algorithm with a MATLAB code and nine applications and describe variants targeted at problems of different kinds. Comparisons are made with vector fitting, RKFIT, and other existing methods for rational approximation.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Nakatsukasa et al_2018_The AAA Algorithm for Rational Approximation.pdf;/Users/driscoll/Dropbox/library/Journal Article/Nakatsukasa_Sète_Trefethen-2018-The AAA Algorithm for Rational Approximation.pdf;/Users/driscoll/Zotero/storage/CAEEMFCK/16M1106122.html}
}

@article{NakatsukasaAlgorithmReal2020a,
  title = {An {{Algorithm}} for {{Real}} and {{Complex Rational Minimax Approximation}}},
  author = {Nakatsukasa, Yuji and Trefethen, Lloyd N.},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {42},
  number = {5},
  pages = {A3157-A3179},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/19M1281897},
  urldate = {2023-09-13},
  abstract = {We introduce a new algorithm for approximation by rational functions on a real or complex set of points, implementable in 40 lines of MATLAB and requiring no user input parameters.  Even on a disk or interval the algorithm may outperform existing methods, and on more complicated domains it is especially competitive.  The core ideas are (1) representation of the rational approximant in barycentric form with interpolation at certain support points and (2) greedy selection of the support points to avoid exponential instabilities.  The name AAA stands for ``adaptive Antoulas--Anderson'' in honor of the authors who introduced a scheme based on (1).  We present the core algorithm with a MATLAB code and nine applications and describe variants targeted at problems of different kinds. Comparisons are made with vector fitting, RKFIT, and other existing methods for rational approximation.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Nakatsukasa_Trefethen_2020_An Algorithm for Real and Complex Rational Minimax Approximation2.pdf}
}

@book{nashHistoryScientificComputing1990,
  title = {A {{History}} of {{Scientific Computing}}},
  author = {Nash, Stephen},
  year = {1990},
  publisher = {{Addison-Wesley Publishing Company}},
  abstract = {Essays about pioneers in the field of scientific and numeric computing--John von Neumann, James Wilkinson, George Forsythe, and Howard Aiken--show how the drive to solve particular problems influenced the development of algorithms, software, and even computers. Methods that have led to new tools in computer analysis, such as the fast Fourier transform and finite-element and iterative methods, also are discussed, as well as the contributions of scientific organizations like ACM and SIAM and institutions like the Los Alamos Laboratory and the former National Bureau of Standards. The volume concludes with a view of numerical analysis in Europe and the Soviet Union. Annotation copyrighted by Book News, Inc., Portland, OR},
  googlebooks = {XscmAAAAMAAJ},
  isbn = {978-0-201-50814-7},
  langid = {english},
  keywords = {Computers / General}
}

@book{nazarathyStatisticsJuliaFundamentals2020,
  title = {Statistics with {{Julia}}: {{Fundamentals}} for {{Data Science}}, {{Machine Learning}} and {{Artificial Intelligence}}},
  author = {Nazarathy, Yoni and Klok, Hayden},
  year = {2020},
  month = aug,
  annotation = {DRAFT},
  file = {/Users/driscoll/Dropbox/library/Book/Nazarathy_Klok_2020_Statistics with Julia.pdf;/Users/driscoll/Zotero/storage/87F4FC7H/StatisticsWithJulia.pdf}
}

@article{Neidinger2010,
  title = {Introduction to Automatic Differentiation and {{MATLAB}} Object-Oriented Programming},
  author = {Neidinger, Richard D.},
  year = {2010},
  month = jan,
  journal = {SIAM Review},
  volume = {52},
  number = {3},
  pages = {545--563},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/080743627},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Neidinger_2010_Introduction to automatic differentiation and MATLAB object-oriented programming.pdf}
}

@article{NevesAdaptiveMethods2011,
  ids = {nevesAdaptiveMethodsAnalysis2011a},
  title = {Adaptive {{Methods}} for {{Analysis}} of {{Composite Plates}} with {{Radial Basis Functions}}},
  author = {Neves, A. M. A. and Driscoll, T. A. and Heryudono, A. R. H. and Ferreira, A. J. M. and Soares, C. M. M. and Jorge, R. M. N.},
  year = {2011},
  month = sep,
  journal = {Mechanics of Advanced Materials and Structures},
  volume = {18},
  number = {6},
  pages = {420--430},
  issn = {1537-6494},
  doi = {10.1080/15376494.2010.528155},
  abstract = {Driscoll and Heryudono [1] developed an adaptive method for radial basis functions method. This article addresses the adaptive analysis of composite plates in bending with radial basis multiquadric functions using Driscoll and Heryudono's technique. In this article, various laminates, thickness to side length ratios, and boundary conditions are considered. The method allows for a more natural and automatic selection of the problem grid, where the user must only define the error tolerance. The results obtained show an interesting and promising approach to the static analysis of composite laminates. Driscoll and Heryudono [1] developed an adaptive method for radial basis functions method. This article addresses the adaptive analysis of composite plates in bending with radial basis multiquadric functions using Driscoll and Heryudono's technique. In this article, various laminates, thickness to side length ratios, and boundary conditions are considered. The method allows for a more natural and automatic selection of the problem grid, where the user must only define the error tolerance. The results obtained show an interesting and promising approach to the static analysis of composite laminates.},
  copyright = {All rights reserved}
}

@article{nevesRBFDirectMethod2012,
  title = {3.1 {{On}} the {{RBF-Direct}} Method},
  author = {Neves, Ana MA and Driscoll, {\relax TA} and Heryudono, {\relax ARH} and Ferreira, {\relax AJM} and Soares, {\relax CMM} and Jorge, {\relax RMN} and Roque, {\relax CMC} and others},
  year = {2012},
  journal = {Departamento de Engenharia Mec{\^a}nica},
  pages = {419},
  keywords = {No DOI found}
}

@article{NewmanScientificCollaboration2001,
  title = {Scientific Collaboration Networks.  {{I}}. {{Network}} Construction and Fundamental Results},
  author = {Newman, M. E. J.},
  year = {2001},
  month = jun,
  journal = {Physical Review E},
  volume = {64},
  number = {1},
  pages = {016131},
  publisher = {{American Physical Society}},
  doi = {10.1103/PhysRevE.64.016131},
  urldate = {2023-05-02},
  abstract = {Using computer databases of scientific papers in physics, biomedical research, and computer science, we have constructed networks of collaboration between scientists in each of these disciplines. In these networks two scientists are considered connected if they have coauthored one or more papers together. We study a variety of statistical properties of our networks, including numbers of papers written by authors, numbers of authors per paper, numbers of collaborators that scientists have, existence and size of a giant component of connected scientists, and degree of clustering in the networks. We also highlight some apparent differences in collaboration patterns between the subjects studied. In the following paper, we study a number of measures of centrality and connectedness in the same networks.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Newman_2001_Scientific collaboration networks.pdf;/Users/driscoll/Zotero/storage/NFCIX2QE/PhysRevE.64.html}
}

@article{NewmanStructureFunction2003,
  title = {The {{Structure}} and {{Function}} of {{Complex Networks}}},
  author = {Newman, M. E. J.},
  year = {2003},
  month = jan,
  journal = {SIAM Review},
  volume = {45},
  number = {2},
  pages = {167--256},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/S003614450342480},
  urldate = {2023-06-08},
  abstract = {In recent years, the size of many social networks such as Facebook, MySpace, and LinkedIn has exploded at a rapid pace, because of its convenience in using the internet in order to connect geographically disparate users. This has lead to considerable interest in many graph-theoretical aspects of social networks such as the underlying communities, the graph diameter, and other structural information which can be used in order to mine useful information from the social network. The graph structure of social networks is influenced by the underlying social behavior, which can vary considerably over different groups of individuals. One of the disadvantages of existing schemes is that they attempt to determine global communities, which (implicitly) assume uniform behavior over the network. This is not very well suited to the differences in the underlying density in different regions of the social network. As a result, a global analysis over social community structure can result in either very small communities (in sparse regions), or communities which are too large and incoherent (in dense regions). In order to handle the challenge of local heterogeneity, we will explore a simple property of social networks, which we refer to as the local succinctness property. We will use this property in order to extract compressed descriptions of the underlying community representation of the social network with the use of a min-hash approach. We will show that this approach creates balanced communities across a heterogeneous network in an effective way. We apply the approach to a variety of data sets, and illustrate its effectiveness over competing techniques.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Newman_2003_The Structure and Function of Complex Networks.pdf}
}

@article{newtonPlasmaSalivaryPharmacokinetics1981,
  title = {Plasma and Salivary Pharmacokinetics of Caffeine in Man},
  author = {Newton, R. and Broughton, L. J. and Lind, M. J. and Morrison, P. J. and Rogers, H. J. and Bradbrook, I. D.},
  year = {1981},
  month = jan,
  journal = {European Journal of Clinical Pharmacology},
  volume = {21},
  number = {1},
  pages = {45--52},
  issn = {1432-1041},
  doi = {10.1007/bf00609587},
  urldate = {2020-06-18},
  abstract = {Plasma and salivary caffeine concentrations were measured by gas-liquid chromatography in 6 healthy caffeine-free volunteers following oral administration of 50, 300, 500 and 750 mg caffeine. Caffeine was also given to a single subject intravenously in doses of 300, 500 and 750 mg. Caffeine was rapidly absorbed and was completely available at all doses. The apparent first-order elimination rate constant decreased linearly with dose and was 0.163{\textpm}0.081 h-1 for 50 mg and 0.098{\textpm}0.027 h-1 for 750 mg. The total body clearance was unaffected by dose and was 0.98{\textpm}0.38 ml/min/kg. There was a trend towards increasing apparent volume of distribution with increasing dose. A linear relationship existed between the area under the plasma concentration, time curve and dose and dose-normalised plasma concentration, time plots were superimposable. These findings suggest that caffeine obeys linear pharmacokinetics over the dose range investigated. Despite significant inter-individual differences in pharmacokinetic parameters there was good reproducibility within 5 subjects given 300 mg caffeine orally on 3 occasions. Salivary caffeine levels probably reflect the unbound plasma caffeine concentration and can be used to estimate the pharmacokinetic parameters of the drug. Overall the saliva/plasma concentration ratio was 0.74{\textpm}0.08 but within subjects some time-dependence of the ratio was found with higher ratios initially (even after intravenous administration) and lower ratios at longer time intervals after the dose. Urinary elimination of caffeine was low and independent of dose: 1.83\% of the dose was eliminated unchanged.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Newton et al-1981-Plasma and salivary pharmacokinetics of caffeine in man.pdf}
}

@inproceedings{ngSpectralClusteringAnalysis2002,
  title = {On Spectral Clustering: {{Analysis}} and an Algorithm},
  shorttitle = {On Spectral Clustering},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Ng, Andrew Y. and Jordan, Michael I. and Weiss, Yair},
  year = {2002},
  pages = {849--856},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Ng et al_2002_On spectral clustering.pdf}
}

@article{NicholsThinningRate2005,
  title = {Thinning {{Rate}} of the {{Precorneal}} and {{Prelens Tear Films}}},
  author = {Nichols, Jason J. and Mitchell, G. Lynn and {King-Smith}, P. Ewen},
  year = {2005},
  month = jul,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {46},
  number = {7},
  pages = {2353--2361},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {1552-5783},
  doi = {10.1167/iovs.05-0094},
  urldate = {2021-08-06},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/9CS3SJ6H/Nichols et al. - 2005 - Thinning Rate of the Precorneal and Prelens Tear F.pdf;/Users/driscoll/Zotero/storage/N9T5NX3X/article.html}
}

@article{nielsenNeuralNetworksDeep2015,
  title = {Neural {{Networks}} and {{Deep Learning}}},
  author = {Nielsen, Michael A.},
  year = {2015},
  urldate = {2020-03-16},
  langid = {english},
  keywords = {No DOI found},
  file = {/Users/driscoll/Zotero/storage/GD4HJJXH/index.html}
}

@article{NorcliffeFasterTraining2023,
  title = {Faster {{Training}} of {{Neural ODEs Using Gau{\ss}-Legendre Quadrature}}},
  author = {Norcliffe, Alexander and Deisenroth, Marc Peter},
  year = {2023},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2308.10644},
  urldate = {2023-11-02},
  abstract = {Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gau{\ss}-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {FOS: Computer and information sciences,FOS: Mathematics,Machine Learning (cs.LG),Machine Learning (stat.ML),Numerical Analysis (math.NA)},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Norcliffe_Deisenroth_2023_Faster Training of Neural ODEs Using Gauß-Legendre Quadrature.pdf}
}

@article{Norn79,
  title = {Semiquantitative Interference Study of the Fatty Layer of Precorneal Film},
  author = {Norn, M. S.},
  year = {1979},
  journal = {Acta Ophthalmologica},
  volume = {57},
  pages = {766--774},
  doi = {10.1111/j.1755-3768.1979.tb01842.x}
}

@article{nornDesiccationPrecorneal1969,
  title = {Desiccation of the {{Precorneal Film}}},
  author = {Norn, M. S.},
  year = {1969},
  journal = {Acta Ophthalmologica},
  volume = {47},
  number = {4},
  pages = {881--889},
  issn = {1755-3768},
  doi = {10.1111/j.1755-3768.1969.tb03712.x},
  urldate = {2020-11-24},
  copyright = {1969 Institution Acta Ophthalmologica Scandinavica},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/7YU5CC39/j.1755-3768.1969.tb03712.html}
}

@incollection{nornTearFilm1986,
  title = {Tear Film Breakup Time: {{A}} Review},
  booktitle = {The Preocular Tear Film in Health, Disease and Contact Lens Wear},
  author = {Norn, M. S.},
  year = {1986},
  pages = {52--56},
  publisher = {{Dye Eye Institute}},
  address = {{Lubbock, TX}}
}

@book{OAAP,
  title = {Ocular Anatomy and Physiology},
  author = {{Lens} and A., Langley, Nemeth, S.C., T. and Shea, C.},
  year = {1999},
  publisher = {{John H. Bond}}
}

@book{ockendonAppliedPartialDifferential2003,
  title = {Applied {{Partial Differential Equations}}},
  author = {Ockendon, J. R. and Howison, Sam and Lacey, Andrew and Movchan, Alexander},
  year = {2003},
  publisher = {{Oxford University Press}},
  abstract = {Partial differential equations are used in mathematical models of a huge range of real-world phenomena, from electromagnetism to financial markets. This new edition of Applied PDEs contains many new sections and exercises Including, American options, transform methods, free surface flows, linear elasticity and complex characteristics.},
  googlebooks = {CdA6jcJWCToC},
  isbn = {978-0-19-852771-8},
  langid = {english},
  keywords = {Mathematics / Applied,Science / History}
}

@article{odonnellFastAlgorithmNumerical1989,
  title = {A {{Fast Algorithm}} for the {{Numerical Evaluation}} of {{Conformal Mappings}}},
  author = {O'Donnell, S. T. and Rokhlin, V.},
  year = {1989},
  month = may,
  journal = {SIAM Journal on Scientific and Statistical Computing},
  volume = {10},
  number = {3},
  pages = {475--487},
  issn = {0196-5204, 2168-3417},
  doi = {10.1137/0910031},
  urldate = {2019-11-18},
  langid = {english}
}

@article{Olver2013,
  title = {A Fast and Well-Conditioned Spectral Method},
  author = {Olver, Sheehan and Townsend, Alex},
  year = {2013},
  month = jan,
  journal = {SIAM Review},
  volume = {55},
  number = {3},
  pages = {462--489},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/120865458}
}

@book{olverNISTHandbookMathematical2010,
  title = {{{NIST Handbook}} of {{Mathematical Functions Hardback}} and {{CD-ROM}}},
  author = {Olver, Frank W. J. and Lozier, Daniel W. and Boisvert, Ronald F. and Clark, Charles W.},
  year = {2010},
  month = may,
  publisher = {{Cambridge University Press}},
  abstract = {Modern developments in theoretical and applied science depend on knowledge of the properties of mathematical functions, from elementary trigonometric functions to the multitude of special functions. These functions appear whenever natural phenomena are studied, engineering problems are formulated, and numerical simulations are performed. They also crop up in statistics, financial models, and economic analysis. Using them effectively requires practitioners to have ready access to a reliable collection of their properties. This handbook results from a 10-year project conducted by the National Institute of Standards and Technology with an international group of expert authors and validators. Printed in full color, it is destined to replace its predecessor, the classic but long-outdated Handbook of Mathematical Functions, edited by Abramowitz and Stegun. Included with every copy of the book is a CD with a searchable PDF of each chapter. Check out the news release and the video for this new book!},
  googlebooks = {3I15Ph1Qf38C},
  isbn = {978-0-521-19225-5},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / Mathematical Analysis,Mathematics / Reference}
}

@inproceedings{OlverPracticalFramework2014,
  title = {A Practical Framework for Infinite-Dimensional Linear Algebra},
  booktitle = {Roceedings of the 1st {{Workshop}} for {{High Performance Technical Computing}} in {{Dynamic Languages}} -- {{HPTCDL}} '14},
  author = {Olver, Sheehan and Townsend, Alex},
  year = {2014},
  publisher = {{IEEE}},
  doi = {10.1109/HPTCDL.2014.10}
}

@book{ortegaIterativeSolutionNonlinear2014,
  title = {Iterative {{Solution}} of {{Nonlinear Equations}} in {{Several Variables}}},
  author = {Ortega, J. M. and Rheinboldt, W. C.},
  year = {2014},
  month = may,
  publisher = {{Elsevier}},
  abstract = {Computer Science and Applied Mathematics: Iterative Solution of Nonlinear Equations in Several Variables presents a survey of the basic theoretical results about nonlinear equations in n dimensions and analysis of the major iterative methods for their numerical solution.This book discusses the gradient mappings and minimization, contractions and the continuation property, and degree of a mapping. The general iterative and minimization methods, rates of convergence, and one-step stationary and multistep methods are also elaborated. This text likewise covers the contractions and nonlinear majorants, convergence under partial ordering, and convergence of minimization methods.This publication is a good reference for specialists and readers with an extensive functional analysis background.},
  googlebooks = {UMDSBQAAQBAJ},
  isbn = {978-1-4832-7672-4},
  langid = {english},
  keywords = {Mathematics / General}
}

@article{owhadiKernelFlowsLearning2019,
  title = {Kernel {{Flows}}: {{From}} Learning Kernels from Data into the Abyss},
  shorttitle = {Kernel {{Flows}}},
  author = {Owhadi, Houman and Yoo, Gene Ryan},
  year = {2019},
  month = jul,
  journal = {Journal of Computational Physics},
  volume = {389},
  pages = {22--47},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2019.03.040},
  urldate = {2021-03-02},
  abstract = {Learning can be seen as approximating an unknown function by interpolating the training data. Although Kriging offers a solution to this problem, it requires the prior specification of a kernel and it is not scalable to large datasets. We explore a numerical approximation approach to kernel selection/construction based on the simple premise that a kernel must be good if the number of interpolation points can be halved without significant loss in accuracy (measured using the intrinsic RKHS norm {\textbardbl}{$\cdot$}{\textbardbl} associated with the kernel). We first test and motivate this idea on a simple problem of recovering the Green's function of an elliptic PDE (with inhomogeneous coefficients) from the sparse observation of one of its solutions. Next we consider the problem of learning non-parametric families of deep kernels of the form K1(Fn(x),Fn(x{$\prime$})) with Fn+1=(Id+{$\epsilon$}Gn+1){$\circ$}Fn and Gn+1{$\in$}span\{K1(Fn(xi),{$\cdot$})\}. With the proposed approach constructing the kernel becomes equivalent to integrating a stochastic data driven dynamical system, which allows for the training of very deep (bottomless) networks and the exploration of their properties. These networks learn by constructing flow maps in the kernel and input spaces via incremental data-dependent deformations/perturbations (appearing as the cooperative counterpart of adversarial examples) and, at profound depths, they (1) can achieve accurate classification from only one data point per class (2) appear to learn archetypes of each class (3) expand distances between points that are in different classes and contract distances between points in the same class. For kernels parameterized by the weights of Convolutional Neural Networks, minimizing approximation errors incurred by halving random subsets of interpolation points, appears to outperform training (the same CNN architecture) with relative entropy and dropout.},
  langid = {english},
  keywords = {Data driven dynamical system,Deep learning,Kriging,Learning Kernels,Reproducing Kernel Hilbert space,Support vector machine},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Owhadi_Yoo_2019_Kernel Flows.pdf;/Users/driscoll/Zotero/storage/A2X6FFVZ/S0021999119302232.html}
}

@article{Ozkan_Lens_2013,
  title = {Lens Parameter Changes under in Vitro and Ex Vivo Conditions and Their Effect on the Conjunctiva},
  author = {Ozkan, Jerome and Ehrmann, Klaus and Meadows, David and Lally, John and Holden, Brien and {de la Jara}, Percy},
  year = {2013},
  volume = {36},
  number = {4},
  pages = {171--175},
  issn = {1367-0484},
  doi = {10.1016/j.clae.2013.01.004},
  abstract = {PurposeTo quantify changes in contact lens parameters induced by lens wear and determine whether these changes are associated with contact lens-induced conjunctival staining (CLICS).MethodsIn vitro: Lens diameter, sag, edge shape, base curve of six contact lens brands (balafilcon, comfilcon, etafilcon, lotrafilcon B, omafilcon and senofilcon) measured at 21{$^\circ$}C and 35{$^\circ$}C (eye temperature). Ex vivo: Diameter of lenses collected from a prospective, randomised, contra-lateral, cross-over clinical trial from 36 subjects wearing all lens types for 1 week daily wear, measured in 35{$^\circ$}C PBS after removal. Ocular surface was examined for lens-induced conjunctival staining by masked examiner.ResultsIn vitro: Changes in diameter and base curve outside ISO tolerance were found with etafilcon A and omafilcon A. Ex vivo: Comfilcon A and etafilcon A had greatest shrinkage in diameter (0.18mm) and base curve (0.11mm steeper) with temperature increase from 21{$^\circ$}C to 35{$^\circ$}C. Senofilcon A, lotrafilcon B and balafilcon A maintained most stable parameters between 21{$^\circ$}C and 35{$^\circ$}C. Changes in diameter and base curve from lens wear were not correlated with CLICS (p\{{$>$}\}0.49). Multivariate analysis showed significantly greater levels of lens induced staining were associated with lens modulus (p\{{$<$}\}0.001) and knife (p\{{$<$}\}0.001) and chisel (p\{{$<$}\}0.001) edge shapes.ConclusionsParameter changes induced by lens wear were associated with increasing temperature, but these changes in lens diameter and base curve did not induce CLICS. Modulus and edge shape were associated with increased CLICS. The susceptibility of etafilcon A and omafilcon A lenses to parameter changes might be related to their high water content.},
  pmid = {23395396}
}

@article{Palakru07,
  title = {Effect of Blinking on Tear Dynamics},
  author = {Palakru, J. and Wang, J. and Aquavella, J.V.},
  year = {2007},
  journal = {Investigative Ophthalmology and Visual Science},
  volume = {48},
  pages = {3032--3037},
  doi = {10.1167/iovs.06-1507}
}

@article{PangNeuralnetinducedGaussian2019,
  title = {Neural-Net-Induced {{Gaussian}} Process Regression for Function Approximation and {{PDE}} Solution},
  author = {Pang, Guofei and Yang, Liu and Karniadakis, George Em},
  year = {2019},
  month = may,
  journal = {Journal of Computational Physics},
  volume = {384},
  pages = {270--288},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2019.01.045},
  urldate = {2024-02-14},
  abstract = {Neural-net-induced Gaussian process (NNGP) regression inherits both the high expressivity of deep neural networks (deep NNs) as well as the uncertainty quantification property of Gaussian processes (GPs). We generalize the current NNGP to first include a larger number of hyperparameters and subsequently train the model by maximum likelihood estimation. Unlike previous works on NNGP that targeted classification, here we apply the generalized NNGP to function approximation and to solving partial differential equations (PDEs). Specifically, we develop an analytical iteration formula to compute the covariance function of GP induced by deep NN with an error-function nonlinearity. We compare the performance of the generalized NNGP for function approximations and PDE solutions with those of GPs and fully-connected NNs. We observe that for smooth functions the generalized NNGP can yield the same order of accuracy with GP, while both NNGP and GP outperform deep NN. For non-smooth functions, the generalized NNGP is superior to GP and comparable or superior to deep NN.},
  keywords = {Machine learning,Neural network,NN-induced Gaussian process,Partial differential equation,Uncertainty quantification},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Pang et al_2019_Neural-net-induced Gaussian process regression for function approximation and.pdf;/Users/driscoll/Zotero/storage/DW7QZ9X6/S0021999119301032.html}
}

@book{parlettSymmetricEigenvalueProblem1980,
  title = {The {{Symmetric Eigenvalue Problem}}},
  author = {Parlett, Beresford N.},
  year = {1980},
  month = jan,
  publisher = {{SIAM}},
  abstract = {According to Parlett, \&\#39;Vibrations are everywhere, and so too are the eigenvalues associated with them. As mathematical models invade more and more disciplines, we can anticipate a demand for eigenvalue calculations in an ever richer variety of contexts.\&\#39; Anyone who performs these calculations will welcome the reprinting of Parlett\&\#39;s book (originally published in 1980). In this unabridged, amended version, Parlett covers aspects of the problem that are not easily found elsewhere. The chapter titles convey the scope of the material succinctly. The aim of the book is to present mathematical knowledge that is needed in order to understand the art of computing eigenvalues of real symmetric matrices, either all of them or only a few. The author explains why the selected information really matters and he is not shy about making judgments. The commentary is lively but the proofs are terse.},
  googlebooks = {YAm9Ny6Z7PkC},
  isbn = {978-0-89871-402-9},
  langid = {english},
  keywords = {Mathematics / Algebra / Linear,Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis}
}

@inproceedings{pascanuHowConstructDeep2014,
  title = {How to Construct Deep Recurrent Neural Networks},
  booktitle = {Proceedings of the {{Second International Conference}} on {{Learning Representations}} ({{ICLR}} 2014)},
  author = {Pascanu, Razvan and Gulcehre, Caglar and Cho, Kyunghyun and Bengio, Yoshua},
  year = {2014},
  address = {{Banff}},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Pascanu et al_2014_How to construct deep recurrent neural networks.pdf}
}

@article{PeleskoEffectSmallaspectratio2006,
  title = {The Effect of the Small-Aspect-Ratio Approximation on Canonical Electrostatic {{MEMS}} Models},
  author = {Pelesko, John A. and Driscoll, Tobin A.},
  year = {2006},
  month = jan,
  journal = {Journal of Engineering Mathematics},
  volume = {53},
  number = {3-4},
  pages = {239--252},
  issn = {0022-0833},
  doi = {10.1007/s10665-005-9013-2},
  copyright = {All rights reserved},
  keywords = {file-import-09-09-29}
}

@article{pellegriniAssessmentCorneal2019,
  title = {Assessment of {{Corneal Fluorescein Staining}} in {{Different Dry Eye Subtypes Using Digital Image Analysis}}},
  author = {Pellegrini, Marc and Bernabei, Federic and Moscardelli, Fabian and Vagge, Ald and Scotto, Riccard and Bovone, Cristin and Scorcia, Vincenz and Giannaccare, Giusepp},
  year = {2019},
  month = nov,
  journal = {Translational Vision Science \& Technology},
  volume = {8},
  number = {6},
  pages = {34},
  issn = {2164-2591},
  doi = {10.1167/tvst.8.6.34},
  abstract = {Purpose: To describe a new objective technique of digital image analysis for the quantification and the morphological characterization of corneal staining in the setting of dry eye disease (DED), and to apply it to distinguish Sj{\"o}gren syndrome (SS) from ocular graft versus-host disease (oGVHD). Methods: Slit-lamp photographs of corneal staining obtained from 40 patients with DED (20 with SS and 20 with oGVHD; mean age 60.7 {\textpm} 12.3 years) were evaluated. Images were subjectively graded using Oxford and National Eye Institute (NEI) scales, the staining pattern was classified as micropunctate, macropunctate, coalescent, or patch. The corneal staining index (CSI) was calculated automatically using the software ImageJ 1.51s. Particles analysis was used to calculate mean area, circularity, and roundness of staining spots. Results: CSI was significantly correlated with Oxford and NEI scales (respectively Rs = 0.823 and Rs = 0.773; both P {$<$} 0.001), and showed a good interobserver reliability (intraclass correlation coefficient [ICC] = 0.988 [95\% confidence interval [CI]: 0.978-0.994]). The mean area of staining spots calculated with particles analysis was significantly correlated with the subjective classification of the staining pattern (Rs = 0.550, P {$<$} 0.001). The circularity and roundness of staining spots were significantly higher in oGVHD patients compared with SS (respectively, 0.51 {\textpm} 0.11 vs. 0.44 {\textpm} 0.10, P = 0.040; 0.61 {\textpm} 0.03 vs. 0.59 {\textpm} 0.02, P = 0.004). Sensitivity and specificity to distinguish oGVHD from SS were respectively 65.0\% and 60\% for circularity and 80.0\% and 70.0\% for roundness. Conclusions: The new algorithm showed good reliability and was well correlated with the traditional subjective grading scales. Particles analysis for the objective assessment of the staining pattern may help to differentiate patients with oGVHD from those with SS. Translational Relevance: The digital image analysis technique may be a reliable alternative to evaluate corneal staining objectively in the clinic and in clinical trials.},
  langid = {english},
  pmcid = {PMC6910610},
  pmid = {31857917},
  keywords = {corneal staining,dry eyes,image analysis,ocular GVHD,Sjogren syndrome},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Pellegrini et al-2019-Assessment of Corneal Fluorescein Staining in Different Dry.pdf}
}

@article{pena-verdealDiurnalVariations2016,
  title = {Diurnal Variations in Tear Film Break-up Time Determined in Healthy Subjects by Software-Assisted Interpretation of Tear Film Video Recordings},
  author = {Pena-Verdeal, Hugo and Garc{\'i}a-Res{\'u}a, Carlos and Ramos, Luc{\'i}a and Yebra-Pimentel, Eva and Gir{\'a}ldez, Mª Jes{\'u}s},
  year = {2016},
  journal = {Clinical and Experimental Optometry},
  volume = {99},
  number = {2},
  pages = {142--148},
  issn = {1444-0938},
  doi = {10.1111/cxo.12324},
  urldate = {2020-11-24},
  abstract = {Background This study was designed to examine diurnal variations in tear film break-up time (BUT) and maximum blink interval (MBI) and to assess two different ways of calculating these variables on video recordings of the BUT test interpreted with the help of especially designed software. The repeatability of interpreting BUT video recordings was also addressed. Methods Twenty-six healthy young adults were enrolled after ruling out dry eye according to a battery of tests (ocular surface disease index, McMonnies questionnaire, Schirmer test, phenol red test and corneal staining). BUT and maximum blink interval were determined on video-recordings of the BUT test conducted over a day in four sessions (9.30 am, 12.30 pm, 3.30 pm and 6.30 pm). In each session, the test was repeated three times to give three videos in which three BUT and MBI values were obtained by a masked observer. BUT and MBI were determined by averaging the three measurements and by averaging only the two closest measurements. Finally, two further experienced observers re-examined the videos to assess the repeatability of the BUT measurements made. Results No diurnal variation in BUT was observed regardless of whether three or two video measurements were averaged. Significant correlation was detected between BUT and MBI. Inter-observer repeatability was better when BUT times were no longer than 15 seconds. Conclusions Tear film BUT was not influenced by the time of day and moderate to strong correlation with MBI was observed in all four sessions. The software-assisted method proved useful and identified the need to clarify the BUT end-point and to limit the test to 15 seconds to improve observer repeatability.},
  copyright = {{\copyright} 2016 Optometry Australia},
  langid = {english},
  keywords = {diurnal variations,maximum blink interval,tear break-up time,tear film},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Pena‐Verdeal et al-2016-Diurnal variations in tear film break-up time determined in.pdf;/Users/driscoll/Zotero/storage/ZGGBB6IM/cxo.html}
}

@article{PengEvaporationdrivenInstability2014,
  title = {Evaporation-Driven Instability of the Precorneal Tear Film},
  author = {Peng, C.-C. and Cerretani, C. and Braun, R. J. and Radke, C. J.},
  year = {2014},
  journal = {Adv. Coll. Interface Sci.},
  volume = {206},
  pages = {250--264},
  doi = {10.1016/j.cis.2013.06.001},
  date-modified = {2014-05-26 15:44:03 +0000},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Peng et al-2014-Evaporation-driven instability of the precorneal tear film.pdf}
}

@article{pereynaIteratedDeferredCorrections1968,
  title = {Iterated Deferred Corrections for Nonlinear Boundary Value Problems},
  author = {Pereyna, Victor},
  year = {1968},
  month = feb,
  journal = {Numerische Mathematik},
  volume = {11},
  number = {2},
  pages = {111--125},
  issn = {0945-3245},
  doi = {10.1007/BF02165307},
  urldate = {2022-08-15},
  langid = {english},
  keywords = {Mathematical Method,Nonlinear Boundary},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Pereyna-1968-Iterated deferred corrections for nonlinear boundary value problems.pdf}
}

@article{PlatteComputingEigenmodes2004,
  title = {Computing Eigenmodes of Elliptic Operators Using Radial Basis Functions},
  author = {Platte, Rodrigo B and Driscoll, Tobin A},
  year = {2004},
  journal = {Computers \& Mathematics with Applications},
  volume = {48},
  number = {3-4},
  pages = {561--576},
  doi = {10.1016/j.camwa.2003.08.007},
  copyright = {All rights reserved},
  keywords = {file-import-09-09-29}
}

@article{PlatteEigenvalueStability2006,
  title = {Eigenvalue Stability of Radial Basis Function Discretizations for Time-Dependent Problems},
  author = {Platte, Rodrigo B and Driscoll, Tobin A},
  year = {2006},
  journal = {Computers \& Mathematics with Applications},
  volume = {51},
  number = {8},
  pages = {1251--1268},
  doi = {10.1016/j.camwa.2006.04.007},
  copyright = {All rights reserved},
  keywords = {basis,functions,Radial}
}

@article{PlattePolynomialsPotential2005a,
  title = {Polynomials and {{Potential Theory}} for {{Gaussian Radial Basis Function Interpolation}}},
  author = {Platte, Rodrigo B. and Driscoll, Tobin A.},
  year = {2005},
  journal = {SIAM Journal on Numerical Analysis},
  volume = {43},
  number = {2},
  pages = {750--766},
  doi = {10.1137/040610143},
  copyright = {All rights reserved},
  keywords = {file-import-09-09-29,potential-theory,radial-basis-functions,runge-phenomenon,stability}
}

@inproceedings{pmlr-v15-coates11a,
  title = {An Analysis of Single-Layer Networks in Unsupervised Feature Learning},
  booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
  author = {Coates, Adam and Ng, Andrew and Lee, Honglak},
  editor = {Gordon, Geoffrey and Dunson, David and Dud{\'i}k, Miroslav},
  year = {2011},
  month = apr,
  series = {Proceedings of Machine Learning Research},
  volume = {15},
  pages = {215--223},
  publisher = {{PMLR}},
  address = {{Fort Lauderdale, FL, USA}},
  abstract = {A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR-10 by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several off-the-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR-10, NORB, and STL datasets using only single-layer networks. We then present a detailed analysis of the effect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (``stride'') between extracted features, and the effect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance - so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyper-parameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6\% and 97.2\% respectively). [pdf]},
  pdf = {http://proceedings.mlr.press/v15/coates11a/coates11a.pdf},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Coates et al_2011_An analysis of single-layer networks in unsupervised feature learning.pdf}
}

@article{pnevmatikakisSimultaneousDenoisingDeconvolution2016,
  title = {Simultaneous {{Denoising}}, {{Deconvolution}}, and {{Demixing}} of {{Calcium Imaging Data}}},
  author = {Pnevmatikakis, Eftychios A. and Soudry, Daniel and Gao, Yuanjun and Machado, Timothy A. and Merel, Josh and Pfau, David and Reardon, Thomas and Mu, Yu and Lacefield, Clay and Yang, Weijian and Ahrens, Misha and Bruno, Randy and Jessell, Thomas M. and Peterka, Darcy S. and Yuste, Rafael and Paninski, Liam},
  year = {2016},
  month = jan,
  journal = {Neuron},
  volume = {89},
  number = {2},
  pages = {285--299},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2015.11.037},
  urldate = {2019-03-18},
  abstract = {We present a modular approach for analyzing calcium imaging recordings of large neuronal ensembles. Our goal is to simultaneously identify the locations of the neurons, demix spatially overlapping components, and denoise and deconvolve the spiking activity from the slow dynamics of the calcium indicator. Our approach relies on a constrained nonnegative matrix factorization that expresses the spatiotemporal fluorescence activity as the product of a spatial matrix that encodes the spatial footprint of each neuron in the optical field and a temporal matrix that characterizes the calcium concentration of each neuron over time. This framework is combined with a novel constrained deconvolution approach that extracts estimates of neural activity from fluorescence traces, to create a spatiotemporal processing algorithm that requires minimal parameter tuning. We demonstrate the general applicability of our method by applying it to in vitro and in vivo multineuronal imaging data, whole-brain light-sheet imaging data, and dendritic imaging data.},
  pmcid = {PMC4881387},
  pmid = {26774160},
  keywords = {data science,NMF,time series},
  file = {/Users/driscoll/Zotero/storage/KXP8QQ2F/Pnevmatikakis et al. - 2016 - Simultaneous Denoising, Deconvolution, and Demixin.pdf}
}

@article{PoliGraphNeural2019,
  title = {Graph {{Neural Ordinary Differential Equations}}},
  author = {Poli, Michael and Massaroli, Stefano and Park, Junyoung and Yamashita, A. and Asama, H. and Park, Jinkyoo},
  year = {2019},
  month = nov,
  journal = {ArXiv},
  urldate = {2023-11-02},
  abstract = {We introduce the framework of continuous--depth graph neural networks (GNNs). Graph neural ordinary differential equations (GDEs) are formalized as the counterpart to GNNs where the input-output relationship is determined by a continuum of GNN layers, blending discrete topological structures and differential equations. The proposed framework is shown to be compatible with various static and autoregressive GNN models. Results prove general effectiveness of GDEs: in static settings they offer computational advantages by incorporating numerical methods in their forward pass; in dynamic settings, on the other hand, they are shown to improve performance by exploiting the geometry of the underlying dynamics.},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Poli et al_2019_Graph Neural Ordinary Differential Equations.pdf}
}

@article{Ponder_On_1927,
  title = {On the Act of Blinking},
  author = {Ponder, E and Kennedy, {\relax WP}},
  year = {1927},
  journal = {Quarterly Journal of Experimental {\dots}},
  doi = {10.1113/expphysiol.1927.sp000433},
  abstract = {IN the course of a research on certain defence mechanisms in man we had occasion to examine the protective movement of the eyelids, or blink, which occurs when a solid body is suddenly approached to the face. The proper treatment of this problem required, in its turn, an ...}
}

@article{PorterNetworkAnalysis2005,
  title = {A Network Analysis of Committees in the {{U}}.{{S}}. {{House}} of {{Representatives}}},
  author = {Porter, Mason A. and Mucha, Peter J. and Newman, M. E. J. and Warmbrand, Casey M.},
  year = {2005},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {102},
  number = {20},
  pages = {7057--7062},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.0500191102},
  urldate = {2023-06-08},
  abstract = {Network theory provides a powerful tool for the representation and analysis of complex systems of interacting agents. Here, we investigate the U.S. House of Representatives network of committees and subcommittees, with committees connected according to ``interlocks,'' or common membership. Analysis of this network reveals clearly the strong links between different committees, as well as the intrinsic hierarchical structure within the House as a whole. We show that network theory, combined with the analysis of roll-call votes using singular value decomposition, successfully uncovers political and organizational correlations between committees in the House without the need to incorporate other political information.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Porter et al_2005_A network analysis of committees in the U.pdf}
}

@article{Power2002,
  title = {A Comparison Analysis between Unsymmetric and Symmetric Radial Basis Function Collocation Methods for the Numerical Solution of Partial Differential Equations},
  author = {Power, H. and Barraco, V.},
  year = {2002},
  month = feb,
  journal = {Computers {{\&}} Mathematics with Applications},
  volume = {43},
  number = {3-5},
  pages = {551--583},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0898-1221(01)00305-4},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Power_Barraco_2002_A comparison analysis between unsymmetric and symmetric radial basis function.pdf}
}

@article{Powers_Blinks_2012,
  title = {Blinks Slow Memory-Guided Saccades},
  author = {Powers, {\relax AS} and Basso, {\relax MA} and Evinger, C},
  year = {2012},
  volume = {109},
  number = {3},
  pages = {734--741},
  issn = {0022-3077},
  doi = {10.1152/jn.00746.2012}
}

@misc{PradoveraCertifiedGreedy2023,
  title = {Toward a Certified Greedy {{Loewner}} Framework with Minimal Sampling},
  author = {Pradovera, Davide},
  year = {2023},
  month = mar,
  number = {arXiv:2303.01015},
  eprint = {2303.01015},
  primaryclass = {cs, eess, math},
  publisher = {{arXiv}},
  urldate = {2023-04-12},
  abstract = {We propose a strategy for greedy sampling in the context of non-intrusive interpolation-based surrogate modeling for frequency-domain problems. We rely on a non-intrusive and cheap error indicator to drive the adaptive selection of the high-fidelity samples on which the surrogate is based. We develop a theoretical framework to support our proposed indicator. We also present several practical approaches for the termination criterion that is used to end the greedy sampling iterations. To showcase our greedy strategy, we numerically test it in combination with the well-known Loewner framework. To this effect, we consider several benchmarks, highlighting the effectiveness of our adaptive approach in approximating the transfer function of complex systems from few samples.},
  archiveprefix = {arxiv},
  keywords = {30D30 35B30 41A20 65D15 93C80,Electrical Engineering and Systems Science - Systems and Control,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Pradovera_2023_Toward a certified greedy Loewner framework with minimal sampling.pdf;/Users/driscoll/Zotero/storage/W6DE4NHA/2303.html}
}

@inproceedings{PRECONDITIONED2002,
  title = {{{SIAM}} j. {{SCI}}. {{COMPUT}}. {\copyright}c 2002 Society for Industrial and Applied Mathematics Vol. 24, No. 1, Pp},
  author = {PRECONDITIONED, {\relax NONLINEARLY} and NEWTON, {\relax INEXACT} and {ALGORITHMS{$\ast$}}},
  year = {2002},
  abstract = {Inexact Newton algorithms are commonly used for solving large sparse nonlinear system of equations F (u{$\ast$}) = 0 arising, for example, from the discretization of partial differential equations. Even with global strategies such as linesearch or trust region, the methods often stagnate at local minima of {\textbardbl}F{\textbardbl}, especially for problems with unbalanced nonlinearities, because the methods do not have built-in machinery to deal with the unbalanced nonlinearities. To find the same solution u{$\ast$}, one may want to solve instead an equivalent nonlinearly preconditioned system F(u{$\ast$}) = 0 whose nonlinearities are more balanced. In this paper, we propose and study a nonlinear additive Schwarz- based parallel nonlinear preconditioner and show numerically that the new method converges well even for some difficult problems, such as high Reynolds number flows, where a traditional inexact Newton method fails.},
  keywords = {No DOI found}
}

@article{pritchardSubjectiveObjective2003,
  title = {Subjective and Objective Measures of Corneal Staining Related to Multipurpose Care Systems},
  author = {Pritchard, Nicola and Young, Graeme and Coleman, Sarah and Hunt, Chris},
  year = {2003},
  month = mar,
  journal = {Contact Lens \& Anterior Eye: The Journal of the British Contact Lens Association},
  volume = {26},
  number = {1},
  pages = {3--9},
  issn = {1367-0484},
  doi = {10.1016/s1367-0484(02)00083-8},
  abstract = {An objective, digital-imaging method of measuring corneal staining was evaluated in 24 subjects wearing soft contact lenses. The method was used to compare the clinical performance of common multipurpose care systems (MPS) for soft contact lens care. Subjects used three different MPS, one containing polyquaternium-1 (PQ) and two containing polyhexanide (PX1 and PX2), for 2 weeks in a randomised, single-masked (investigator) crossover study. Corneal staining induced with the three MPS was analysed using an image-processing program (ImageTool, UTHSCSA Version 2, University of Texas, USA). Conjunctival hyperaemia and papillae were also evaluated. The intraclass correlation coefficient was similar with image analysis to that of investigator grading (0.876, 0.879, respectively). Significant differences in staining response were detected using the objective method. There was significantly less staining area with polyquaternium-1 (PQ) than polyhexanide (PQ: 0.12 mm(2), PX2: 0.91 mm(2)). Inferior palpebral papillae were significantly greater with PX2 than with PQ (1.0, 0.7 (0-4), respectively). The technique was shown to be an effective method of evaluating different corneal staining responses. Bilateral corneal staining in three or more quadrants is useful in the diagnosis of MPS-related staining.},
  langid = {english},
  pmid = {16303491}
}

@article{Pult_Spontaneous_2015,
  title = {Spontaneous Blinking from a Tribological Viewpoint},
  author = {Pult, Heiko and Tosatti, Samuele and Spencer, Nicholas D and Asfour, Jean-Michel and Ebenhoch, Michael and Murphy, Paul J},
  year = {2015},
  volume = {13},
  number = {3},
  pages = {236--249},
  issn = {1542-0124},
  doi = {10.1016/j.jtos.2014.12.004},
  abstract = {The mechanical forces between the lid wiper and the ocular surface, and between a contact lens and the lid wiper, are reported to be related to dry eye symptoms. Furthermore, the mechanical forces between these sliding partners are assumed to be related to the ocular signs of lid-wiper epitheliopathy (LWE) and lid-parallel conjunctival folds (LIPCOF). Recent literature provides some evidence that a contact lens with a low coefficient of friction (CoF) improves wearing comfort by reducing the mechanical forces between the contact lens surface and the lid wiper. This review discusses the mechanical forces during spontaneous blinks from a tribological perspective, at both low and high sliding velocities, in a healthy subject. It concludes that the coefficient of friction of the ocular surfaces appears to be strongly comparable to that of hydrophilic polymer brushes at low sliding velocity, and that, with increased sliding velocity, there is no wear at the sliding partners' surfaces thanks to the presence of a fluid film between the two sliding partners. In contrast, in the case of dry eye, the failure to maintain a full fluid film lubrication regime at high blinking speeds may lead to increased shear rates, resulting in deformation and wear of the sliding pairs. These shear rates are most likely related to tear film viscosity.},
  pmid = {26045237}
}

@book{quarteroniNumericalMathematics2007,
  title = {Numerical {{Mathematics}}},
  author = {Quarteroni, Alfio and Sacco, Riccardo and Saleri, Fausto},
  year = {2007},
  publisher = {{Springer}},
  abstract = {Numerical mathematics is the branch of mathematics that proposes, develops, analyzes and applies methods from scientific computing to several fields including analysis, linear algebra, geometry, approximation theory, functional equations, optimization and differential equations. Other disciplines, such as physics, the natural and biological sciences, engineering, and economics and the financial sciences frequently give rise to problems that need scientific computing for their solutions.As such, numerical mathematics is the crossroad of several disciplines of great relevance in modern applied sciences, and can become a crucial tool for their qualitative and quantitative analysis.One of the purposes of this book is to provide the mathematical foundations of numerical methods, to analyze their basic theoretical properties (stability, accuracy, computational complexity) and demonstrate their performances on examples and counterexamples which outline their pros and cons. This is done using the MATLAB software environment which is user-friendly and widely adopted. Within any specific class of problems, the most appropriate scientific computing algorithms are reviewed, their theoretical analyses are carried out and the expected results are verified on a MATLAB computer implementation. Every chapter is supplied with examples, exercises and applications of the discussed theory to the solution of real-life problems.This book is addressed to senior undergraduate and graduate students with particular focus on degree courses in Engineering, Mathematics, Physics and Computer Sciences. The attention which is paid to the applications and the related development of software makes it valuable also for researchers and users of scientific computing in a large variety of professional fields.},
  googlebooks = {FA3\_DQAAQBAJ},
  isbn = {978-0-387-22750-4},
  langid = {english},
  keywords = {Mathematics / Applied,Mathematics / Calculus,Mathematics / General,Mathematics / Mathematical Analysis,Mathematics / Number Systems,Mathematics / Numerical Analysis}
}

@article{RackauckasUniversalDifferential2020,
  title = {Universal {{Differential Equations}} for {{Scientific Machine Learning}}},
  author = {Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},
  year = {2020},
  month = jan,
  journal = {arXiv:2001.04385 [cs, math, q-bio, stat]},
  eprint = {2001.04385},
  primaryclass = {cs, math, q-bio, stat},
  urldate = {2020-02-24},
  abstract = {In the context of science, the well-known adage "a picture is worth a thousand words" might well be "a model is worth a thousand datasets." Scientific models, such as Newtonian physics or biological gene regulatory networks, are human-driven simplifications of complex phenomena that serve as surrogates for the countless experiments that validated the models. Recently, machine learning has been able to overcome the inaccuracies of approximate modeling by directly learning the entire set of nonlinear interactions from data. However, without any predetermined structure from the scientific basis behind the problem, machine learning approaches are flexible but data-expensive, requiring large databases of homogeneous labeled training data. A central challenge is reconciling data that is at odds with simplified models without requiring "big data". In this work we develop a new methodology, universal differential equations (UDEs), which augments scientific models with machine-learnable structures for scientifically-based learning. We show how UDEs can be utilized to discover previously unknown governing equations, accurately extrapolate beyond the original data, and accelerate model simulation, all in a time and data-efficient manner. This advance is coupled with open-source software that allows for training UDEs which incorporate physical constraints, delayed interactions, implicitly-defined events, and intrinsic stochasticity in the model. Our examples show how a diverse set of computationally-difficult modeling issues across scientific disciplines, from automatically discovering biological mechanisms to accelerating climate simulations by 15,000x, can be handled by training UDEs.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Mathematics - Dynamical Systems,No DOI found,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Rackauckas et al_2020_Universal Differential Equations for Scientific Machine Learning2.pdf}
}

@article{RaissiInferringSolutions2017,
  title = {Inferring Solutions of Differential Equations Using Noisy Multi-Fidelity Data},
  author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  year = {2017},
  month = apr,
  journal = {Journal of Computational Physics},
  volume = {335},
  pages = {736--746},
  issn = {0021-9991},
  doi = {10.1016/j.jcp.2017.01.060},
  urldate = {2023-12-12},
  abstract = {For more than two centuries, solutions of differential equations have been obtained either analytically or numerically based on typically well-behaved forcing and boundary conditions for well-posed problems. We are changing this paradigm in a fundamental way by establishing an interface between probabilistic machine learning and differential equations. We develop data-driven algorithms for general linear equations using Gaussian process priors tailored to the corresponding integro-differential operators. The only observables are scarce noisy multi-fidelity data for the forcing and solution that are not required to reside on the domain boundary. The resulting predictive posterior distributions quantify uncertainty and naturally lead to adaptive solution refinement via active learning. This general framework circumvents the tyranny of numerical discretization as well as the consistency and stability issues of time-integration, and is scalable to high-dimensions.},
  keywords = {Integro-differential equations,Machine learning,Multi-fidelity modeling,Uncertainty quantification},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Raissi et al_2017_Inferring solutions of differential equations using noisy multi-fidelity data.pdf;/Users/driscoll/Dropbox/library/Journal Article/Raissi et al_2017_Inferring solutions of differential equations using noisy multi-fidelity data2.pdf;/Users/driscoll/Zotero/storage/9SMIX778/S0021999117300761.html}
}

@article{RaissiNumericalGaussian2018,
  title = {Numerical {{Gaussian Processes}} for {{Time-Dependent}} and {{Nonlinear Partial Differential Equations}}},
  author = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {40},
  number = {1},
  pages = {A172-A198},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/17M1120762},
  urldate = {2023-12-12},
  abstract = {Implicit-explicit (IMEX) schemes have been widely used, especially in conjunction with spectral methods, for the time integration of spatially discretized partial differential equations (PDEs) of diffusion-convection type. Typically, an implicit scheme is used for the diffusion term and an explicit scheme is used for the convection term. Reaction-diffusion problems can also be  approximated in this manner. In this work we systematically analyze the performance of such schemes, propose improved new schemes, and pay particular attention to their relative performance in the context of fast multigrid algorithms and of aliasing reduction for spectral methods.For the prototype linear advection-diffusion equation, a stability analysis for first-, second-, third-, and fourth-order multistep IMEX schemes is performed. Stable schemes permitting large time steps for a wide variety of problems and yielding appropriate decay of high frequency error modes are identified. Numerical experiments demonstrate that weak decay of high frequency modes can lead to extra iterations on the finest grid when using multigrid computations with finite difference spatial discretization, and to aliasing when using spectral collocation for spatial discretization. When this behavior occurs, use of weakly damping schemes such as the popular combination of Crank--Nicolson with second-order Adams--Bashforth is discouraged and better alternatives are proposed.Our findings are demonstrated on several examples.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Raissi et al_2018_Numerical Gaussian Processes for Time-Dependent and Nonlinear Partial.pdf}
}

@article{ramosAnalysisParameters2014,
  title = {Analysis of Parameters for the Automatic Computation of the Tear Film Break-up Time Test Based on {{CCLRU}} Standards},
  author = {Ramos, L. and Barreira, N. and Mosquera, A. and Penedo, M. G. and {Yebra-Pimentel}, E. and {Garc{\'i}a-Res{\'u}a}, C.},
  year = {2014},
  month = mar,
  journal = {Computer Methods and Programs in Biomedicine},
  volume = {113},
  number = {3},
  pages = {715--724},
  issn = {0169-2607},
  doi = {10.1016/j.cmpb.2013.12.003},
  urldate = {2020-10-15},
  abstract = {Dry eye syndrome is affecting a remarkable percentage of population. The prevalence is 10--15\% of normal population, and 18--30\% of contact lenses users. The break-up time (BUT) is a clinical test used for the diagnosis of this disease. In this work, we perform an analysis of parameters for a global and a local automatic computation of the BUT measure, based on criteria of specificity and sensitivity. We have tested our methodology on a dataset composed of 18 videos annotated by 4 different experts. The local analysis preserves the results of the global approach providing useful additional information about the break-up tear zone.},
  langid = {english},
  keywords = {BUT test,Dry eye syndrome,Image processing,Tear film,Video analysis},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Ramos et al-2014-Analysis of parameters for the automatic computation of the.pdf;/Users/driscoll/Zotero/storage/82L4YVYG/S0169260713003921.html}
}

@article{ramosComputationalApproach2015,
  title = {Computational Approach for Tear Film Assessment Based on Break-up Dynamics},
  author = {Ramos, L. and Barreira, N. and {Pena-Verdeal}, H. and Gir{\'a}ldez, M. J. and {Yebra-Pimentel}, E.},
  year = {2015},
  month = oct,
  journal = {Biosystems Engineering},
  series = {Innovations in {{Medicine}} and {{Healthcare}}},
  volume = {138},
  pages = {90--103},
  issn = {1537-5110},
  doi = {10.1016/j.biosystemseng.2015.04.009},
  urldate = {2020-07-07},
  abstract = {Dry eye syndrome is a common disorder of the tear film which affects a remarkable percentage of the population, impacting on quality of life. The study of the tear film stability is essential for the dry eye characterisation. The Break-Up Time (BUT) is a clinical test which computes the time the first tear film break-up appears. Besides the time, break-up properties can be related to specific aspects of the tear film that could affect dry eye severity. This work describes a fully automatic methodology to compute the BUT measurement and evaluate the dynamics of break-up areas. This methodology has been tested on a data set consisting of 18 tear film videos, achieving similar results to the manual annotations marked by the experts. This analysis provides useful additional information for the tear film assessment.},
  langid = {english},
  keywords = {BUT test,Dry eye syndrome,Image processing,Tear film,Video analysis},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Ramos et al-2015-Computational approach for tear film assessment based on.pdf;/Users/driscoll/Zotero/storage/HGTPK2QY/S1537511015000720.html}
}

@misc{RecoveringNumberClusters,
  title = {Recovering the Number of Clusters in Data Sets with Noise Features Using Feature Rescaling Factors - {{ScienceDirect}}},
  urldate = {2019-11-10},
  howpublished = {https://www.sciencedirect.com/science/article/pii/S0020025515004715?via\%3Dihub}
}

@article{redmonYOLO9000BetterFaster2016,
  title = {{{YOLO9000}}: {{Better}}, {{Faster}}, {{Stronger}}},
  shorttitle = {{{YOLO9000}}},
  author = {Redmon, Joseph and Farhadi, Ali},
  year = {2016},
  month = dec,
  journal = {arXiv:1612.08242 [cs]},
  eprint = {1612.08242},
  primaryclass = {cs},
  urldate = {2020-01-27},
  abstract = {We introduce YOLO9000, a state-of-the-art, real-time object detection system that can detect over 9000 object categories. First we propose various improvements to the YOLO detection method, both novel and drawn from prior work. The improved model, YOLOv2, is state-of-the-art on standard detection tasks like PASCAL VOC and COCO. Using a novel, multi-scale training method the same YOLOv2 model can run at varying sizes, offering an easy tradeoff between speed and accuracy. At 67 FPS, YOLOv2 gets 76.8 mAP on VOC 2007. At 40 FPS, YOLOv2 gets 78.6 mAP, outperforming state-of-the-art methods like Faster RCNN with ResNet and SSD while still running significantly faster. Finally we propose a method to jointly train on object detection and classification. Using this method we train YOLO9000 simultaneously on the COCO detection dataset and the ImageNet classification dataset. Our joint training allows YOLO9000 to predict detections for object classes that don't have labelled detection data. We validate our approach on the ImageNet detection task. YOLO9000 gets 19.7 mAP on the ImageNet detection validation set despite only having detection data for 44 of the 200 classes. On the 156 classes not in COCO, YOLO9000 gets 16.0 mAP. But YOLO can detect more than just 200 classes; it predicts detections for more than 9000 different object categories. And it still runs in real-time.},
  archiveprefix = {arxiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Redmon_Farhadi_2016_YOLO9000.pdf}
}

@article{ReidFormingDelocalized2012a,
  title = {Forming Delocalized Intermediate States with Realistic Quantum Dots},
  author = {Reid, William M and Driscoll, Tobin A and Doty, Matthew F},
  year = {2012},
  journal = {Journal of Applied Physics},
  volume = {111},
  pages = {056102},
  doi = {10.1063/1.3691113},
  abstract = {Experiments and theoretical models suggest that the performance of intermediate band solar cells based on quantum dots (QDs) will be enhanced by the formation of delocalized intermediate bands. However, reasonable device performance has only been achieved when the QD separation is large and energy states are localized to individual QDs. In this paper we analyze the formation of delocalized bands in a realistic QD material that has inhomogeneously distributed energy levels. We calculate the QD uniformity or barrier thickness necessary to create delocalized states in realistic materials and propose a design to create delocalized states while including strain balancing layers.},
  copyright = {All rights reserved}
}

@article{remeseiroCASDESComputerAided2016,
  title = {{{CASDES}}: {{A Computer-Aided System}} to {{Support Dry Eye Diagnosis Based}} on {{Tear Film Maps}}},
  shorttitle = {{{CASDES}}},
  author = {Remeseiro, Beatriz and Mosquera, Antonio and Penedo, Manuel G.},
  year = {2016},
  month = may,
  journal = {IEEE Journal of Biomedical and Health Informatics},
  volume = {20},
  number = {3},
  pages = {936--943},
  issn = {2168-2194, 2168-2208},
  doi = {10.1109/jbhi.2015.2419316},
  urldate = {2020-07-07},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Remeseiro_Mosquera_Penedo-2016-CASDES.pdf}
}

@inproceedings{remeseiroTearFilm2014,
  title = {Tear {{Film Maps}} Based on the {{Lipid Interference Patterns}}:},
  shorttitle = {Tear {{Film Maps}} Based on the {{Lipid Interference Patterns}}},
  booktitle = {Proceedings of the 6th {{International Conference}} on {{Agents}} and {{Artificial Intelligence}}},
  author = {Remeseiro, Beatriz and Mosquera, Antonio and Penedo, Manuel G. and {Garcia-Res{\'u}a}, Carlos},
  year = {2014},
  pages = {732--739},
  publisher = {{SCITEPRESS - Science and and Technology Publications}},
  address = {{ESEO, Angers, Loire Valley, France}},
  doi = {10.5220/0004926307320739},
  urldate = {2020-10-30},
  isbn = {978-989-758-015-4 978-989-758-016-1},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/2014-Tear Film Maps based on the Lipid Interference Patterns.pdf}
}

@article{RenFasterRCNN2016,
  title = {Faster {{R-CNN}}: {{Towards Real-Time Object Detection}} with {{Region Proposal Networks}}},
  shorttitle = {Faster {{R-CNN}}},
  author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
  year = {2016},
  month = jan,
  journal = {arXiv:1506.01497 [cs]},
  eprint = {1506.01497},
  primaryclass = {cs},
  urldate = {2020-08-07},
  abstract = {State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features---using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Ren et al_2016_Faster R-CNN.pdf;/Users/driscoll/Dropbox/library/Journal Article/Ren et al-2016-Faster R-CNN.pdf;/Users/driscoll/Zotero/storage/9L9RJRUD/1506.html}
}

@book{roacheFundamentalsComputationalFluid1998,
  title = {Fundamentals of {{Computational Fluid Dynamics}}},
  author = {Roache, Patrick J.},
  year = {1998},
  publisher = {{Hermosa Publishers}},
  abstract = {This work is built on the author's 1972 text, Computational Fluid Dynamics. That work is expanded yet essentially reproduced here as Part I, with chapters on incompressible and compressible flow equations, computational methods for incompressible and compressible flow, other mesh and coordinate systems, and recommendations on programming, testing, and information processing. Part II contains newer material on areas including operation count for direct Gaussian elimination, multigrid solvers, a sixth-order accurate direct solver for Poisson and Helmholtz equations in polar coordinates, nonlinear flux limiters applied to groundwater contaminant transport, and verification of codes and calculations. Annotation copyrighted by Book News, Inc., Portland, OR},
  googlebooks = {rhh2QgAACAAJ},
  isbn = {978-0-913478-09-7},
  langid = {english},
  keywords = {Science / Mechanics / Fluids}
}

@inproceedings{RobustMultiViewSpectral,
  title = {Robust {{Multi-View Spectral Clustering}} via {{Low-Rank}} and {{Sparse Decomposition}}},
  booktitle = {Twenty-{{Eighth AAAI Conference}} on {{Artificial Intelligence}}},
  file = {/Users/driscoll/Zotero/storage/R8ILQR9R/Robust Multi-View Spectral Clustering via Low-Rank.pdf}
}

@article{rodriguezAutomatedGrading2015,
  title = {Automated {{Grading System}} for {{Evaluation}} of {{Superficial Punctate Keratitis Associated With Dry Eye}}},
  author = {Rodriguez, John D. and Lane, Keith J. and Ousler, George W. and Angjeli, Endri and Smith, Lisa M. and Abelson, Mark B.},
  year = {2015},
  month = apr,
  journal = {Investigative Opthalmology \& Visual Science},
  volume = {56},
  number = {4},
  pages = {2340},
  issn = {1552-5783},
  doi = {10.1167/iovs.14-15318},
  urldate = {2020-12-16},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Rodriguez et al-2015-Automated Grading System for Evaluation of Superficial.pdf}
}

@misc{RodriguezPAAAAlgorithm2022,
  title = {The P-{{AAA}} Algorithm for Data Driven Modeling of Parametric Dynamical Systems},
  author = {Rodriguez, Andrea Carracedo and Balicki, Linus and Gugercin, Serkan},
  year = {2022},
  month = jul,
  number = {arXiv:2003.06536},
  eprint = {2003.06536},
  primaryclass = {cs, eess, math},
  publisher = {{arXiv}},
  urldate = {2023-04-12},
  abstract = {The AAA algorithm has become a popular tool for data-driven rational approximation of single variable functions, such as transfer functions of a linear dynamical system. In the setting of parametric dynamical systems appearing in many prominent applications, the underlying (transfer) function to be modeled is a multivariate function. With this in mind, we develop the AAA framework for approximating multivariate functions where the approximant is constructed in the multivariate barycentric form. The method is data-driven, in the sense that it does not require access to full state-space model and requires only function evaluations. We discuss an extension to the case of matrix-valued functions, i.e., multi-input/multi-output dynamical systems, and provide a connection to the tangential interpolation theory. Several numerical examples illustrate the effectiveness of the proposed approach.},
  archiveprefix = {arxiv},
  keywords = {Electrical Engineering and Systems Science - Systems and Control,Mathematics - Dynamical Systems,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Rodriguez et al_2022_The p-AAA algorithm for data driven modeling of parametric dynamical systems.pdf;/Users/driscoll/Zotero/storage/TIVJWY24/2003.html}
}

@article{roeschCollocationBasedTraining2021,
  title = {Collocation Based Training of Neural Ordinary Differential Equations},
  author = {Roesch, Elisabeth and Rackauckas, Christopher and Stumpf, Michael P. H.},
  year = {2021},
  month = apr,
  journal = {Statistical Applications in Genetics and Molecular Biology},
  volume = {20},
  number = {2},
  pages = {37--49},
  publisher = {{De Gruyter}},
  issn = {1544-6115},
  doi = {10.1515/sagmb-2020-0025},
  urldate = {2022-12-06},
  abstract = {The predictive power of machine learning models often exceeds that of mechanistic modeling approaches. However, the interpretability of purely data-driven models, without any mechanistic basis is often complicated, and predictive power by itself can be a poor metric by which we might want to judge different methods. In this work, we focus on the relatively new modeling techniques of neural ordinary differential equations. We discuss how they relate to machine learning and mechanistic models, with the potential to narrow the gulf between these two frameworks: they constitute a class of hybrid model that integrates ideas from data-driven and dynamical systems approaches. Training neural ODEs as representations of dynamical systems data has its own specific demands, and we here propose a collocation scheme as a fast and efficient training strategy. This alleviates the need for costly ODE solvers. We illustrate the advantages that collocation approaches offer, as well as their robustness to qualitative features of a dynamical system, and the quantity and quality of observational data. We focus on systems that exemplify some of the hallmarks of complex dynamical systems encountered in systems biology, and we map out how these methods can be used in the analysis of mathematical models of cellular and physiological processes.},
  langid = {english},
  keywords = {collocation,dynamical systems,neural ODE,systems biology},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Roesch et al_2021_Collocation based training of neural ordinary differential equations.pdf}
}

@article{Rojas-CamposLearningCOVID192023,
  title = {Learning {{COVID-19 Regional Transmission Using Universal Differential Equations}} in a {{SIR}} Model},
  author = {{Rojas-Campos}, Adrian and Stelz, Lukas and Nieters, Pascal},
  year = {2023},
  publisher = {{arXiv}},
  doi = {10.48550/ARXIV.2310.16804},
  urldate = {2023-11-02},
  abstract = {Highly-interconnected societies difficult to model the spread of infectious diseases such as COVID-19. Single-region SIR models fail to account for incoming forces of infection and expanding them to a large number of interacting regions involves many assumptions that do not hold in the real world. We propose using Universal Differential Equations (UDEs) to capture the influence of neighboring regions and improve the model's predictions in a combined SIR+UDE model. UDEs are differential equations totally or partially defined by a deep neural network (DNN). We include an additive term to the SIR equations composed by a DNN that learns the incoming force of infection from the other regions. The learning is performed using automatic differentiation and gradient descent to approach the change in the target system caused by the state of the neighboring regions. We compared the proposed model using a simulated COVID-19 outbreak against a single-region SIR and a fully data-driven model composed only of a DNN. The proposed UDE+SIR model generates predictions that capture the outbreak dynamic more accurately, but a decay in performance is observed at the last stages of the outbreak. The single-area SIR and the fully data-driven approach do not capture the proper dynamics accurately. Once the predictions were obtained, we employed the SINDy algorithm to substitute the DNN with a regression, removing the black box element of the model with no considerable increase in the error levels.},
  copyright = {Creative Commons Attribution 4.0 International},
  keywords = {FOS: Computer and information sciences,FOS: Physical sciences,Machine Learning (cs.LG),Physics and Society (physics.soc-ph)},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Rojas-Campos et al_2023_Learning COVID-19 Regional Transmission Using Universal Differential Equations.pdf}
}

@article{Ruthotto2017,
  title = {{{jInv}}--a Flexible Julia Package for {{PDE}} Parameter Estimation},
  author = {Ruthotto, Lars and Treister, Eran and Haber, Eldad},
  year = {2017},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {39},
  number = {5},
  pages = {S702-S722},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/16m1081063},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Ruthotto et al_2017_jInv–a flexible julia package for PDE parameter estimation.pdf}
}

@book{saadIterativeMethodsSparse2003,
  title = {Iterative {{Methods}} for {{Sparse Linear Systems}}: {{Second Edition}}},
  shorttitle = {Iterative {{Methods}} for {{Sparse Linear Systems}}},
  author = {Saad, Yousef},
  year = {2003},
  month = jan,
  publisher = {{SIAM}},
  abstract = {Since the first edition of this book was published in 1996, tremendous progress has been made in the scientific and engineering disciplines regarding the use of iterative methods for linear systems. The size and complexity of the new generation of linear and nonlinear systems arising in typical applications has grown. Solving the three-dimensional models of these problems using direct solvers is no longer effective. At the same time, parallel computing has penetrated these application areas as it became less expensive and standardized. Iterative methods are easier than direct solvers to implement on parallel computers but require approaches and solution algorithms that are different from classical methods. Iterative Methods for Sparse Linear Systems, Second Edition gives an in-depth, up-to-date view of practical algorithms for solving large-scale linear systems of equations. These equations can number in the millions and are sparse in the sense that each involves only a small number of unknowns. The methods described are iterative, i.e., they provide sequences of approximations that will converge to the solution.},
  googlebooks = {h9nwszYPblEC},
  isbn = {978-0-89871-800-3},
  langid = {english},
  keywords = {Mathematics / General,Mathematics / Geometry / General,Mathematics / Numerical Analysis}
}

@misc{SaadRationalApproximation2020,
  title = {A Rational Approximation Method for the Nonlinear Eigenvalue Problem},
  author = {Saad, Yousef and {El-Guide}, Mohamed and Mi{\k e}dlar, Agnieszka},
  year = {2020},
  month = jun,
  number = {arXiv:1901.01188},
  eprint = {1901.01188},
  primaryclass = {cs, math},
  publisher = {{arXiv}},
  urldate = {2023-04-12},
  abstract = {This paper presents a method for computing eigenvalues and eigenvectors for some types of nonlinear eigenvalue problems. The main idea is to approximate the functions involved in the eigenvalue problem by rational functions and then apply a form of linearization. Eigenpairs of the expanded form of this linearization are not extracted directly. Instead, its structure is exploited to develop a scheme that allows to extract all eigenvalues in a certain region of the complex plane by solving an eigenvalue problem of much smaller dimension. Because of its simple implementation and the ability to work efficiently in large dimensions, the presented method is appealing when solving challenging engineering problems. A few theoretical results are established to explain why the new approach works and numerical experiments are presented to validate the proposed algorithm.},
  archiveprefix = {arxiv},
  keywords = {65F15 15A18 47J10 41A20,Mathematics - Numerical Analysis},
  file = {/Users/driscoll/Dropbox/library/Preprint/Saad et al_2020_A rational approximation method for the nonlinear eigenvalue problem.pdf;/Users/driscoll/Zotero/storage/ETY6VNXQ/1901.html}
}

@article{saibabaRandomizedDiscreteEmpirical2020,
  title = {Randomized {{Discrete Empirical Interpolation Method}} for {{Nonlinear Model Reduction}}},
  author = {Saibaba, Arvind K.},
  year = {2020},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {42},
  number = {3},
  pages = {A1582-A1608},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/19m1243270},
  urldate = {2020-07-03},
  abstract = {The discrete empirical interpolation method (DEIM) is a popular technique for nonlinear model reduction, and it has two main ingredients: an interpolating basis that is computed from a collection of snapshots of the solution, and a set of indices which determine the nonlinear components to be simulated. The computation of these two ingredients dominates the overall cost of the DEIM algorithm. To specifically address these two issues, we present randomized versions of the DEIM algorithm. There are three main contributions of this paper. First, we use randomized range finding algorithms to efficiently find an approximate DEIM basis. Second, we develop randomized subset selection tools, based on leverage scores, to efficiently select the nonlinear components. Third, we develop several theoretical results that quantify the accuracy of the randomization on the DEIM approximation. We also present numerical experiments that demonstrate the benefits of the proposed algorithms.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Saibaba-2020-Randomized Discrete Empirical Interpolation Method for.pdf;/Users/driscoll/Zotero/storage/HX7DYZVJ/19M1243270.html}
}

@article{sametConnectedComponentLabeling1981,
  title = {Connected {{Component Labeling Using Quadtrees}}},
  author = {Samet, Hanan},
  year = {1981},
  month = jul,
  journal = {Journal of the ACM},
  volume = {28},
  number = {3},
  pages = {487--501},
  issn = {0004-5411},
  doi = {10.1145/322261.322267},
  urldate = {2020-07-29},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Samet_1981_Connected Component Labeling Using Quadtrees.pdf}
}

@article{Sane_Void_2011,
  title = {Void Volume Variations in Contact Lens Polymers},
  author = {Sane, P and Tuomisto, F and Holopainen, J.M.},
  year = {2011},
  volume = {34},
  number = {1},
  pages = {2--6},
  issn = {1367-0484},
  doi = {10.1016/j.clae.2010.06.008},
  abstract = {AimIn this study, void size and free volume properties in different contact lens materials have been investigated in their hydrated state using positron annihilation lifetime spectroscopy (PALS).MethodsPALS is used to characterize the void size distributions inside the lens materials. Three different types of contact lenses were used (Balafilcon A, Hilafilcon B and Polymacon).ResultsMeasurements on different contact lenses reveal significant differences between the materials, up to {$\sim$}100\% difference in void volume was observed between Hilafilcon B and Balafilcon A, the latter having larger voids. As oxygen diffusion is strongly correlated with the void sizes, the results are in good agreement with the usage recommendations of the specific lens types (daily disposable lenses or 1 month continuous use lenses). The void sizes in monthly lenses (Balafilcon A) were found to decrease 25\% under artificial aqueous tear (albumin--water solution) exposure in 4 weeks leading to a significant decrease in the oxygen permeation rate through the contact lens. Yet, the voids were still significantly larger than in disposable or semi-disposable lenses.ConclusionsWe have showed that PALS is a viable method to probe the microstructure of biotechnologically relevant polymers and can be used to quantify the void properties in different types of contact lenses. Usage recommendations correlate well with measured void sizes and the median void size decreases during the incubation of albumin solution as a function of time. We anticipate the use of PALS for any polymer-based intracorneal/intraocular device in which diffusivity plays a crucial role.},
  pmid = {20638893}
}

@misc{santamoreBalancingCirculation,
  title = {Balancing the {{Circulation}}},
  author = {Santamore, William},
  file = {/Users/driscoll/Zotero/storage/3ADX2UWN/Barnea-BalancingTheCirculation.pdf}
}

@article{SchneiderNewAspects1986,
  title = {Some New Aspects of Rational Interpolation},
  author = {Schneider, Claus and Werner, Wilhelm},
  year = {1986},
  journal = {Mathematics of Computation},
  volume = {47},
  number = {175},
  pages = {285--299},
  issn = {0025-5718, 1088-6842},
  doi = {10.1090/S0025-5718-1986-0842136-8},
  urldate = {2023-04-18},
  abstract = {A new algorithm for rational interpolation based on the barycentric formula is developed; the barycentric representation of the rational interpolation function possesses various advantages in comparison with other representations such as continued fractions: it provides, e.g., information concerning the existence and location of poles of the interpolant.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Schneider_Werner_1986_Some new aspects of rational interpolation.pdf}
}

@article{SchubertDBSCANRevisited2017,
  title = {{{DBSCAN Revisited}}, {{Revisited}}: {{Why}} and {{How You Should}} ({{Still}}) {{Use DBSCAN}}},
  shorttitle = {{{DBSCAN Revisited}}, {{Revisited}}},
  author = {Schubert, Erich and Sander, J{\"o}rg and Ester, Martin and Kriegel, Hans Peter and Xu, Xiaowei},
  year = {2017},
  month = jul,
  journal = {ACM Transactions on Database Systems},
  volume = {42},
  number = {3},
  pages = {19:1--19:21},
  issn = {0362-5915},
  doi = {10.1145/3068335},
  urldate = {2024-02-05},
  abstract = {At SIGMOD 2015, an article was presented with the title ``DBSCAN Revisited: Mis-Claim, Un-Fixability, and Approximation'' that won the conference's best paper award. In this technical correspondence, we want to point out some inaccuracies in the way DBSCAN was represented, and why the criticism should have been directed at the assumption about the performance of spatial index structures such as R-trees and not at an algorithm that can use such indexes. We will also discuss the relationship of DBSCAN performance and the indexability of the dataset, and discuss some heuristics for choosing appropriate DBSCAN parameters. Some indicators of bad parameters will be proposed to help guide future users of this algorithm in choosing parameters such as to obtain both meaningful results and good performance. In new experiments, we show that the new SIGMOD 2015 methods do not appear to offer practical benefits if the DBSCAN parameters are well chosen and thus they are primarily of theoretical interest. In conclusion, the original DBSCAN algorithm with effective indexes and reasonably chosen parameter values performs competitively compared to the method proposed by Gan and Tao.},
  keywords = {DBSCAN,density-based clustering,range-search complexity},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Schubert et al_2017_DBSCAN Revisited, Revisited.pdf}
}

@article{SchwabDeepLearning2023,
  title = {Deep {{Learning}} in {{High Dimension}}: {{Neural Network Expression Rates}} for {{Analytic Functions}} in {\textbackslash}({\textbackslash}pmb\{\vphantom\}{{L}}\^{}2({\textbackslash}mathbb\{\vphantom\}{{R}}\vphantom\{\}\^{}d,{\textbackslash}gamma\_d)\vphantom\{\}{\textbackslash})},
  shorttitle = {Deep {{Learning}} in {{High Dimension}}},
  author = {Schwab, Christoph and Zech, Jakob},
  year = {2023},
  month = mar,
  journal = {SIAM/ASA Journal on Uncertainty Quantification},
  volume = {11},
  number = {1},
  pages = {199--234},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/21M1462738},
  urldate = {2024-02-21},
  abstract = {.In this paper, based on the physics-informed neural networks (PINNs) framework, a meshfree method using the deep neural network approach is developed for solving two kinds of two-phase interface problems governed by different dynamic partial differential equations on either side of the stationary interface with the jump and high-contrast coefficients. The first type of two-phase interface problem is the fluid-fluid (two-phase flow) interface problem modeled by Navier--Stokes equations with high-contrast physical parameters across the interface. The second one is the fluid-structure interaction problem modeled by Navier--Stokes equations on one side of the interface and the structural equation on the other side, where the fluid and the structure interact with each other via the kinematic and dynamic interface conditions across the interface. Following the PINNs framework, the DNN/meshfree method is respectively developed for two kinds of two-phase interface problems by approximating the solutions using different DNN's structures in different subdomains and reformulating the interface problems as least-squares minimization problems based on a space-time sampling-point set (as the training dataset). Mathematically, the approximation error analyses are carried out for both interface problems, revealing an intrinsic strategy for efficiently sampling points to improve the accuracy. In addition, compared with traditional discretization approaches (e.g., finite element/volume/difference methods), the proposed DNN/meshfree method and its error analysis technique can be smoothly extended to many other dynamic interface problems with stationary interfaces. Numerical experiments illustrate the accuracy of the proposed method for the presented two-phase interface problems and validate theoretical results to some extent through two numerical examples.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Schwab_Zech_2023_Deep Learning in High Dimension.pdf}
}

@article{Schwenker2001,
  title = {Three Learning Phases for Radial-Basis-Function Networks},
  author = {Schwenker, Friedhelm and Kestler, Hans A. and Palm, G{\"u}nther},
  year = {2001},
  month = may,
  journal = {Neural Networks},
  volume = {14},
  number = {4-5},
  pages = {439--458},
  publisher = {{Elsevier BV}},
  doi = {10.1016/s0893-6080(01)00027-2},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Schwenker et al_2001_Three learning phases for radial-basis-function networks.pdf}
}

@article{SegevDynamicAssessment2020,
  title = {Dynamic Assessment of the Tear Film Muco-Aqueous and Lipid Layers Using a Novel Tear Film Imager ({{TFI}})},
  author = {Segev, Fani and Geffen, Noa and Galor, Anat and Cohen, Yoel and Gefen, Raanan and Belkin, Avner and Arieli, Yoel and Epshtein, Shlomi and Oren, Anat and Harris, Alon},
  year = {2020},
  month = jan,
  journal = {British Journal of Ophthalmology},
  volume = {104},
  number = {1},
  pages = {136--141},
  issn = {0007-1161, 1468-2079},
  doi = {10.1136/bjophthalmol-2018-313379},
  urldate = {2023-02-03},
  abstract = {Purpose               The objective of the study was to assess a new technology, the tear film imager (TFI), which can dynamically image the muco-aqueous and lipid layers.                                         Methods               Prospective pilot case series of individuals with and without dry eye (DE). Two sequential images were obtained with the TFI. Measurements were assessed for reproducibility and compared with clinically derived DE metrics. Individuals were grouped into DE categories based on signs of DE.                                         Results               49 patients participated in the study with a mean age of 58.8 years (SD 15.9) and a female majority (69\%). Reproducibility of the muco-aqueous layer thickness (MALT) was excellent (r=0.88). MALT measurements significantly correlated with the Schirmer score (r=0.31). Lipid break up time (LBUT) as measured by the TFI significantly correlated with the clinical measure of tear break up time (TBUT) (r=0.73). MALT and LBUT were significantly thinner and shorter, respectively, in the DE groups (mild--moderate and severe) compared with the control group. When comparing TFI parameters to clinically assessed signs, sensitivity of the device was 87\% and specificity was 88\%.                                         Conclusion               The TFI is the first machine capable of reproducibly measuring muco-aqueous thickness in human subjects which correlates with Schirmer score. In parallel, it assesses other important aspects of tear film function which correlate with clinician assessed DE metrics.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Segev et al_2020_Dynamic assessment of the tear film muco-aqueous and lipid layers using a novel.pdf}
}

@article{Seydel1987,
  title = {New Methods for Calculating the Stability of Periodic Solutions},
  author = {Seydel, R.},
  year = {1987},
  journal = {Computers {{\&}} Mathematics with Applications},
  volume = {14},
  number = {7},
  pages = {505--510},
  publisher = {{Elsevier BV}},
  doi = {10.1016/0898-1221(87)90045-9},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Seydel_1987_New methods for calculating the stability of periodic solutions.pdf}
}

@article{Shampine_1999,
  title = {Solving Index-1 {{DAEs}} in {{MATLAB}} and Simulink},
  author = {Shampine, Lawrence F. and Reichelt, Mark W. and Kierzenka, Jacek A.},
  year = {1999},
  month = jan,
  journal = {SIAM Review},
  volume = {41},
  number = {3},
  pages = {538--552},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/s003614459933425x},
  abstract = {SIAM Rev. 1999.41:538-552},
  keywords = {34A99,65L05,65Y99},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Shampine et al_1999_Solving index-1 DAEs in MATLAB and simulink.pdf}
}

@article{shampineMATLABODESuite1997,
  title = {The {{MATLAB ODE Suite}}},
  author = {Shampine, Lawrence F. and Reichelt, Mark W.},
  year = {1997},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {18},
  number = {1},
  pages = {1--22},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/s1064827594276424},
  urldate = {2020-06-18},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Shampine_Reichelt-1997-The MATLAB ODE Suite.pdf}
}

@article{SHEEDY_Blink_2005,
  title = {Blink Rate Decreases with Eyelid Squint},
  author = {E, JAMES, {\relax SHEEDY} and SOWJANYA, {\relax GOWRISANKARAN} and R, JOHN, {\relax HAYES}},
  year = {2005},
  volume = {82},
  number = {10},
  pages = {905},
  issn = {1040-5488},
  doi = {10.1097/01.opx.0000181234.63194.a7},
  abstract = {Purpose. We hypothesize that eyelid squint inhibits blink rate. This is part of a larger hypothesis that, because eyelid squint improves vision under conditions of optical defocus and/or glare, and reduced blink rate is assumed to contribute to dry eye symptoms, eyelid squint is part of the mechanism resulting in asthenopia. This study investigates the effect of voluntary eyelid squint on blink activity and on electromyography (EMG) measures from the orbicularis oculi. Methods. Ten subjects (18 to 38 years of age) performed 3 1-minute trials each (Latin Square order) of voluntary target squint levels of 5\%, 20\%, 35\%, and 50\% with respect to previously demonstrated 0\% (relaxed) and 100\% (maximum) squint levels. EMG recordings using surface electrodes were obtained from the orbicularis muscle. Vertical dimension of the palpebral fissure and eye lid blinks were measured with an ISCAN eye tracker and video recorder. Results. Each target squint level produced significant changes (p \{{$<$}\} 0.0001) in ocular aperture size, EMG power, and EMG amplitude. For target voluntary squint levels of 5\%, 20\%, 35\%, and 50\%, the mean squint responses were 24\%, 35\%, 42\%, and 53\%, respectively. Blink rate was inversely related to both target squint level and squint response (p \{{$<$}\} 0.0001), decreasing from 15 blinks per minute at 0\% squint to 7.5 blinks per minute at 5\% target voluntary squint and to 4 blinks per minute at 50\% target voluntary squint. Conclusions. Voluntary eyelid squint significantly reduces blink rate by an average of 50\% or more dependent on attempted level. Further study is required to determine if involuntary squint causes the same. All tested levels of voluntary squint resulted in an EMG signal from the orbicularis muscle that is measurably different from resting state. This indicates that EMG can be used as a reliable indicator of eyelid squint.},
  pmid = {16276323}
}

@article{Shen_Characterization_2011,
  title = {Characterization of Soft Contact Lens Edge Fitting Using Ultra-High Resolution and Ultra-Long Scan Depth Optical Coherence Tomography.},
  author = {Shen, Meixiao and Cui, Lele and Riley, Colleen and Wang, Michael R and Wang, Jianhua},
  year = {2011},
  journal = {Investigative Ophthalmology and Visual Science},
  volume = {52},
  number = {7},
  pages = {4091--7},
  issn = {0146-0404},
  doi = {10.1167/iovs.10-6507},
  abstract = {To characterize the edge fitting of soft contact lenses using ultra-high resolution optical coherence tomography (UHR-OCT) and ultra-long scan depth optical coherence tomography (UL-OCT).},
  pmcid = {PMC3175978},
  pmid = {21372023}
}

@article{shenGraphEncoderEmbedding2021,
  title = {Graph {{Encoder Embedding}}},
  author = {Shen, Cencheng and Wang, Qizhe and Priebe, Carey E.},
  year = {2021},
  month = sep,
  journal = {arXiv:2109.13098 [cs, stat]},
  eprint = {2109.13098},
  primaryclass = {cs, stat},
  urldate = {2022-04-28},
  abstract = {In this paper we propose a lightning fast graph embedding method called graph encoder embedding. The proposed method has a linear computational complexity and the capacity to process billions of edges within minutes on standard PC -- an unattainable feat for any existing graph embedding method. The speedup is achieved without sacrificing embedding performance: the encoder embedding performs as good as, and can be viewed as a transformation of the more costly spectral embedding. The encoder embedding is applicable to either adjacency matrix or graph Laplacian, and is theoretically sound, i.e., under stochastic block model or random dot product graph, the graph encoder embedding asymptotically converges to the block probability or latent positions, and is approximately normally distributed. We showcase three important applications: vertex classification, vertex clustering, and graph bootstrap; and the embedding performance is evaluated via a comprehensive set of synthetic and real data. In every case, the graph encoder embedding exhibits unrivalled computational advantages while delivering excellent numerical performance.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,No DOI found,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Shen et al-2021-Graph Encoder Embedding.pdf;/Users/driscoll/Zotero/storage/MALN4Z5S/2109.html}
}

@misc{ShenMathBERTPretrained2023,
  title = {{{MathBERT}}: {{A Pre-trained Language Model}} for {{General NLP Tasks}} in {{Mathematics Education}}},
  shorttitle = {{{MathBERT}}},
  author = {Shen, Jia Tracy and Yamashita, Michiharu and Prihar, Ethan and Heffernan, Neil and Wu, Xintao and Graff, Ben and Lee, Dongwon},
  year = {2023},
  month = aug,
  number = {arXiv:2106.07340},
  eprint = {2106.07340},
  primaryclass = {cs},
  publisher = {{arXiv}},
  urldate = {2023-10-17},
  abstract = {Since the introduction of the original BERT (i.e., BASE BERT), researchers have developed various customized BERT models with improved performance for specific domains and tasks by exploiting the benefits of transfer learning. Due to the nature of mathematical texts, which often use domain specific vocabulary along with equations and math symbols, we posit that the development of a new BERT model for mathematics would be useful for many mathematical downstream tasks. In this resource paper, we introduce our multi-institutional effort (i.e., two learning platforms and three academic institutions in the US) toward this need: MathBERT, a model created by pre-training the BASE BERT model on a large mathematical corpus ranging from pre-kindergarten (pre-k), to high-school, to college graduate level mathematical content. In addition, we select three general NLP tasks that are often used in mathematics education: prediction of knowledge component, auto-grading open-ended Q\&A, and knowledge tracing, to demonstrate the superiority of MathBERT over BASE BERT. Our experiments show that MathBERT outperforms prior best methods by 1.2-22\% and BASE BERT by 2-8\% on these tasks. In addition, we build a mathematics specific vocabulary 'mathVocab' to train with MathBERT. We discover that MathBERT pre-trained with 'mathVocab' outperforms MathBERT trained with the BASE BERT vocabulary (i.e., 'origVocab'). MathBERT is currently being adopted at the participated leaning platforms: Stride, Inc, a commercial educational resource provider, and ASSISTments.org, a free online educational platform. We release MathBERT for public usage at: https://github.com/tbs17/MathBERT.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {/Users/driscoll/Dropbox/library/Preprint/Shen et al_2023_MathBERT.pdf;/Users/driscoll/Zotero/storage/NFTVXZCV/2106.html}
}

@article{shensaDiscreteWaveletTransform1992,
  title = {The Discrete Wavelet Transform: Wedding the a Trous and {{Mallat}} Algorithms},
  shorttitle = {The Discrete Wavelet Transform},
  author = {Shensa, M.J.},
  year = {1992},
  month = oct,
  journal = {IEEE Transactions on Signal Processing},
  volume = {40},
  number = {10},
  pages = {2464--2482},
  issn = {1941-0476},
  doi = {10.1109/78.157290},
  abstract = {Two separately motivated implementations of the wavelet transform are brought together. It is observed that these algorithms are both special cases of a single filter bank structure, the discrete wavelet transform, the behavior of which is governed by the choice of filters. In fact, the a trous algorithm is more properly viewed as a nonorthonormal multiresolution algorithm for which the discrete wavelet transform is exact. Moreover, it is shown that the commonly used Lagrange a trous filters are in one-to-one correspondence with the convolutional squares of the Daubechies filters for orthonormal wavelets of compact support. A systematic framework for the discrete wavelet transform is provided, and conditions are derived under which it computes the continuous wavelet transform exactly. Suitable filter constraints for finite energy and boundedness of the discrete transform are also derived. Relevant signal processing parameters are examined, and it is observed that orthonormality is balanced by restrictions on resolution.{$<>$}},
  keywords = {a trous algorithm,continuous wavelet transform,Continuous wavelet transforms,Convolution,convolutional squares,Daubechies filters,Discrete transforms,discrete wavelet transform,Discrete wavelet transforms,Energy resolution,Filter bank,filtering and prediction theory,finite energy,Lagrange a trous filters,Lagrangian functions,Mallat algorithms,nonorthonormal multiresolution algorithm,signal processing,Signal processing,Signal processing algorithms,signal processing parameters,Signal resolution,single filter bank structure,wavelet transforms},
  file = {/Users/driscoll/Zotero/storage/HRCPFZAL/Shensa - 1992 - The discrete wavelet transform wedding the a trou.pdf;/Users/driscoll/Zotero/storage/7UZ93JDH/157290.html}
}

@article{sherMultimodalAssessment2019,
  title = {Multimodal {{Assessment}} of {{Corneal Erosions Using Optical Coherence Tomography}} and {{Automated Grading}} of {{Fluorescein Staining}} in a {{Rabbit Dry Eye Model}}},
  author = {Sher, Ifat and Tzameret, Adi and Szalapak, Alicja M. and Carmeli, Tomer and Derazne, Estela and {Avni-Zauberman}, Noa and Marcovich, Arie L. and Simon, Guy Ben and Rotenstreich, Ygal},
  year = {2019},
  month = jan,
  journal = {Translational Vision Science \& Technology},
  volume = {8},
  number = {1},
  pages = {27},
  issn = {2164-2591},
  doi = {10.1167/tvst.8.1.27},
  abstract = {Purpose: To evaluate the potential use of anterior segment spectral domain optical coherence tomography (AS-SD-OCT) combined with an automated grading of fluorescein staining for assessment of corneal erosions in a rabbit short-term dry eye model. Methods: Twenty-one New Zealand white rabbits were anesthetized and eyes were kept open for 140 minutes to induce acute corneal desiccation. Rectangular scans of the cornea were performed using Spectralis AS-SD-OCT. Total corneal thickness, corneal epithelial thickness, and the percentage of epithelial erosion area (PEEA) were evaluated. Corneas were stained with fluorescein and graded automatically using EpiView and semi-automatically using ImageJ. Spearman's rank-order correlations were calculated to compare the AS-SD-OCT PEEA and the two corneal staining scores. Results: Eye desiccation resulted in corneal epithelium erosions that covered 0.67\% to 14.2\% of the central cornea (mean {\textpm} SD: 3.95\% {\textpm} 3.2\%) by AS-SD-OCT. The percentage of corneal area positively stained with fluorescein ranged from 0.24\% to 38.01\% (mean {\textpm} SD: 12.24\% {\textpm} 9.7\%) by using ImageJ, correlating with the AS-SD-OCT PEEA (Spearman's {$\rho$}, 0.574; P = 0.007). The EpiView score ranged from 0.5 to 10.17 and was better correlated with the AS-SD-OCT PEEA score (Spearman's {$\rho$}, 0.795; P = 0.000017). Conclusions: Our study suggests that multimodal analysis of AS-SD-OCT and grading of fluorescein staining using EpiView software may enable quantitative assessment of corneal epithelial erosions in a rabbit short-term dry eye model. Translational Relevance: This multimodal imaging analysis may be applied for evaluation of superficial punctate keratitis associated with dry eye.},
  langid = {english},
  pmcid = {PMC6396684},
  pmid = {30834175},
  keywords = {corneal defects,dry eye,epithelial erosions,fluorescein,SD-OCT},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Sher et al-2019-Multimodal Assessment of Corneal Erosions Using Optical.pdf}
}

@article{shiReviewZeroD1D2011,
  title = {Review of Zero-{{D}} and 1-{{D}} Models of Blood Flow in the Cardiovascular System},
  author = {Shi, Yubing and Lawford, Patricia and Hose, Rodney and others},
  year = {2011},
  journal = {Biomed. Eng. Online},
  volume = {10},
  number = {1},
  pages = {33},
  doi = {10.1186/1475-925X-10-33},
  urldate = {2015-07-23},
  keywords = {HLHS},
  file = {/Users/driscoll/Zotero/storage/3GS5SKWH/Shi-ReviewZeroD1DModelsBloodFlow-2011.pdf}
}

@article{Shyy_Moving_2001,
  title = {Moving Boundaries in Micro-Scale Biofluid Dynamics},
  author = {Shyy, W and Francois, M and Udaykumar, {\relax HS} and Ndri, N and R, Tran-Son-Tay},
  year = {2001},
  volume = {54},
  number = {5},
  pages = {405--454},
  abstract = {2.}
}

@article{Siggers_Fluid_2012,
  title = {Fluid Mechanics of the Eye},
  author = {Siggers, Jennifer H and Ethier, Ross C},
  year = {2012},
  volume = {44},
  number = {1},
  pages = {347--372},
  issn = {0066-4189},
  doi = {10.1146/annurev-fluid-120710-101058},
  abstract = {Fluid mechanical processes are an intrinsic part of several aspects of the physiology and pathology of the human eye. In this article we describe selected phenomena that are amenable to particularly interesting mathematical, experimental, or numerical analyses. We initially focus on glaucoma, a condition often associated with raised intraocular pressure. The mechanics in this disease is by no means fully understood, but we present some of the modeling work that provides a partial explanation. We next focus on other features of the dynamics of the two specialized ocular fluids: the aqueous and vitreous humors. With regard to the aqueous humor, we discuss problems concerning the transport of heat and proteins and the hydration of the cornea. With regard to the vitreous humor, we discuss the possibility of flow, which occurs primarily as a result of saccades or motions of the eyeball. Finally, we describe a model of the degradation of Bruch's membrane in the retina.}
}

@misc{SilhouettesGraphicalAid,
  title = {Silhouettes: {{A}} Graphical Aid to the Interpretation and Validation of Cluster Analysis - {{ScienceDirect}}},
  urldate = {2019-11-10},
  howpublished = {https://www.sciencedirect.com/science/article/pii/0377042787901257?via\%3Dihub}
}

@article{simpsonCanonicalGrading,
  title = {Canonical {{Grading Scales}} of {{Corneal}} and {{Conjunctival Staining Based}} on {{Psychophysical}} and {{Physical Attributes}}},
  author = {Simpson, T and Begley, C G and Situ, P and Feng and Nelson, J D and Caffery, Barbara and Springs, C and Connell, S B},
  journal = {Translational Vision Science and Technology},
  volume = {in review},
  keywords = {No DOI found}
}

@article{Singh2007,
  title = {Topological Methods for the Analysis of High Dimensional Data Sets and {{3D}} Object Recognition},
  author = {Singh, Gurjeet and Memoli, Facundo and Carlsson, Gunnar},
  year = {2007},
  pages = {-},
  publisher = {{The Eurographics Association}},
  doi = {10.2312/spbg/spbg07/091-100},
  langid = {english},
  keywords = {Categories and Subject Descriptors (according to ACM CCS): I.3.5 [Computer Graphics]: Computational Geometry and Object Modelling.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Singh et al_2007_Topological methods for the analysis of high dimensional data sets and 3D.pdf}
}

@article{SituEffectsTear2019,
  title = {Effects of {{Tear Film Instability}} on {{Sensory Responses}} to {{Corneal Cold}}, {{Mechanical}}, and {{Chemical Stimuli}}},
  author = {Situ, Ping and Begley, Carolyn G. and Simpson, Trefford L.},
  year = {2019},
  month = jul,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {60},
  number = {8},
  pages = {2935--2941},
  issn = {1552-5783},
  doi = {10.1167/iovs.19-27298},
  urldate = {2022-01-31},
  abstract = {To investigate the effects of tear film instability (TFI) induced by sustained tear exposure (STARE) on sensory responses to corneal cold, mechanical, and chemical stimuli.    Fifteen normal subjects were enrolled. TFI was induced during 10 repeated trials of STARE. Pneumatic cold, mechanical, and chemical stimuli were delivered using a computer-controlled Belmonte esthesiometer on three separate visits. The magnitude of the sensory responses to threshold and suprathreshold (1.25 and 1.50 times threshold levels) stimuli were assessed for intensity, coolness or warmness, irritation and pain, using a 0 (none) to 100 (very strong) scale, before and after STARE trials. Symptoms of ocular discomfort were evaluated using the Current Symptom Questionnaire (CSQ). Repeated measures ANOVA was used for data analysis.    Following STARE trials, the intensity and coolness ratings to cooling stimuli decreased (P = 0.043 and 0.044 for intensity and coolness, respectively), while rated irritation to mechanical stimuli was increased (P = 0.024). The CSQ scores also increased regardless of visits (all P \&lt; 0.001). Intensity ratings, coolness to room temperature stimuli and irritation to mechanical and chemical stimuli increased for all suprathreshold stimuli with increasing stimulus levels (P {$\leq$} 0.005).    Repeated TFI induced by STARE affects neurosensory function of the ocular surface. The decrease in reports of cooling and increase in irritation after repeated TFI suggest a complex interaction of neural mechanisms (particularly nonnociceptive cold and nociceptive mechanical) giving rise to ocular surface sensation in humans.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Situ et al-2019-Effects of Tear Film Instability on Sensory Responses to Corneal Cold,.pdf;/Users/driscoll/Zotero/storage/FKXF2SPZ/article.html}
}

@article{smaragdisStaticDynamicSource2014,
  title = {Static and {{Dynamic Source Separation Using Nonnegative Factorizations}}: {{A}} Unified View},
  shorttitle = {Static and {{Dynamic Source Separation Using Nonnegative Factorizations}}},
  author = {Smaragdis, P. and Fevotte, C. and Mysore, G. J. and Mohammadiha, N. and Hoffman, M.},
  year = {2014},
  month = may,
  journal = {IEEE Signal Processing Magazine},
  volume = {31},
  number = {3},
  pages = {66--75},
  issn = {1053-5888},
  doi = {10.1109/MSP.2013.2297715},
  abstract = {Source separation models that make use of nonnegativity in their parameters have been gaining increasing popularity in the last few years, spawning a significant number of publications on the topic. Although these techniques are conceptually similar to other matrix decompositions, they are surprisingly more effective in extracting perceptually meaningful sources from complex mixtures. In this article, we will examine the various methodologies and extensions that make up this family of approaches and present them under a unified framework. We will begin with a short description of the basic concepts and in the subsequent sections we will delve in more details and explore some of the latest extensions.},
  keywords = {complex mixtures,Data mining,Data models,dynamic source separation model,matrix decomposition,Matrix decomposition,matrix decompositions,NMF,nonnegative factorizations,Probabilistic logic,Signal processing algorithms,source separation,Source separation,static source separation model,time series,Time-frequency analysis},
  file = {/Users/driscoll/Zotero/storage/URUNC8D2/Smaragdis et al. - 2014 - Static and Dynamic Source Separation Using Nonnega.pdf;/Users/driscoll/Zotero/storage/JVNWTKK8/6784107.html}
}

@book{smithNumericalSolutionPartial1985,
  title = {Numerical {{Solution}} of {{Partial Differential Equations}}: {{Finite Difference Methods}}},
  shorttitle = {Numerical {{Solution}} of {{Partial Differential Equations}}},
  author = {Smith, Gordon D.},
  year = {1985},
  edition = {3rd},
  publisher = {{Clarendon Press}},
  abstract = {Substantially revised, this authoritative study covers the standard finite difference methods of parabolic, hyperbolic, and elliptic equations, and includes the concomitant theoretical work on consistency, stability, and convergence. The new edition includes revised and greatly expanded sections on stability based on the Lax-Richtmeyer definition, the application of Pade approximants to systems of ordinary differential equations for parabolic and hyperbolic equations, and a considerably improved presentation of iterative methods. A fast-paced introduction to numerical methods, this will be a useful volume for students of mathematics and engineering, and for postgraduates and professionals who need a clear, concise grounding in this discipline.},
  googlebooks = {hDpvljaHOrMC},
  isbn = {978-0-19-859650-9},
  langid = {english},
  keywords = {Mathematics / Differential Equations / General,Mathematics / Differential Equations / Partial,Mathematics / Finite Mathematics}
}

@article{smithTestingUniformityMultidimensional1984,
  title = {Testing for {{Uniformity}} in {{Multidimensional Data}}},
  author = {Smith, Stephen P. and Jain, Anil K.},
  year = {1984},
  month = jan,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {PAMI-6},
  number = {1},
  pages = {73--81},
  issn = {0162-8828, 2160-9292, 1939-3539},
  doi = {10.1109/tpami.1984.4767477},
  abstract = {Testing for uniformity in multidimensional data is important in exploratory pattern analysis, statistical pattern recognition, and image processing. The goal of this paper is to determine whether the data follow the uniform distribution over some compact convex set in K-dimensional space, called the sampling window. We first provide a simple, computationally efficient method for generating a uniformly distributed sample over a set which approximates the convex hul of the data. We then test for uniformity by comparing this generated sample to the data by using Friedman-Rafsky's minimal spanning tree (MST) based test. Experiments with both simulated and real data indicate that this MST-based test is useful in deciding if data are uniform.},
  keywords = {Clustering tendency,Computational modeling,Computer science,convex hull,Distributed computing,exploratory pattern analysis,Image processing,Image sampling,minimal spanning tree,Multidimensional systems,Pattern analysis,Pattern recognition,Sampling methods,Testing},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Smith_Jain_1984_Testing for Uniformity in Multidimensional Data.pdf;/Users/driscoll/Zotero/storage/VVPRUBCN/4767477.html}
}

@article{speakmanDiagnosticUtilityNITBUT2022,
  title = {Investigating the Diagnostic Utility of Non-Invasive Tear Film Stability and Breakup Parameters: {{A}} Prospective Diagnostic Accuracy Study},
  shorttitle = {Investigating the Diagnostic Utility of Non-Invasive Tear Film Stability and Breakup Parameters},
  author = {Speakman, Sophie and Wang, Michael T.M. and Muntz, Alex and {Vidal-Rohr}, Maria and Menduni, Francesco and Dhallu, Sandeep and Ipek, Tugce and Acar, Duygu and Recchioni, Alberto and France, Alex and Kingsnorth, Alec and Wolffsohn, James S. and Craig, Jennifer P.},
  year = {2022},
  month = jul,
  journal = {The Ocular Surface},
  volume = {25},
  pages = {72--74},
  issn = {15420124},
  doi = {10.1016/j.jtos.2022.04.006},
  urldate = {2022-08-05},
  langid = {english}
}

@article{Stamer_Sphingosine_2009,
  title = {Sphingosine-1-Phosphate Effects on the Inner Wall of {{Schlemm}}'s Canal and Outflow Facility in Perfused Human Eyes},
  author = {Stamer, Daniel W and Read, Thomas A and Sumida, Grant M and Ethier, Ross C},
  year = {2009},
  volume = {89},
  number = {6},
  pages = {980--988},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2009.08.008},
  abstract = {Previous work has shown that sphingosine 1-phosphate (S1P) decreases outflow facility in perfused porcine eyes while dramatically increasing giant vacuole density in the inner wall of the aqueous plexus, with no obvious changes in the trabecular meshwork (TM). Due to known effects of S1P on cell--cell junction assembly in vascular endothelia, we hypothesized that S1P would decrease outflow facility in human eyes by increasing the complexity of cell--cell junctions in Schlemm's canal (SC) inner wall endothelia. Perfusion of enucleated post mortem human eyes at 8 mmHg constant pressure in the presence or absence of 5 {$\mu$}M S1P showed that S1P decreased outflow facility by 36  20\% (n = 10 pairs; p = 0.0004); an effect likely mediated by activation of S1P1 and/or S1P3 receptor subtypes, which were found to be the principal S1P receptors expressed by both TM and SC cells by RT-PCR, confocal immunofluorescence microscopy and western blot analyses. Examination of SC's inner wall using confocal microscopy revealed no consistent differences in VE-cadherin, {$\beta$}-catenin, phosphotyrosine or filamentous actin abundance/distribution between S1P-treated eyes and controls. Moreover, morphological inspection of conventional outflow tissues by light and scanning electron microscopy showed no significant differences between S1P-treated and control eyes, particularly in giant vacuole density. Thus, unlike the situation in porcine eyes, we did not observe changes in inner wall morphology in human eyes treated with S1P, despite a significant and immediate decrease in outflow facility in both species. Regardless, S1P receptor antagonists represent novel therapeutic prospects for ocular hypertension in humans.},
  pmcid = {PMC2794662},
  pmid = {19715693}
}

@misc{Stapf_Modeling_2015,
  title = {Modeling Tear Film Evaporation and Breakup with Duplex Films},
  author = {Stapf, Michael and Braun, Richard J and Begley, Carolyn G and Driscoll, Tobin A and E., P., King-Smith},
  year = {2015},
  copyright = {All rights reserved}
}

@article{StapfDuplexTear2017,
  title = {Duplex {{Tear Film Evaporation Analysis}}},
  author = {Stapf, M. R. and Braun, R. J. and {King-Smith}, P. E.},
  year = {2017},
  month = dec,
  journal = {Bulletin of Mathematical Biology},
  volume = {79},
  number = {12},
  pages = {2814--2846},
  issn = {1522-9602},
  doi = {10.1007/s11538-017-0351-9},
  urldate = {2024-02-06},
  abstract = {Tear film thinning, hyperosmolarity, and breakup can cause irritation and damage to the human eye, and these form an area of active investigation for dry eye syndrome research. Recent research demonstrates that deficiencies in the lipid layer may cause locally increased evaporation, inducing conditions for breakup. In this paper, we explore the conditions for tear film breakup by considering a model for tear film dynamics with two mobile fluid layers, the aqueous and lipid layers. In addition, we include the effects of osmosis, evaporation as modified by the lipid, and the polar portion of the lipid layer. We solve the system numerically for reasonable parameter values and initial conditions and analyze how shifts in these cause changes to the system's dynamics.},
  langid = {english},
  keywords = {Evaporation,Lipid layer,Tear film,Tear osmolarity},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Stapf et al_2017_Duplex Tear Film Evaporation Analysis.pdf}
}

@inproceedings{StapfModelingTear2015,
  title = {Modeling {{Tear Film Evaporation}} and {{Breakup}} with {{Duplex Films}}},
  booktitle = {{{APS Meeting Abstracts}}},
  author = {Stapf, Michael and Braun, Richard and Begley, Carolyn and Driscoll, Tobin and {King-Smith}, Peter Ewen},
  year = {2015},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{Stapleton_The_2013,
  title = {The {{TFOS}} International Workshop on Contact Lens Discomfort: {{Report}} of the Subcommittee on Neurobiology},
  author = {Stapleton, Fiona and Marfurt, Carl and Golebiowski, Blanka and Rosenblatt, Mark and Bereiter, David and Begley, Carolyn and Dartt, Darlene and Gallar, Juana and Belmonte, Carlos and Hamrah, Pedram and Willcox, Mark and {on Discomfort}, {\relax TFOS}},
  year = {2013},
  volume = {54},
  number = {11},
  pages = {TFOS71-TFOS97},
  issn = {1552-5783},
  doi = {10.1167/iovs.13-13226},
  abstract = {This report characterizes the neurobiology of the ocular surface and highlights relevant mechanisms that may underpin contact lens--related discomfort. While there is limited evidence for the mechanisms involved in contact lens--related discomfort, neurobiological mechanisms in dry eye disease, the inflammatory pathway, the effect of hyperosmolarity on ocular surface nociceptors, and subsequent sensory processing of ocular pain and discomfort have been at least partly elucidated and are presented herein to provide insight in this new arena. The stimulus to the ocular surface from a contact lens is likely to be complex and multifactorial, including components of osmolarity, solution effects, desiccation, thermal effects, inflammation, friction, and mechanical stimulation. Sensory input will arise from stimulation of the lid margin, palpebral and bulbar conjunctiva, and the cornea.},
  pmid = {24058137}
}

@article{stapletonDEWSIIepi2017,
  title = {{{TFOS DEWS II Epidemiology Report}}},
  author = {Stapleton, Fiona and Alves, Monica and Bunya, Vatinee Y. and Jalbert, Isabelle and Lekhanont, Kaevalin and Malet, Florence and Na, Kyung-Sun and Schaumberg, Debra and Uchino, Miki and Vehof, Jelle and Viso, Eloy and Vitale, Susan and Jones, Lyndon},
  year = {2017},
  month = jul,
  journal = {The Ocular Surface},
  series = {{{TFOS International Dry Eye WorkShop}} ({{DEWS II}})},
  volume = {15},
  number = {3},
  pages = {334--365},
  issn = {1542-0124},
  doi = {10.1016/j.jtos.2017.05.003},
  urldate = {2022-08-05},
  abstract = {The subcommittee reviewed the prevalence, incidence, risk factors, natural history, morbidity and questionnaires reported in epidemiological studies of dry eye disease (DED). A meta-analysis of published prevalence data estimated the impact of age and sex. Global mapping of prevalence was undertaken. The prevalence of DED ranged from 5 to 50\%. The prevalence of signs was higher and more variable than symptoms. There were limited prevalence studies in youth and in populations south of the equator. The meta-analysis confirmed that prevalence increases with age, however signs showed a greater increase per decade than symptoms. Women have a higher prevalence of DED than men, although differences become significant only with age. Risk factors were categorized as modifiable/non-modifiable, and as consistent, probable or inconclusive. Asian ethnicity was a mostly consistent risk factor. The economic burden and impact of DED on vision, quality of life, work productivity, psychological and physical impact of pain, are considerable, particularly costs due to reduced work productivity. Questionnaires used to evaluate DED vary in their utility. Future research should establish the prevalence of disease of varying severity, the incidence in different populations and potential risk factors such as youth and digital device usage. Geospatial mapping might elucidate the impact of climate, environment and socioeconomic factors. Given the limited study of the natural history of treated and untreated DED, this remains an important area for future research.},
  langid = {english},
  keywords = {Dry eye disease,Incidence,Natural history,Prevalence,Quality of life,Questionnaire,Risk factor,Societal cost},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Stapleton et al-2017-TFOS DEWS II Epidemiology Report.pdf;/Users/driscoll/Zotero/storage/8KIVUNNV/S154201241730109X.html}
}

@article{Stay_Computer_2003,
  title = {Computer Simulation of Convective and Diffusive Transport of Controlled-Release Drugs in the Vitreous Humor},
  author = {Stay, {\relax MS} and Xu, J and Randolph, {\relax TW} and Barocas, {\relax VH}},
  year = {2003},
  journal = {Pharmaceutical research},
  doi = {10.1023/a:1022207026982},
  abstract = {Abstract Purpose. Biodistribution of drugs in the eye is central to the efficacy of pharmaceutical ocular therapies. Of particular interest to us is the effect of intravitreal transport on distribution of controlled-released drugs within the vitreous. Methods. A ...}
}

@article{stelzlHumanProteinProteinInteraction2005,
  title = {A {{Human Protein-Protein Interaction Network}}: {{A Resource}} for {{Annotating}} the {{Proteome}}},
  shorttitle = {A {{Human Protein-Protein Interaction Network}}},
  author = {Stelzl, Ulrich and Worm, Uwe and Lalowski, Maciej and Haenig, Christian and Brembeck, Felix H. and Goehler, Heike and Stroedicke, Martin and Zenkner, Martina and Schoenherr, Anke and Koeppen, Susanne and Timm, Jan and Mintzlaff, Sascha and Abraham, Claudia and Bock, Nicole and Kietzmann, Silvia and Goedde, Astrid and Toks{\"o}z, Engin and Droege, Anja and Krobitsch, Sylvia and Korn, Bernhard and Birchmeier, Walter and Lehrach, Hans and Wanker, Erich E.},
  year = {2005},
  month = sep,
  journal = {Cell},
  volume = {122},
  number = {6},
  pages = {957--968},
  issn = {00928674},
  doi = {10.1016/j.cell.2005.08.029},
  urldate = {2022-04-28},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Stelzl et al-2005-A Human Protein-Protein Interaction Network.pdf}
}

@book{stewartMatrixAlgorithmsVolume2001,
  title = {Matrix {{Algorithms Volume}} 2: {{Eigensystems}}},
  shorttitle = {Matrix {{Algorithms Volume}} 2},
  author = {Stewart, G. W.},
  year = {2001},
  month = aug,
  publisher = {{SIAM}},
  abstract = {This is the second volume in a projected five-volume survey of numerical linear algebra and matrix algorithms. It treats the numerical solution of dense and large-scale eigenvalue problems with an emphasis on algorithms and the theoretical background required to understand them. The notes and reference sections contain pointers to other methods along with historical comments. The book is divided into two parts: dense eigenproblems and large eigenproblems. The first part gives a full treatment of the widely used QR algorithm, which is then applied to the solution of generalized eigenproblems and the computation of the singular value decomposition. The second part treats Krylov sequence methods such as the Lanczos and Arnoldi algorithms and presents a new treatment of the Jacobi-Davidson method. These volumes are not intended to be encyclopedic, but provide the reader with the theoretical and practical background to read the research literature and implement or modify new algorithms.},
  googlebooks = {uSOBoVpqVUYC},
  isbn = {978-0-89871-503-3},
  langid = {english},
  keywords = {Mathematics / Algebra / General,Mathematics / Applied,Mathematics / Mathematical Analysis,Mathematics / Matrices,Mathematics / Numerical Analysis}
}

@book{stoerIntroductionNumericalAnalysis2002,
  title = {Introduction to {{Numerical Analysis}}},
  author = {Stoer, Josef and Bulirsch, R.},
  year = {2002},
  month = aug,
  edition = {3rd},
  publisher = {{Springer Science \& Business Media}},
  abstract = {Mathematics is playing an ever more important role in the physical and biological sciences, provoking a blurring of boundaries between scientific disciplines and a resurgence of interest in the modern as well as the classical techniques of applied mathematics. This renewal of interest, both in re search and teaching, has led to the establishment of the series Texts in Applied Mathematics (TAM). The development of new courses is a natural consequence of a high level of excitement on the research frontier as newer techniques, such as numeri cal and symbolic computer systems, dynamical systems, and chaos, mix with and reinforce the traditional methods of applied mathematics. Thus, the purpose of this textbook series is to meet the current and future needs of these advances and to encourage the teaching of new courses. TAM will publish textbooks suitable for use in advanced undergraduate and beginning graduate courses, and will complement the Applied Mathe matical Sciences (AMS) series, which will focus on advanced textbooks and research-level monographs.},
  googlebooks = {1oDXWLb9qEkC},
  isbn = {978-0-387-95452-3},
  langid = {english},
  keywords = {Mathematics / Algebra / General,Mathematics / Applied,Mathematics / Calculus,Mathematics / Counting & Numeration,Mathematics / Mathematical Analysis,Mathematics / Number Systems,Mathematics / Numerical Analysis}
}

@article{Strang2018,
  title = {Multiplying and Factoring Matrices},
  author = {Strang, Gilbert},
  year = {2018},
  month = feb,
  journal = {The American Mathematical Monthly},
  volume = {125},
  number = {3},
  pages = {223--230},
  publisher = {{Informa UK Limited}},
  doi = {10.1080/00029890.2018.1408378},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Strang_2018_Multiplying and factoring matrices.pdf}
}

@book{strangAnalysisFiniteElement1997,
  title = {An {{Analysis}} of the {{Finite Element Method}}},
  author = {Strang, Gilbert and Fix, George J.},
  year = {1997},
  publisher = {{Wellesley-Cambridge Press}},
  isbn = {978-0-9614088-8-6},
  langid = {english},
  keywords = {Mathematics / Mathematical Analysis}
}

@book{strangComputationalScienceEngineering2007,
  title = {Computational {{Science}} and {{Engineering}}},
  author = {Strang, Gilbert},
  year = {2007},
  month = nov,
  publisher = {{Wellesley-Cambridge Press}},
  abstract = {Encompasses the full range of computational science and engineering from modelling to solution, both analytical and numerical. It develops a framework for the equations and numerical methods of applied mathematics. Gilbert Strang has taught this material to thousands of engineers and scientists (and many more on MIT's OpenCourseWare 18.085-6). His experience is seen in his clear explanations, wide range of examples, and teaching method. The book is solution-based and not formula-based: it integrates analysis and algorithms and MATLAB codes to explain each topic as effectively as possible. The topics include applied linear algebra and fast solvers, differential equations with finite differences and finite elements, Fourier analysis and optimization. This book also serves as a reference for the whole community of computational scientists and engineers. Supporting resources, including MATLAB codes, problem solutions and video lectures from Gilbert Strang's 18.085 courses at MIT, are provided at math.mit.edu/cse.},
  googlebooks = {GQ9pQgAACAAJ},
  isbn = {978-0-9614088-1-7},
  langid = {english},
  keywords = {Computers / General,Mathematics / Applied}
}

@book{strangIntroductionLinearAlgebra2016,
  title = {Introduction to {{Linear Algebra}}},
  author = {Strang, Gilbert},
  year = {2016},
  month = aug,
  publisher = {{Wellesley-Cambridge Press}},
  abstract = {Linear algebra is something all mathematics undergraduates and many other students, in subjects ranging from engineering to economics, have to learn. The fifth edition of this hugely successful textbook retains all the qualities of earlier editions, while at the same time seeing numerous minor improvements and major additions. The latter include: {$\bullet$} A new chapter on singular values and singular vectors, including ways to analyze a matrix of data {$\bullet$} A revised chapter on computing in linear algebra, with professional-level algorithms and code that can be downloaded for a variety of languages {$\bullet$} A new section on linear algebra and cryptography {$\bullet$} A new chapter on linear algebra in probability and statistics. A dedicated and active website also offers solutions to exercises as well as new exercises from many different sources (including practice problems, exams, and development of textbook examples), plus codes in MATLAB{\textregistered}, Julia, and Python.},
  googlebooks = {efbxjwEACAAJ},
  isbn = {978-0-9802327-7-6},
  langid = {english},
  keywords = {Mathematics / Algebra / General}
}

@book{strangLinearAlgebraGeodesy1997,
  title = {Linear {{Algebra}}, {{Geodesy}}, and {{GPS}}},
  author = {Strang, Gilbert and Borre, Kai},
  year = {1997},
  month = jan,
  publisher = {{SIAM}},
  abstract = {Discusses algorithms generally expressed in MATLAB for geodesy and global positioning. Three parts cover basic linear algebra, the application to the (linear and also nonlinear) science of measurement, and the GPS system and its applications. A popular article from SIAM News (June 1997) The Mathematics of GPS is included as an introduction. Annot},
  googlebooks = {MjNwWUY8jx4C},
  isbn = {978-0-9614088-6-2},
  langid = {english},
  keywords = {Technology & Engineering / Engineering (General)}
}

@article{Suga1974,
  title = {Instantaneous Pressure-Volume Relationships and Their Ratio in the Excised, Supported Canine Left Ventricle},
  author = {Suga, H. and Sagawa, K.},
  year = {1974},
  month = jul,
  journal = {Circulation Research},
  volume = {35},
  number = {1},
  pages = {117--126},
  publisher = {{Ovid Technologies (Wolters Kluwer Health)}},
  doi = {10.1161/01.res.35.1.117},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Suga_Sagawa_1974_Instantaneous pressure-volume relationships and their ratio in the excised,.pdf}
}

@article{sunSurveyMultiviewMachine2013,
  title = {A Survey of Multi-View Machine Learning},
  author = {Sun, Shiliang},
  year = {2013},
  month = dec,
  journal = {Neural Computing and Applications},
  volume = {23},
  number = {7},
  pages = {2031--2038},
  issn = {1433-3058},
  doi = {10.1007/s00521-013-1362-6},
  urldate = {2019-11-07},
  abstract = {Multi-view learning or learning with multiple distinct feature sets is a rapidly growing direction in machine learning with well theoretical underpinnings and great practical success. This paper reviews theories developed to understand the properties and behaviors of multi-view learning and gives a taxonomy of approaches according to the machine learning mechanisms involved and the fashions in which multiple views are exploited. This survey aims to provide an insightful organization of current developments in the field of multi-view learning, identify their limitations, and give suggestions for further research. One feature of this survey is that we attempt to point out specific open problems which can hopefully be useful to promote the research of multi-view machine learning.},
  langid = {english},
  keywords = {Canonical correlation analysis,Co-regularization,Co-training,Multi-view learning,Statistical learning theory},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Sun_2013_A survey of multi-view machine learning.pdf}
}

@article{suTearFilm2018,
  title = {Tear {{Film Break-Up Time Measurement Using Deep Convolutional Neural Networks}} for {{Screening Dry Eye Disease}}},
  author = {Su, Tai-Yuan and Liu, Zi-Yuan and Chen, Duan-Yu},
  year = {2018},
  month = aug,
  journal = {IEEE Sensors Journal},
  volume = {18},
  number = {16},
  pages = {6857--6862},
  issn = {2379-9153},
  doi = {10.1109/jsen.2018.2850940},
  abstract = {Tear film instability is one of the major characteristics of dry eye syndrome. However, traditional diagnostic methods, such as the fluorescein tear film break-up time (FTBUT) test, are limited by the subjective interpretation of results. The test needs to manually identify break-up areas in the fluorescent image, thus producing variable diagnosis results. This paper proposes an automatic method to detect the fluorescent tear film break-up area using a deep convolutional neural network (CNN) model and to define its appearance as CNN-BUT. A digital slit-lamp recorded the standard FTBUT measurement for each of 80 study participants. Fifty participants were used to train the CNN model to identify the tear film break-up area, while the remaining 30 were used to validate the proposed CNN-BUT test. Among six normal controls and 24 dry eye patients enrolled in this paper, CNN-BUT was significantly lower in dry eye patients (p {$<$};0.05). The correlation between CNN-BUT and FTBUT was also significant (r =0.9; p {$<$};0.05). Using 5 s as the cutoff value, the CNN-BUT offered acceptable sensitivity and specificity to screen dry eye patients (0.83 and 0.95, respectively). These results indicate that CNN-BUT may be used to evaluate tear film stability and to assess the status of dry eye syndrome automatically.},
  keywords = {Artificial intelligence,Atmospheric measurements,automatic method,biomedical optical imaging,CNN model,CNN-BUT,deep convolutional neural network model,digital slit-lamp,diseases,dry eye disease,dry eye patients,dry eye syndrome,eye,Eyelids,feedforward neural nets,fluorescein film break-up time test,fluorescence,Fluorescence,fluorescent image,fluorescent tear film break-up areas,Image segmentation,medical diagnostic computing,medical diagnostic imaging,medical information systems,multi-layer neural network,Particle measurements,standard FTBUT measurement,tear film break-up time measurement,tear film instability,Time measurement,traditional diagnostic methods,Training},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Su et al_2018_Tear Film Break-Up Time Measurement Using Deep Convolutional Neural Networks.pdf;/Users/driscoll/Zotero/storage/6U9837RD/8398407.html}
}

@article{TakahasiDoubleExponential1973,
  title = {Double {{Exponential Formulas}} for {{Numerical Integration}}},
  author = {Takahasi, Hidetosi and Mori, Masatake},
  year = {1973},
  month = dec,
  journal = {Publications of the Research Institute for Mathematical Sciences},
  volume = {9},
  number = {3},
  pages = {721--741},
  issn = {0034-5318},
  doi = {10.2977/prims/1195192451},
  urldate = {2020-06-18},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Takahasi_Mori-1973-Double Exponential Formulas for Numerical Integration.pdf;/Users/driscoll/Zotero/storage/N22LS9FX/show_abstract.html}
}

@article{Tamm_The_2009,
  title = {The Trabecular Meshwork Outflow Pathways: Structural and Functional Aspects.},
  author = {Tamm, Ernst R},
  year = {2009},
  volume = {88},
  number = {4},
  pages = {648--55},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2009.02.007},
  abstract = {The major drainage structures for aqueous humor (AH) are the conventional or trabecular outflow pathways, which are comprised of the trabecular meshwork (made up by the uveal and corneoscleral meshworks), the juxtacanalicular connective tissue (JCT), the endothelial lining of Schlemm's canal (SC), the collecting channels and the aqueous veins. The trabecular meshwork (TM) outflow pathways are critical in providing resistance to AH outflow and in generating intraocular pressure (IOP). Outflow resistance in the TM outflow pathways increases with age and primary open-angle glaucoma. Uveal and corneoscleral meshworks form connective tissue lamellae or beams that are covered by flat TM cells which rest on a basal lamina. TM cells in the JCT are surrounded by fibrillar elements of the extracellular matrix (ECM) to form a loose connective tissue. In contrast to the other parts of the TM, JCT cells and ECM fibrils do not form lamellae, but are arranged more irregularly. SC inner wall endothelial cells form giant vacuoles in response to AH flow, as well as intracellular and paracellular pores. In addition, minipores that are covered with a diaphragm are observed. There is considerable evidence that normal AH outflow resistance resides in the inner wall region of SC, which is formed by the JCT and SC inner wall endothelium. Modulation of TM cell tone by the action of their actomyosin system affects TM outflow resistance. In addition, the architecture of the TM outflow pathways and consequently outflow resistance appear to be modulated by contraction of ciliary muscle and scleral spur cells. The scleral spur contains axons that innervate scleral spur cells or that have the ultrastructural characteristics of mechanosensory nerve endings.},
  pmid = {19239914}
}

@article{tanObjectiveQuantification2013,
  title = {Objective Quantification of Fluorescence Intensity on the Corneal Surface Using a Modified Slit-Lamp Technique},
  author = {Tan, Bo and Zhou, Yixiu and Svitova, Tatyana and Lin, Meng C.},
  year = {2013},
  month = may,
  journal = {Eye \& Contact Lens},
  volume = {39},
  number = {3},
  pages = {239--246},
  issn = {1542-233X},
  doi = {10.1097/icl.0b013e31828dc7f3},
  abstract = {OBJECTIVES: To improve the digital quantification of fluorescence intensity of sodium fluorescein instilled on corneal surface by modifying a slit lamp hardware and performing computerized processing of captured digital images. METHODS: The optics of a slit lamp were modified to remove corneal Purkinje reflection and to expand the illuminated area on the cornea, followed by postexperiment image processing to minimize the influence of uneven illumination. To demonstrate the feasibility and reliability of this new technique, we applied it to objective grading of corneal staining with sodium fluorescein. The results of computerized grading were compared with the results obtained using standard subjective grading of corneal staining. Objective digital grades, staining area, and staining pixel with manually and automatically defined threshold (SP-M and SP-A) were calculated for both original and processed images. Standard subjective grades of the original images were performed by 13 trained observers using National Eye Institute (NEI), Efron, and CCLRU grading scales. A series of linear regression analyses were performed to investigate the correlation between objective and subjective grades. RESULTS: Digital grades of the captured images were correlated significantly with subjective grades. After minimization of the artifact caused by the nonuniform illumination, correlations between digital and subjective grading were mostly strengthened. In some cases, digital grading of corneal staining was more sensitive than subjective grading methods when differentiating subtle differences of corneal staining. CONCLUSIONS: Modifications performed on commercial slit-lamp hardware and the proposed digital image-processing technique have improved the quality of captured images for semiautomated quantification of fluorescein intensity on the cornea.},
  langid = {english},
  pmid = {23629006},
  keywords = {Adolescent,Adult,Corneal Diseases,Diagnostic Techniques Ophthalmological,Female,Fluorescein,Fluorescent Dyes,Humans,Male,Young Adult},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Tan et al-2013-Objective quantification of fluorescence intensity on the.pdf}
}

@misc{TaranchukExtensionalFlow2023,
  title = {Extensional {{Flow}} of a {{Free Film}} of {{Nematic Liquid Crystal}} with {{Moderate Elasticity}}},
  author = {Taranchuk, M. J. and Cummings, L. J. and Driscoll, T. A. and Braun, R. J.},
  year = {2023},
  month = apr,
  number = {arXiv:2304.03356},
  eprint = {2304.03356},
  primaryclass = {physics},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2304.03356},
  urldate = {2023-04-11},
  abstract = {Motivated by problems arising in tear film dynamics, we present a model for the extensional flow of thin sheets of nematic liquid crystal. The rod-like molecules of these substances impart an elastic contribution to its response. We rescale a weakly elastic model due to Cummings et al. [European Journal of Applied Mathematics 25 (2014): 397-423] to describe a case of moderate elasticity. The resulting system of two nonlinear partial differential equations for sheet thickness and axial velocity is nonlinear and fourth order in space, but still represents a significant reduction of the full system. We analyze solutions arising from several different boundary conditions, motivated by the underlying application, with particular focus on dynamics and underlying mechanisms under stretching. We solve the system numerically, via collocation with either finite difference or Chebyshev spectral discretization in space, together with implicit time stepping. At early times, depending on the initial film shape, pressure either aids or opposes extensional flow, which changes the shape of the sheet and may result in the loss of a minimum or maximum at the moving end. We contrast this finding with the cases of weak elasticity and Newtonian flow, where the sheet retains all extrema from the initial condition throughout time.},
  archiveprefix = {arxiv},
  copyright = {All rights reserved},
  keywords = {Physics - Fluid Dynamics},
  file = {/Users/driscoll/Dropbox/library/Preprint/Taranchuk et al_2023_Extensional Flow of a Free Film of Nematic Liquid Crystal with Moderate.pdf;/Users/driscoll/Zotero/storage/CUDKN82R/2304.html}
}

@article{TaranchukExtensionalFlow2023a,
  title = {Extensional Flow of a Free Film of Nematic Liquid Crystal with Moderate Elasticity},
  author = {Taranchuk, M. J. and Cummings, L. J. and Driscoll, T. A. and Braun, R. J.},
  year = {2023},
  month = jun,
  journal = {Physics of Fluids},
  volume = {35},
  number = {6},
  pages = {062113},
  issn = {1070-6631},
  doi = {10.1063/5.0151809},
  urldate = {2023-06-15},
  abstract = {The human tear film is a multilayer structure in which the dynamics are often strongly affected by a floating lipid layer. That layer has liquid crystalline characteristics and plays important roles in the health of the tear film. Previous models have treated the lipid layer as a Newtonian fluid in extensional flow. Motivated to develop a more realistic treatment, we present a model for the extensional flow of thin sheets of nematic liquid crystal. The rod-like molecules of these substances impart an elastic contribution to the rheology. We rescale a weakly elastic model due to Cummings et al. [``Extensional flow of nematic liquid crystal with an applied electric field,'' Eur. J. Appl. Math. 25, 397--423 (2014).] to describe a lipid layer of moderate elasticity. The resulting system of two nonlinear partial differential equations for sheet thickness and axial velocity is fourth order in space, but still represents a significant reduction of the full system. We analyze solutions arising from several different boundary conditions, motivated by the underlying application, with particular focus on dynamics and underlying mechanisms under stretching. We solve the system numerically, via collocation with either finite difference or Chebyshev spectral discretization in space, together with implicit time stepping. At early times, depending on the initial film shape, pressure either aids or opposes extensional flow, which changes the free surface dynamics of the sheet and can lead to patterns reminiscent of those observed in tear films. We contrast this finding with the cases of weak elasticity and Newtonian flow, where the sheet retains the same qualitative shape throughout time.},
  copyright = {All rights reserved},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Taranchuk et al_2023_Extensional flow of a free film of nematic liquid crystal with moderate.pdf;/Users/driscoll/Dropbox/library/Journal Article/Taranchuk et al_2023_Extensional flow of a free film of nematic liquid crystal with moderate2.pdf;/Users/driscoll/Zotero/storage/QKYPJAEK/Extensional-flow-of-a-free-film-of-nematic-liquid.html}
}

@article{Tee2006,
  title = {A Rational Spectral Collocation Method with Adaptively Transformed Chebyshev Grid Points},
  author = {Tee, T. W. and Trefethen, Lloyd N.},
  year = {2006},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {28},
  number = {5},
  pages = {1798--1811},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/050641296},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Tee_Trefethen_2006_A rational spectral collocation method with adaptively transformed chebyshev.pdf}
}

@article{Teppati2002,
  title = {Conformal-Mapping Design Tools for Coaxial Couplers with Complex Cross Section},
  author = {Teppati, Valeria and Goano, Michele and Ferrero, Andrea},
  year = {2002},
  journal = {IEEE Transactions on microwave theory and techniques},
  volume = {50},
  number = {10},
  pages = {2339--2345},
  publisher = {{IEEE}},
  doi = {10.1109/tmtt.2002.803424},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Teppati et al_2002_Conformal-mapping design tools for coaxial couplers with complex cross section.pdf}
}

@article{terryCCLRUStandards1993,
  title = {{{CCLRU}} Standards for Success of Daily and Extended Wear Contact Lenses},
  author = {Terry, R. L. and Schnider, C. M. and Holden, B. A. and Cornish, R. and Grant, T. and Sweeney, D. and La Hood, D. and Back, A.},
  year = {1993},
  month = mar,
  journal = {Optometry and Vision Science: Official Publication of the American Academy of Optometry},
  volume = {70},
  number = {3},
  pages = {234--243},
  issn = {1040-5488},
  doi = {10.1097/00006324-199303000-00011},
  abstract = {Success in contact lens wear is often judged on the basis of patient "survival" rather than the achievement of satisfactory performance based on specific criteria. In 1971, Sarver and Harris defined a series of standards for successful polymethyl methacrylate (PMMA) lens wear which incorporated criteria for wearing time, comfort, vision, ocular tissue changes, and patient appearance. In this paper we propose a revision of these criteria based on current understanding of the ocular response to contact lens wear. These revised CCLRU (Cornea and Contact Lens Research Unit) standards for success are intended as realistic performance objectives, and can be applied in clinical trials to evaluate and compare the clinical performance of present and future rigid and soft contact lenses, worn for daily and extended wear.},
  langid = {english},
  pmid = {8483586},
  keywords = {Contact Lenses,Contact Lenses Extended-Wear,Humans,Patient Satisfaction}
}

@book{teunissenDynamicDataProcessing2001,
  title = {Dynamic Data Processing: Recursive Least-Squares},
  shorttitle = {Dynamic Data Processing},
  author = {Teunissen, P. J. G.},
  year = {2001},
  series = {Series on Mathematical Geodesy and Positioning},
  publisher = {{VSSD}},
  address = {{Delft, the Netherlands}},
  urldate = {2020-06-18},
  isbn = {9786610450640},
  lccn = {QA9.615},
  keywords = {Geodesy,Least squares,Mathematical models,Parameter estimation,Recursive functions}
}

@inproceedings{theisGeneralIndependentSubspace2006,
  title = {Towards a General Independent Subspace Analysis},
  booktitle = {Proceedings of the 19th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Theis, Fabian J.},
  year = {2006},
  month = dec,
  series = {{{NIPS}}'06},
  pages = {1361--1368},
  publisher = {{MIT Press}},
  address = {{Canada}},
  urldate = {2020-01-17},
  abstract = {The increasingly popular independent component analysis (ICA) may only be applied to data following the generative ICA model in order to guarantee algorithm-independent and theoretically valid results. Subspace ICA models generalize the assumption of component independence to independence between groups of components. They are attractive candidates for dimensionality reduction methods, however are currently limited by the assumption of equal group sizes or less general semi-parametric models. By introducing the concept of irreducible independent subspaces or components, we present a generalization to a parameter-free mixture model. Moreover, we relieve the condition of at-most-one-Gaussian by including previous results on non-Gaussian component analysis. After introducing this general model, we discuss joint block diagonalization with unknown block sizes, on which we base a simple extension of JADE to algorithmically perform the subspace analysis. Simulations confirm the feasibility of the algorithm.},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Theis_2006_Towards a general independent subspace analysis.pdf}
}

@article{ThibosClinicalApplications1999,
  title = {Clinical {{Applications}} of the {{Shack-Hartmann Aberrometer}}},
  shorttitle = {Clinical {{Applications}} of the {{Shack-Hartmann Aberrometer}}},
  author = {Thibos, Larry N. and Hong, Xin},
  year = {1999},
  month = dec,
  journal = {Optometry and Vision Science},
  volume = {76},
  number = {12},
  pages = {817--825},
  issn = {1040-5488},
  doi = {10.1097/00006324-199912000-00016},
  urldate = {2022-08-05},
  langid = {english}
}

@article{TomlinsonTearFilm2006,
  title = {Tear {{Film Osmolarity}}: {{Determination}} of a {{Referent}} for {{Dry Eye Diagnosis}}},
  shorttitle = {Tear {{Film Osmolarity}}},
  author = {Tomlinson, Alan and Khanal, Santosh and Ramaesh, Kanna and Diaper, Charles and McFadyen, Angus},
  year = {2006},
  month = oct,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {47},
  number = {10},
  pages = {4309--4315},
  issn = {1552-5783},
  doi = {10.1167/iovs.05-1504},
  urldate = {2023-02-13},
  abstract = {purpose. To determine new referents, or cutoff levels for tear film hyperosmolarity in the diagnosis of keratoconjunctivitis sicca (KCS) and to assess their effectiveness in independent patient groups.  method. A meta-analysis was performed on published data for tear osmolarity in samples of normal eyes and various subtypes of dry eye, and pooled estimates of the mean and standard deviations for normal and (all) dry eye subjects were determined. Diagnostic referents were derived from the intercept between the distributions of osmolarity in the two samples and from receiver operator characteristic (ROC) curves. This referent was tested for effectiveness of diagnosis in independent groups with normal and dry eyes.  results. An osmolarity referent of 315.6 mOsmol/L was derived from the intercept of the distribution curves, and 316 mOsmol/L from the ROC curve. When applied to independent groups of normal and dry eye subjects a value of 316 mOsmol/L was found to yield sensitivity of 59\%, specificity of 94\%, and an overall predictive accuracy of 89\% for the diagnosis of dry eye syndrome.  conclusions. Tear hyperosmolarity, defined by a referent of 316 mOsmol/L, was superior in overall accuracy to any other single test for dry eye diagnosis (Lactoplate, Schirmer test, and Rose Bengal staining), even when the other test measures were applied to a diagnosis within the sample groups from which they were derived. For overall accuracy in the diagnosis of dry eye, the osmolarity test was found to be comparable with the results of combined (in parallel or series) tests.},
  file = {/Users/driscoll/Zotero/storage/ZWWHLKZM/article.html}
}

@article{townsendContinuousAnaloguesMatrix2015,
  title = {Continuous Analogues of Matrix Factorizations},
  author = {Townsend, Alex and Trefethen, Lloyd N.},
  year = {2015},
  month = jan,
  journal = {Proceedings. Mathematical, Physical, and Engineering Sciences / The Royal Society},
  volume = {471},
  number = {2173},
  pages = {20140585},
  issn = {1364-5021},
  doi = {10.1098/rspa.2014.0585},
  urldate = {2022-08-10},
  abstract = {Analogues of singular value decomposition (SVD), QR, LU and Cholesky factorizations are presented for problems in which the usual discrete matrix is replaced by a `quasimatrix', continuous in one dimension, or a `cmatrix', continuous in both dimensions. Two challenges arise: the generalization of the notions of triangular structure and row and column pivoting to continuous variables (required in all cases except the SVD, and far from obvious), and the convergence of the infinite series that define the cmatrix factorizations. Our generalizations of triangularity and pivoting are based on a new notion of a `triangular quasimatrix'. Concerning convergence of the series, we prove theorems asserting convergence provided the functions involved are sufficiently smooth.},
  pmcid = {PMC4277194},
  pmid = {25568618},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Townsend_Trefethen-2015-Continuous analogues of matrix factorizations.pdf}
}

@article{Tran_Ethnic_2013,
  title = {Ethnic Differences in Dry Eye Symptoms: {{Effects}} of Corneal Staining and Length of Contact Lens Wear},
  author = {Tran, Nina and Graham, Andrew D and Lin, Meng C},
  year = {2013},
  volume = {36},
  number = {6},
  pages = {281--288},
  issn = {1367-0484},
  doi = {10.1016/j.clae.2013.06.001},
  abstract = {PurposeTo explore the relationships among length of contact lens (CL) wear, degree of corneal staining and severity of dryness symptoms, and to determine whether these relationships differ between Asians and non-Asians.MethodsAdapted soft CL wearers (n=395; 180 Asian, 215 non-Asian) were required to discontinue CL wear for at least 24h and report to the University of California, Berkeley Clinical Research Center (UCB-CRC). Fluorescein corneal staining was graded according to Brien Holden Vision Institute scales. Length of CL wear was reported by subjects and subjective dryness ratings were collected using the UCB-CRC Dry Eye Flow Chart (DEFC).ResultsMore Asian CL wearers exhibited corneal staining compared to non-Asians, and Asian CL wearers had a higher mean grade of corneal staining (p\{{$<$}\}0.001), as well as a higher mean DEFC classification (p\{{$<$}\}0.001). The difference between Asians and non-Asians in grades of corneal staining extent and depth were significant (p\{{$<$}\}0.001). Among non-Asian CL wearers, dryness symptoms decreased with more years of CL wear and increased in the presence of corneal staining, which was not the case for Asian CL wearers.ConclusionsAsian soft CL wearers reported more severe dryness symptoms and demonstrated more severe corneal staining overall compared to non-Asians. Among non-Asians, dryness symptoms were less severe on average with increased years of CL wear and more severe in the presence of corneal staining. Dryness severity does not appear to be related to years of CL wear or corneal staining among Asians.},
  pmid = {23850062}
}

@book{trangensteinNumericalSolutionHyperbolic2009,
  title = {Numerical Solution of Hyperbolic Partial Differential Equations},
  author = {Trangenstein, J. A.},
  year = {2009},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge ; New York}},
  isbn = {978-0-521-87727-5},
  lccn = {QA377 .T62 2009},
  keywords = {Differential equations Hyperbolic,Numerical solutions,Textbooks},
  annotation = {OCLC: ocn145388396}
}

@inproceedings{tranLearningSpatiotemporalFeatures,
  title = {Learning {{Spatiotemporal Features}} with {{3D Convolutional Networks}}},
  author = {Tran, Du},
  doi = {10.1109/iccv.2015.510},
  file = {/Users/driscoll/Dropbox/library/Conference Paper/Tran_Learning Spatiotemporal Features with 3D Convolutional Networks.pdf}
}

@book{trefethenApproximationTheoryApproximation2013,
  title = {Approximation {{Theory}} and {{Approximation Practice}}},
  author = {Trefethen, Lloyd N.},
  year = {2013},
  month = jan,
  publisher = {{SIAM}},
  abstract = {This book presents a twenty-first century approach to classical polynomial and rational approximation theory. The reader will find a strikingly original treatment of the subject, completely unlike any of the existing literature on approximation theory, with a rich set of both computational and theoretical exercises for the classroom. There are many original features that set this book apart: the emphasis is on topics close to numerical algorithms; every idea is illustrated with Chebfun examples; each chapter has an accompanying Matlab file for the reader to download; the text focuses on theorems and methods for analytic functions; original sources are cited rather than textbooks, and each item in the bibliography is accompanied by an editorial comment. This textbook is ideal for advanced undergraduates and graduate students across all of applied mathematics.},
  googlebooks = {En41UGQ6YXsC},
  isbn = {978-1-61197-239-9},
  langid = {english},
  keywords = {Computers / Programming / Algorithms,Mathematics / Calculus,Mathematics / General,Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis}
}

@misc{TrefethenChebfunVersion2009,
  title = {Chebfun Version 2},
  author = {Trefethen, {\relax LN} and Hale, N and Platte, {\relax RB} and Driscoll, {\relax TA} and Pach{\'o}n, R},
  year = {2009},
  copyright = {All rights reserved}
}

@article{trefethenConformalMappingSolution1986,
  title = {Conformal Mapping Solution of {{Laplace}}'s Equation on a Polygon with Oblique Derivative Boundary Conditions},
  author = {Trefethen, Lloyd N. and Williams, Ruth J.},
  year = {1986},
  month = feb,
  journal = {Journal of Computational and Applied Mathematics},
  volume = {14},
  number = {1-2},
  pages = {227--249},
  issn = {03770427},
  doi = {10.1016/0377-0427(86)90141-x},
  urldate = {2019-11-18},
  langid = {english}
}

@book{TrefethenExploringODEs2017,
  title = {Exploring {{ODEs}}},
  author = {Trefethen, Lloyd N and Birkisson, {\'A}sgeir and Driscoll, Tobin A},
  year = {2017},
  publisher = {{SIAM}},
  copyright = {All rights reserved},
  isbn = {978-1-61197-515-4},
  file = {/Users/driscoll/Dropbox/library/Book/Trefethen et al-2017-Exploring ODEs.pdf}
}

@article{TrefethenExponentialNode2021,
  title = {Exponential Node Clustering at Singularities for Rational Approximation, Quadrature, and {{PDEs}}},
  author = {Trefethen, Lloyd N. and Nakatsukasa, Yuji and Weideman, J. A. C.},
  year = {2021},
  month = jan,
  journal = {Numerische Mathematik},
  volume = {147},
  number = {1},
  pages = {227--254},
  issn = {0945-3245},
  doi = {10.1007/s00211-020-01168-2},
  urldate = {2023-04-12},
  abstract = {Rational approximations of functions with singularities can converge at a root-exponential rate if the poles are exponentially clustered. We begin by reviewing this effect in minimax, least-squares, and AAA approximations on intervals and complex domains, conformal mapping, and the numerical solution of Laplace, Helmholtz, and biharmonic equations by the ``lightning'' method. Extensive and wide-ranging numerical experiments are involved. We then present further experiments giving evidence that in all of these applications, it is advantageous to use exponential clustering whose density on a logarithmic scale is not uniform but tapers off linearly to zero near the singularity. We propose a theoretical model of the tapering effect based on the Hermite contour integral and potential theory, which suggests that tapering doubles the rate of convergence. Finally we show that related mathematics applies to the relationship between exponential (not tapered) and doubly exponential (tapered) quadrature formulas. Here it is the Gauss--Takahasi--Mori contour integral that comes into play.},
  langid = {english},
  keywords = {41A20,65D32,65N35},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Trefethen et al_2021_Exponential node clustering at singularities for rational approximation,.pdf}
}

@article{trefethenGaussQuadratureBetter2008,
  title = {Is {{Gauss Quadrature Better}} than {{Clenshaw}}--{{Curtis}}?},
  author = {Trefethen, Lloyd N.},
  year = {2008},
  month = jan,
  journal = {SIAM Review},
  volume = {50},
  number = {1},
  pages = {67--87},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {0036-1445},
  doi = {10.1137/060659831},
  urldate = {2020-06-18},
  abstract = {We compare the convergence behavior of Gauss quadrature with that of its younger brother, Clenshaw--Curtis. Seven-line MATLAB codes are presented that implement both methods, and experiments show that the supposed factor-of-2 advantage of Gauss quadrature is rarely realized. Theorems are given to explain this effect. First, following O'Hara and Smith in the 1960s, the phenomenon is explained as a consequence of aliasing of coefficients in Chebyshev expansions. Then another explanation is offered based on the interpretation of a quadrature formula as a rational approximation of \${\textbackslash}log((z+1)/(z-1))\$ in the complex plane. Gauss quadrature corresponds to Pad{\'e} approximation at \$z={\textbackslash}infty\$. Clenshaw--Curtis quadrature corresponds to an approximation whose order of accuracy at \$z={\textbackslash}infty\$ is only half as high, but which is nevertheless equally accurate near \$[-1,1]\$.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Trefethen-2008-Is Gauss Quadrature Better than Clenshaw–Curtis.pdf;/Users/driscoll/Zotero/storage/DNJGBNUG/060659831.html}
}

@article{TrefethenHydrodynamicStability1993,
  title = {Hydrodynamic Stability without Eigenvalues},
  author = {Trefethen, Lloyd N and Trefethen, Anne E and Reddy, Satish C and Driscoll, Tobin A},
  year = {1993},
  journal = {Science},
  volume = {261},
  number = {5121},
  pages = {578--584},
  doi = {10.1126/science.261.5121.578},
  copyright = {All rights reserved},
  keywords = {file-import-09-09-29}
}

@article{TrefethenNearcircularityError1981,
  title = {Near-Circularity of the Error Curve in Complex {{Chebyshev}} Approximation},
  author = {Trefethen, Lloyd N},
  year = {1981},
  month = apr,
  journal = {Journal of Approximation Theory},
  volume = {31},
  number = {4},
  pages = {344--367},
  issn = {0021-9045},
  doi = {10.1016/0021-9045(81)90102-7},
  urldate = {2023-04-12},
  abstract = {Let f(z) be analytic on the unit disk, and let p{$\ast$}(z) be the best (Chebyshev) polynomial approximation to f(z) on the disk of degree at most n. It is observed that in typical problems the ``error curve,'' the image of the unit circle under (f - p{$\ast$})(z), often approximates to a startling degree a perfect circle with winding number n + 1. This phenomenon is approached by consideration of related problems whose error curves are exactly circular, making use of a classical theorem of Carath{\'e}odory and Fej{\'e}r. This leads to a technique for calculating approximations in one step that are roughly as close to best as the best approximation error curve is close to circular, and hence to strong theorems on near-circularity as the radius of the domain shrinks to 0 or as n increases to {$\infty$}. As a computational example, very tight bounds are given for approximation of ez on the unit disk. The generality of the near-circularity phenomenon (more general domains, rational approximation) is discussed.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Trefethen_1981_Near-circularity of the error curve in complex Chebyshev approximation.pdf;/Users/driscoll/Zotero/storage/X7RVFFAP/0021904581901027.html}
}

@techreport{TrefethenNewDirection1992,
  title = {A New Direction in Hydrodynamic Stability: Beyond Eigenvalues},
  author = {Trefethen, Lloyd N and Trefethen, Anne E and Reddy, Satish C and Driscoll, Tobin A},
  year = {1992},
  number = {NASA-CR-191411, NAS 1.26:191411, ICASE-92-71, AD-A261846},
  address = {{Washington, DC}},
  institution = {{NASA}},
  copyright = {All rights reserved}
}

@article{TREFETHENNewDirection1992a,
  title = {A New Direction in Hydrodynamic Stability: {{Beyond}} Eigenvalues({{Final Report}})},
  author = {TREFETHEN, {\relax LLOYDN} and TREFETHEN, {\relax ANNEE} and REDDY, {\relax SATISHC} and DRISCOLL, {\relax TOBINA}},
  year = {1992},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{TrefethenNumericalConformal2020,
  title = {Numerical {{Conformal Mapping}} with {{Rational Functions}}},
  author = {Trefethen, Lloyd N.},
  year = {2020},
  month = nov,
  journal = {Computational Methods and Function Theory},
  volume = {20},
  number = {3},
  pages = {369--387},
  issn = {2195-3724},
  doi = {10.1007/s40315-020-00325-w},
  urldate = {2023-06-14},
  abstract = {New algorithms are presented for numerical conformal mapping based on rational approximations and the solution of Dirichlet problems by least-squares fitting on the boundary. The methods are targeted at regions with corners, where the Dirichlet problem is solved by the ``lightning Laplace solver'' with poles exponentially clustered near each singularity. For polygons and circular polygons, further simplifications are possible.},
  langid = {english},
  keywords = {30C30,41A20,65E05,AAA approximation,circular polygon,Conformal mapping,Lightning Laplace solver,Rational approximation,Schwarz-Christoffel formula},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Trefethen_2020_Numerical Conformal Mapping with Rational Functions2.pdf}
}

@book{trefethenNumericalLinearAlgebra1997,
  title = {Numerical {{Linear Algebra}}},
  author = {Trefethen, Lloyd N. and III, David Bau},
  year = {1997},
  month = jun,
  publisher = {{SIAM}},
  abstract = {This is a concise, insightful introduction to the field of numerical linear algebra. The clarity and eloquence of the presentation make it popular with teachers and students alike. The text aims to expand the reader\&\#39;s view of the field and to present standard material in a novel way. All of the most important topics in the field are covered with a fresh perspective, including iterative methods for systems of equations and eigenvalue problems and the underlying principles of conditioning and stability. Presentation is in the form of 40 lectures, which each focus on one or two central ideas. The unity between topics is emphasized throughout, with no risk of getting lost in details and technicalities. The book breaks with tradition by beginning with the QR factorization - an important and fresh idea for students, and the thread that connects most of the algorithms of numerical linear algebra.},
  googlebooks = {4Mou5YpRD\_kC},
  isbn = {978-0-89871-361-9},
  langid = {english},
  keywords = {Mathematics / Algebra / General,Mathematics / Algebra / Linear,Mathematics / Applied,Mathematics / Mathematical Analysis,Technology & Engineering / Engineering (General)}
}

@inproceedings{TrefethenSchwarzChristoffelMapping1998,
  title = {Schwarz-{{Christoffel}} Mapping in the Computer Era},
  booktitle = {Proceedings of the {{International Congress}} of {{Mathematicians}}},
  author = {Trefethen, Lloyd N and Driscoll, Tobin A},
  year = {1998},
  volume = {3},
  pages = {533--542},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{TrefethenSERIESSOLUTION2018,
  title = {{{SERIES SOLUTION OF LAPLACE PROBLEMS}}},
  author = {Trefethen, Lloyd N.},
  year = {2018},
  month = jul,
  journal = {The ANZIAM Journal},
  volume = {60},
  number = {1},
  pages = {1--26},
  publisher = {{Cambridge University Press}},
  issn = {1446-1811, 1446-8735},
  doi = {10.1017/S1446181118000093},
  urldate = {2023-07-13},
  abstract = {At the ANZIAM conference in Hobart in February 2018, there were several talks on the solution of Laplace problems in multiply connected domains by means of conformal mapping. It appears to be not widely known that such problems can also be solved by the elementary method of series expansions with coefficients determined by least-squares fitting on the boundary. (These are not convergent series; the coefficients depend on the degree of the approximation.) Here we give a tutorial introduction to this method, which converges at an exponential rate if the boundary data are sufficiently well-behaved. The mathematical foundations go back to Runge in 1885 and Walsh in 1929. One of our examples involves an approximate Cantor set with up to 2048 components.},
  langid = {english},
  keywords = {Cantor set,conformal mapping,Green function,harmonic measure,Laplace problem,least-squares,primary 31A99,secondary 35J08,series expansion},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Trefethen_2018_SERIES SOLUTION OF LAPLACE PROBLEMS.pdf}
}

@article{trefethenSixMythsPolynomial2011,
  title = {Six Myths of Polynomial Interpolation and Quadrature},
  author = {Trefethen, Lloyd N.},
  year = {2011},
  journal = {Mathematics Today},
  volume = {2011},
  number = {August},
  keywords = {No DOI found}
}

@book{trefethenSpectralMethodsMATLAB2000,
  title = {Spectral {{Methods}} in {{MATLAB}}},
  author = {Trefethen, Lloyd N.},
  year = {2000},
  month = jan,
  publisher = {{SIAM}},
  abstract = {This is the only book on spectral methods built around MATLAB programs. Along with finite differences and finite elements, spectral methods are one of the three main technologies for solving partial differential equations on computers. Since spectral methods involve significant linear algebra and graphics they are very suitable for the high level programming of MATLAB. This hands-on introduction is built around forty short and powerful MATLAB programs, which the reader can download from the World Wide Web.},
  googlebooks = {9Zu4YqPQKocC},
  isbn = {978-0-89871-959-8},
  langid = {english},
  keywords = {Computers / Computer Science,Computers / Mathematical & Statistical Software,Mathematics / Applied,Mathematics / Differential Equations / General,Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis}
}

@book{trefethenSpectraPseudospectraBehavior2005,
  title = {Spectra and {{Pseudospectra}}: {{The Behavior}} of {{Nonnormal Matrices}} and {{Operators}}},
  shorttitle = {Spectra and {{Pseudospectra}}},
  author = {Trefethen, Lloyd N. and Embree, Mark},
  year = {2005},
  month = aug,
  publisher = {{Princeton University Press}},
  abstract = {Pure and applied mathematicians, physicists, scientists, and engineers use matrices and operators and their eigenvalues in quantum mechanics, fluid mechanics, structural analysis, acoustics, ecology, numerical analysis, and many other areas. However, in some applications the usual analysis based on eigenvalues fails. For example, eigenvalues are often ineffective for analyzing dynamical systems such as fluid flow, Markov chains, ecological models, and matrix iterations. That's where this book comes in. This is the authoritative work on nonnormal matrices and operators, written by the authorities who made them famous. Each of the sixty sections is written as a self-contained essay. Each document is a lavishly illustrated introductory survey of its topic, complete with beautiful numerical experiments and all the right references. The breadth of included topics and the numerous applications that provide links between fields will make this an essential reference in mathematics and related sciences.},
  isbn = {978-0-691-11946-5},
  langid = {english},
  keywords = {Mathematics / Algebra / General,Mathematics / Applied,Mathematics / Matrices,Mathematics / Numerical Analysis}
}

@article{Ursino1999,
  title = {A Mathematical Model of the Carotid Baroregulation in Pulsating Conditions},
  author = {Ursino, M.},
  year = {1999},
  month = apr,
  journal = {IEEE Transactions on Biomedical Engineering},
  volume = {46},
  number = {4},
  pages = {382--392},
  publisher = {{Institute of Electrical and Electronics Engineers (IEEE)}},
  doi = {10.1109/10.752935},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Ursino_1999_A mathematical model of the carotid baroregulation in pulsating conditions.pdf}
}

@article{UsherTransformativeModel2010,
  ids = {usherTransformativeModelUndergraduate2010a},
  title = {A Transformative Model for Undergraduate Quantitative Biology Education.},
  author = {Usher, David C and Driscoll, Tobin A and Dhurjati, Prasad and Pelesko, John A and Rossi, Louis F and Schleiniger, Gilberto and Pusecker, Kathleen and White, Harold B},
  year = {2010},
  month = jan,
  journal = {CBE life sciences education},
  volume = {9},
  number = {3},
  pages = {181--8},
  issn = {1931-7913},
  doi = {10.1187/cbe.10-03-0029},
  abstract = {The BIO2010 report recommended that students in the life sciences receive a more rigorous education in mathematics and physical sciences. The University of Delaware approached this problem by (1) developing a bio-calculus section of a standard calculus course, (2) embedding quantitative activities into existing biology courses, and (3) creating a new interdisciplinary major, quantitative biology, designed for students interested in solving complex biological problems using advanced mathematical approaches. To develop the bio-calculus sections, the Department of Mathematical Sciences revised its three-semester calculus sequence to include differential equations in the first semester and, rather than using examples traditionally drawn from application domains that are most relevant to engineers, drew models and examples heavily from the life sciences. The curriculum of the B.S. degree in Quantitative Biology was designed to provide students with a solid foundation in biology, chemistry, and mathematics, with an emphasis on preparation for research careers in life sciences. Students in the program take core courses from biology, chemistry, and physics, though mathematics, as the cornerstone of all quantitative sciences, is given particular prominence. Seminars and a capstone course stress how the interplay of mathematics and biology can be used to explain complex biological systems. To initiate these academic changes required the identification of barriers and the implementation of solutions.},
  copyright = {All rights reserved},
  langid = {english},
  keywords = {Biology,Biology: education,Curriculum,Educational,Mathematics,Mathematics: education,Models,Students,Universities}
}

@article{ValderramaIntegratingMachine2023,
  title = {Integrating Machine Learning with Pharmacokinetic Models: {{Benefits}} of Scientific Machine Learning in Adding Neural Networks Components to Existing {{PK}} Models},
  shorttitle = {Integrating Machine Learning with Pharmacokinetic Models},
  author = {Valderrama, Diego and Ponce-Bobadilla, Ana Victoria and Mensing, Sven and Fr{\"o}hlich, Holger and Stodtmann, Sven},
  year = {2023},
  month = oct,
  journal = {CPT: Pharmacometrics \& Systems Pharmacology},
  pages = {psp4.13054},
  issn = {2163-8306, 2163-8306},
  doi = {10.1002/psp4.13054},
  urldate = {2023-11-02},
  abstract = {Abstract             Recently, the use of machine-learning (ML) models for pharmacokinetic (PK) modeling has grown significantly. Although most of the current approaches use ML techniques as black boxes, there are only a few that have proposed interpretable architectures which integrate mechanistic knowledge. In this work, we use as the test case a one-compartment PK model using a scientific machine learning (SciML) framework and consider learning an unknown absorption using neural networks, while simultaneously estimating other parameters of drug distribution and elimination. We generate simulated data with different sampling strategies to show that our model can accurately predict concentrations in extrapolation tasks, including new dosing regimens with different sparsity levels, and produce reliable forecasts even for new patients. By using a scenario of fitting PK data with complex absorption, we demonstrate that including known physiological structure into an SciML model allows us to obtain highly accurate predictions while preserving the interpretability of classical compartmental models.},
  langid = {english}
}

@book{vandervorstIterativeKrylovMethods2003,
  title = {Iterative {{Krylov Methods}} for {{Large Linear Systems}}},
  author = {{van der Vorst}, H. A.},
  year = {2003},
  month = apr,
  publisher = {{Cambridge University Press}},
  abstract = {Computational simulation of scientific phenomena and engineering problems often depend on solving linear systems with a large number of unknowns. This book gives an insight into the construction of iterative methods for the solution of such systems and helps the reader to select the best solver for given classes of problems. The emphasis is on the main ideas and how they have led to efficient solvers such as CG, GMRES, and Bi-CGSTAB. The book also explains the main concepts behind the construction of preconditioners. The reader is encouraged to build their own experience by analysing numerous examples that illustrate how best to exploit the methods. The book also hints at many open problems and as such it will appeal to established researchers. There are many exercises that motivate the material and help students to understand the essential steps in the analysis and construction of algorithms.},
  googlebooks = {wE0NrHkrqRAC},
  isbn = {978-0-521-81828-5},
  langid = {english},
  keywords = {Mathematics / Mathematical Analysis,Mathematics / Numerical Analysis,Mathematics / Probability & Statistics / General,Technology & Engineering / Industrial Technology}
}

@book{vanloanIntroductionScientificComputing2000,
  title = {Introduction to Scientific Computing: A Matrix-Vector Approach Using {{MATLAB}}},
  shorttitle = {Introduction to Scientific Computing},
  author = {Van Loan, Charles F.},
  year = {2000},
  series = {The {{MATLAB}} Curriculum Series},
  publisher = {{Prentice Hall}},
  address = {{Upper Saddle River, NJ}},
  isbn = {978-0-13-949157-3},
  lccn = {QA76.95 .V35 1999},
  keywords = {Data processing,Mathematics,MATLAB}
}

@article{varoquauxMachineLearningMedical2022,
  title = {Machine Learning for Medical Imaging: Methodological Failures and Recommendations for the Future},
  shorttitle = {Machine Learning for Medical Imaging},
  author = {Varoquaux, Ga{\"e}l and Cheplygina, Veronika},
  year = {2022},
  month = apr,
  journal = {npj Digital Medicine},
  volume = {5},
  number = {1},
  pages = {1--8},
  publisher = {{Nature Publishing Group}},
  issn = {2398-6352},
  doi = {10.1038/s41746-022-00592-y},
  urldate = {2022-09-07},
  abstract = {Research in computer analysis of medical images bears many promises to improve patients' health. However, a number of systematic challenges are slowing down the progress of the field, from limitations of the data, such as biases, to research incentives, such as optimizing for publication. In this paper we review roadblocks to developing and assessing methods. Building our analysis on evidence from the literature and data challenges, we show that at every step, potential biases can creep in. On a positive note, we also discuss on-going efforts to counteract these problems. Finally we provide recommendations on how to further address these problems in the future.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Computer science,Medical research,Research data},
  file = {/Users/driscoll/Zotero/storage/WGPD5KLC/Varoquaux and Cheplygina - 2022 - Machine learning for medical imaging methodologic.pdf;/Users/driscoll/Zotero/storage/26UFXZUA/s41746-022-00592-y.html}
}

@article{vaswaniAttentionAllYou2017,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2017},
  month = dec,
  journal = {arXiv:1706.03762 [cs]},
  eprint = {1706.03762},
  primaryclass = {cs},
  urldate = {2020-10-24},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Vaswani et al_2017_Attention Is All You Need.pdf;/Users/driscoll/Zotero/storage/T8GFS6P2/1706.html}
}

@techreport{vavasisNumericalConformalMapping1996,
  title = {Numerical {{Conformal Mapping Using Cross-ratios}} and {{Delaunay Triangulation}}},
  author = {Vavasis, Stephen A},
  year = {1996},
  institution = {{Cornell Theory Center, Cornell University}}
}

@article{versnelGeometricalCorrectionFactor1982,
  title = {The Geometrical Correction Factor for a Rectangular {{Hall}} Plate},
  author = {Versnel, W.},
  year = {1982},
  month = jul,
  journal = {Journal of Applied Physics},
  volume = {53},
  number = {7},
  pages = {4980--4986},
  issn = {0021-8979, 1089-7550},
  doi = {10.1063/1.331373},
  urldate = {2019-11-18},
  langid = {english}
}

@article{VersuraPerformanceTear2010,
  title = {Performance of {{Tear Osmolarity Compared}} to {{Previous Diagnostic Tests}} for {{Dry Eye Diseases}}},
  author = {Versura, P. and Profazio, V. and Campos, E. C.},
  year = {2010},
  month = jul,
  journal = {Current Eye Research},
  volume = {35},
  number = {7},
  pages = {553--564},
  publisher = {{Taylor \& Francis}},
  issn = {0271-3683},
  doi = {10.3109/02713683.2010.484557},
  urldate = {2023-02-13},
  abstract = {Purpose: Tear osmolarity is considered a key point in dry eye disease (DED) and its measurement is the gold standard in dry eye diagnosis. Tear osmolarity was evaluated in dry eye (DE) patients vs. a control group to assess its diagnostic performance compared to clinical and laboratory tests performed in either clinical or research settings.Methods: Tear osmolarity was measured with the TearLab Osmolarity System (OcuSense) in 25 normal subjects and 105 DE patients (severity score 1--4, Dry Eye Workshop (DEWS)). The following tests were also performed: Ocular Surface Disease Index (OSDI) symptoms questionnaire, Schirmer I test, Tear Film Break Up Time (TFBUT), ferning test, lissamine green staining, tear clearance, corneal esthesiometry, and conjunctival cytology by scraping and imprint. Statistical evaluation was performed by unpaired Student's t and Mann-Whitney tests, the Spearman's {$\rho$} and the Pearson's r correlation coefficients (significance p {$<$} 0.05); all variables were also analyzed for sensitivity, specificity, Receiver Operating Characteristics (ROC) curves, likelihood ratio LR+, and positive predictive value (PPV).Results: Tear osmolarity normal values were 296.5 {\textpm} 9.8 mOsm/L, increasing values were shown stepwise DE severity (mild to moderate to severe dry eye, respectively: 298.1 {\textpm} 10.6 vs. 306.7 {\textpm} 9.5 vs. 314.4 {\textpm} 10.1, p {$<$} 0.05). A progressive worsening occurred in all the parameters with DED severity increase. Tear osmolarity exhibited the larger correlation strength vs. tear clearance, TFBUT and clinical score, strength increased with DED severity, mainly to inflammatory score and corneal sensitivity. Tear osmolarity 305 mOsm/L was selected as cut-off value for dry eye, 309 mOsm/L for moderate dry eye, 318 mOsm/L for severe dry eye (Area-Under-the-Curve was 0.737, 0.759, and 0.711, respectively).Conclusions: Tear osmolarity can now be considered a test suitable to be performed in a clinical setting. It showed a good performance in dry eye diagnosis, higher than the other tests considered, mainly in severe dry eye. Tear osmolarity values should be interpreted as an indicator of DED evolutionary process to severity.},
  pmid = {20597641},
  keywords = {Corneal sensitivity,Diagnosis,Dry eye,Inflammation,Osmolarity},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Versura et al_2010_Performance of Tear Osmolarity Compared to Previous Diagnostic Tests for Dry.pdf}
}

@article{Vrankar2013,
  title = {Solving Moving-Boundary Problems with the Wavelet Adaptive Radial Basis Functions Method},
  author = {Vrankar, Leopold and Libre, Nicolas Ali and Ling, Leevan and Turk, Goran and Runovc, Franc},
  year = {2013},
  month = nov,
  journal = {Computers {{\&}} Fluids},
  volume = {86},
  pages = {37--44},
  publisher = {{Elsevier BV}},
  doi = {10.1016/j.compfluid.2013.06.029}
}

@article{vyasComprehensiveSurvey2020,
  title = {A {{Comprehensive Survey}} on {{Image Modality}} Based {{Computerized Dry Eye Disease Detection Techniques}}},
  author = {Vyas, Aditi Haresh and Mehta, Mayuri A.},
  year = {2020},
  journal = {Advances in Science, Technology and Engineering Systems Journal},
  volume = {5},
  number = {2},
  pages = {748--756},
  issn = {24156698, 24156698},
  doi = {10.25046/aj050293},
  urldate = {2021-01-04},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Vyas_Mehta-2020-A Comprehensive Survey on Image Modality based Computerized.pdf}
}

@article{wangDeepLearning2019,
  title = {A {{Deep Learning Approach}} for {{Meibomian Gland Atrophy Evaluation}} in {{Meibography Images}}},
  author = {Wang, Jiayun and Yeh, Thao N. and Chakraborty, Rudrasis and Yu, Stella X. and Lin, Meng C.},
  year = {2019},
  month = nov,
  journal = {Translational Vision Science \& Technology},
  volume = {8},
  number = {6},
  pages = {37--37},
  publisher = {{The Association for Research in Vision and Ophthalmology}},
  issn = {2164-2591},
  doi = {10.1167/tvst.8.6.37},
  urldate = {2020-07-07},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Wang et al-2019-A Deep Learning Approach for Meibomian Gland Atrophy.pdf;/Users/driscoll/Zotero/storage/XU4GM2ZK/article.html}
}

@article{wangEquivalentMechanismReleasing2019,
  title = {Equivalent Mechanism: {{Releasing}} Location Data with Errors through Differential Privacy},
  shorttitle = {Equivalent Mechanism},
  author = {Wang, Tao and Zheng, Zhigao and Elhoseny, Mohamed},
  year = {2019},
  month = sep,
  journal = {Future Generation Computer Systems},
  volume = {98},
  pages = {600--608},
  issn = {0167739X},
  doi = {10.1016/j.future.2018.11.047},
  urldate = {2021-06-14},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Wang et al_2019_Equivalent mechanism.pdf;/Users/driscoll/Zotero/storage/VUKNU5TV/Wang et al. - 2019 - Equivalent mechanism Releasing location data with.pdf}
}

@article{WangEtal03,
  title = {Precorneal and Pre- and Postlens Tear Film Thickness Measured Indirectly with Optical Coherence Tomography},
  author = {Wang, J. and Fonn, D. and Simpson, T. L. and Jones, L.},
  year = {2003},
  journal = {Investigative Ophthalmology and Visual Science},
  volume = {44},
  pages = {2524--2528},
  doi = {10.1167/iovs.02-0731},
  date-modified = {2013-10-31 05:42:21 +0000}
}

@misc{WegertPhasePlots2010,
  title = {Phase {{Plots}} of {{Complex Functions}}: A {{Journey}} in {{Illustration}}},
  shorttitle = {Phase {{Plots}} of {{Complex Functions}}},
  author = {Wegert, Elias},
  year = {2010},
  month = jul,
  number = {arXiv:1007.2295},
  eprint = {1007.2295},
  primaryclass = {math},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.1007.2295},
  urldate = {2023-06-08},
  abstract = {We propose to visualize complex (meromorphic) functions \$f\$ by their phase \$P\_f:=f/{\textbar}f{\textbar}\$. Color--coding the points on the unit circle converts the function \$P\_f\$ to an image (the phase plot of \$f\$), which represents the function directly on its domain. We discuss how special properties of \$f\$ are reflected by their phase plots and indicate several applications. In particular we reformulate a universality theorem for Riemann's Zeta function in the language of phase plots.},
  archiveprefix = {arxiv},
  keywords = {30A99 30D30,Mathematics - Complex Variables},
  file = {/Users/driscoll/Dropbox/library/Preprint/Wegert_2010_Phase Plots of Complex Functions.pdf;/Users/driscoll/Zotero/storage/AL3IT898/1007.html}
}

@article{WegertPhasePlots2010a,
  title = {Phase Plots of Complex Functions: A Journey in Illustration},
  author = {Wegert, Elias and Semmler, Gunter},
  year = {2010},
  journal = {Notices of the American Mathematical Society},
  volume = {58},
  pages = {768--780},
  keywords = {No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Wegert_Semmler_2010_Phase plots of complex functions.pdf}
}

@article{whitcherSimplifiedQuantitative2010,
  title = {A Simplified Quantitative Method for Assessing Keratoconjunctivitis Sicca from the {{Sj{\"o}gren}}'s {{Syndrome International Registry}}},
  author = {Whitcher, John P. and Shiboski, Caroline H. and Shiboski, Stephen C. and Heidenreich, Ana Maria and Kitagawa, Kazuko and Zhang, Shunhua and Hamann, Steffen and Larkin, Genevieve and McNamara, Nancy A. and Greenspan, John S. and Daniels, Troy E. and {Sj{\"o}gren's International Collaborative Clinical Alliance Research Groups}},
  year = {2010},
  month = mar,
  journal = {American Journal of Ophthalmology},
  volume = {149},
  number = {3},
  pages = {405--415},
  issn = {1879-1891},
  doi = {10.1016/j.ajo.2009.09.013},
  abstract = {PURPOSE: To describe, apply, and test a new ocular grading system for assessing keratoconjunctivitis sicca (KCS) using lissamine green and fluorescein. DESIGN: Prospective, observational, multicenter cohort study. METHODS: The National Institutes of Health-funded Sj{\"o}gren's Syndrome International Registry (called Sj{\"o}gren's International Collaborative Clinical Alliance [SICCA]) is developing standardized classification criteria for Sj{\"o}gren syndrome (SS) and is creating a biospecimen bank for future research. Eight SICCA ophthalmologists developed a new quantitative ocular grading system (SICCA ocular staining score [OSS]), and we analyzed OSS distribution among the SICCA cohort and its association with other phenotypic characteristics of SS. The SICCA cohort includes participants ranging from possibly early SS to advanced disease. Procedures include sequenced unanesthetized Schirmer test, tear break-up time, ocular surface staining, and external eye examination at the slit lamp. Using statistical analyses and proportional Venn diagrams, we examined interrelationships between abnormal OSS ({$>$}or=3) and other characteristics of SS (labial salivary gland [LSG] biopsy with focal lymphocytic sialadenitis and focus score {$>$}1 positive anti-SS A antibodies, anti-SS B antibodies, or both). RESULTS: Among 1208 participants, we found strong associations between abnormal OSS, positive serologic results, and positive LSG focus scores (P {$<$} .0001). Analysis of the overlapping relationships of these 3 measures defined a large group of participants who had KCS without other components of SS, representing a clinical entity distinct from the KCS associated with SS. CONCLUSIONS: This new method for assessing KCS will become the means for diagnosing the ocular component of SS in future classification criteria. We find 2 forms of KCS whose causes may differ.},
  langid = {english},
  pmcid = {PMC3459675},
  pmid = {20035924},
  keywords = {Adult,Aged,Aged 80 and over,Cohort Studies,Coloring Agents,Female,Fluorescein,Fluorescent Dyes,Humans,International Classification of Diseases,Keratoconjunctivitis Sicca,Lissamine Green Dyes,Male,Middle Aged,Prospective Studies,Registries,Sjogren's Syndrome,Young Adult},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Whitcher et al-2010-A simplified quantitative method for assessing.pdf}
}

@book{whithamLinearNonlinearWaves1974,
  title = {Linear and {{Nonlinear Waves}}},
  author = {Whitham, G. B.},
  year = {1974},
  publisher = {{John Wiley \& Sons}},
  abstract = {Now in an accessible paperback edition, this classic work is just as relevant as when it first appeared in 1974, due to the increased use of nonlinear waves. It covers the behavior of waves in two parts, with the first part addressing hyperbolic waves and the second addressing dispersive waves. The mathematical principles are presented along with examples of specific cases in communications and specific physical fields, including flood waves in rivers, waves in glaciers, traffic flow, sonic booms, blast waves, and ocean waves from storms.},
  isbn = {978-1-118-03120-9},
  langid = {english},
  keywords = {Mathematics / General,Science / Waves & Wave Mechanics}
}

@article{WilberDataDrivenAlgorithms2022,
  title = {Data-{{Driven Algorithms}} for {{Signal Processing}} with {{Trigonometric Rational Functions}}},
  author = {Wilber, Heather and Damle, Anil and Townsend, Alex},
  year = {2022},
  month = jun,
  journal = {SIAM Journal on Scientific Computing},
  volume = {44},
  number = {3},
  pages = {C185-C209},
  publisher = {{Society for Industrial and Applied Mathematics}},
  issn = {1064-8275},
  doi = {10.1137/21M1420277},
  urldate = {2023-04-12},
  abstract = {We introduce a new algorithm for approximation by rational functions on a real or complex set of points, implementable in 40 lines of MATLAB and requiring no user input parameters.  Even on a disk or interval the algorithm may outperform existing methods, and on more complicated domains it is especially competitive.  The core ideas are (1) representation of the rational approximant in barycentric form with interpolation at certain support points and (2) greedy selection of the support points to avoid exponential instabilities.  The name AAA stands for ``adaptive Antoulas--Anderson'' in honor of the authors who introduced a scheme based on (1).  We present the core algorithm with a MATLAB code and nine applications and describe variants targeted at problems of different kinds. Comparisons are made with vector fitting, RKFIT, and other existing methods for rational approximation.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Wilber et al_2022_Data-Driven Algorithms for Signal Processing with Trigonometric Rational.pdf}
}

@incollection{wilkinsonPerfidiousPolynomial1984,
  title = {The Perfidious Polynomial},
  booktitle = {Studies in {{Mathematics}}},
  author = {Wilkinson, J. H.},
  year = {1984},
  volume = {24},
  pages = {1--28},
  publisher = {{Mathematical Association of America}}
}

@article{witelskiADISchemesHigherorder2003,
  title = {{{ADI}} Schemes for Higher-Order Nonlinear Diffusion Equations},
  author = {Witelski, T. P. and Bowen, M.},
  year = {2003},
  month = may,
  journal = {Applied Numerical Mathematics},
  volume = {45},
  number = {2},
  pages = {331--351},
  issn = {0168-9274},
  doi = {10.1016/s0168-9274(02)00194-0},
  urldate = {2021-10-22},
  abstract = {Alternating Direction Implicit (ADI) schemes are constructed for the solution of two-dimensional higher-order linear and nonlinear diffusion equations, particularly including the fourth-order thin film equation for surface tension driven fluid flows. First and second-order accurate schemes are derived via approximate factorization of the evolution equations. This approach is combined with iterative methods to solve nonlinear problems. Problems in the fluid dynamics of thin films are solved to demonstrate the effectiveness of the ADI schemes.},
  langid = {english},
  keywords = {ADI methods,Approximate factorization,Higher-order equations,Nonlinear diffusion equations,Parabolic PDE},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Witelski_Bowen_2003_ADI schemes for higher-order nonlinear diffusion equations.pdf}
}

@book{witelskiMethodsMathematicalModelling2015,
  title = {Methods of {{Mathematical Modelling}}},
  author = {Witelski, Thomas and Bowen, Mark},
  year = {2015},
  series = {Springer {{Undergraduate Mathematics Series}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-23042-9},
  urldate = {2021-10-22},
  isbn = {978-3-319-23041-2 978-3-319-23042-9},
  file = {/Users/driscoll/Dropbox/library/Book/Witelski_Bowen_2015_Methods of Mathematical Modelling.pdf}
}

@inproceedings{WojcikPseudospectralMethods1997,
  title = {Pseudospectral Methods for Large-Scale Bioacoustic Models},
  booktitle = {1997 {{IEEE Ultrasonics Symposium Proceedings}}. {{An International Symposium}} ({{Cat}}. {{No}}. {{97CH36118}})},
  author = {Wojcik, G and Fomberg, B and Waag, R and Carcione, L and Mould, J and Nikodym, L and Driscoll, Tobin A},
  year = {1997},
  volume = {2},
  pages = {1501--1506},
  publisher = {{IEEE}},
  doi = {10.1109/ultsym.1997.661861},
  copyright = {All rights reserved}
}

@article{Wolffsohn_Role_2011,
  title = {Role of Contact Lenses in Relieving Ocular Allergy},
  author = {Wolffsohn, James S and Emberlin, Jean C},
  year = {2011},
  volume = {34},
  number = {4},
  pages = {169--172},
  issn = {1367-0484},
  doi = {10.1016/j.clae.2011.03.004},
  abstract = {PurposeTo examine the potential barrier and lubricating effects of modern daily disposable contact lenses (DD) against airborne antigens.MethodsTen patients with skin prick and ocular conjunctival provocation confirmed allergic sensitivity to grass pollen were recruited (average age 27.47.7 years). Each had their ocular symptoms (on a 0 none to 5 extreme scale) and appearance of bulbar and limbal conjunctival redness, palpebral conjunctival redness and roughness, and corneal and conjunctival fluorescein staining (CCLRU scale) graded before and five minutes after exposure to 400 grains grass pollen/m3 for 2min in a purpose-designed exposure chamber to simulate the conditions of a `very high' pollen-count day. This was repeated on three occasions separated by \{{$>$}\}72h wearing etafilcon A (sDD), nelfilcon A with enhanced lubricating agents (ELDD) and no contact lenses in random order out of the pollen season. Each sign and symptom was compared to baseline for each condition. The duration of the symptoms was also recorded (http://www.clinicaltrials.gov NCT01125540).ResultsOnly symptoms of burning and stinging were significantly reduced in severity by ELDD (Chi-Sq=7.6, p=0.02), but overall symptoms were significantly reduced in duration (F=3.60, p=0.05). Bulbar hyperaemia, corneal and conjunctival staining, and palpebral conjunctival roughness were significantly reduced by DD wear (p\{{$<$}\}0.01), with limbal and palpebral conjunctival redness further reduced in ELDD (p\{{$<$}\}0.05).ConclusionDaily disposable contact lenses offer a barrier to airborne antigen which is enhanced by modern lenses with enhanced lubricating agents.},
  pmid = {21530362}
}

@article{wolffsohnClinicalMonitoring2003,
  title = {Clinical Monitoring of Ocular Physiology Using Digital Image Analysis},
  author = {Wolffsohn, James S. and Purslow, Christine},
  year = {2003},
  month = mar,
  journal = {Contact Lens and Anterior Eye},
  volume = {26},
  number = {1},
  pages = {27--35},
  issn = {13670484},
  doi = {10.1016/s1367-0484(02)00062-0},
  urldate = {2020-12-16},
  langid = {english}
}

@article{wolffsohnTFOSDEWS2017,
  title = {{{TFOS DEWS II Diagnostic Methodology}} Report},
  author = {Wolffsohn, James S. and Arita, Reiko and Chalmers, Robin and Djalilian, Ali and Dogru, Murat and Dumbleton, Kathy and Gupta, Preeya K. and Karpecki, Paul and Lazreg, Sihem and Pult, Heiko and Sullivan, Benjamin D. and Tomlinson, Alan and Tong, Louis and Villani, Edoardo and Yoon, Kyung Chul and Jones, Lyndon and Craig, Jennifer P.},
  year = {2017},
  month = jul,
  journal = {The Ocular Surface},
  series = {{{TFOS International Dry Eye WorkShop}} ({{DEWS II}})},
  volume = {15},
  number = {3},
  pages = {539--574},
  issn = {1542-0124},
  doi = {10.1016/j.jtos.2017.05.001},
  urldate = {2020-11-24},
  abstract = {The role of the Tear Film and Ocular Surface Society (TFOS) Dry Eye Workshop (DEWS) II Diagnostic Methodology Subcommittee was 1) to identify tests used to diagnose and monitor dry eye disease (DED), 2) to identify those most appropriate to fulfil the definition of DED and its sub-classifications, 3) to propose the most appropriate order and technique to conduct these tests in a clinical setting, and 4) to provide a differential diagnosis for DED and distinguish conditions where DED is a comorbidity. Prior to diagnosis, it is important to exclude conditions that can mimic DED with the aid of triaging questions. Symptom screening with the DEQ-5 or OSDI confirms that a patient might have DED and triggers the conduct of diagnostic tests of (ideally non-invasive) breakup time, osmolarity and ocular surface staining with fluorescein and lissamine green (observing the cornea, conjunctiva and eyelid margin). Meibomian gland dysfunction, lipid thickness/dynamics and tear volume assessment and their severity allow sub-classification of DED (as predominantly evaporative or aqueous deficient) which informs the management of DED. Videos of these diagnostic and sub-classification techniques are available on the TFOS website. It is envisaged that the identification of the key tests to diagnose and monitor DED and its sub-classifications will inform future epidemiological studies and management clinical trials, improving comparability, and enabling identification of the sub-classification of DED in which different management strategies are most efficacious.},
  langid = {english},
  keywords = {DEWS,Diagnosis,Dry eye disease (DED),Dry Eye Workshop,Methodology,Monitoring,Questionnaires,Sub-classification of dry eye,Tests for dry eye},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Wolffsohn et al-2017-TFOS DEWS II Diagnostic Methodology report.pdf;/Users/driscoll/Zotero/storage/Z23RZWFG/S1542012417301106.html}
}

@article{wongMotorPlanning2015,
  title = {Motor {{Planning}}},
  author = {Wong, Aaron L. and Haith, Adrian M. and Krakauer, John W.},
  year = {2015},
  month = aug,
  journal = {The Neuroscientist},
  volume = {21},
  number = {4},
  pages = {385--398},
  issn = {1073-8584, 1089-4098},
  doi = {10.1177/1073858414541484},
  urldate = {2019-10-14},
  langid = {english},
  file = {/Users/driscoll/Zotero/storage/3NE3L4YA/Wong-Motor-Planning.pdf}
}

@article{Wu_Increasing_2014,
  title = {The Effects of Increasing Ocular Surface Stimulation on Blinking and Sensation},
  author = {Wu, Ziwei and Begley, Carolyn G and Situ, Ping and Simpson, Trefford},
  year = {2014},
  volume = {55},
  number = {3},
  pages = {1555},
  issn = {1552-5783},
  doi = {10.1167/iovs.13-13780}
}

@article{WuDunn_Mechanobiology_2009,
  title = {Mechanobiology of Trabecular Meshwork Cells},
  author = {Darrell, WuDunn},
  year = {2009},
  volume = {88},
  number = {4},
  pages = {718--723},
  issn = {0014-4835},
  doi = {10.1016/j.exer.2008.11.008},
  abstract = {Trabecular meshwork (TM) cells likely play a key role in regulating outflow facility and hence intraocular pressure. They function in a dynamic environment subjected to variations in mechanical and fluid shear forces. Because the extent of mechanical stress on the trabecular meshwork is dependent on the intraocular pressure, the behavior of TM cells under mechanical strain may suggest mechanisms for how outflow facility is regulated. Studies have demonstrated that TM cells respond in a variety of ways to mechanical loads, including increased extracellular matrix turnover, altered gene expression, cytokine release, and altered signal transduction. This review highlights some of the considerations and limitations of studying the mechanobiology of TM cells.},
  pmid = {19071113}
}

@article{WuEffectsIncreasing2015,
  title = {The {{Effects}} of {{Increasing Ocular Surface Stimulation}} on {{Blinking}} and {{Tear Secretion}}},
  author = {Wu, Ziwei and Begley, Carolyn G. and Port, Nicholas and Bradley, Arthur and Braun, Richard and {King-Smith}, Ewen},
  year = {2015},
  month = jul,
  journal = {Investigative Ophthalmology \& Visual Science},
  volume = {56},
  number = {8},
  pages = {4211--4220},
  issn = {1552-5783},
  doi = {10.1167/iovs.14-16313},
  urldate = {2022-02-25},
  abstract = {To investigate the effect of varying levels of ocular surface stimulation on the timing and amplitude of the blink and tear secretion.    Following instillation of fluorescein dye, increasing levels of air flow were directed toward the central corneas of 10 healthy subjects. Interblink interval (IBI), tear meniscus height (TMH), and fluorescence intensity were measured simultaneously. Because blinking can obscure changes in TMH, we developed novel measures of tear secretion by calculating tear meniscus fluorescein concentration (TMFC) from intensity using a mathematical model. The change of TMH and TMFC over trials and the slope of the TMFC within each IBI (IBI-TTR) were further calculated.    The mean IBI was decreased by 8.08 {\textpm} 8.54 seconds from baseline to maximum air stimulation. The TMH increase was highly variable (0.41 {\textpm} 0.39 mm) among subjects, compared to the fluorescence tear turnover metrics: decrease in TMFC of 2.84 {\textpm} 0.98 natural logarithm or ln(\%) and IBI-TTR of 0.065 {\textpm} 0.032 ln(\%)/sec. Ocular surface stimulation was highly correlated with the TMFC and IBI-TTR, but less so with TMH (Pearson's r = 0.71, 0.69, and 0.40, P \&lt; 0.01, respectively). Blinking and tearing were significantly correlated with each other (Pearson's r = 0.56, P \&lt; 0.01), but tearing lagged behind by an average of 6.54 {\textpm} 4.07 seconds.    Blinking and tearing share a common origin with sensory stimulation at the ocular surface. Both showed a dose--response increase with surface stimulation and were correlated with each other. These methods can potentially be used to understand alterations in ocular surface sensory function and associated protective responses in dry eye and other disorders of the ocular surface.},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Wu et al-2015-The Effects of Increasing Ocular Surface Stimulation on Blinking and Tear.pdf;/Users/driscoll/Zotero/storage/Q9Y3RCWD/article.html}
}

@article{WuEffectsMild2014,
  title = {The {{Effects}} of {{Mild Ocular Surface Stimulation}} and {{Concentration}} on {{Spontaneous Blink Parameters}}},
  author = {Wu, Ziwei and Begley, Carolyn G. and Situ, Ping and Simpson, Trefford and Liu, Haixia},
  year = {2014},
  month = jan,
  journal = {Current Eye Research},
  volume = {39},
  number = {1},
  pages = {9--20},
  issn = {0271-3683, 1460-2202},
  doi = {10.3109/02713683.2013.822896},
  urldate = {2020-06-18},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Wu et al-2014-The Effects of Mild Ocular Surface Stimulation and.pdf}
}

@article{Xi2018,
  title = {Fast Computation of Spectral Densities for Generalized Eigenvalue Problems},
  author = {Xi, Yuanzhe and Li, Ruipeng and Saad, Yousef},
  year = {2018},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {40},
  number = {4},
  pages = {A2749-A2773},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/17m1135542},
  abstract = {The distribution of the eigenvalues of a Hermitian matrix (or of a Hermitian matrix pencil) reveals important features of the underlying problem, whether a Hamiltonian system in physics or a social network in behavioral sciences. However, computing all the eigenvalues explicitly is prohibitively expensive for real-world applications. This paper presents two types of methods to efficiently estimate the spectral density of a matrix pencil (A,B) where both A and B are sparse Hermitian and B is positive definite. The methods are targeted at the situation when the matrix B scaled by its diagonal is very well conditioned, as is the case when the problem arises from some finite element discretizations of certain partial differential equations. The first method is an adaptation of the kernel polynomial method (KPM) and the second is based on Gaussian quadrature by the Lanczos procedure. By employing Chebyshev polynomial approximation techniques, we can avoid direct factorizations in both methods, making the resulting algorithms suitable for large matrices. Under some assumptions, we prove bounds that suggest that the Lanczos method converges twice as fast as the KPM method. Numerical examples further indicate that the Lanczos method can provide more accurate spectral densities when the eigenvalue distribution is highly nonuniform. As an application, we show how to use the computed spectral density to partition the spectrum into intervals that contain roughly the same number of eigenvalues. This procedure, which makes it possible to compute the spectrum by parts, is a key ingredient in the new breed of eigensolvers that exploit ``spectrum slicing.""},
  keywords = {Chebyshev approximation,density of states,generalized eigenvalue problems,spectral density}
}

@article{Xiao2009,
  title = {Nearest-Neighbor and Logistic Regression Analyses of Clinical and Heart Rate Characteristics in the Early Diagnosis of Neonatal Sepsis},
  author = {Xiao, Yuping and Griffin, M. Pamela and Lake, Douglas E. and Moorman, J. Randall},
  year = {2009},
  month = jun,
  journal = {Medical Decision Making},
  volume = {30},
  number = {2},
  pages = {258--266},
  publisher = {{SAGE Publications}},
  doi = {10.1177/0272989x09337791},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Xiao et al_2009_Nearest-neighbor and logistic regression analyses of clinical and heart rate.pdf}
}

@article{xuShowAttendTell2016,
  title = {Show, {{Attend}} and {{Tell}}: {{Neural Image Caption Generation}} with {{Visual Attention}}},
  shorttitle = {Show, {{Attend}} and {{Tell}}},
  author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
  year = {2016},
  month = apr,
  journal = {arXiv:1502.03044 [cs]},
  eprint = {1502.03044},
  primaryclass = {cs},
  urldate = {2020-10-24},
  abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,No DOI found},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Xu et al_2016_Show, Attend and Tell.pdf;/Users/driscoll/Zotero/storage/87ZQYNKR/1502.html}
}

@unpublished{YaoDataSci,
  title = {A Mathematical Introduction to Data Science},
  author = {Yao, Yuan},
  file = {/Users/driscoll/Dropbox/library/Manuscript/Yao_A mathematical introduction to data science.pdf}
}

@article{yiGenerativeAdversarialNetwork2019,
  title = {Generative Adversarial Network in Medical Imaging: {{A}} Review},
  shorttitle = {Generative Adversarial Network in Medical Imaging},
  author = {Yi, Xin and Walia, Ekta and Babyn, Paul},
  year = {2019},
  month = dec,
  journal = {Medical Image Analysis},
  volume = {58},
  pages = {101552},
  issn = {1361-8415},
  doi = {10.1016/j.media.2019.101552},
  urldate = {2022-09-07},
  abstract = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.},
  langid = {english},
  keywords = {Deep learning,Generative adversarial network,Generative model,Medical imaging,Review},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Yi et al_2019_Generative adversarial network in medical imaging.pdf;/Users/driscoll/Dropbox/library/Journal Article/Yi et al_2019_Generative adversarial network in medical imaging2.pdf}
}

@article{YokoiTearfilmorientedDiagnosis2019,
  title = {Tear-Film-Oriented Diagnosis for Dry Eye},
  author = {Yokoi, Norihiko and Georgiev, Georgi As},
  year = {2019},
  month = mar,
  journal = {Japanese Journal of Ophthalmology},
  volume = {63},
  number = {2},
  pages = {127--136},
  issn = {1613-2246},
  doi = {10.1007/s10384-018-00645-4},
  urldate = {2022-02-18},
  abstract = {Tear-film (TF) stability protects the ocular surface epithelium from desiccation and is ensured via cooperation between the ocular surface components including constituents of the TF and ocular surface epithelium. Thus, when those components are insufficient or impaired, the TF breakup that initiates dry eye occurs. Recently, new, commercially available eye drops have appeared in Japan that enable TF stabilization via targeted supplementation of deficient ocular surface components. Hence, a new layer-by-layer diagnosis and treatment concept for dry eye, termed tear-film-oriented diagnosis and tear-film-oriented therapy (TFOD and TFOT, respectively), have emerged and become widely accepted in Asian countries and beyond. TFOD is a diagnostic method for dry eye based on the TF dynamics and breakup patterns (BUPs), through which dry-eye subtypes, including aqueous-deficient dry eye, decreased-wettability dry eye, and increased-evaporation dry eye, are diagnosed. BUPs and/or each diagnosed dry-eye subtype can, in a layer-by-layer fashion, reveal the insufficient ocular surface components responsible for the TF breakup. Using these data, the optimal topical TFOT to treat dry eye can be proposed by addressing the TF breakup via the supplementation of the insufficient components. In Japan, TF breakup is now regarded as a visible core mechanism of dry eye, and abnormal breakup time (ie,\,{$\leq$}\,5 seconds) and symptoms are currently considered part of the diagnostic criteria for dry eye. In this review, the importance of TF instability as a core manifestation of dry eye, the molecular mechanism of TF breakup, the concept of TFOD, and the methods for implementing TFOD for TFOT are introduced.},
  langid = {english},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Yokoi_Georgiev-2019-Tear-film-oriented diagnosis for dry eye.pdf}
}

@article{youLearningDeepImplicit2022,
  title = {Learning {{Deep Implicit Fourier Neural Operators}} ({{IFNOs}}) with {{Applications}} to {{Heterogeneous Material Modeling}}},
  author = {You, Huaiqian and Zhang, Quinn and Ross, Colton J. and Lee, Chung-Hao and Yu, Yue},
  year = {2022},
  month = aug,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {398},
  eprint = {2203.08205},
  primaryclass = {cond-mat},
  pages = {115296},
  issn = {00457825},
  doi = {10.1016/j.cma.2022.115296},
  urldate = {2022-11-14},
  abstract = {Constitutive modeling based on continuum mechanics theory has been a classical approach for modeling the mechanical responses of materials. However, when constitutive laws are unknown or when defects and/or high degrees of heterogeneity are present, these classical models may become inaccurate. In this work, we propose to use data-driven modeling, which directly utilizes high-fidelity simulation and/or experimental measurements to predict a material's response without using conventional constitutive models. Specifically, the material response is modeled by learning the implicit mappings between loading conditions and the resultant displacement and/or damage fields, with the neural network serving as a surrogate for a solution operator. To model the complex responses due to material heterogeneity and defects, we develop a novel deep neural operator architecture, which we coin as the Implicit Fourier Neural Operator (IFNO). In the IFNO, the increment between layers is modeled as an integral operator to capture the long-range dependencies in the feature space. As the network gets deeper, the limit of IFNO becomes a fixed point equation that yields an implicit neural operator and naturally mimics the displacement/damage fields solving procedure in material modeling problems. We demonstrate the performance of our proposed method for a number of examples, including hyperelastic, anisotropic and brittle materials. As an application, we further employ the proposed approach to learn the material models directly from digital image correlation (DIC) tracking measurements, and show that the learned solution operators substantially outperform the conventional constitutive models in predicting displacement fields.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Condensed Matter - Materials Science},
  file = {/Users/driscoll/Dropbox/library/Journal Article/You et al_2022_Learning Deep Implicit Fourier Neural Operators (IFNOs) with Applications to.pdf;/Users/driscoll/Zotero/storage/2F8SR66G/2203.html}
}

@article{zhangPathfinderParallelQuasiNewton2021,
  title = {Pathfinder: {{Parallel}} Quasi-{{Newton}} Variational Inference},
  shorttitle = {Pathfinder},
  author = {Zhang, Lu and Carpenter, Bob and Gelman, Andrew and Vehtari, Aki},
  year = {2021},
  month = sep,
  journal = {arXiv:2108.03782 [cs, stat]},
  eprint = {2108.03782},
  primaryclass = {cs, stat},
  urldate = {2022-05-04},
  abstract = {We introduce Pathfinder, a variational method for approximately sampling from differentiable log densities. Starting from a random initialization, Pathfinder locates normal approximations to the target density along a quasi-Newton optimization path, with local covariance estimated using the inverse Hessian estimates produced by the optimizer. Pathfinder returns draws from the approximation with the lowest estimated Kullback-Leibler (KL) divergence to the true posterior. We evaluate Pathfinder on a wide range of posterior distributions, demonstrating that its approximate draws are better than those from automatic differentiation variational inference (ADVI) and comparable to those produced by short chains of dynamic Hamiltonian Monte Carlo (HMC), as measured by 1-Wasserstein distance. Compared to ADVI and short dynamic HMC runs, Pathfinder requires one to two orders of magnitude fewer log density and gradient evaluations, with greater reductions for more challenging posteriors. Importance resampling over multiple runs of Pathfinder improves the diversity of approximate draws, reducing 1-Wasserstein distance further and providing a measure of robustness to optimization failures on plateaus, saddle points, or in minor modes. The Monte Carlo KL-divergence estimates are embarrassingly parallelizable in the core Pathfinder algorithm, as are multiple runs in the resampling version, further increasing Pathfinder's speed advantage with multiple cores.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,No DOI found,Statistics - Machine Learning},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Zhang et al_2021_Pathfinder.pdf;/Users/driscoll/Zotero/storage/XZM5GJ97/2108.html}
}

@article{zhaoNovelLinearSecond2017,
  title = {A Novel Linear Second Order Unconditionally Energy Stable Scheme for a Hydrodynamic {{Q-tensor}} Model of Liquid Crystals},
  author = {Zhao, Jia and Yang, Xiaofeng and Gong, Yuezheng and Wang, Qi},
  year = {2017},
  month = may,
  journal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {318},
  pages = {803--825},
  issn = {0045-7825},
  doi = {10.1016/j.cma.2017.01.031},
  urldate = {2019-11-25},
  abstract = {The hydrodynamic Q-tensor model has been used for studying flows of liquid crystals and liquid crystal polymers. It can be derived from a variational approach together with the generalized Onsager principle, in which the total energy decreases in time. In this paper, we develop a novel, linear, second order semi-discrete scheme in time to solve the governing system of equations in the model. The scheme is developed following the novel ` energy quadratization ' strategy so that it is linear and unconditionally energy stable at the semi-discrete level. This scheme is further discretized in space using a second order finite difference method and implemented on a GPU for high performance computing. The convergence rate in time is established using a mesh refinement test. Several numerical examples are presented to demonstrate the usefulness of the model and the effectiveness of the numerical scheme in simulating defect dynamics in flows of liquid crystals.},
  langid = {english},
  keywords = {-tensor model,Energy quadratization,Hydrodynamics,Linear,Second order,Unconditional energy stability},
  file = {/Users/driscoll/Dropbox/library/Zhao et al_2017_A novel linear second order unconditionally energy stable scheme for a.pdf;/Users/driscoll/Zotero/storage/G6CBQH97/S0045782516306533.html}
}

@article{zhifenghaoLinearSupportHigherOrder2013,
  title = {A {{Linear Support Higher-Order Tensor Machine}} for {{Classification}}},
  author = {{Zhifeng Hao} and {Lifang He} and {Bingqian Chen} and {Xiaowei Yang}},
  year = {2013},
  month = jul,
  journal = {IEEE Transactions on Image Processing},
  volume = {22},
  number = {7},
  pages = {2911--2920},
  issn = {1057-7149, 1941-0042},
  doi = {10.1109/tip.2013.2253485},
  urldate = {2020-08-24},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Zhifeng Hao et al_2013_A Linear Support Higher-Order Tensor Machine for Classification.pdf}
}

@misc{Zhong_A_2015,
  title = {A Model Problem for {{Blob-Driven}} Tear Film Breakup ({{TBU}})},
  author = {Zhong, Lan and Ketelaar, C. F. and Braun, Richard J. and Driscoll, Tobin A and E., P., King-Smith and Begley, Carolyn G.},
  year = {2015},
  copyright = {All rights reserved}
}

@article{ZhongDynamicsFluorescent2019,
  title = {Dynamics of {{Fluorescent Imaging}} for {{Rapid Tear Thinning}}},
  author = {Zhong, L and Braun, R J and Begley, C G and {King-Smith}, P E},
  year = {2019},
  month = jan,
  journal = {Bulletin of mathematical biology},
  volume = {81},
  number = {1},
  pages = {39--80},
  issn = {1522-9602},
  doi = {10.1007/s11538-018-0517-0},
  urldate = {2024-02-08},
  abstract = {A previous mathematical model has successfully simulated the rapid tear thinning caused by glob (thicker lipid) in the lipid layer. It captured a fast spreading of polar lipid and a corresponding strong tangential flow in the aqueous layer. With the simulated strong tangential flow, we now extend the model by adding equations for conservation of solutes, for osmolarity and fluorescein, in order to study their dynamics. We then compare our computed results for the resulting intensity distribution with fluorescence experiments on the tear film. We conclude that in rapid thinning, the fluorescent intensity can linearly approximate the tear film thickness well, when the initial fluorescein concentration is small. Thus, a dilute fluorescein is recommended for visualizing the rapid tear thinning during fluorescent imaging.},
  langid = {english},
  pmcid = {PMC6781631},
  pmid = {30324271},
  keywords = {Dry Eye,Fluorescent Imaging,Marangoni Effect,tear film},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Zhong et al_2019_Dynamics of Fluorescent Imaging for Rapid Tear Thinning.pdf;/Users/driscoll/Zotero/storage/GP3WNCFI/Zhong et al. - 2019 - Dynamics of Fluorescent Imaging for Rapid Tear Thi.pdf}
}

@inproceedings{ZhongMathematicalModeling2016,
  title = {Mathematical {{Modeling}} of {{Glob-Driven Tear Film Breakup}}},
  booktitle = {Investigative {{Ophthalmology}} \& {{Visual Science}}},
  author = {Zhong, Lan and Ketelaar, Christiaan F and Braun, Richard J and Driscoll, Tobin A and {King-Smith}, Peter Ewen and Begley, Carolyn G},
  year = {2016},
  volume = {57},
  publisher = {{ASSOC RESEARCH VISION OPHTHALMOLOGY INC 12300 TWINBROOK PARKWAY, ROCKVILLE {\dots}}},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{zhongMathematicalModelling2018,
  title = {Mathematical Modelling of Glob-Driven Tear Film Breakup},
  author = {Zhong, L and Ketelaar, {\relax CF} and Braun, {\relax RJ} and Begley, {\relax CG} and {King-Smith}, {\relax PE}},
  year = {2018},
  journal = {Mathematical Medicine and Biology},
  volume = {36},
  number = {1},
  pages = {55--91},
  doi = {10.1093/imammb/dqx021}
}

@inproceedings{ZhongModelProblem2015,
  title = {A {{Model Problem}} for {{Blob-Driven Tear Film Breakup}} ({{TBU}})},
  booktitle = {{{APS Meeting Abstracts}}},
  author = {Zhong, Lan and Ketelaar, {\relax CF} and Braun, {\relax RJ} and Driscoll, {\relax TA} and {King-Smith}, {\relax PE} and Begley, Carolyn G},
  year = {2015},
  copyright = {All rights reserved},
  keywords = {No DOI found}
}

@article{Zhou2014,
  title = {Multivariate Discrete Least-Squares Approximations with a New Type of Collocation Grid},
  author = {Zhou, Tao and Narayan, Akil and Xu, Zhiqiang},
  year = {2014},
  month = jan,
  journal = {SIAM Journal on Scientific Computing},
  volume = {36},
  number = {5},
  pages = {A2401-A2422},
  publisher = {{Society for Industrial {{\&}} Applied Mathematics (SIAM)}},
  doi = {10.1137/130950434},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Zhou et al_2014_Multivariate discrete least-squares approximations with a new type of.pdf}
}

@article{zhouReviewDeepLearning2021,
  title = {A {{Review}} of {{Deep Learning}} in {{Medical Imaging}}: {{Imaging Traits}}, {{Technology Trends}}, {{Case Studies With Progress Highlights}}, and {{Future Promises}}},
  shorttitle = {A {{Review}} of {{Deep Learning}} in {{Medical Imaging}}},
  author = {Zhou, S. Kevin and Greenspan, Hayit and Davatzikos, Christos and Duncan, James S. and Van Ginneken, Bram and Madabhushi, Anant and Prince, Jerry L. and Rueckert, Daniel and Summers, Ronald M.},
  year = {2021},
  month = may,
  journal = {Proceedings of the IEEE},
  volume = {109},
  number = {5},
  pages = {820--838},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2021.3054390},
  abstract = {Since its renaissance, deep learning (DL) has been widely used in various medical imaging tasks and has achieved remarkable success in many medical imaging applications, thereby propelling us into the so-called artificial intelligence (AI) era. It is known that the success of AI is mostly attributed to the availability of big data with annotations for a single task and the advances in high-performance computing. However, medical imaging presents unique challenges that confront DL approaches. In this survey article, we first present traits of medical imaging, highlight both clinical needs and technical challenges in medical imaging, and describe how emerging trends in DL are addressing these issues. We cover the topics of network architecture, sparse and noisy labels, federating learning, interpretability, uncertainty quantification, and so on. Then, we present several case studies that are commonly found in clinical practice, including digital pathology and chest, brain, cardiovascular, and abdominal imaging. Rather than presenting an exhaustive literature survey, we instead describe some prominent research highlights related to these case study applications. We conclude with a discussion and presentation of promising future directions.},
  keywords = {Artificial intelligence,Biomedical imaging,Clinical diagnosis,Computed tomography,Deep learning,Deep learning (DL),Diseases,Image segmentation,Market research,Medical diagnostic imaging,medical imaging,Medical services,Network architecture,survey},
  file = {/Users/driscoll/Dropbox/library/Journal Article/Zhou et al_2021_A Review of Deep Learning in Medical Imaging.pdf;/Users/driscoll/Zotero/storage/5UNHWQZN/9363915.html}
}

@misc{zotero-340,
  type = {Misc}
}

@misc{zotero-353,
  urldate = {2022-01-24},
  howpublished = {https://data.delaware.gov/api/views/5zy2-grhr/rows.json?accessType=DOWNLOAD}
}

@misc{ZoteroReport,
  title = {Zotero {{Report}}},
  urldate = {2013-06-20},
  howpublished = {zotero://report/items/0\_GU6K4V8A-0\_JZU2HZWK-0\_GBTBFHE5-0\_RQT5BESG-0\_GEADFK53-0\_G54ARTQI-0\_ZERK7E64-0\_INA8CUGU-0\_G6VAHX7E-0\_5W68PJZW-0\_39PQK6T8-0\_33FCS6DG-0\_3DE54N8W-0\_V2KBECQQ-0\_V5M55HG3-0\_CH8HPTAS-0\_JJ6DEAV3-0\_JHQ4SGX7-0\_E7WEWZV3-0\_RKFNZVUN-0\_EAF483P2-0\_FEPCGTAB-0\_WT2D5SNW-0\_X2HGTHFI-0\_2WPDJU4D-0\_B4RSBTFU-0\_ZVFPVHDM-0\_8IF75V6K-0\_WAAUWMRQ-0\_6SJ7HRQJ-0\_XKRJZ49U-0\_XXRH63HA-0\_IJPVJGVS-0\_6FF3T8EI-0\_K395N4WA-0\_7SE7GMQJ-0\_NC7G9G5E-0\_GK5JC5DE-0\_ZHVKHM48-0\_PKQFF4DZ-0\_93NQG492-0\_GMFSGBEM/html/report.html?sort=date}
}

@article{ZubkovBreward12,
  title = {Coupling Fluid and Solute Dynamics within the Ocular Surface Tear Film: A Modelling Study of Black Line Osmolarity},
  author = {Zubkov, V. S. and Breward, C. J. and Gaffney, E. A.},
  year = {2012},
  journal = {Bulletin of Mathematical Biology},
  volume = {74},
  pages = {2062--2093},
  doi = {10.1007/s11538-012-9746-9},
  date-added = {2013-02-28 18:28:44 +0000},
  date-modified = {2013-02-28 18:33:02 +0000}
}

@misc{ZubovNeuralPDEAutomating2021,
  title = {{{NeuralPDE}}: {{Automating Physics-Informed Neural Networks}} ({{PINNs}}) with {{Error Approximations}}},
  shorttitle = {{{NeuralPDE}}},
  author = {Zubov, Kirill and McCarthy, Zoe and Ma, Yingbo and Calisto, Francesco and Pagliarino, Valerio and Azeglio, Simone and Bottero, Luca and Luj{\'a}n, Emmanuel and Sulzer, Valentin and Bharambe, Ashutosh and Vinchhi, Nand and Balakrishnan, Kaushik and Upadhyay, Devesh and Rackauckas, Chris},
  year = {2021},
  month = jul,
  number = {arXiv:2107.09443},
  eprint = {2107.09443},
  primaryclass = {cs},
  publisher = {{arXiv}},
  doi = {10.48550/arXiv.2107.09443},
  urldate = {2023-09-19},
  abstract = {Physics-informed neural networks (PINNs) are an increasingly powerful way to solve partial differential equations, generate digital twins, and create neural surrogates of physical models. In this manuscript we detail the inner workings of NeuralPDE.jl and show how a formulation structured around numerical quadrature gives rise to new loss functions which allow for adaptivity towards bounded error tolerances. We describe the various ways one can use the tool, detailing mathematical techniques like using extended loss functions for parameter estimation and operator discovery, to help potential users adopt these PINN-based techniques into their workflow. We showcase how NeuralPDE uses a purely symbolic formulation so that all of the underlying training code is generated from an abstract formulation, and show how to make use of GPUs and solve systems of PDEs. Afterwards we give a detailed performance analysis which showcases the trade-off between training techniques on a large set of PDEs. We end by focusing on a complex multiphysics example, the Doyle-Fuller-Newman (DFN) Model, and showcase how this PDE can be formulated and solved with NeuralPDE. Together this manuscript is meant to be a detailed and approachable technical report to help potential users of the technique quickly get a sense of the real-world performance trade-offs and use cases of the PINN techniques.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Mathematical Software,Computer Science - Symbolic Computation},
  file = {/Users/driscoll/Dropbox/library/Preprint/Zubov et al_2021_NeuralPDE.pdf;/Users/driscoll/Zotero/storage/249IV7FY/2107.html}
}

@book{Zygierewicz2011,
  title = {Practical Biomedical Signal Analysis Using {{MATLAB}}},
  author = {Blinowska, K J and Zygierewicz, J},
  year = {2011},
  month = sep,
  publisher = {{CRC Press}},
  doi = {10.1201/b11148},
  file = {/Users/driscoll/Dropbox/library/Book/Blinowska_Zygierewicz_2011_Practical biomedical signal analysis using MATLAB.pdf}
}
